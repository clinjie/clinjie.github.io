<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[word2vec]]></title>
    <url>%2F2017%2F03%2F28%2Fword2vec%2F</url>
    <content type="text"><![CDATA[仅适用基于Hierarchical Softmax。 edit. 适用Negative Smapling 资源 word2vec通过训练将每个词映射成K维实数向量。通过词之间的距离，比如cosine相似度，欧式距离等来判断他们之间的语义相似度。根据词频使用哈弗慢编码，使得所有词频相似的词隐藏层的激活内容基本一致。出现频率越高的词语，他们激活的隐藏层数目越少，这样有效的降低了计算的复杂度。 用one-hot来通俗简单的理解，有三个词“麦克风”、“话筒”、“杯子”，用one-hot编码，三个词对应[1, 0, 0]， [0, 1, 0]，[0, 0, 1]。当成千上万的词语，会造成每个词向量含有很多0，也就是稀疏编码，所以我们需要降维。比如说，上面的三个词语可以表示为[0, 1]， [0.4, 0.9]，[1, 0]。这里要注意的是“麦克风”和“话筒”的意思很接近，所以它们对应的向量也很接近，即空间距离短，向量夹角小。 分布式假设，其核心思想为出现于上下文情景中的词汇都有相类似的语义。 word2vec中用到的两个重要模型-CBOW（Continuous Bag-of-Words Model）模型和Skip-gram（Contunuous Skip-gram）模型。 两个模型都包含三层：输入层、投影层和输出层。前者是在已知当前词$w_t$的上下文$w_{t-2},w_{t-1},w_{t+1},w_{t+2}$的前提下预测当前词$w_t$，即$P(w_t \mid w_{t-2},w_{t-1},w_{t+1},w_{t+2})$；后者恰恰相反，在已知当前词$w_t$的前提下，预测上下文$w_{t-2},w_{t-1},w_{t+1},w_{t+2}$,也就是$P(w_{t-2},w_{t-1},w_{t+1},w_{t+2} \mid w_t)$ CBOW模型CBOW模型包括三层：输入层投影层和输出层。 上面讲过CBOW模型网络结构是通过上下文context对当前词target做预测，求$P(w_t \mid w_{t-1},w_{t+1})$。 这里是假设Context(w)由w前后各c个词构成 输入层：包含Context(w)中2c个词的词向量$v(Context(w)_1),v(Context(w)_2),…,v(Context(w)_{2c})$，$Context(w) \in R^m$，这里，m的含义同上表示词向量的长度。 投影层：将输出层的2c个向量做求和累加，即$x_w=\sum_{i=1}^{2c}v(Countext(w)_i) \in R^m$ 输出层：输出层对应一个二叉树，以语聊中出现的词当叶子节点，以各次在语聊中出现的次数当权值构造出来哈夫曼树。在哈夫曼树中，叶子节点一共$\mid D \mid$个，分别对应词典D中词，非叶子结点N-1个 取一个适当大小的窗口当做context window，输入层读入窗口内的词，将它们的向量（K维，初始随机）加和在一起，形成隐藏层K个节点。输出层是一个巨大的二叉树，叶节点代表语料里所有的词（语料含有V个独立的词，则二叉树有|V|个叶节点）。而这整颗二叉树构建的算法就是Huffman树。这样，对于叶节点的每一个词，就会有一个全局唯一的编码，形如”010011”，不妨记左子树为1，右子树为0。接下来，隐层的每一个节点都会跟二叉树的内节点有连边，于是对于二叉树的每一个内节点都会有K条连边，每条边上也会有权值。 对于语料库中的某个词$w_$t，对应着二叉树的某个叶子节点，因此它必然有一个二进制编码，如”010011”。在训练阶段，当给定上下文，要预测后面的词$w_t$的时候，我们就从二叉树的根节点开始遍历，这里的目标就是预测这个词的二进制编号的每一位。即对于给定的上下文，我们的目标是使得预测词的二进制编码概率最大。形象地说，我们希望在根节点，词向量和与根节点相连经过logistic计算得到bit=1的概率尽量接近0，在第二层，希望其bit=1的概率尽量接近1，这么一直下去，我们把一路上计算得到的概率相乘，即得到目标词$w_t$在当前网络下的概率$P(w_t\mid w_{t-1},w_{t+1})$。显而易见，按照目标词的二进制编码计算到最后的概率值就是归一化的. 模型的目标式子$p(w \mid Context(w))=\prod\limits_{j=2}^N p(d_j^w \mid x_w,\theta_{j-1}^w)$,用SGD训练优化模型，过程中更新相关的参数值（输入之后的加和向量值$x$，哈夫曼树中的内部节点向量$\theta$,以及原始的输入context中的所有向量参数$w$），每次取出一个样本$(context(w),w)$做训练，就要对整体的参数进行更新一次。对于$\theta$和$x$的值，通过SGD求偏导更新，而没有直接参与训练预测的原始context输入词向量$w$，我们通过$x$这个所有context词的加和向量来更新词向量$w$。把梯度贡献的更新项分配到所有输入中。 Skip-gram Skip-Gram模型采取CBOW的逆过程的动机在于：CBOW算法对于很多分布式信息进行了平滑处理（例如将一整段上下文信息视为一个单一观察量）。很多情况下，对于小型的数据集，这一处理是有帮助的。相形之下，Skip-Gram模型将每个“上下文-目标词汇”的组合视为一个新观察量，这种做法在大型数据集中会更为有效。 Skip-gram模型包括两层：输入层和输出层，相比CBOW，少了投影层，因为它不需要对所有的context词进行特征向量相加。 输入层：目标词的词向量$v(w) \in R^m$ 输出层：与CBOW类似，输出层十一颗哈夫曼树 大体上来讲，Skip-Gramm与CBOW的流程相反，通过目标词对context进行预测，Skip-Gramm将其定义为$p(Context(w)\mid w)=\prod\limits_{w \in Context(w)} p(u \mid w)$，而上市中的$p(u \mid w)$可以按照上面的思想，通过哈夫曼树的路径节点乘积确定：$p(u \mid w)=\prod\limits_{j=2}^{l^u} p(d_j^u \mid v(w),\theta_{j-1}^u)$ 之后就是对公式进行MLE的SGD优化。要注意的是，因为这里是要对context词进行预测，所以要从哈夫曼树的根部到叶子结点，进行$\mid context \mid$次。每次预测之后，都要处理完一个Context中的一个词之后，就要更新输入词的特征向量。 下面开始介绍基于Negative Smapling的模型，翻译过来就是负采样模型，是由NCE（Noise Contrastive Estimation）的一个简化版本，目的是用来提高训练速度并改善词向量的质量。与上面介绍的基于Hierarchical Softmax的CBOW和Skip-gram相比，这种不使用复杂的哈夫曼树，而使用相对简单的随机负采样。因为在计算损失函数的时候，只是有我们挑选出来的k个noise word，而非整个的语料库V，这使得训练非常快。大幅度提高性能。 假设要求的未知的概率密度函数为X，已知的概率密度是Y，如果知道了X与Y的关系，那么X也就可以求出来。本质就是利用已知的概率密度估计未知的概率密度函数。 负采样算法主要讲对于一个给定的词w，如何生成$NEG(w)$。 词典$D$中的词在语料$C$中出现的次数有高有低，高频词应该被选为负样本的概率应该高点，低的反之，本质上是一个带权采样，这就是大体的要求。 记$l_0=0,l_k=\sum\limits_{j=1}^k len(w_j),k=1,2,3…,N$，这里$w_j$表示词典D中的第j个词，则以${l_j}^N_{j=0}$为部分节点可得到区间$[0,1]$上的一个等距划分，$I_i=(l_{i-1},l_i],i=1,2,…,N$为N个剖分区间。 进一步的引入区间$[0,1]$上的等距离剖分，剖分节点为${m_j}_{j=0}^M$，其中$M &gt; &gt; N$ 将内部剖分节点${m_j}^{M-1}_{j=1}$投影到非等距剖分上，则可建立${m_j}^{M-1}_{j=1}$与区间${I_j}^N_{j=1}$的映射关系。之后每次生成一个$[1,M-1]$间的堆积整数r，通过映射关系就能确定选择那个词作负样本。注意万一选中的就是w自己，则跳过。 基于负采样的CBOW在CBOW模型中，一直词w的上下文Context(w)，需要预测w，因此对于给定的Countext(w)，词w就是一个正样本，其他词就是负样本（分类问题）。 假定现在选好了关于Countext(w)的负采样集$NEG(w) \neq \emptyset$，并且$$L^w(\hat{w})=\begin{cases}1,\hat{w}=w;\0,\hat{w}=w\end{cases}$$ 表示词$\hat{w}$的标签，即正样本的标签为1，负样本的标签为0. 对于一个给定的正样本（Context（w）,w），我们希望最大化$$g(w)=\prod_{u \in {w} \bigcup NEG(w)} p(u \mid Context(w))$$ 其中$$p(u\mid Context(w))=\begin{cases}\sigma(x^T_w\theta^u),\ \ L^w(u)=1;\ \ 1-\sigma(x^T_w\theta^u), \ \ L^w(u)=0\end{cases}$$ 这里$x_w$表示Context(w)中各词的词向量之和，而$\theta^u \in R^m$表示词u对应的一个辅助向量，其实就是word-embeding中的嵌入值。 $\sigma(x_w^T \theta^w)$表示当上下文为Context(w)时，预测中心词为w的概率，而$\sigma(x^T_w\theta^u)\, u \in NEG(w)$则表示上下文为Context(w)时，预测中心词为u的概率。式子$g(w)$表示，所有在NEG集合加上实际的中心词w概率相乘，最大化这个式子，每一项，如果是实际的中心词w，最大化$p$，如果属于NEG集合，最大化$(1-p)$。增大正样本的概率同时降低负样本的概率。 之后的内容就是使用SGD对求解最大化这个公式进行训练，参数的更新，包括$\theta$对应词的嵌入，$x$对应Context(w)中各词的词向量之和，以及通过$x$更新最初的输入词$w$的向量，对于整个数据集，当梯度下降的过程中不断地更新参数，对应产生的效果就是不断地移动每个单词的嵌套向量，直到可以把真实单词和噪声单词很好得区分开。 基于负采样的Skip-gram对于一个给定的样本$(w,Context(w))$，我们希望最大化$$g(w)=\prod\limits_{\hat{w} \in Context(w)}\prod\limits_{u \in {w} \bigcup NEG^{\hat{w}}(w)} p(u\mid \hat{w})$$ 其中$$p(u\mid \hat{w})=\begin{cases}\sigma(v(\hat{w})^T\theta^u, \ \ L^w(u)=1; \ \1-\sigma(v(\hat{w})^T\theta^u, \ \ L^w(u)=0 \end{cases}$$ 这里$NEG^{\hat{w}}(w)$表示处理词$\hat{w}$时候生成的负样本子集，于是对于一个给定的语料库C，函数$$G=\prod\limits_{w\in C}g(w)$$作为整体优化的目标，然后为了变成和项，我们取对数等等。 之后的步骤就跟原来一样。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234from __future__ import print_functionimport tensorflow.python.platformimport collectionsimport mathfrom six.moves import xrangeimport numpy as npimport osimport randomimport tensorflow as tfimport urllib.requestimport zipfile# Step 1: Download the data.url = 'http://mattmahoney.net/dc/'def maybe_download(filename, expected_bytes): """Download a file if not present, and make sure it's the right size.""" if not os.path.exists(filename): filename, _ = urllib.request.urlretrieve(url + filename, filename) # 文件信息获取 statinfo = os.stat(filename) if statinfo.st_size == expected_bytes: print('Found and verified', filename) else: print(statinfo.st_size) raise Exception( 'Failed to verify ' + filename + '. Can you get to it with a browser?') return filenamefilename = maybe_download('text8.zip', 31344016)# Read the data into a string.def read_data(filename): f = zipfile.ZipFile(filename) # 获取压缩文件中的文件列表，返回第一个文件内容，根据空格进行分割成列表。 for name in f.namelist(): return f.read(name).split() f.close()words = read_data(filename)print('Data size', len(words))# Step 2: Build the dictionary and replace rare words with UNK token.#将稀少的词使用UNK替换vocabulary_size = 50000def build_dataset(words): count = [['UNK', -1]]# 词'UNK'代表UnKnow # 将count扩展，使用collections模块的计数器，根据出现次数的多少进行排序然后填充进count，排序之后UNK为第一位。s.most_common(n)方法返回对象s的Top n数据，没有指定的话，返回全部 count.extend(collections.Counter(words).most_common(vocabulary_size - 1)) dictionary = dict() for word, _ in count:#count中按item有两个内容：str以及对应的times频率。定义一个字典对象，键为str，对应的值为上面count中按str频率高低的排名例如 the:1,of:2。。。 dictionary[word] = len(dictionary) data = list() unk_count = 0 for word in words: if word in dictionary: index = dictionary[word] else: index = 0 # dictionary['UNK'] 注意之前在dictionary中根据排序，UNK还是在第一位，对应的值为0 unk_count = unk_count + 1 # index代表了词对应的排名，出现一次，填充进data中一次。data中包含的是原来文件中词对应的排名列表 data.append(index) count[0][1] = unk_count # count是一个二维的元祖，一个元素是'UNK':times，count[0][1]代表的就是UNK对应的频率 reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))#键值对reverse return data, count, dictionary, reverse_dictionarydata, count, dictionary, reverse_dictionary = build_dataset(words)del words # Hint to reduce memory.print('Most common words (+UNK)', count[:5])# 输出频率最高的5个词print('Sample data', data[:10])data_index = 0# Step 4: Function to generate a training batch for the skip-gram model.# num_skips 训练样本的源端要使用几次，出于n-skip算法的原因，一个中心词要对应多个周边词，也就是说一个中心词target要预测几次周边词，对应的词的数量# skip_window 左右各考虑多少个词，skip_windows*2=num_skipsdef generate_batch(batch_size, num_skips, skip_window): global data_index assert batch_size % num_skips == 0 assert num_skips &lt;= 2 * skip_window # ndarray本质是数组，其不同于一般的数组，或者Python 的list的地方在于它可以有N 维（dimentions），也可简单理解为数组里面嵌套数组。 batch = np.ndarray(shape=(batch_size), dtype=np.int32) labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32) span = 2 * skip_window + 1 # [ skip_window target skip_window ] buffer = collections.deque(maxlen=span) for _ in range(span): # 最初的填充，填充进原来文本中word的频率 buffer.append(data[data_index]) # 因为data_index是全局变量，训练要很多步，后面取余 data_index = (data_index + 1) % len(data) for i in range((int)(batch_size / num_skips)):#batch中样batch_size个样本，衣蛾target有num_skips个样本 target = skip_window # target label at the center of the buffer targets_to_avoid = [ skip_window ] for j in range(num_skips): while target in targets_to_avoid: # 进行了num_skips轮，每次找到一个不在target_to_avoid中的元素，实际上就是每次找一个与target配对的word target = random.randint(0, span - 1) targets_to_avoid.append(target) batch[i * num_skips + j] = buffer[skip_window] #batch中是连续的num_skips个target词 labels[i * num_skips + j, 0] = buffer[target]#label中连续的num_skip个周边词 buffer.append(data[data_index])#buffer是有容量限制的，之前的状态是满的，此时会将最早的元素挤出去 data_index = (data_index + 1) % len(data) return batch, labelsbatch, labels = generate_batch(batch_size=8, num_skips=2, skip_window=1)for i in range(8): print(batch[i], '-&gt;', labels[i, 0]) print(reverse_dictionary[batch[i]], '-&gt;', reverse_dictionary[labels[i, 0]])# Step 5: Build and train a skip-gram model.batch_size = 128embedding_size = 128 # 嵌入矩阵的密度，或者说是矩阵长度，batch_size要和embedding_size一致skip_window = 1 # How many words to consider left and right.num_skips = 2 # How many times to re-use an input to generate a label.# 构造NEG集合相关参数，集合中的元素就作为分类结果的干扰valid_size = 16 # Random set of words to evaluate similarity on.#随机的word集合估计相似度valid_window = 100 # 选择在头部分布的开发样本valid_examples = np.array(random.sample(xrange(valid_window), valid_size))# 从[0,valid_window]中随机的获取valid_size个数值返回num_sampled = 64 # 负采样的个数graph = tf.Graph()with graph.as_default(): # Input data. train_inputs = tf.placeholder(tf.int32, shape=[batch_size]) train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1]) valid_dataset = tf.constant(valid_examples, dtype=tf.int32) # Construct the variables. embeddings = tf.Variable(#使用唯一的随机值来初始化大矩阵，shape=[vocabulary_size, embedding_size] tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0)) nce_weights = tf.Variable(#每个word定义一个权重值与偏差 # tf.truncated_normal初始函数将根据所得到的均值和标准差，生成一个随机分布。shape=[vocabulary_size, embedding_size] tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size))) nce_biases = tf.Variable(tf.zeros([vocabulary_size])) # Look up embeddings for inputs. 根据train_inputs中的id，寻找embeddings中的对应元素。比如，train_inputs=[1,3,5]，则找出embeddings中下标为1,3,5的向量组成一个矩阵返回。 embed = tf.nn.embedding_lookup(embeddings, train_inputs)#这里是从train_inputs给的索引值找到embeddings大矩阵中的对应的嵌入值 # Compute the average NCE loss for the batch. # tf.nce_loss automatically draws a new sample of the negative labels each # time we evaluate the loss. loss = tf.reduce_mean(# reduce_mean是平均值 vocabulary_size代表可能的数目 num_sampled代表per batch随机抽样的个数 tf.nn.nce_loss(nce_weights, nce_biases, train_labels,embed,#这里的参数都是按batch计算的，而非具体的某个样本.同时要注意的是原文件中参数排序出错，这里修正 num_sampled, vocabulary_size)) optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss) # 计算在minibatch和所有的embedding的cosine相似度 norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))#tf.reduce_sum就是求和 normalized_embeddings = embeddings / norm# 正则化嵌入值 valid_embeddings = tf.nn.embedding_lookup( #NEG集嵌入值 normalized_embeddings, valid_dataset)#寻找NEG集合中对应的正则化后的嵌入值 similarity = tf.matmul(#NEG集合正则化后的嵌入值与词典集合正则化后的嵌入值的矩阵乘 valid_embeddings, normalized_embeddings, transpose_b=True)# Step 6: Begin trainingnum_steps = 100001with tf.Session(graph=graph) as session: # We must initialize all variables before we use them. tf.initialize_all_variables().run() print("Initialized") average_loss = 0 for step in xrange(num_steps): batch_inputs, batch_labels = generate_batch( batch_size, num_skips, skip_window) feed_dict = &#123;train_inputs : batch_inputs, train_labels : batch_labels&#125; # We perform one update step by evaluating the optimizer op (including it # in the list of returned values for session.run() _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict) average_loss += loss_val if step % 2000 == 0: if step &gt; 0: average_loss = average_loss / 2000 # The average loss is an estimate of the loss over the last 2000 batches. print("Average loss at step ", step, ": ", average_loss) average_loss = 0 # 这里是构建nosie词作 # 注意这里的代价是很大的，没500步差不多就会减慢20%的计算 if step % 10000 == 0: sim = similarity.eval() for i in xrange(valid_size): valid_word = reverse_dictionary[valid_examples[i]] top_k = 8 # number of nearest neighbors# nearest = (-sim[i, :]).argsort()[1:top_k+1]# 返回的是按相似度排序后元素值的索引值 log_str = "Nearest to %s:" % valid_word for k in xrange(top_k): close_word = reverse_dictionary[nearest[k]] log_str = "%s %s," % (log_str, close_word) print(log_str) final_embeddings = normalized_embeddings.eval()# Step 7: Visualize the embeddings.def plot_with_labels(low_dim_embs, labels, filename='tsne.png'): assert low_dim_embs.shape[0] &gt;= len(labels), "More labels than embeddings" plt.figure(figsize=(18, 18)) #in inches for i, label in enumerate(labels): x, y = low_dim_embs[i,:] plt.scatter(x, y) plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom') plt.savefig(filename) try: from sklearn.manifold import TSNE import matplotlib.pyplot as plt tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000) plot_only = 500 low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only,:]) labels = list(dictionary.keys())[:plot_only] plot_with_labels(low_dim_embs, labels) except ImportError: print("Please install sklearn and matplotlib to visualize embeddings.")''' 运行结果如下：]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow简单使用Cifar数据集]]></title>
    <url>%2F2017%2F03%2F26%2Ftf-cifar%2F</url>
    <content type="text"><![CDATA[这篇文章是对TensorFlow官方例子：CIFAR-10数据集分类的理解记录。 对CIFAR-10 数据集的分类是机器学习中一个公开的基准测试问题，其任务是对一组大小为32x32的RGB图像进行分类，这些图像涵盖了10个类别： 飞机， 汽车， 鸟， 猫， 鹿， 狗， 青蛙， 马， 船以及卡车。 数据集主页 Python项目代码页面 这里主要介绍cifar10_input.py、caifar10.py、caifar_train.py和cifar10_eval.py 模型输入cifar10_input.py文件，从二进制文件cifar-10-binary.tar.gz中提取数据 1234567891011121314151617181920212223242526272829303132333435def distorted_inputs(data_dir, batch_size): filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in xrange(1, 6)] for f in filenames: if not tf.gfile.Exists(f): raise ValueError('Failed to find file: ' + f) filename_queue = tf.train.string_input_producer(filenames) read_input = read_cifar10(filename_queue) reshaped_image = tf.cast(read_input.uint8image, tf.float32) height = IMAGE_SIZE width = IMAGE_SIZE distorted_image = tf.random_crop(reshaped_image, [height, width, 3]) distorted_image = tf.image.random_flip_left_right(distorted_image) distorted_image = tf.image.random_brightness(distorted_image, max_delta=63) distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8) float_image = tf.image.per_image_standardization(distorted_image) float_image.set_shape([height, width, 3]) read_input.label.set_shape([1]) min_fraction_of_examples_in_queue = 0.4 min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * min_fraction_of_examples_in_queue) return _generate_image_and_label_batch(float_image,read_input.label,min_queue_examples, batch_size,shuffle=True) 主要函数有两个，inputs和distorted_inputs，这里贴出来的是distorted_inputs。两个方法都是从训练/测试 数据集文件中读取数据，后者针对测试集，裁剪图像、提取变换成相应的格式，前者针对训练集，在变化成需要格式前，还要进行图像的处理，如翻转，亮度变换、随机替换等等来增加数据集。返回的是构建生成的数据样本和标签。 模型构建使用CNN模型，包括两级卷基层、两级全连接层和最后的softmax激励函数输出。 模型1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465def inference(images): # 卷基层1 with tf.variable_scope('conv1') as scope: # 过滤器 kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3, 64], stddev=5e-2, wd=0.0) conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME') # 偏置 biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0)) pre_activation = tf.nn.bias_add(conv, biases) # Relu非线性处理 conv1 = tf.nn.relu(pre_activation, name=scope.name) _activation_summary(conv1) # 池化降维 pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1') # 归一化处理 norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,name='norm1') # 卷积层2 with tf.variable_scope('conv2') as scope: kernel = _variable_with_weight_decay('weights', shape=[5, 5, 64, 64], stddev=5e-2, wd=0.0) conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME') biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1)) pre_activation = tf.nn.bias_add(conv, biases) conv2 = tf.nn.relu(pre_activation, name=scope.name) _activation_summary(conv2) # 归一化 norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2') # 池化 pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='SAME', name='pool2') # 全连接层 with tf.variable_scope('local3') as scope: # 尺寸对应全连接层变换处理 reshape = tf.reshape(pool2, [FLAGS.batch_size, -1]) dim = reshape.get_shape()[1].value weights = _variable_with_weight_decay('weights', shape=[dim, 384], stddev=0.04, wd=0.004) biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1)) # 不再使用卷积乘tf.nn.conv2d，直接矩阵乘 local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name) _activation_summary(local3) # 全连接层2 with tf.variable_scope('local4') as scope: weights = _variable_with_weight_decay('weights', shape=[384, 192],stddev=0.04, wd=0.004) biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1)) local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name) _activation_summary(local4) # (WX + b),线性logit，这里没使用softmax直接输出未归一化的logits是因为需要在loss中直接计算熵，使用的sparse_softmax_cross_entropy_with_logits函数接受的是未归一化的形式 with tf.variable_scope('softmax_linear') as scope: weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],stddev=1/192.0,wd=0.0) biases = _variable_on_cpu('biases', [NUM_CLASSES],tf.constant_initializer(0.0)) softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name) _activation_summary(softmax_linear) return softmax_linear 训练阶段loss1234567891011def loss(logits, labels):# 接受从模型构造函数inference返回的logits，以及从input或者distorted_inputs中的label部分，返回损失tensor labels = tf.cast(labels, tf.int64) cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits( labels=labels, logits=logits, name='cross_entropy_per_example') cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy') tf.add_to_collection('losses', cross_entropy_mean) # The total loss is defined as the cross entropy loss plus all of the weight # decay terms (L2 loss). return tf.add_n(tf.get_collection('losses'), name='total_loss') train训练阶段就是通过训练算法迭代优化，最小化损失函数的过程。 1234567891011121314151617181920212223242526272829303132333435363738394041#接受参数：总损失def train(total_loss, global_step): num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY) # 根据当前的训练步数、衰减速度、初始的学习速率确定更新新的学习速率.staircase=True，标明按照梯度下降衰减。即global_step,每隔decay_steps, learing_rate会按照LEARNING_RATE_DECAY_FACTOR（衰减系数）衰减一次。 如果straircase = false, 代表 learning rate 按照连续函数衰减， 即每训练一次，learning rate 都会衰减一次 lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE, global_step, decay_steps, LEARNING_RATE_DECAY_FACTOR, staircase=True) tf.summary.scalar('learning_rate', lr) loss_averages_op = _add_loss_summaries(total_loss) # 计算梯度。函数tf.control_dependencies，计算单元梯度计算要在统计之后 with tf.control_dependencies([loss_averages_op]): opt = tf.train.GradientDescentOptimizer(lr) grads = opt.compute_gradients(total_loss) # 梯度更新参数：计算完了，就反向传播一次，更新被训练的参数 apply_gradient_op = opt.apply_gradients(grads, global_step=global_step) for var in tf.trainable_variables(): tf.summary.histogram(var.op.name, var) for grad, var in grads: if grad is not None: tf.summary.histogram(var.op.name + '/gradients', grad) # 指数移动平均，是指tensorflow会创建一个变量（一般称为shadow variable）来储存某个变量的指数移动平均值，在训练过程中，每训练一次，变量都会学习到一个新的值，则对应的shadow变量也会跟着更新一次（更新需要run update op）。在训练过程中，只会不断更新shadow变量的值，而不会在模型中使用这个shadow变量。这个shadow变量一般是提供给评估过程使用的。 我理解的是，直接使用学习到的变量值进行评估，会导致评估有一定的波动性，如果使用变量的移动平均值替换变量进行评估，则会使评估过程更稳定，而且获得的评估效果也更好。 variable_averages = tf.train.ExponentialMovingAverage( MOVING_AVERAGE_DECAY, global_step) variables_averages_op = variable_averages.apply(tf.trainable_variables()) with tf.control_dependencies([apply_gradient_op, variables_averages_op]): train_op = tf.no_op(name='train') # 返回训练op return train_op 测试阶段12345678910111213141516171819202122232425262728293031323334353637383940414243# 测试一次的函数，saver是操作模型参数文件checkpoints的对象;top_k_op计算准确率def eval_once(saver, summary_writer, top_k_op, summary_op): with tf.Session() as sess: ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir) if ckpt and ckpt.model_checkpoint_path: # 从checkpoint取出参数 saver.restore(sess, ckpt.model_checkpoint_path) global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1] else: print('No checkpoint file found') return # 开始测试样本队列，多线程 coord = tf.train.Coordinator() try: threads = [] # tensorflow单独创建一个queue runner线程，它负责从文件中读取样本数据，并将其装载到一个队列中。我们只需要开启这个线程，在需要数据时从队列中获取想要的size的数据集就可以了，队列数据的装载由该线程自动实现的。 for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS): threads.extend(qr.create_threads(sess, coord=coord, daemon=True, start=True)) num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size)) true_count = 0 # Counts the number of correct predictions. total_sample_count = num_iter * FLAGS.batch_size step = 0 while step &lt; num_iter and not coord.should_stop(): # 计算准确率 predictions = sess.run([top_k_op]) true_count += np.sum(predictions) step += 1 # 计算准确率 precision = true_count / total_sample_count print('%s: precision @ 1 = %.3f' % (datetime.now(), precision)) summary = tf.Summary() summary.ParseFromString(sess.run(summary_op)) summary.value.add(tag='Precision @ 1', simple_value=precision) summary_writer.add_summary(summary, global_step) except Exception as e: # pylint: disable=broad-except coord.request_stop(e) coord.request_stop() coord.join(threads, stop_grace_period_secs=10) 其他关于tf.train.shuffle_batch 中的参数 shuffle、min_after_dequeue shuffle的作用在于指定是否需要随机打乱样本的顺序，一般作用于训练阶段，提高鲁棒性。 当shuffle = false时，每次dequeue是从队列中按顺序取数据，遵从先入先出的原则 当shuffle = true时，每次从队列中dequeue取数据时，不再按顺序，而是随机的，所以打乱了样本的原有顺序。 shuffle还要配合参数min_after_dequeue使用才能发挥作用。这个参数min_after_dequeue的意思是队列中，做dequeue（取数据）的操作后，queue runner线程要保证队列中至少剩下min_after_dequeue个数据。如果min_after_dequeue设置的过少，则即使shuffle为true，也达不到好的混合效果。 因为我们的目的肯定是想尽最大可能的混合数据，因此设置min_after_dequeue，可以保证每次dequeue后都有足够量的数据填充尽队列，保证下次dequeue时可以很充分的混合数据。 但是min_after_dequeue也不能设置的太大，这样会导致队列填充的时间变长，尤其是在最初的装载阶段，会花费比较长的时间。 关于训练与测试在以前的教程中，都是将训练和评估放在一个程序中运行，而在这个教程中，训练和评估是分开在两个独立的程序中进行的，之所以这样做，是因为评估过程不会直接使用训练学习到的模型参数（trainable variable的值），而是要使用的是变量的滑动平均（shadow variable）来代替原有变量进行评估。 具体的实现方法是，在训练过程中，为每个trainable variable 添加 指数滑动平均变量，然后每训练1000步就将模型训练到的变量值保存在checkpoint中，评估过程运行时，从最新存储的checkpoint中取出模型的shadow variable，赋值给对应的变量，然后进行评估]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dropout]]></title>
    <url>%2F2017%2F03%2F23%2Fdropout%2F</url>
    <content type="text"><![CDATA[前言训练神经网络模型时，如果训练样本较少，为了防止模型过拟合，Dropout可以作为一种trikc供选择。Dropout是hintion最近2年提出的，源于其文章Improving neural networks by preventing co-adaptation of feature detectors.中文大意为：通过阻止特征检测器的共同作用来提高神经网络的性能。本篇博文就是按照这篇论文简单介绍下Dropout的思想。 大部分内容来源tornadomeet，先记录，之后填充。 基础知识 Dropout是指在模型训练时随机让网络某些隐含层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重得保留下来（只是暂时不更新而已），因为下次样本输入时它可能又得工作了（有点抽象，具体实现看后面的实验部分）。 按照hinton的文章，他使用Dropout时训练阶段和测试阶段做了如下操作： 在样本的训练阶段，在没有采用pre-training的网络时（Dropout当然可以结合pre-training一起使用），hintion并不是像通常那样对权值采用L2范数惩罚，而是对每个隐含节点的权值L2范数设置一个上限bound，当训练过程中如果该节点不满足bound约束，则用该bound值对权值进行一个规范化操作（即同时除以该L2范数值），说是这样可以让权值更新初始的时候有个大的学习率供衰减，并且可以搜索更多的权值空间。 在模型的测试阶段，使用”mean network(均值网络)”来得到隐含层的输出，其实就是在网络前向传播到输出层前时隐含层节点的输出值都要减半（如果dropout的比例为50%），其理由文章说了一些，可以去查看（没理解）。 关于Dropout，文章中没有给出任何数学解释，Hintion的直观解释和理由如下： 由于每次用输入网络的样本进行权值更新时，隐含节点都是以一定概率随机出现，因此不能保证每2个隐含节点每次都同时出现，这样权值的更新不再依赖于有固定关系隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况。 可以将dropout看作是模型平均的一种。对于每次输入到网络中的样本（可能是一个样本，也可能是一个batch的样本），其对应的网络结构都是不同的，但所有的这些不同的网络结构又同时share隐含节点的权值。这样不同的样本就对应不同的模型，是bagging的一种极端情况。个人感觉这个解释稍微靠谱些，和bagging，boosting理论有点像，但又不完全相同。 native bayes是dropout的一个特例。Native bayes有个错误的前提，即假设各个特征之间相互独立，这样在训练样本比较少的情况下，单独对每个特征进行学习，测试时将所有的特征都相乘，且在实际应用时效果还不错。而Droput每次不是训练一个特征，而是一部分隐含层特征。 还有一个比较有意思的解释是，Dropout类似于性别在生物进化中的角色，物种为了使适应不断变化的环境，性别的出现有效的阻止了过拟合，即避免环境改变时物种可能面临的灭亡。 下面一个使用MNIST的CNN小例子使用dropout： 123456789101112131415# 进行20000次训练for i in range(20000): # 随机取出50个样本数据，包括图片的灰度值x [28*28]，以及label数据y_ batch = mnist.train.next_batch(50) if i%100 == 0: # 这里没有再学习权值和偏置，没有对他们更新，是使用训练集做了一个简单的测试，所以概率设置为1 train_accuracy = accuracy.eval(feed_dict=&#123; x:batch[0], y_: batch[1], keep_prob: 1.0&#125;) print("step %d, training accuracy %g"%(i, train_accuracy)) # 训练时使用dropout，概率为0.5 train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)# 测试时不使用dropout，将概率设置为1print("test accuracy %g"%accuracy.eval(feed_dict=&#123; x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;))]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（转载）CNN卷积神经网络]]></title>
    <url>%2F2017%2F03%2F22%2Fcnn%2F</url>
    <content type="text"><![CDATA[先述卷积神经网络-翻译 英文原文（ConvNets 或者 CNNs）属于神经网络的范畴，已经在诸如图像识别和分类的领域证明了其高效的能力。卷积神经网络可以成功识别人脸、物体和交通信号，从而为机器人和自动驾驶汽车提供视力。 上图中，ConvNet主要有四个操作： 卷积 非线性处理（ReLU） 池化pooling 分类 图像是像素值的矩阵本质上来说，每张图像都可以表示为像素值的矩阵： 通道 （chain）常用于表示图像的某种组成。一个标准数字相机拍摄的图像会有三通道 - 红、绿和蓝；你可以把它们看作是互相堆叠在一起的二维矩阵（每一个通道代表一个颜色），每个通道的像素值在 0 到 255 的范围内。 灰度图像，仅仅只有一个通道。在本篇文章中，我们仅考虑灰度图像，这样我们就只有一个二维的矩阵来表示图像。矩阵中各个像素的值在 0 到 255 的范围内——零表示黑色，255 表示白色。 卷积卷积的主要目的是为了从输入图像中提取特征。卷积可以通过从输入的一小块数据中学到图像的特征，并可以保留像素间的空间关系。 每张图像都可以看作是像素值的矩阵。考虑一下一个 5 x 5 的图像，它的像素值仅为 0 或者 1（注意对于灰度图像而言，像素值的范围是 0 到 255，下面像素值为 0 和 1 的绿色矩阵仅为特例），同时，考虑下另一个 3 x 3 的矩阵。接下来，5 x 5 的图像和 3 x 3 的矩阵的卷积可以按下图所示的动画一样计算： 现在停下来好好理解下上面的计算是怎么完成的。我们用橙色的矩阵在原始图像（绿色）上滑动，每次滑动一个像素（也叫做“步长”），在每个位置上，我们计算对应元素的乘积（两个矩阵间），并把乘积的和作为最后的结果，得到输出矩阵（粉色）中的每一个元素的值。注意，3 x 3 的矩阵每次步长中仅可以“看到”输入图像的一部分。 在 CNN 的术语中，3x3 的矩阵叫做“滤波器（filter）”或者“核（kernel）”或者“特征检测器（feature detector）”，通过在图像上滑动滤波器并计算点乘得到矩阵叫做“卷积特征（Convolved Feature）”或者“激活图（Activation Map）”或者“特征图（Feature Map）”。记住滤波器在原始输入图像上的作用是特征检测器。 不同滤波器对上图卷积的效果。通过在卷积操作前修改滤波矩阵的数值，我们可以进行诸如边缘检测、锐化和模糊等操作 —— 这表明不同的滤波器可以从图中检测到不同的特征，比如边缘、曲线等。 在实践中，CNN 会在训练过程中学习到这些滤波器的值（尽管我们依然需要在训练前指定诸如滤波器的个数、滤波器的大小、网络架构等参数）。我们使用的滤波器越多，提取到的图像特征就越多，网络所能在未知图像上识别的模式也就越好。 特征图的大小（卷积特征）由下面三个参数控制，我们需要在卷积前确定它们： 深度（Depth）：深度对应的是卷积操作所需的滤波器个数。在下图的网络中，我们使用三个不同的滤波器对原始图像进行卷积操作，这样就可以生成三个不同的特征图。你可以把这三个特征图看作是堆叠的 2d 矩阵，那么，特征图的“深度”就是三。 步长（Stride）：步长是我们在输入矩阵上滑动滤波矩阵的像素数。当步长为 1 时，我们每次移动滤波器一个像素的位置。当步长为 2 时，我们每次移动滤波器会跳过 2 个像素。步长越大，将会得到更小的特征图。 零填充（Zero-padding）：有时，在输入矩阵的边缘使用零值进行填充，这样我们就可以对输入图像矩阵的边缘进行滤波。零填充的一大好处是可以让我们控制特征图的大小。使用零填充的也叫做泛卷积，不适用零填充的叫做严格卷积。这个概念在下面的参考文献 14 中介绍的非常详细。 ReLU每次的卷积操作后都使用了一个叫做 ReLU 的操作。ReLU 表示修正线性单元（Rectified Linear Unit），是一个非线性操作。它的输入如下所示： ReLU 是一个元素级别的操作（应用到各个像素），并将特征图中的所有小于 0 的像素值设置为零。ReLU 的目的是在 ConvNet 中引入非线性，因为在大部分的我们希望 ConvNet 学习的实际数据是非线性的（卷积是一个线性操作——元素级别的矩阵相乘和相加，所以我们需要通过使用非线性函数 ReLU 来引入非线性。 池化空间池化（Spatial Pooling）（也叫做亚采用或者下采样）降低了各个特征图的维度，但可以保持大部分重要的信息。空间池化有下面几种方式：最大化、平均化、加和等等。 对于最大池化（Max Pooling），我们定义一个空间邻域（比如，2x2 的窗口），并从窗口内的修正特征图中取出最大的元素。除了取最大元素，我们也可以取平均（Average Pooling）或者对窗口内的元素求和。在实际中，最大池化被证明效果更好一些。 我们以 2 个元素（也叫做“步长”）滑动我们 2x2 的窗口，并在每个区域内取最大值。如上图所示，这样操作可以降低我们特征图的维度。 池化函数可以逐渐降低输入表示的空间尺度。特别地，池化： 使输入表示（特征维度）变得更小，并且网络中的参数和计算的数量更加可控的减小，因此，可以控制过拟合 使网络对于输入图像中更小的变化、冗余和变换变得不变性（输入的微小冗余将不会改变池化的输出——因为我们在局部邻域中使用了最大化/平均值的操作。 帮助我们获取图像最大程度上的尺度不变性（准确的词是“不变性”）。它非常的强大，因为我们可以检测图像中的物体，无论它们位置在哪里（参考 18 和 19 获取详细信息）。 到目前为止我们了解了卷积、ReLU 和池化是如何操作的。理解这些层是构建任意 CNN 的基础是很重要的。我们有两组卷积、ReLU &amp; 池化层 —— 第二组卷积层使用六个滤波器对第一组的池化层的输出继续卷积，得到一共六个特征图。接下来对所有六个特征图应用 ReLU。接着我们对六个修正特征图分别进行最大池化操作。 这些层一起就可以从图像中提取有用的特征，并在网络中引入非线性，减少特征维度，同时保持这些特征具有某种程度上的尺度变化不变性。 第二组池化层的输出作为全连接层的输入，我们会在下一部分介绍全连接层。 全连接层全连接层是传统的多层感知器，在输出层使用的是 softmax 激活函数（也可以使用其他像 SVM 的分类器，但在本文中只使用 softmax）。“全连接（Fully Connected）”这个词表明前面层的所有神经元都与下一层的所有神经元连接。 卷积和池化层的输出表示了输入图像的高级特征。全连接层的目的是为了使用这些特征把输入图像基于训练数据集进行分类。 除了分类，添加一个全连接层也（一般）是学习这些特征的非线性组合的简单方法。从卷积和池化层得到的大多数特征可能对分类任务有效，但这些特征的组合可能会更好。 从全连接层得到的输出概率和为 1。这个可以在输出层使用 softmax 作为激活函数进行保证。softmax 函数输入一个任意大于 0 值的矢量，并把它们转换为零一之间的数值矢量，其和为一。 卷积 + 池化层的作用是从输入图像中提取特征，而全连接层的作用是分类器。 小结完整的卷积网络的训练过程可以总结如下： 第一步：我们初始化所有的滤波器，使用随机值设置参数/权重 第二步：网络接收一张训练图像作为输入，通过前向传播过程（卷积、ReLU 和池化操作，以及全连接层的前向传播），找到各个类的输出概率 我们假设船这张图像的输出概率是 [0.2, 0.4, 0.1, 0.3] 因为对于第一张训练样本的权重是随机分配的，输出的概率也是随机的 第三步：在输出层计算总误差（计算 4 类的和） Total Error = ∑ ½ (target probability – output probability) ² 第四步：使用反向传播算法，根据网络的权重计算误差的梯度，并使用梯度下降算法更新所有滤波器的值/权重以及参数的值，使输出误差最小化 权重的更新与它们对总误差的占比有关 当同样的图像再次作为输入，这时的输出概率可能会是 [0.1, 0.1, 0.7, 0.1]，这就与目标矢量 [0, 0, 1, 0] 更接近了 这表明网络已经通过调节权重/滤波器，可以正确对这张特定图像的分类，这样输出的误差就减小了 像滤波器数量、滤波器大小、网络结构等这样的参数，在第一步前都是固定的，在训练过程中保持不变——仅仅是滤波器矩阵的值和连接权重在更新 第五步：对训练数据中所有的图像重复步骤 1 ~ 4 补充有时候，我们会在池化前后进行局部对比度归一化层（local contract normalization）。这个归一化包括两个部分：局部做减和局部做除 自然图像存在低阶和高阶的统计特征，低阶（例如二阶）的统计特征是满足高斯分布的，但高阶的统计特性是非高斯分布。图像中，空间上相邻的像素点有着很强的相关性。而对于PCA来说，因为它是对协方差矩阵操作，所以可以去掉输入图像的二阶相关性，但是却无法去掉高阶相关性。而有人证明了除以一个隐含的变量就可以去除高阶相关性。 对输入图像的每一个像素，我们计算其邻域（例如3x3窗口）的均值，然后每个像素先减去这个均值，再除以这个邻域窗口（例如3x3窗口）拉成的9维向量的欧几里德范数（如果这个范数大于1的时候才除：这个约束是为了保证归一化只作用于减少响应（除以大于1的数值变小），而不会加强响应（除以小于1的数值变大））。也有论文在计算均值和范数的时候，都加入了距离的影响，也就是距离离该窗口中心越远，影响越小，例如加个高斯权重窗口（空间上相邻的像素点的相关性随着距离变大而变小）。 数据归一化，就是将数据映射到[0,1]或[-1,1]区间或更小的区间，比如(0.1,0.9) 。 为什么要归一化处理？ 输入数据的单位不一样，有些数据的范围可能特别大，导致的结果是神经网络收敛慢、训练时间长。 数据范围大的输入在模式分类中的作用可能会偏大，而数据范围小的输入作用就可能会偏小。 由于神经网络输出层的激活函数的值域是有限制的，因此需要将网络训练的目标数据映射到激活函数的值域。例如神经网络的输出层若采用S形激活函数，由于S形函数的值域限制在(0,1)，也就是说神经网络的输出只能限制在(0,1)，所以训练数据的输出就要归一化到[0,1]区间。 S形激活函数在(0,1)区间以外区域很平缓，区分度太小。例如S形函数f(X)在参数a=1时，f(100)与f(5)只相差0.0067。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAP、SRM、ERM与MLE]]></title>
    <url>%2F2017%2F03%2F20%2FMAP-MLE-SRM%2F</url>
    <content type="text"><![CDATA[最大似然与经验风险最小化 当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计 首先给出对数形式的ERM的公式：$$\min \frac{1}{n}\sum\limits_{i=1}^n L(y_i,p(y_i\mid x_i))$$ 其中$L(y_i,f(x_i))$是损失函数，输出预测值为$f(x_i)$，n是观察到的样本数。 最大似然的前提是从模型总体随机抽取样本观测值，所有的采样都是独立同分布的。假设$x_1,x_2,…,x_n$为独立同分布的采样，$\theta$为模型参数，f为我们使用的模型，我们使用条件概率分布，遵循独立同分布。假设我们需要根据观察数据$x$估计没有观察到的总体参数$\theta$： $$f(x_1,x_2,…,x_n \mid \theta)=f(x_1 \mid \theta)\times f(x_2 \mid \theta)\times…\times f(x_n \mid \theta)$$ 此时似然定义为： $$L(\theta \mid x_1,x_2,…,x_n)=P(x_1,x_2,…,x_n\mid \theta)=\prod\limits_{i=1}^n f(x_i \mid \theta)$$ 在实际应用中常用的是取两边取对数，并取似然值得平均值： $$\frac{1}{n} \log L(\theta \mid x_1,x_2,…,x_n)=\frac{1}{n} \sum\limits_{i=1}^n \log f(x_i \mid \theta)$$ 去取极大似然估计MLE： $$\arg\max\limits_{\theta} \frac{1}{n} \sum\limits_{i=1}^n \log f(x_i\mid \theta)=\min \frac{1}{n}\sum\limits_{i=1}^n - \log f(x_i \mid \theta)$$ $-\log f(x_i\mid \theta)$可以看做是对数似然损失函数。可以明显看出此时的经验风险最小化就等价于极大似然估计。上式是要求参数$\theta$，在这个参数条件下，使得已知数据$x$出现的概率最大。 后验概率与结构风险最小化 当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。 最大后验估计是根据经验数据获得对难以观察的量的点估计。与最大似然估计类似，但是最大的不同时，最大后验估计的融入了要估计量的先验分布在其中。故最大后验估计可以看做规则化的最大似然估计。 MAP推导先来一段后验概率最大化MAP的推导，摘自Wiki： 假设我们需要根据观察数据$x$估计没有观察到的总体参数 $\theta$，让$f$作为$x$的采样分布，这样$f(x\mid \theta)$就是在那个题参数为$\theta$时$x$的概率。函数$\theta \to f(x \mid \theta)$，即为似然函数，其估计$\hat{\theta}_{ML}(x)=\arg\max\limits_{\theta}f(x\mid \theta)$，就是$\theta$的最大似然估计。 假设$\theta$存在一个先验分布$g$，这就允许我们将$\theta$作为贝叶斯分布中的随机变量，这样$\theta$的后验分布就是: $$\theta \to \frac{f(x \mid \theta)g(\theta)}{\int_{\Theta}f(x \mid \theta_1)g(\theta_1)d\theta_1}$$ 其中$\Theta$是$g$的域，上式分母的下部就相当于对已知数据$x$概率的估计，这里用的公式是贝叶斯公式，由先验概率去求后验概率$P(A\mid B)=(P(B\mid A)*P(A))/P(B)$。 最大后验估计方法估计$\theta$为这个随机变量的后验分布的众数： $$\hat{\theta}_{MAP}(x)=\arg\max\limits_{\theta} \frac{f(x \mid \theta)g(\theta)}{\int_{\Theta}f(x \mid \theta_1)g(\theta_1)d\theta_1}=\arg\max\limits_{\theta}f(x\mid \theta)g(\theta)$$ 后验分布的分母与$\theta$ 无关，在求解中分母不变，当成一个常数使用，所以在优化过程中不起作用。注意当前验$g$是常数函数时最大后验概率与最大似然估计的重合。 先验概率这里我先对我理解的先验概率含义做个叙述。先验分布，我理解的就是在没有输入数据或者其他数据，根据经验主观或者频数客观的对整个模型的各个结果集占比的推测。 举例来说：假设有五个袋子，各袋中都有无限量的饼干(樱桃口味或柠檬口味)，已知五个袋子中两种口味的比例分别是 樱桃 100% 樱桃 75% + 柠檬 25% 樱桃 50% + 柠檬 50% 樱桃 25% + 柠檬 75% 柠檬 100% 如果只有如上所述条件，那问从同一个袋子中连续拿到2个柠檬饼干，那么这个袋子最有可能是上述五个的哪一个？ 我们首先采用MLE来解这个问题。假设从袋子中能拿出柠檬饼干的概率为p(我们通过这个概率p来确定是从哪个袋子中拿出来的)，则似然函数可以写作： $$p(两个柠檬饼干 \mid 袋子)=p^2$$ 由于p的取值是一个离散值，即上面描述中的0,25%，50%，75%，1。我们只需要评估一下这五个值哪个值使得似然函数最大即可，得到为袋子5。这里便是最大似然估计的结果。 上述最大似然估计有一个问题，就是没有考虑到模型本身的概率分布，下面我们扩展这个饼干的问题。 假设拿到袋子1或5的机率都是0.1，拿到2或4的机率都是0.2，拿到3的机率是0.4，那同样上述问题的答案呢？这个时候就变MAP了。我们根据公式$$\hat{\theta}_{MAP}(x)=\arg\max\limits_{\theta} \frac{f(x \mid \theta)g(\theta)}{\int_{\Theta}f(x \mid \theta_1)g(\theta_1)d\theta_1}=\arg\max\limits_{\theta}f(x\mid \theta)g(\theta)$$写出我们的MAP函数：$MAP=p^2 \times g$ 根据题意的描述可知，p的取值分别为0,25%，50%，75%，1，g的取值分别为0.1，0.2,0.4,0.2,0.1.分别计算出MAP函数的结果为：0,0.0125,0.125,0.28125,0.1.由上可知，通过MAP估计可得结果是从第四个袋子中取得的最高。 SRM与MAP我们对MAP进行一些变换(先加上对数，再将对数展开)，则上式等价于： $$\hat{\theta}_{MAP}(x)=\arg\max\limits_{\theta} [\ln f(x\mid \theta)+\ln g(\theta)]$$ 进一步的，有： $$\hat{\theta}_{MAP}(x)=\arg\max\limits_{\theta} \ln f(x \mid \theta)+\arg\max\limits_{\theta} \ln g(\theta)$$可以发现，等式右边第一部分刚好为最大似然估计的公式，我们将最大似然估计的公式写出： $$\max \frac{1}{n}\sum\limits_{i=1}^n \ln f(x_i \mid \theta)$$将最大似然估计的公式代入，然后通过增加负号将最大后验概率分布公式的max改为min。这样，最大后验概率估计的公式可以写成下面这样： $$\hat{\theta}_{MAP}(x)=\arg\min\limits_{\theta}{[\frac{1}{n}\sum\limits_{i=1}^n-\ln f(x_i \mid \theta)]- g(\theta)}$$ 对比结构风险最小化公式： $$\min\limits_{f \in F}\frac{1}{n}\sum\limits_{i=1}^n L(y_i,f(x_i))+\lambda J(f)$$ 由于$f(\mid)$是模型，可以是条件概率分布模型，那么$-\ln f(x_i\mid \theta)$便可以看做是对数似然损失函数。 $g(\theta)$表示模型的先验概率，模型的复杂度与模型的先验概率没有必然的正比反比关系。这里我为了推导，暂且假定先验概率与模型复杂度成反比，$-g(\theta)$可以认为与复杂度成正比，$-g(\theta)$越大，复杂度越高。 此时，上式中的后半项就对应着结构风险最小化中的正则项。]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度坐标下降]]></title>
    <url>%2F2017%2F03%2F17%2Flagrange-coordinate%2F</url>
    <content type="text"><![CDATA[梯度下降梯度下降法是一种常用的一阶优化方法，是求解无约束优化问题方法之一。 原理：考虑无约束优化问题$$\min_x f(x)$$，其中$f(x)$为连续可微函数，若能构造一个序列$x^0,x^1,x^2,…$满足$$f(x^{t+1}) &lt; f(x^t),\ t=0,1,2…$$不断迭代执行该过程即可收敛到局部极小点。根据泰勒展开式：$$f(x+\Delta x) \approx f(x)+\Delta x^T \nabla f(x)$$ 欲满足：$$f(x+\Delta x) \ &lt; f(x)$$也就是近似满足：$$f(x)+\Delta x^T \nabla f(x)\ &lt;\ f(x)\ \rightleftharpoons \Delta x f(x) \ &lt; 0$$ 为了保证$\Delta x f(x) \ &lt; \ 0$成立，这里一般设置$\Delta x\ = \ -\gamma \nabla f(x)$这就是梯度下降法。当连续的两次迭代结果差小于阈值或者到达一定的迭代次数后，得到极小点 通过选取合适的步长，保证通过梯度下降收敛到局部极小点。当目标函数为凸函数时，局部极小点就对应着函数的全局最小点。 坐标下降法坐标下降法是一种非梯度优化方法，在每次迭代中沿一个坐标方向进行搜索，通过循环使用不同的坐标方向来达到目标函数的局部极小值。 他的原理就是在各个维度上搜索当前维度上函数的最小值，知道维度循环完毕。 不妨假设目标是求解函数$f(x)$的极小值，其中$x=(x_1,x_2,…,x_d)^T \ \in R^d$是一个d维向量。从初始点$x_0$开始，坐标下降法通过迭代构造序列求解问题，$x^{t+1}$的第i个分量$x_i^{t+1}$构造为$$x_i^{t+1}= \arg\min\limits_{y \in R} f(x_1^(t+1),…,x_{i-1}^{t+1},y,x_{i+1}^t,…,x_d^t)$$ 通过迭代执行过程显然有$$f(x^0)\geq f(x^1) \geq f(x^2)$$ 这里要注意函数必须要可微，否则不成立。]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对偶问题]]></title>
    <url>%2F2017%2F03%2F16%2Flagrange-dual%2F</url>
    <content type="text"><![CDATA[对偶问题再来看不等式约束优化问题： $$\begin{aligned}&amp;\min\limits_{x} \ f(x)\\&amp;s.t.\ \ h_i(x)=0,\ i=1,2,…,m\\&amp;g_j(x) \leq 0,\ j=1,2,…,n\\\end{aligned}$$ 定义Lagrange如下：$$L(x,\lambda,\mu)=f(x)+\sum\limits_{i=1}^m\lambda_ih_i(x)+\sum\limits_{j=1}^n\mu_jg_j(x)$$ 在优化理论中，目标函数 f(x) 会有多种形式：如果目标函数和约束条件都为变量 x 的线性函数, 称该问题为线性规划； 如果目标函数为二次函数, 约束条件为线性函数, 称该最优化问题为二次规划; 如果目标函数或者约束条件均为非线性函数, 称该最优化问题为非线性规划。每个线性规划问题都有一个与之对应的对偶问题，对偶问题有非常良好的性质，以下列举几个： 对偶问题的对偶是原问题； 无论原始问题是否是凸的，对偶问题都是凸优化问题； 对偶问题可以给出原始问题一个下界； 当满足一定条件时，原始问题与对偶问题的解是完全等价的； 上式的拉格朗日对偶函数： $$\begin{aligned}\Gamma(\lambda,\mu)=&amp;\inf\limits_{x \in D}\ L(x,\lambda,\mu)\\=&amp;\inf\limits_{x \in D}\lbrace f(x)+\sum\limits_{i=1}^m \lambda_i h_i(x)+\sum\limits_{j=1}^n \mu_jg_j(x) \rbrace\end{aligned}$$ 若$\hat{x} \in D$是约束问题可行域的点，则对任意的$\mu \geq 0$和$\lambda$都有$\sum\limits_{i=1}^m \lambda_i h_i(x) + \sum\limits_{j=1}^n\mu_j g_j(x) \leq 0$ 进而有 $$\Gamma(\lambda,\mu)=\inf\limits_{x \in D}L(x,\lambda,\mu) \leq L(\hat{x},\lambda,\mu) \leq f(\hat{x})$$ 若对上面约束优化问题的最优值为$p^*$，则对任意$\mu \geq 0$和$\lambda$都有 $$\Gamma(\lambda,\mu)\leq p^*$$ 对偶函数的最大值对应着原来约束条件优化问题的最大值，也就是说对偶问题能给主问题最优值的下界。 那么对偶函数能获得的最好的下界是什么呢？ $$\max\limits_{\lambda,\mu}\ \Gamma(\lambda,\mu)\ s.t. \ \mu \geq 0$$ 这就是原来约束问题对应的对偶问题，$\mu,\lambda$叫对偶变量。为了方便，我们把它称为对偶式，原来约束问题称为原式。 强弱对偶假设对偶式的最优值为$d^$，显然有$d^ \leq p^$，这称为弱对偶性，如果$d^ = p^*$，称为强对偶性。 如果主问题为凸优化问题（例如原式中$f(x),g_j(x)$都是凸函数，$h_i(x)$是仿射函数），且可行域中至少有一点使不等式约束严格成立，此时强对偶成立。 强对偶下，将拉格朗日函数分别对原变量和对偶变量求导，再令导数为零，即可得到原变量与对偶变量的数值关系。]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乘子与KKT]]></title>
    <url>%2F2017%2F03%2F16%2Flagrange-kkt%2F</url>
    <content type="text"><![CDATA[拉格朗日乘子法拉格朗日乘子法（Lagrange multipliers）是一种寻找多元函数在一组约束下的极值的方法。通过引入拉格朗日乘子，可将有$d$个变量与$k$个约束条件的最优化问题转化为具有$d+k$个变量的无约束优化问题求解 基本的拉格朗日乘子法就是求函数$f(x_1,x_2,…)$在$g(x_1,x_2,…)=0$的约束条件下的极值的方法。主要思想是将约束条件与原函数联系在一起，使能配成与变量数量相等的等式方程，从而求得原函数极值的各个变量的解。 例子：假设需要求极值的目标函数为$f(x)$，约束条件为$\phi(x,y)=M$设$g(x,y)=M-\phi(x,y)$，定义一个新函数$F(x,y,\lambda)=f(x,y)+\lambda g(x,y)$ 求偏导： $$\begin{cases}&amp;\frac{\partial F}{\partial x}=0 \\&amp;\frac{\partial F}{\partial y}=0\\&amp;\frac{\partial F}{\partial \lambda}=0\end{cases}$$ 求出$x,y,\lambda$的值，代入即可得到目标函数的极值。 机器学习中的拉格朗日乘子法，一般用于求解约束优化问题的方法，当目标函数是凸函数时，求解最小值，使用拉格朗日乘子法求得的局部最优解就是全局最优解。类似的，在凹函数中，求得的最大值，局部最大解就是全局最大解。 在没有约束条件下，直接使用求导取指即可，但是有了约束条件后，就不能这样任意的小了，需要首先满足约束条件之后再求解。 在二维空间中求解，假设约束条件是一个曲线： 环线是目标函数的取值的等高线，需要紧贴约束线来满足约束条件求得理想值。 图中可以很清晰的看出来，与约束条件相切的等高线正合适。至于其他的与约束条件曲线相切的都不能考虑，因为这种取值一部分是符合约束条件的，一部分不能满足约束条件。 曲线相切，实际上就是法线向量平行，同方向或者反方向。最优解处，f和g的斜率平行。也就是说，存在一个非零实数与其中一个斜率相乘，等于另外一个曲线的斜率。这个实数称之为$\lambda$，或者$-\lambda$随便啦 $\nabla[f(x,y)+\lambda(g(x,y)-c)]=0$ 一旦求出λ的值，将其套入下式，易求在无约束极值和极值所对应的点。 $F \left( x , y \right) = f \left( x , y \right) + \lambda \left( g \left( x , y \right) - c \right)$ 新方程$F(x,y)$在达到极值时与$f(x,y)$相等，因为$F(x,y)$达到极值时$g(x,y)-c$总等于零。 定义拉格朗日函数：$L(x,\lambda)=f(x)+\lambda g(x)$ 将其对$x$的偏导数$\nabla_xL(x,\lambda)$置零即得式子$\nabla f(x)+\lambda g(x)=0$；同时对$\lambda$的偏导数$\nabla_{\lambda}L(x,\lambda)$置零即得约束条件$g(x)=0$。所以原约束问题转换成了对拉格朗日函数$L(x,\lambda)$的无约束优化问题。 KKT KKT 现在考虑不等式$g(x) \leq 0$，如上图，此时最优点$x$或者在$g(x)&lt;0$也就是环形区域内；或者在$g(x)=0$环形线上。 对于$g(x)&lt;0$的情况，约束$g(x) \leq 0$不起作用，可以直接通过条件$\nabla f(x)=0$来获得最优点，这里等价于将$\lambda=0$之后求解$\nabla _x L(x,\lambda)=0$ $g(x)=0$的情况类似与上图左侧，但是有一些区别。在拉格朗日乘子中，约束条件$g(x)$与$f(x)$保持梯度平行即可，可就是说参数$\lambda$无关正负；到了这里，我们好好分析一下，假设两者的梯度是同方向的，都是向外（就是环线区域外，相反方向当然也可以）。我们都知道，函数是按沿着梯度方向增大，所以$f(x)$在区域外的值是大于区域内的值，也就是说，区域内的值是小值。我们的目标就是在约束条件下求$\min f(x)$，这里区域内是满足约束条件的，所以最优值显然不在环线上取，而是在区域内取。如果我们非要在环线上取怎么办？两个函数的梯度方向相反。这样才符合我们的认知嘛，梯度相反，同一个方向一个变小一个变大，环线是临界值，很符合人们的罗辑思维。 接着说不等式约束条件，整合上面的两种情况： $g(x)&lt;0$，约束条件不起作用，使$\lambda=0$ $g(x)=0$，约束条件使得$\lambda &gt; 0$ 所以必有$\lambda g(x)=0$ KKT条件推出来了： $$\begin{cases}&amp;g(x) \leq 0;\\&amp;\lambda \geq 0;\\&amp;\mu_jg_j(x)=0;\\\end{cases}.$$ 推广推广到多个约束，考虑有m个等式约束和n个不等式约束，优化问题$$\begin{cases}&amp;\min\limits_x f(x)\\&amp;s.t. h_i(x)=0 \ \ (i=1,…,m),\\&amp;g_j(x) \leq 0 \ \ (j=1,…,n).\\\end{cases}$$ 引入拉格朗日乘子$\lambda=(\lambda_1,\lambda_2,…,\lambda_m)^T$和$\mu=(\mu_1,\mu_2,…,\mu_n)^T$,相应的拉格朗日函数为$$L(x,\lambda,\mu)=f(x)+\sum\limits_{i=1}^m\lambda_ih_i(x)+\sum\limits_{j=1}^n\mu_jg_j(x)$$ 引入的拉格朗日乘子条件与KKT条件为： $$\begin{cases}&amp;h_i(x)=0;\\&amp;\lambda_i \neq 0;\\&amp;g_j(x) \leq 0;\\&amp;\mu_j \geq 0;\\&amp;\mu_jg_j(x)=0.\\&amp;\end{cases}$$]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[半监督学习]]></title>
    <url>%2F2017%2F03%2F13%2Fml-semi-supervised%2F</url>
    <content type="text"><![CDATA[主动学习与半监督假设我们有训练样本集$D_l={ (x_1,y_1),(x_2,y_2),…,(x_l,y_l) }$，l个样本的类别标记已知，称为有标记（labeled）；此外还有$D_u={ x_1,x_2,…,x_u },l \ll u$，这u个样本样本的类别标记未知，称为未标记的unlabeled样本。 若直接使用之前一直介绍的监督学习，则仅有$D_l$能用于构建模型，剩余的未标记样本都浪费了；另一方面远小于u数量的标记样本往往由于训练样本不足，学得模型的泛化能力往往不佳。 主动学习一个做法是用$D_l$先训练一个模型，使用这个模型在$D_u$中拿一个模型出来，寻求专家知识，判定结果，然后把这个新标记的样本加入到$D_l$中重新训练一个模型，然后再去$D_u$中获取一个新的未标记样本。。。；如果每次都能挑出来对改善模型性能帮助大的瓜，则只需要询问专家较少的次数就能构建出较强的模型，大幅度的降低标记成本。称为主动学习（active learning），其目标是使用尽量少的查询获取尽量好的性能。 半监督学习半监督（semi supervised）让学习器不依赖外界交互（针对主动学习的专家经验）、自动的利用未标记样本来提升学习性能。主要是考虑如何利用少量的标注样本和大量的未标注样本进行训练和分类。 半监督学习进一步可分为纯半监督学习和直推学习。前者假定训练数据中的未标记样本并非待预测的数据，而后者假定学习过程中所考虑的未标记样本是待预测数据，学习目的是在这些未标记样本上获得最优泛化能力。也就是说，纯半监督学习是基于开放世界，希望学得的模型能适用于训练过程中未观测带的数据；直推学习是基于封闭世界假设，仅试图对学习过程中观察到的未标记数据进行预测。 生成式方法生成模型是半监督学习的一种模型，生成式方法是直接基于生成式模型的方法。此类方法假设所有数据（labeled、unlabeled）都是由同一个潜在的模型生成的，这个假设使得我们能够通过潜在模型的参数将未标记数据与学习目标联系起来，而未标记数据的标记则可看作模型的缺失参数，基于EM算法进行极大似然估计求解。 给定样本x，其真实类别标记为$y \in Y$，其中$Y = { 1,2,…,N }$为所有可能的类别。假设样本由高斯混合模型生成，且每个类别对应一个高斯混合成分：$p(x)=\sum\limits_{i=1}^N \alpha_i \cdot p(x \mid \mu_i,\sum_i)$ 其中，混合系数$\alpha \geq 0,\sum_{i=1}^N \alpha_i=1;p(x \mid \mu_i,\sum_i)$是样本x属于第i个高斯混合成分的概率；$\mu_i$和$\sum_i$为该高斯混合成分的参数。 令$f(x) \in Y$表示模型f对x的预测标记，$\Theta \in { 1,2,…,N }$表示样本x隶属的高斯混合成分。由最大化后验概率可知： $$f(x)=arg \max\limits_{j \in Y} p(y= j \mid x)=arg \max\limits_{j \in Y} \sum\limits_{i=1}^Np(y=j,\Theta=i \mid x)=arg \max\limits_{j \in Y} \sum\limits_{i=1}^Np(y=j,\Theta=i,x)\cdot p(\Theta =i \mid x)$$ 其中$p(\Theta=i \mid x)=\frac{\alpha_i \cdot p(x \mid \mu_i,\sum_i)}{\sum\limits_{i=1}^N\alpha_i \cdot p(x \mid \mu_i,\sum_i)}$（不涉及样本标记）是样本x由第i个高斯混合成分生成的后验概率，$p(y=j \mid \Theta =i ,x)$是x由第i个高斯混合成分且类别为j的概率。 给定标记样本集$D_l={ (x_1,y_1),(x_2,y_2),…,(x_l,y_l) }$和未标记样本集合$D_u={ x_{l+1},x_{l+2},…,x_{l+u} },l \ll u l+u=m$假定所有样本独立同分布，且都是由同一个高斯混合模型生成。用极大似然估计法来估计高斯混合模型的参数，使用EM算法。 半监督SVM半监督SVM（简称S3VM）是支持向量机在半监督学习上的推广，在不考虑未标记样本时，支持向量机试图找到最大间隔划分超平面，而在考虑未标记样本后，S3VM试图找能将两类有标记样本分开，且穿过数据低密度区域的划分超平面。 简单介绍一下其中最出名的TSVM，针对二分类问题，TSVM考虑对未标记样本进行各种可能的标记指派，然后再所有这些结果中寻求一个在所有样本（包括labeled and unlabeled）上间隔最大化的划分超平面。一旦划分超平面确定，未标记样本最终标记就是预测结果。 显然上面的思路是利用穷举方法，这样明显效率不高，TSVM在上面再进一步。给定$D_l={(x_1,y_1),(x_2,y_2),…,(x_l,y_l)}$和$D_u={x_{l+1},x_{l+2},…,x_{l+u}},y_i \in {-1,+1},l \ll u,l+u=m$。TSVM的学习目标就是为$D_u$中的样本给出预测标记$\hat{y}=(\hat{y}_{l+1},\hat{y}_{l+2},…,\hat{y}_{l+u}),\hat{y_i} \in {-1,+1}$，使得：$\min\limits_{\omega,b,\hat{y},\xi}\frac{1}{2}\mid\mid \omega \mid\mid_2^2+C_l\sum\limits_{i=1}^l \xi_i +C_u \sum\limits_{i=l+1}^m \xi_i$ 上式中，$(\omega,b)$确定了一个划分超平面；$\xi$为松弛向量，$\xi_i(i=1,2,…,l)$对应于有标记样本，$\xi_i(i=l+1,l+2,…,m)$对应与未标记样本；$C_l,C_u$是由用户指定的用于平衡模型复杂度、有标记样本与未标记样本重要程度的这种参数。 它使用有标记样本学得一个SVM，然后使用这个SVM对未标记的数据进行标记指派，将SVM预测的结果作为伪标记赋予未标记样本。接下来TSVM找出两个标记指派为异类且很可能发生错误的未标记样本，交换标记，重新求得更新后SVM的划分超平面和松弛向量（在这一步中，因为SVM求得的伪标记往往是不准确的，所以需要设置好$C_l,C_u$，将$C_l$值大一点，标明有标记样本的作用更大)；然后再找两个标记指派为异类且很可能发生错误的未标记样本，交换。。标记指派完成后逐渐提高未标记样本对优化目标的影响，进行下一轮标记指派调整。。直到$C_u=C_l$ 图半监督思想：相似或者相关联的顶点尽可能的赋予相同标记连接，以保证图的标记尽可能的平滑。相似性或者关系度越高，连接的权值越大。 定义相似矩阵$W=(w_{ij})_{(l+u)\times(l+u)},w_{ij}=exp(-\frac{\mid\mid x_i-x_j \mid\mid^2}{2\sigma^2})\ if\ e=(x_i,e_j) \in E\ else\ 0$其中$\sigma$是带宽系数，用于控制权值的减缓程度。$w_{ij}$随着欧式距离的增加会减少。 标记传递算法：已标记数据$Rightarrow$近邻未标记数据$Rightarrow$次级近邻未标记数据 协同训练协同训练（co-training）使用多学习器，学习器之间的分歧对未标记数据的利用很重要。 一个数据对象往往同时拥有多个属性集，每个属性集构成一个视图。假设不同的试图有相容性，即其包含的关于输出空间的信息是一只的，当两个一起考虑就会有大概率使得与真实标记接近。不同视图信息的互补性会给学习器的构建带来很多便利。 协同训练正是使用了多视图的相容互补性，假设数据有两个充分且条件独立视图。充分是指每个视图都包含足以产生最优学习器的信息，条件独立则是指在给定类别的标记下两个视图独立。协同训练使用下面的策略使用未标记数据：首先在每个视图上基于有标记样本分别训练出一个分类器，然后让每个分类器分别去挑选自己最有把握的未标记样本赋予伪标记，并将伪标记样本提供给另一个分类器作为新增的有标记样本用于训练更新。。。之后就是不断的过程迭代，直到分类器不再更新。 协同学习也可以在单视图上使用，例如使用不同的学习方法、不同的数据采样、甚至不同的参数设置。 半监督聚类聚类是一种典型的无监督学习任务，不过我们通常能够获取一些额外的信息：必连与勿连信息，即两个样本一定属于一个label、一定不属于一个label；第二种就是获得少量的有标记样本。]]></content>
  </entry>
  <entry>
    <title><![CDATA[特征选择/稀疏学习]]></title>
    <url>%2F2017%2F03%2F12%2Fml-feature-chosen%2F</url>
    <content type="text"><![CDATA[范数 $L_0$范数表示向量中非零元素的个数：$\mid\mid x \mid\mid_0 = count(x_i) while x_i \neq 0$ 使用这个范数希望参数的大部分元素是0（稀疏数据），通过最优化范数，可以寻找最优稀疏特征，不过这个范数的最优问题是NP难度。 $L_1$范数表示向量中每个元素绝对值的和：$\mid\mid x \mid\mid_1=\sum_{i=1}^n \mid x_i \mid$ $L_1$范数是$L_0$范数的最优凸优化，常用$L_1$代替$L_0$范数。 $L_2$范数即欧式距离：$\mid\mid x \mid\mid_2=\sqrt{\sum_{i=1}^n x_i^2}$ Forbenius范数：$\mid\mid A \mid\mid_F = \sqrt{\sum\limits_{i=1}^m\sum\limits_{j=1}^n \mid a_{ij} \mid^2}$ 子图搜索与特征选择给定特征集合${a_1,a_2,…,a_d }$，我们可将每个特征看作一个候选子集，对这d个候选单特征子集进行评价，假定$a_2$最优，于是将$a_2$作为第一轮的选定集；然后，在上一轮的选定集中加入一个特征，构成包含两个特征的候选子集，假定在这d-1个候选两特征子集中$(a_2,a_4)$最优，且优于$(a_2)$，于是将$(a_2,a_4)$作为本轮的选定集； ……假定在第it+1轮时，最优的候选(k+1)特征子集不如上一轮的选定集，则停止生成候选子集，并将上一轮选定的k特征集合作为特征选择结果.这样逐渐增加相关特征的策略称为“前向”（forward)搜索。 类似的，若我们从完整的特征集合开始，每次尝试去掉一个无关特征，这样逐渐减少特征的策略称为“后向”（backward)搜索.还可将前向与后向搜索结合起来，每一轮逐渐增加选定相关特征(这些特征在后续轮中将确定不会被去除同时减少无关特征，这样的策略称为“双向”（bidirectional)搜索. 常见的特征选择方法大致分为三类，过滤式、包裹式和嵌入式。 过滤式过滤式先对数据集进行特征选择，然后再训练学习器，特侦选择过程与后续学习器无关。这相当于先用特征选择过程对初始特征进行过滤，再用过滤后的特征来训练模型。 Relif过滤式特征选择方法，方法设计了一个相关统计量度量特征的重要性。统计量是一个向量，每个向量分别对应与一个初始特征，而特征子集的重要性则是由子集中每个特征对应的相关统计量分量之和决定。 过滤的方法就是设定一个阈值$\tau$，选择比$\tau$大的相关统计量分量对应的特征即可。 给定训练集${(x_1,y_1),(x_2,y_2),…,(x_m,y_m)}$，对每个示例$x_i$，算法先在$x_i$的同类样本中寻找其最近邻$x_{i,nh}$，称为猜中近邻，再从$x_i$的异类样本中寻找其最近临$x_{i,nm}$，称为猜错近邻，然后相关统计量对应于属性j的分量为：$\delta^j=\sum\limits_i -diff(x_i^j,x_{i,nh}^j)^2+diff(x_i^j,x_{i,nm}^j)^2$ 其中$x_a^j$表示样本$x_a$在属性j上的取指，若属性j为离散型，则$diff(x_a^j,x_b^j)=0 if x_a^j==x_b^j else 1$，若是连续型，$diff(x_a^j,x_b^j)=\mid x_a^j-x_b^j \mid$ 若$x_i$与其猜中近邻在属性j上的距离小于$x_i$与其猜错近邻的距离，则说明属性j对区分同类与异类样本是有益的，则增大属性j对应的统计分量。 包裹式选择包裹式特征选择直接把最终将要使用的学习器性能作为特征子集的评价准则。 从最终学习性能来看，包裹式选择比过滤式更好，然而需要的开销要大得多。 LVM使用随机策略进行子图搜集，并以最终分类器的误差作为特征子集的评价准则。随机搜索，每次都要进行学习，交叉验证的结果作为误差标准比较，所以开销比较大。 嵌入式选择嵌入式特征选择是将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成，即在学习器训练过程中自动的进行了特征选择。 给定数据集$D={(x_1,y_1),(x_2,y_2),…,(x_m,y_m)}$，我们考虑最简单的线性回归模型，以平方误差为损失函数： $\min\limits_{\omega} \sum\limits_{i=1}^m (y_i-\omega^Tx_i)^2$ 当样本特征很多，样本数目较少时，容易陷入过拟合，此时需要加入正则化项： $\min\limits_{\omega} \sum\limits_{i=1}^m (y_i-\omega^Tx_i)^2+\lambda\mid\mid \omega \mid\mid_2^2$ $\min\limits_{\omega} \sum\limits_{i=1}^m (y_i-\omega^Tx_i)^2+\lambda\mid\mid \omega \mid\mid_1^2$ 分别使用了$L_2,L_1$范数，前者能比后者更易于获得稀疏解：求得的$\omega$有更少的非零向量。所以$\omega$取得的稀疏解意味着初始的d个特征中仅有对应着$\omega$的非零分量特征才会出现在最终模型中，于是求解$L_1$范数正则化的结果是得到了仅采用一部分初始特征的模型，基于$L_1$正则化的学习方法就是一种嵌入式特征选择方法。 稀疏表示与字典学习稀疏表达形式对学习任务来说有不少的好处，例如线性的SVM之所以在文本数据上有很好的性能，就是因为文本数据使用上述的字频表示后有高度的稀疏性，使大多数问题变得线性可分。同时稀疏表示可以减少存储空间。 若给定数据集D是稠密的，普通非稀疏数据，我们需要一个“字典”，将样本转化成为合适的稀疏表示形式，使得模型复杂度降低，称为字典学习或者稀疏编码。 字典学习侧重于学得字典的过程；稀疏编码偏重对样本进行稀疏表达的过程。 给定数据集（训练集）${x_1,x_2,…,x_m}$，字典学习最简单的形式为$\min\limits_{B,\alpha_i}\sum\limits_{i=1}^m \mid\mid x_i-B\alpha_i \mid\mid_2^2 +\lambda\sum\limits_{i=1}^m \mid\mid \alpha_i \mid\mid_1$ 前面的部分是最小化训练样本与学习的字典学习模型之间的误差，后面则是字典学习模型的$L_1$范数，即寻找稀疏数据。 其中B为字典矩阵，k为字典词汇量，由用户设定，$\alpha_i \in R^k$是样本$x_i \in R^d$的稀疏表示。 因为这里我们需要对B和%\alpha%进行学习，我们使用变量交替优化的策略求解。 固定字典B，我ie每个样本$x_i$找到相应的$\alpha_i$ $\min\limits_{\alpha_i} \mid\mid x_i-B\alpha_i \mid\mid_2^2 + \alpha\mid \alpha_i \mid_1$ 固定$\alpha_i$来更新字典B，此时原式改为了$\min\limits_{B}\mid\mid X-BA \mid\mid_F^2$ 其中$A=(\alpha_1,\alpha_2,…,\alpha_m)$， 初始化字典B后，迭代这两步，通过设置k的数值控制稀疏程度。 压缩感知压缩感知关注的是如何利用信号本身所具有的稀疏性，从部分观测样本中恢复原信号。通常认为压缩感知分为：感知测量和重构恢复两个阶段。前者关注如何对原始信号进行处理以获得稀疏样本表示，这方面技术包括傅里叶变换、小波变换以及字典学习和稀疏编码；重构恢复则主要针对基于稀疏性从少量观测中恢复原信号，这部分是压缩感知的核心。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[周报(1)]]></title>
    <url>%2F2017%2F03%2F10%2Fweek-report310%2F</url>
    <content type="text"><![CDATA[周报3.10这次周报，主要回顾从周一下午在公司开完会回来后的工作情况以及状态。 状态 时间：由于每天坚持健身锻炼，以及在临睡前习惯的观看某栏目的逻辑思维导论，拖拖拉拉的晚上会睡的比较迟。早上也是醒的蛮晚。这些习惯会在月底前的一周里改正。 地点：现在每天宿舍里空调打孔，噪音比较大。除了早上在寝室学习之外，之前没在实验室的会议室学习前，都会到教三的三楼自习。周二开始在保密会议室内学习，晚上九点半离开。 效率：工作效率方面，白天的学习效率很低，经常会被外界的环境影响；在封闭的实验室内效率提高不少，特别是晚上六点之后。deadline是第一生产力，那个时候开始有时间危机，想着不能又白白浪费一天时间，逐渐不去理会外界干扰。同时在会议室的办公桌上可以使用外接的大屏显示器辅助工作，感觉很棒。 工作情况目前是三月份，导师要我们9月份之前确定论文的题目，留给我们几乎半年的时间。所以这一阶段的前几十天我主要目标是在导师的指引下，在自己感兴趣的、或者认为有前景的领域粗粗的学一学，领略一番，期望遇到自己有深入进去欲望的方向、点。 最近一直在看南大周教授的《机器学习》和李航老师的《统计学习方法》。第一遍读不求甚解，没有公示的推倒，只是在顺着作者的思路学习，目的就是了解这一领域的基础知识、原理与技术。 两本书都对数学有一定的要求。上学期的《概率论与随机过程》课程中的部分章节在这里派上了用场，但是还有一些需要用到本科时的内容，包括《概率论与数理统计》、《线性代数》甚至《高级数学》。由于我没有参加统考，没有对这几门课程有系统的复习，几年过去，说实话遗忘了很多。类似协方差$Cov(\vec{x},\vec{y})$，特征值$\lambda$，矩阵的秩、迹、线性空间、欧氏空间、超平面等等很多定义、用法都要用到。这些有的是我学过还记得，有的学过忘掉了，还有部分没有接触过的，往往一个书上式子的理解都需要很长时间。不过嘛，这是我必经的路。前天听了同学的介绍，准备在网络上听一些课程，期望有所好转。 这期间开始使用latex。 周四，也就是昨天参加了在《中欧在5G及物联网领域的合作》会议。主要内容就是5G的最新进展以及物联网领域的突飞猛进。会议基本以英文演说为主，很多由于英文水平有限没有很好的理解，不过几个突出表达的新技术名词记录下来，回来查看资料还是大开眼见。几个关键词：光通信LIFI、AIOTI物联网组织、ICT合作。 昨天拿到了上届学长学姐的开题报告，到写周报前，只是把题目、时间安排简单的浏览了一下。]]></content>
      <categories>
        <category>周报</category>
      </categories>
      <tags>
        <tag>周报</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[降维]]></title>
    <url>%2F2017%2F03%2F09%2Fml-dimension-reduction%2F</url>
    <content type="text"><![CDATA[k近邻学习k近邻（k-Nearest Neighboor，KNN）是一种常用的监督学习方法：给定测试样本，基于某种距离距离度量找出训练集中与其最靠近的k个训练样本，然后基于这k个训练样本的信息对本样本进行预测。分类学习中通常使用投票法，少数服从多数；回归学习中则使用平均法。通常为了体现出靠近的距离指标，在分类学习与回归学习中使用加权法，越靠近样本的权值越大。 给定测试样本x，若其最近邻样本为z，则最近邻分类器出错的概率就是x与z类别标记不同的概率：$P(err)=1-\sum\limits_{c \in y}P(c \mid x)P(c \mid z)$ 假设样本独立同分布，且对任意x和任意小正数$\delta$，在x附近$\delta$距离范围内找到一个训练样本z；令$c^T=arg \max\limits_{c \in y}P(c \mid x)$表示贝叶斯最优分类器的结果，有： $$P(err)=1-\sum\limits_{c \in y}P(c \mid x)P(c \mid z)\approx1-\sum\limits_{c \in y}P^2(c \mid x)\leq 1- P^2(c^T \mid x)=(1+P(c^T \mid x))(1-P(c^T \mid x))\leq 2 \times (1-p(c^T \mid x))$$ 可以看出，在这种理想条件下KNN分类器的泛化错误率不超过贝叶斯错误率的两倍。 降维上面的讨论的基础是在足够小的距离内都有相邻的样本作为参考，考虑到做个属性（也就是多个维度）的情况，需要的合适的样本数量回事天文数字。高维度空间会给距离计算带来很大麻烦。 一般采用的方式是通过某种数学变换将原始高维属性空间转变为一个低维子空间。子空间中样本密度大幅提升。 MDSMDS即多维缩放(Multiple Dimensional Scaling)，是要就将原始空间中样本间的距离在低维空间中得以保持。 假定m个样本在原始空间的距离矩阵为$D \in R^{m \times m}$，在第i行j列的元素$dist_{ij}$为样本$x_i$到$s_j$的距离。目标是获得样本在$d^c$维空间的表示$Z \in R^{d^c \times m},d^c \leq d$，且任意两个样本在$d^c$维空间的欧式距离等于原始空间$\mid\mid z_i-z_j \mid\mid = dist_{ij}$ 令$B=Z^TZ \in R^{m \times m}$，其中B为降维后样本的内积矩阵，$b_{ij}=b_{ji}=z_i^Tz_j$ $$dist_{i.}^2=\frac{1}{m}\sum\limits_{j=1}^m dist_{ij}^2dist_{.j}^2=\frac{1}{m}\sum\limits_{i=1}^m dist_{ij}^2dist_{..}^2=\frac{1}{m^2}\sum\limits_{i=1}^m\sum\limits_{j=1}^m dist_{ij}^2$$ 由以上的式子推出： $b_ij=-\frac{1}{2}(dist_{ij}^2-dist_{i.}^2-dist_{.j}^2+dist_{..}^2)$ 依次求出矩阵B中所有的元素，然后对矩阵做特征值分解：$B=V\Lambda V^T$其中V为特征向量矩阵，$\Lambda$为特征值构成的对角矩阵。假定其中有$d^c$个非零特征值，构成对角矩阵$\Lambda_x=diag(\lambda_1,\lambda_2,…,\lambda_{dx})$，令$Vx$表示相应的特征向量矩阵，则： $Z=\Lambda_c^{1/2}V_c^T \in R^(d^c \times m)$ 主成分分析通过正交变换将一组可能存在相关性的变量转换为一组线性不相关的变量，转换后的这组变量叫主成分。 主成份（Principal Component Analysis）分析是降维（Dimension Reduction）的重要手段。每一个主成分都是数据在某一个方向上的投影，在不同的方向上这些数据方差Variance的大小由其特征值（eigenvalue）决定。一般我们会选取最大的几个特征值所在的特征向量（eigenvector），这些方向上的信息丰富，一般认为包含了更多我们所感兴趣的信息。 在很多情形，变量之间是有一定的相关关系的，当两个变量之间有一定相关关系时，可以解释为这两个变量反映此课题的信息有一定的重叠。主成分分析是对于原先提出的所有变量，将重复的变量（关系紧密的变量）删去多余，建立尽可能少的新变量，使得这些新变量是两两不相关的，而且这些新变量在反映课题的信息方面尽可能保持原有的信息。 设法将原来变量重新组合成一组新的互相无关的几个综合变量，同时根据实际需要从中可以取出几个较少的综合变量尽可能多地反映原来变量的信息的统计方法叫做主成分分析或称主分量分析，是数学上用来降维的一种方法。 先定义一些变量： 样本$(\vec{x_1},\vec{x_2},\vec{x_3},…,\vec{x_m})$ 投影变换得到的 新坐标系${ \vec{\omega_1},\vec{\omega_2},…,\vec{\omega_d}, }$ 样本点在低维坐标系中的投影是$z_i=(z_{i1};z_{i2};z_{i3};…;z_{id_‘};)$ 其中$z_{ij}=\vec{\omega}_j^T\vec{x_i}$是x在低维坐标系下的第j维坐标 投影点方差是$\sum_i W^Tx_ix_i^TW$ 优化目标是最大化这个方差，使得在投影之后尽可能的分散 PCA一般有以下几个步骤： 数据减去均值：样本中心化$\sum_i \vec{x_i}=\vec{0}$ 计算协方差矩阵：$C=\frac{XX^T}{N}$ 计算协方差矩阵的特征矢量和特征值：对协方差矩阵$\frac{XX^T}{N}$特征分解$CU=U\Lambda$，其中C为方差矩阵，U为计算的特征矢量，$\Lambda$是对角线矩阵$\Lambda=diag(\lambda_1,\lambda_2,…,\lambda_d)$ 选择成分组成模式矢量对应最大特征值的特征矢量就是数据的主成分：取最大的d个特征值所对应的特征向量$u_1,u_2,…,u_d$ 一般地，从协方差矩阵找到特征矢量以后，下一步就是按照特征值由大到小进行排列，这将给出成分的重要性级别。现在，如果你喜欢，可以忽略那些重要性很小的成分，当然这会丢失一些信息，但是如果对应的特征值很小，你不会丢失很多信息。 获得投影的新数据$y_i=U_k^T x_i$ 核化线性降维线性降维假设从高维空间到低维度空间的函数映射是线性的，然而在不少的现实任务中，可能需要非线性映射才能找到恰当的低维嵌入。 非线性降维的一种常用方法是基于核技巧对线性降维方法进行”核化”。 在KPCA中，除了在PCA中的一些先决条件外，我们认为原有的数据有更高的维数，我们可以在更高的维度空间中做PCA分析（即在更高维里，把原始数据向不同方向进行投影） 我们拿到样本点，需要将它映射到高维空间中，然后使用PCA算法进行降维。 假定我们将在高维特征空间中把数据投影到由W确定的超平面上，即PCA欲求解$(\sum\limits_{i=1}^m)\vec(W)=\lambda \vec{W}$ （拉格朗日乘子法） 其中$z_i$是样本点在高维特征空间的像，有$\vec{W}=\sum\limits_{i=1}^m z_i \alpha _i$ $\alpha_i=\frac{1}{\lambda}z_i^T \vec{W}$ z是由原始属性空间中的样本点x通过映射$\phi$产生。但是在映射到高维空间这一步，一般情况下，我们并不知道映射函数$phi$的具体形，不知道要映射到哪重维度上，于是引入核函数$\kappa(x_i,x_j)=\phi(x_i)^T\phi(x_j)$ 化简式子：$KA=\lambda A$，K为$\kappa$对应核矩阵，$A=(\alpha_1;\alpha_2;…;\alpha_m)$ 上式是特征值分解问题，取K对应的最大的d个特征值对应的特征向量。 对于新样本x，投影的第j维坐标为$z_j=\omega_j^T \phi(x)=\sum\limits_{i=1}^m \alpha_i^j \kappa(x_i,x)$ 流形学习流形是一类借鉴了拓扑流形概念的降维方法，在局部有欧式空间的性质，能用欧式距离来进行距离计算。 若低维流形嵌入到高维空间中，则数据样本在高维空间的分布虽然看上去非常复杂，但在局部上仍具有欧式空间的性质。因此可以容易的在局部建立降维映射关系，然后再设法将局部映射关系推广到全局。 等度量映射等度量映射（Isometric Mapping）认为低维流形嵌入到高维空间后，直接在高维空间中计算直线距离具有误导性，因为高维空间中的直线距离往往在低维嵌入流形上是不可达的。 对每个点基于欧式距离找出其近邻点，然后就能建立一个近邻连接图，图中近邻点之间存在连接，而非近邻之间不存在连接，于是计算两点间测地线距离的问题，转变为了计算近邻点之间最短路径问题。 步骤： 确定$x_i$的k近邻，并将$x_i$与k近邻之间的距离设置为欧氏距离，与其他点的距离设置为无穷大 调用最短路径算法计算任意来那个样本之间的距离$dist(x_i,dist_j)$ 将$dist(x_i,dist_j)$作为MDS算法的输入求解 局部线性嵌入局部线性嵌入（Locally Linear Embedding，LEE）试图保持邻域内样本之间的线性关系。假定样本点$x_i$的坐标能通过他的邻域样本$x_j,x_k,x_l$的坐标通过线性组合组成，$x_i=w_{ij}x_j+w_{ik}x_k+w_{il}x_l$ LLE希望关系在低维空间中得以保持。 LLE算法的主要原理就是先在高维空间，计算出相应的重构系数序列$W={w_1,w_2,…,_m}$，随后在低维空间中通过相同的重构系数获取投影点。 令$Z=(z_1,z_2,…,z_m) \in R^{d^. \times m}$ $M = (I-W)^T(I-W)$则寻求最小化：$\min\limits_z tr(ZMZ^T)$，约束条件$ZZ^T=I$ 上式通过特征值分解，M最小的$d^.$个特征值对应的特征向量组成的矩阵就是$Z^T$，即在低维的投影 度量学习对两个d维样本$x_i x_j$，他们之间的平方欧式距离可写为：$dist^2(x_i,x_j)=dist_{ij,1}^2+dist_{ij,2}^2+…+dist_{ij,d}^2$ 其中$dist_{ij,k}$表示$x_i,x_j$在第k维上的距离，若嘉定不同属性的重要程度不一样，可以引入属性权重$\omega$ $dist^2(w_i,x_j)=\omega_1\cdot dist_{ij,1}^2+\omega_2\cdot dist_{ij,2}^2+…+\omega_d\cdot dist_{ij,d}^2=(x_i-x_j)^T W(x_i-x_j)$ 其中$\omega_i \geq 0,W=diag(\omega)$是一个对角矩阵 W是对角矩阵，坐标轴正交，属性之间无关；然而现实中并不是这样将W图换位一个普通的半正定对称矩阵M，得到马氏距离。 其中M称作“度量矩阵”，而度量学习是对M进行学习。M必须是正定对称的，即必有正交基P使得M能写成$M=PP^T$ 对M的学习，我们需要把M直接嵌入到需要提高效率的评价指标中，通过优化指标求得M]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聚类]]></title>
    <url>%2F2017%2F03%2F08%2Fml-clustering%2F</url>
    <content type="text"><![CDATA[机器学习可以根据样本是否有标签分类为有监督学习与无监督学习，前面介绍的基本都是有监督学习。无监督学习中，目标通过对无标记训练样本的学习来揭示数据的内在性质及规律。 聚类试图将数据集中的样本划分为若干个通常不相交的子集，每个子集称为一个簇（cluster）。通过这样的划分，每个簇可能对应与一些潜在的类别。这些类别两两不相交，并起来是整个数据集，聚类的结果就是产生一个标签结果序列。 性能度量对聚类来讲，我们需要通过某种性能来评估聚类效果的好坏；若明确了最终要使用的性能度量，可以直接将其作为聚类过程的优化目标。 聚类性能度量大致有两类，一类是将聚类结果与某个参考模型进行比较，称为外部指标；另一类是直接考察聚类结果而不利用任何参考模型，称为内部指标。 外部指标对数据集$D={x_1,x_2,…,x_m}$，假定通过聚类给出额簇划分为$C={C_1,C_2,…,C_k}$，参考模型给出的簇划分为$C^`={C_1^T,C_2^T,…,C_s^T}$。相应的，令$\lambda$与$\lambda^T$分别表示与C和$C^T$对应的簇标记向量。注意的是，参考模型给出的划分类别数量不一定等于通过聚类得到的数量。 样本两两配对： $a=\mid SS \mid ,SS={(x_i,x_j)\mid \lambda_i = \lambda_j,\lambda_i^T=\lambda_j^T,i&lt;j}$ $b=\mid SS \mid ,SD={(x_i,x_j)\mid \lambda_i = \lambda_j,\lambda_i^T\neq \lambda_j^T,i&lt;j}$ $c=\mid SS \mid ,DS={(x_i,x_j)\mid \lambda_i \neq \lambda_j,\lambda_i^T=\lambda_j^T,i&lt;j}$ $a=\mid SS \mid ,DD={(x_i,x_j)\mid \lambda_i \neq \lambda_j,\lambda_i^T \neq \lambda_j^T,i&lt;j}$ 集合SS包含了C中隶属于相同簇且在$C^`$中也隶属于相同簇的样本对，集合SD包含了在C中隶属于相同簇但在$C^T$中隶属于不同簇的样本对 Jaccard系数：$JC=\frac{a}{a+b+c}$ FM指数：$FMI=\sqrt{\frac{a}{a+b}\frac{a}{a+c}}$ Rand指数：$RI=\frac{2(a+d)}{m(m-1)}$ 上述性能度量的结果值均在[0,1]区间，值越大越好。 内部指标考虑聚类结果的簇划分$C={C_1,C_2,…,C_k}$，定义 $avg(C)=\frac{2}{\mid C \mid(\mid C \mid -1)}\sum_{1 \leq i &lt; j \leq \mid C \mid}dist(x_i,x_j)$ $diam(C)=\max_{1 \leq i &lt;j \leq \mid C \mid}dist(x_i,x_j)$; $d_\min(C_i,C_j)=\min_{x_i \in C_i , x_j \in C_j} dist(x_i,x_j)$ $d_cen(C_i,C_j)=dist(\mu_i,\mu_j)$ 上面的式子中，dist计算两个样本之间的距离；$\mu$代表簇的中心点$\mu=\frac{\sum_{1 \leq i \leq \mid C \mid x_i}}{\mid C \mid}$；avg(C)uiying与簇内样本间的平均距离，diam(C)对应与簇C内样本间的最远距离，$d_min(C_i,Cj)$对应与簇i和簇j最近样本间的距离；$d{cen}(C_i,C_j)$对应与簇i和j中心点间的距离。 基于上面的指标，推出下面几个内部指标： $DBI=\frac{1}{k}\sum\limits_{i=1}^k\max\limits_{j \neq i}(\frac{avg(C_i)+avg(C_j)}{d_{cen}(\mu_i,\mu_j)})$ $DI=\min\limits_{1 \leq i \leq k}{ \min\limits_{j \neq i}(\frac{d_{min}(C_i,C_j)}{\max_{1\leq l \leq k diam(C_l)}}) }$ 显然，DBI的值越小越好，DI值越大越好 距离计算在讨论距离计算的时候，属性是否定义了”序”关系很重要。例如定义域为${ 1,2,3 }$能直接在属性值上计算距离，这样的属性成为有序属性；而定义域为{ 飞机、火车、轮船 }这样的离散属性则不能直接在属性值上计算距离，称为无序属性。 对有序属性的距离计算，通常使用Minkowski distance：$dist_{mk}(x_i,x_j)=(\sum\limits_{u=1}^n \mid x_{iu}-x_{ju} \mid^p)^{\frac{1}{p}}$ 对无需属性采用VDM算式：$VDM_p(a,b)=\sum\limits_{i=1}^k\mid \frac{m_{u,a,i}}{m_{u,a}}-\frac{m_{u,b,i}}{m_u,b} \mid ^p$ 其中$m_{u,a} m_{u,a,i}$分别表示在属性u上取值a的样本数以及在第i个样本簇中属性u上取值为a的样本数。k为样本簇数 混合处理，假定有$n_c$个有序属性以及$n-n_c$个无序属性： $MinkorDM_p(x_i,x_j)=(\sum\limits_{u=1}^{n_c}\mid x_{iu}-x_{ju} \mid ^p +\sum\limits_{u=n_c+1}^n VDM_p(x_{iu},x_{ju}))^{\frac{1}{p}}$ 属性重要性不同时，可以加权处理 原型聚类原型聚类算法假设聚类结构能够通过一组原型刻画，通常情况下算法先对原型进行初始化，然后对原型进行迭代更新。 k均值算法给定样本集$D={x_1,x_2,…,x_m}$，k均值算法针对聚类所得簇划分${ C_1,C_2,…,C_k }$最小化平方误差。$E=\sum\limits_{i=1}^k\sum\limits_{x \in C_i}\mid\mid x-\mu_i \mid\mid_2^2$ 其中$\mu_i=\frac{\sum_{x \in C_i}\vec{x}}{\mid C_i \mid}$是簇$C_i$的均值向量。上式在一定程度上刻画了簇内样本围绕簇均值向量的紧密吃呢孤独，E值越小则簇内样本相似度越高。k均值采用贪心策略，通过迭代优化来近似求解上式。 学习向量量化学习向量量化（LVQ）试图找到一组原型向量来刻画聚类结构，它假设数据样本带有类别标记，学习过程利用样本的这些监督信息来辅助聚类。 算法首先对原型向量进行优化，然后对原型向量进行迭代优化。在每一轮的迭代中，算法随机选取一个有标记训练样本，找出与其距离最近的原型向量，并根据两者的类别标记是否一致来对原型向量进行更新。 在更新原型向量上，对样本$x_i$，若最近的原型向量$p_i$与$x_j$的类别标记相同，则令$p_i$向$x_j$方向靠拢；否则更新原型向量与$x_j$之间距离增大，远离$x_j$ 高斯混合聚类统计学习的模型有两种，一种是概率模型，一种是非概率模型。所谓概率模型，是指训练模型的形式是P(Y|X)。输入是X，输出是Y，训练后模型得到的输出不是一个具体的值，而是一系列的概率值（对应于分类问题来说，就是输入X对应于各个不同Y（类）的概率），然后我们选取概率最大的那个类作为判决对象（软分类–soft assignment）。所谓非概率模型，是指训练模型是一个决策函数Y=f(X)，输入数据X是多少就可以投影得到唯一的Y，即判决结果（硬分类–hard assignment）。 高斯混合模型GMM就是指对样本的概率密度分布进行估计，而估计采用的模型（训练模型）就是几个高斯模型的加权和。每个高斯模型代表一个聚类。对样本中的数据分别在几个高斯模型上进行投影，就会分别得到在各个类上的概率，选取概率最大的类作为判决结果。 理论上可以通过增加模型的数量，用GMM近似任何概率分布 混合高斯模型定义：$p(x)=\sum_{k=1}^k \pi_kp(x \mid k)$ 其中k为模型的个数；$\pi_k$为第k个高斯的权重；$p(x\mid k)$则为第k个高斯概率密度，其均值为$\mu_k$，方差为$\theta_k$。对此概率密度的估计就是要求出$\pi_k,\mu_k,\theta_k$。当求出p(x)的表达式后，求和式的各项的结果就分别代表样本x属于各个类的概率。 在做参数估计的时候，常采用的是最大似然方法。最大似然法就是使样本点在估计的概率密度函数上的概率值最大。由于概率值一般都很小，N 很大的时候, 连乘的结果非常小，容易造成浮点数下溢。所以我们通常取log，将目标改写成：$\max\sum\limits_{i=1}^N log(\sum\limits_{k=1}^K\pi_kN(x_i \mid \mu_k,\theta_k))$ 一般用来做参数估计的时候，我们都是通过对待求变量进行求导来求极值，在上式中，log函数中又有求和，你想用求导的方法算的话方程组将会非常复杂，没有闭合解。可以采用的求解方法是EM算法——将求解分为两步：第一步,假设知道各个高斯模型的参数（可以初始化一个，或者基于上一步迭代结果），去估计每个高斯模型的权值；第二步,基于估计的权值，回过头再去确定高斯模型的参数。重复这两个步骤，直到波动很小，近似达到极值（注意这里是极值不是最值，EM算法会陷入局部最优）。具体表达如下： E：对滴i个样本$x_i$来说，它由第k个模型生成的概率为：$\vec{w_i}(k)=\frac{\pi_kN(x_i \mid \mu_k,\theta_k)}{\sum\limits_{j=1}^K \pi_jN(x_i \mid \mu_j,\theta_j)}$ 在这一步，假设高斯模型的参数是已知的，有上一步迭代而来或者由初始值决定 M：得到每个点的生成概率以后，对样本$x_i$来说，他的$\vec{w}_i(k)x_i$的值是由第k个高斯模型产生的。换句话说，第k个高斯模型很产生了$\vec{w}_i(k)x_i(i=1……N)$这些数据。这样在估计第k个高斯模型参数时，我们就用$\vec{w}_i(k)x_i(i=1……N)$这些数据去做参数估计： $\mu_k=\frac{\sum\limits_{i=1}^N \vec{w}_i (k)x_i}{N}$ $\theta_k=\frac{\sum\limits_{i=1}^N\vec{w}_i(k)(x_i-\mu_k)(x_i-\mu_k)^T}{N_k}$ $N_k=\sum\limits_{i=1}^N\vec{w}_i(k)$ 重复E和M知道算法收敛 密度聚类 $\epsilon$邻域：对象O的是与O为中心，$\epsilon$为半径的空间，参数$\epsilon &gt; 0$，是用户指定每个对象的领域半径值。 MinPts（领域密度阀值）：对象的$\epsilon$邻域的对象数量。 核心对象：如果对象O的$\epsilon$邻域对象数量至少包含MinPts个对象，则该对象是核心对象。 直接密度可达：如果对象p在核心对象q的$\epsilon$邻域内，则p是从q直接密度可达的。 密度可达：在DBSCAN中，p是从q(核心对象)密度可达的，如果存在对象链$(p_1,p_2,…,p_n)$，使得$p_1=x_i,p_n=x_j$,且有$p_{i+1}$由$p_i$直接密度直达 密度相连：对$x_i$和$x_j$，若存在$x_k$使得$x_i,x_j$均由$x_k$密度可达，则两者密度相连。 DBSCAN算法先任选数据集中的一个核心对象为种子，再由此出发确定相应的聚类簇。具体的，现根据给定的邻域参数$(\epsilon,MinPys)$找出所有的核心对象；然后以任意核心对象为出发点，找出由其密度可达的样本生成聚类簇，知道所有核心对象均被访问过为止。 层次聚类层次聚类试图在不同层次对数据集进行划分，从而形成树形的聚类结构。数据集的划分可采用自底向上的聚合策略，也可选择自顶下下的分析策略。 AGNES是一种自底向上聚合策略的层次聚合算法。他先将数据集合中每个样本看作一个初始聚类簇，然后再算法运行的每一步中找出距离最近的两个聚类簇合并，该过程不断重复，直至达到预设的聚类簇个数。 算法的关键是如何找到最近的两个聚类簇，然后不断的进行合并。给定聚类簇$C_i$和$C_j$，通过下面的式子计算距离： 最小距离： $d_min(C_i,C_j)=\min\limits_{x \in C_,z \in C_j} dist(x,z)$ 最大距离： $d_max(C_i,C_j)=\max\limits_{x \in C_,z \in C_j} dist(x,z)$ 平均距离： $d_avg(C_i,C_j)=\frac{\sum\limits_{x \in C_i}\sum\limits_{z \in C_j}dist(x,z)}{\mid C_i \mid \mid C_j \mid}$ 当使用不同的距离公式作为算法的因数时，算法分别被称为单链接，全连接以及均链接。算法首先对仅含一个样本样本的初始聚类簇和相应的距离矩阵进行初始化；然后不断合并距离最近的聚类簇，并对合并得到的新聚类簇距离矩阵进行更新；不断重复，直到聚类簇数量减少到预设目标。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集成学习]]></title>
    <url>%2F2017%2F03%2F07%2Fml-integration%2F</url>
    <content type="text"><![CDATA[个体集成集成学习通过构建并结合多个学习器来完成学习任务，先产生一组个体学习器，再用某种策略把他们结合起来。个体学习器通常由一个现有的学习算法从训练数据产生。 同质集成：个体全是相同类型的学习器，称为基学习器 异质集成：个体可以是不同的学习器，称为组件学习器 根据个体学习器的生成方式，目前的集成学习方法大致分为两大类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法Boosting；以及不存在强依赖关系，可同时生成的并行化方法Bagging和随机森林。 欲构建泛化能力强的集成，getInstance学习器应该好而不同。 Boosting先从初始训练集中训练一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注。然后基于调整后的样本分布来训练下一个基学习器，如此重复进行，直至基学习器数目达到事先制定的值T，最终将这T个基学习器进行加权结合。 AdaBoost假设训练数据集具有均匀的权值分布，即每个训练样本在基本分类器的学习中作用相同。 AdaBoost反复学习基本分类器，在每一轮,=1,2,…,M顺次的执行下面的操作： 使用当前分布$D_m$加权的训练数据集，学习基本分类器$G_m(x)$ 计算基本分类器$G_m(x)$在加权训练数据集上的分类误差率：$e_m=p(G_m(x_i) \neq y_i)=\sum\limits_{G_m(x_i)\neq y_i}\omega_{mi}$ 这里，$\omega_{mi}$表示第m轮中第i个实例的权值，$\sum\limits_{i=1}^N\omega_{mi}=1$ 计算基本分类器$G_m(x)$的系数$\alpha_m$表示$G_m(x)$在最终分类器中的重要性。当上面计算的$e_m \leq \frac{1}{2}$时，$\alpha \geq 0$，并且随着分类误差的减小增大，所以分类误差率越小的基本分类器在最终分类器中的作用越大 更新训练数据的权值分布为下一轮做准备,被基本分类器$G_m(x)$误分类样本的权值得到扩大，所以误分类样本在下一轮学习中起更大更大作用 最后通过线性组合实现M个基本分类器的加权表决，$\alpha_m$表示了基本分类器的重要性 并行化方法BaggingBagging基于自助取样法，给定包含m个样本的数据集，先随机取出一个样本放入采样集中，在吧该样本放回到初始数据集合中，使得下次采样时候仍有可能被选中。经过m次随机采样操作，得到含有m个样本的采样集。 根据上面的自助采样方法，我们得到T个含有m个训练样本（m个训练样本很有可能有重复的），然后基于每个采样集训练一个基学习器。在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务使用简单平均法。若分类预测出现同样票数情况，可以随机选择一个。 随机森林随机森林（Random Forest，RF）是Bagging的一个变体。RF在以决策树为基学习器构建Bagging的基础上，进一步在决策树的训练过程中引入了随机属性选择。 传统决策树在选择划分属性时是在当前节点的属性集合（假定有d个属性中选择一个最优属性），而在RF中对基决策树的每个节点，先从该节点的属性集合中随机选择一个包含k属性的子集，然后再从这个子集中选择一个最优属性用于划分。k决定了随机性，一般推荐$k=log_2 d$]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贝叶斯Bayesian]]></title>
    <url>%2F2017%2F03%2F06%2Fml-intro7%2F</url>
    <content type="text"><![CDATA[贝叶斯决策论在相关概率已知的情况下，贝叶斯决策论考虑如何基于这些概率和误判损失选择最优的类别标记。 假设有N中可能的类别标记${c_1,c_2,c_3,…,c_N}, \lambda_{ij}$是将一个真实标记为$c_j$的样本误分类为i产生的损失。推出来样本x分类为$c_i$所产生的期望损失： $R(c_i \mid x)=\sum\limits_{j=1}^N \lambda_{ij}P(c_j \mid x)$ 显然对每个样本x，若能最小化条件风险$R(h(x)\mid x)$，即在每个样本上选择那个使条件风险$R(c\mid x)$最小的类别标记，总体风险R(h)也将最小化。 $h^{*}(x)=arg_{c in y}\min R(c\mid x)$ 此时$h^$称为贝叶斯最优分类器，与之对应的总体风险$R(h^)$称为贝叶斯风险。$1-R(h^*)$反映了分类器能达到的理论上限。 若目标是最小化分类错误率，则误判损失$\lambda_{ij}$可写为：$\lambda_{ij} =0 if i==j else 1$ 此时的条件风险：$R(c \mid x)=1-P(c \mid x)$，于是最小化分类错误率的贝叶斯最优分类器为$h^*(x)=arg_{c \in y}\max P(c \mid x)$ 这里有两种策略估计后验概率$P(c \mid x)$： 给定x，直接建模$P(c \mid x)$预测c，这种判别式模型，之前介绍的决策树、神经网络、SVM都可行 对联合分布P(x,c)建模，之后获得$P(c \mid x)$，这种生成式建模 $P(c \mid x)=\frac{P(c)P(x \mid c)}{P()x}$ 上式，其中$P(c)$是累先验概率，也就是预估概率；$P(x \mid c)$是样本x相对于类标记c的类条件概率，也称为似然likelihood；$P(x)$是用于归一化的证据因子。对于给定样本x，证据因子$P(x)$与类标记无关。 类先验概率$P(c)$表达了样本空间中各类样本所占的比例；当训练集中包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率估计。 极大似然估计估计类条件概率的一种常用策略就是先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。 具体到上节的类条件概率上，记关于类别c的类条件概率为$P(x \mid c)$，假定$P(x \mid c)$具有确定的形式并且被参数向量$\theta_c$唯一确定，则我们的任务就是利用训练集D估计参数$\theta_c$。此时我们记$P(x \mid c)$为$P(x \mid \theta_c)$ 朴素贝叶斯分类器基于贝叶斯公式来估计后验概率$P(c \mid x)$的主要困难在于累条件概率$P(x \mid c)$是所有属性上的联合概率，难以从有限的训练样本直接估计得到。 为了避开这个障碍，朴素贝叶斯分类采用属性条件独立性假设：对已知类别假设所有的属性相互独立。 $P(c \mid x)=\frac{P(c)P(x \mid c)}{P(x)}=\frac{P(c)}{P(x)}\prod\limits_{i=1}^dP(x_i \mid c)$ 其中d为属性数目，$x_i$为x在第i个属性上的取值。 由于对所有的类别来讲$P(x)$相同，因此贝叶斯判定准则有$h_{nb}=arg\max\limits_{c \in y}P(c)\prod\limits_{i=1}^dP(x_i \mid c)$ 显然朴素贝叶斯分类器的训练过程就是基于训练集D来估计类先验概率P(c)，并为ie每个属性估计条件概率$p(x_i \mid c)$ 小例子令$D_c$表示训练集D中第c类样本组成的集合，若有充足的独立同分布样本，则可以容易的估计出类先验概率：$P(c)=\frac{\mid D_c \mid}{\mid D \mid}$ 对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第i个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i \mid c)$可以估计为：$P(x_i \mid c)=\frac{\mid D_{c,x_i} \mid}{\mid D_c \mid}$ 对于连续属性，假定$p(x_i \mid c) \sim N(\mu_{c,i},\theta_{c,i}^2)$,其中$\mu_{c,i}$和$\theta_{c,i}^2$分别是第c类样本在第i个属性上取指的均值和方差。$p(x_i \mid c)=\frac{exp^({-\frac{(x_i-\mu_{c,i})^2}{2\theta_{c,i}^2}})}{\sqrt{2\pi}\theta_{c,i}}$ 拉普拉斯修正如果某个属性在训练集中没有与某个类同时出现过，则直接使用上式判别将出现问题。具体表现在连乘过程中，一个变量为0，则整个式子都为0.为了避免这种情况的发生，使用拉普拉丝修正：$\hat{P(c)}=\frac{\mid D_c \mid+1}{\mid D \mid+N}$，条件概率修正为$\hat{P}(x_i \mid c)=\frac{\mid D_{c,x_i} \mid+1}{\mid D_c \mid+N_i}$ 半朴素贝叶斯放宽朴素贝叶斯分类中对属性条件独立性的要求，使得贝叶斯更加的普适性，人们在朴素贝叶斯的基础上提出了半朴素贝叶斯。 半朴素贝叶斯适当的考虑一部分属性间的相互依赖关系，从而不至于彻底忽略比较强的属性依赖；但是为了避免问题陷入到复杂的联合概率计算中，一般会对属性依赖的数量有要求。 假定只能最多一个依赖关系，也就是”独依赖估计”：$P(c\mid x) \propto P(c)\prod\limits_{i=1}^dP(x_i \mid c,pa_i) $ 其中$pa_i$为属性$x_i$所依赖的属性，称为$x_i$的父属性。若每个属性的父属性都已知，则可直接使用之前的公式求解；否则我们需要确定每个属性的父属性。 上图是朴素贝叶斯（独、无依赖立）以及两种常见的半贝叶斯（独依赖）：SPODE（SUper Parent ODE）和TAN（Tree Augmented naive Bayes） SPODE中有一个超属性，属性如果有依赖，则都依赖到此属性上面； TAN则是在最大带权生成树算法基础上通过转换将依赖结构化简。 AODE（Averaged One Dependent Estimator）尝试将每个属性作为超父来构建SPODE，然后将那些有足够训练数据支撑的SPODE继承起来作为最终结果。 贝叶斯网贝叶斯网B由结构G和参数$\Theta$两部分组成，即$B=\langle F,\Theta \rangle$。网络结构G是一个有向无环图，每个节点对应一个属性，若两个属性有直接的依赖关系，则由一条边连接起来；参数$\Theta$定量的描述依赖关系。例如属性$x_i$在G中的父节点集为$\pi_i$，则$\Theta$包含了每个属性的条件概率表$\theta_{x_i \mid \pi_i}=P_B(x_i \mid \pi_i)$ 贝叶斯网有效的表达了属性间的条件独立性。给定父节点集合，贝叶斯网假设每个属性与它的非后裔属性独立。 学习正常情况下，我们并不知晓网络结构，需要通过学习方法建立或匹配上适当的网络结构。 评分搜索：定义评分函数来评估贝叶斯网与训练数据的契合程度，然后基于这个评分函数来寻找结构最优的贝叶斯网。 EM算法对于不完整的训练样本，或者说是未观测的变量，学名是隐变量：令X表示已观测变量集，Z表示隐变量集，$\Theta$表示模型参数 对$\Theta$做极大似然估计，则最大化对数似然$LL(\Theta \mid X,Z)=ln P(X,Z\mid \Theta)$ 无法直接求解的隐变量，通过对Z计算期望，最大化已观测数据的对数“边际似然” EM算法是常用的估计参数隐变量的迭代方法： （E）若参数$\Theta$已知，则可根据训练数据推断出最优隐变量Z的值 （M）反之做Z值已知，可方便的对参数$\Theta$做极大似然估计 以初始值$\Theta^0$迭代步骤： 基于$\Theta^t$推断隐变量Z的期望记为$Z^t$ 基于已观测变量X和$Z^t$对参数$\Theta$做极大似然估计，记为$\Theta^{t+1}$]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ML学习-SVM]]></title>
    <url>%2F2017%2F03%2F05%2Fml-intro6%2F</url>
    <content type="text"><![CDATA[支持向量机（Support Vector Machine）的求解通常是借助凸优化技术。 间隔与支持向量给定训练样本集$D={(x_1,y_1),(x_2,y_2),…,(x_m,y_m)},y_i \in (-1,+1 )$ 分类学习最基本的思想就是基于训练集D在样本空间中找到一个划分超平面，将不同类别的样本分开。SVM就是帮助我们寻找到众多划分超平面中最符合的。怎样定义符合这个指标呢，作为分类问题，训练中能够尽可能划分出不同类别的样本是基本，然后在测试集中也能表现出来很好的分类能力，对未见示例泛化能力最强。在训练中表现的就是对训练样本局部扰动容忍度最高。 公式表示划分超平面可以用此式表示： $\vec{\omega}^T \vec{x} + b=0$ 其中$\vec{\omega}=(\omega_1;\omega_2;…;\omega_d)$为法向量，决定了超平面的方向；b为位向量，决定了超平面与原点之间的距离。 样本空间中任意点到超平面x到超平面$(\vec{\omega},b)$的距离可写为： $r=\frac{\mid\vec{\omega}^T \vec{x}+b\mid}{\mid\mid \vec{\omega}\mid\mid}$ 设置函数： $\omega^T x_i + b \geq +1 , y_i= +1$ $\omega^T x_i + b \leq -1 , y_i= -1$ 简化两个式子： $y_i(\omega^T x_i +b) \geq 1 , i=1,2,…,m$这个是之后式子的约束条件 距离超平面最近的几个训练样本点使得上面的不等式等号成立，它们被称为支持向量(support vector)，两个异类支持向量到超平面的距离之和称为间隔(margin) $\gamma = \frac{2}{\omega}$ 为了使得间隔最大，也就是求$\max\limits_{w,b} \frac{2}{\mid\mid \omega \mid\mid}$ 转换为$\min\limits_{w,b}\frac{\mid\mid \omega \mid\mid^2}{2}$ 这就是支持向量机 对偶问题模型$f(x)=\vec{\omega}^T \vec{x}+b$，参数$\omega b$是模型参数。而$\min\limits_{w,b}\frac{\mid\mid \omega \mid\mid^2}{2}$是一个凸二次规划，除了使用现成的优化计算包外，我们可以使用数学上的对偶关系更高效的求出结果。 对这个凸二次规划式子添加拉格朗日乘子$\alpha \geq 0$，则问题的拉格朗日函数可写为： $L(\vec{\omega},b,\vec{\alpha})=\frac{1}{2}\mid\mid \omega \mid\mid^2+\sum\limits_{i=1}^m\alpha_i(1-y_i(\omega^Tx_i+b))$ 令L对$\omega b$的偏导为零可得： $\omega=\sum\limits_{i=1}^m \alpha_iy_ix_i$ $0=\sum\limits_{i=1}^m\alpha_iy_i$ 式1代入拉格朗日式子，式2作为约束函数，得到上一小节式子的对偶问题： $\max\limits_{\alpha} \sum_{i=1}^m\alpha_i-\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m \alpha_i \alpha_j y_i y_jx_i^T x_j$ 约束条件：$\sum\limits_{i=1}^m\alpha_iy_i=0$ 上式是南教授《机器学习》书中记录的式子，这里认为下面式子可能更好理解 $\max\limits_{\alpha} \sum_{i=1}^m\alpha_i+\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m \alpha_i \alpha_j y_i y_jx_i^T x_j$ 从上式解出$\vec{\alpha}$之后，求出$\vec{\omega}$和b即可得到模型： $f(\vec{x})=\vec{\omega}^T\vec{x}+b=\sum\limits_{i=1}^m \alpha_iy_ix_i^T\vec{x}+b$ 支持向量机一个极其重要的特性就是：训练完成后，大部分的训练样本不需要保存，最终模型仅与支持向量有关。上式是一个二次规划问题，求解的高效办法是使用SMO。 使用SMO求解SMO(Sequential Minimal Optimization)基本思路：固定$\alpha_i$之外的所有参数，然后求$\alpha_i$上的极值。 具体到这个问题，由于存在约束条件$\sum\limits_{i=1}^m\alpha_iy_i=0$，固定$\alpha$之外的值，则$\alpha$值都能导出。所以采用了部分的调整，每次固定两个变量$\alpha_i \alpha_j$之外的其余参数，之后不断执行下述步骤直到收敛： 选取一对需要更新的变量$\alpha_i \alpha_j$ 固定其余参数，求解上个小结推导出的式子更新$\alpha_i \alpha_j$ 对于两个需要更新参数$\alpha_i$和$\alpha_j$的选取，遵循一个规则，使选取的两变量所对应样本之间的间隔最大。 核函数这个部分解决不能线性可分问题。 这类问题，一般是将样本从原始空间映射到更高维的特征空间，使得样本在高维度空间中线性可分。 引出令$\phi(\vec{x})$表示将$\vec{x}$映射后的特征向量，于是在特征空间中划分超平面对应的模型可以表示为： $f(\vec{x})=\omega^T \phi(\vec{x})+b$ 类似在线性可分情况下的式子： $\min\limits_{\vec{w},b} \frac{\mid\mid \vec{\omega} \mid\mid^2}{2}$ 约束条件： $y_i(\vec{\omega}^T \phi(x_i)+b) \geq 1, i=1,2,…,m$ 对偶问题： $\max\limits_{\alpha} \sum\limits_{i=1}^m\alpha_i-\frac{1}{2}\sum\limits_{i=1}^m\sum\limits_{j=1}^m \alpha_i\alpha_jy_iy_j \phi(x_i)^T\phi(x_j)$ 约束条件：$\sum\limits_{i=1}^m \alpha_i y_i =0$ 关键问题$\phi(x_i)^T\phi(x_j)$是映射到特征空间之后的内积。由于维度太高不易计算，构造这样的函数： $\kappa(\vec{x}_i,\vec{x}_j)=\langle \phi(x_i),\phi(x_j) \rangle = \phi(x_i)^T\phi(x_j)$ 原式求解得到： $f(\vec{x})=\vec{\omega}^T\phi(\vec{x})+b$ $=\sum\limits_{i=1}^m\alpha_iy_i\phi(x_i)^T\phi(x)+b$ $=\sum\limits_{i=1}^m\alpha_iy_i\kappa(x,x_i)+b$ 这里的\kappa就是核函数。 核函数组合 $\kappa_1$和$\kappa_2$都是核函数，则对于任意正数$\gamma_1$和$\gamma_2$的线性组合:$\gamma_1\kappa_1 + \gamma_2\kappa_2$ 核函数的内积： $\kappa_1 \bigotimes \kappa_2(\vec{x},\vec{z})=\kappa_1(\vec{x},\vec{z})\kappa_2(\vec{x},\vec{z})$ 对于任意函数$g(x)$，$\kappa(\vec{x},\vec{z})=g(x)\kappa_1(\vec{x},\vec{z})g(z)$ 都是核函数 软间隔为了缓解某些连核函数都无法有效处理的分类问题，需要允许SVM在一些样本上出错，即允许某些样本不满足约束$y_i(\vec{w}^Tx_i+b) \geq 1$，引入了软间隔概念。 优化目标可以修改为： $\min\limits{\vec{\omega},b}\frac{\mid\mid \omega \mid\mid^2}{2}+C\sum\limits_{i=1}^m\ell_{0/1}(y_i(\vec{\omega}^Tx_i+b)-1)$ 其中$C &gt; 0$是一个常数，$\ell_{0/1}$是”0/1损失函数” $\ell_{0/1}(z) = 1 if z&lt;0 else 0$ 当C无穷大时，所有样本均需要满足约束，等价于前面小结的式子；C为可数实数，则允许样本不满足约束 为了使得$\ell$容易求导，通常使用下面几个数学性质较好的式子替代： 代入原式，然后使用松弛变量$\xi_i \geq 0$，松弛变量$\xi$替换原来C后面的部分，表示样本不满足约束的程度。 使用之前介绍的对偶问题求解出最终的答案。 支持向量回归支持向量回归（Support Vector Regression）假设我们能够容忍f(x)与y之间最多有$\epsilon$的误差，即仅当f(x)与y之间差别的绝对值大于$\epsilon$时才算损失。 相当于以f(x)为中心，构建了一个宽度为$2\epsilon$的间隔带，落在带内的样本是正确的。 SVR问题可用式子表示： $\min\limits{\vec{\omega},b}\frac{\mid\mid \omega \mid\mid^2}{2}+C\sum\limits_{i=1}^m\ell_{\epsilon}(f(x_i-y_i))$ 其中$\ell_{\epsilon}$：$\ell_{\epsilon} ==0 if \mid z\mid \leq \epsilon else (\mid z \mid - \epsilon)$ 引入松弛变量$\xi_{i}$和$\hat{\xi_{i}}$，原式重写为$\min\limits_{\vec{\omega},b,\xi_{i},\hat{\xi_{i}}}\frac{\mid\mid \vec{\omega}\mid\mid^2}{2}+C\sum\limits_{i=1}^m(\xi_{i} + \hat{\xi_{i}})$ 引入拉格朗日乘子，求对偶问题 推导出带有核函数的算式]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ML学习-神经网络]]></title>
    <url>%2F2017%2F03%2F04%2Fml-intro5%2F</url>
    <content type="text"><![CDATA[神经元Neural Network神经网络：是由具有适应性的简单单元组成的广泛并进行互联的网络，他的组织能够模拟生物神经系统对真实的世界物体做出的交互反应 神经网络由一个个神经元（neuron）互联组成，神经元可以看作一个处理函数，当这个函数的输入超过某一个阈值，经过处理后单元会向其他单元发送信号。 单元的输入来自其他单元传递过来的信号，这些信号通过带权重的连接进行传递。当前单元接受来自其余单元的带权重的信号和与阈值比较，符合条件的产生输出。 感知机感知机由两层神经元组成，输入层接收外界输入信号后传递给输出层，输出层是阈值逻辑单元。 感知机通过简单的算术组合可以轻易的实现与或非逻辑运算。 实现逻辑类似于$y=f(\sum_i\omega_ix_i-\theta)$，其中w是权重向量，x是输入信号，$\theta$则是阈值。 阈值可看作是一个固定输入(x值)为-1的dummy node所对应的连接权重$\omega_{n+1}$，这样权重和阈值就可以统一学习。 学习规则 $\omega_i \leftarrow \omega_i + \Delta \omega_i$ $\Delta \omega_i = \eta(y-\hat{y})x_i$ 其中$\eta \in (0,1)$称为学习率。若感知机对训练样例(x,y)预测正确，即$\hat{y}=y$，则感知机不改变，否则将根据错误的程度进行权重调整。 非线性与多重神经元要解决非线性可分问题，需考虑多层功能神经元。例如异或问题。 一般的多层功能神经元都设置在输入层与输出层之间，也称作隐含层。每一层都有独立的激活函数功能神经元。功能更强大的神经网络：每层神经元与下一层神经元完全互联，而同层之间不存在连接，也不存在跨层连接。要注意的是，这里的相邻层连接是双向的。这种分类型的神经网络通常被称为”多层前馈神经网络”(multi-layer feedforward neural networks)这种网络的输入层的功能仅仅是接受输入，隐层以及输出层有功能神经元，进行函数处理。 学习过程神经网络就是根据训练数据来调整神经元之间的连接权以及每个功能神经元的阈值。 著名的BP算法就是神经网络一种训练学习算法。 BP误差逆传多层神经网络中最著名的学习算法就是BP误差逆传算法（erroe BackPropagation）。 BP算法可以训练包括多层前馈神经网络、递归神经网络等。 BP算法的目标是要最小化训练集D上的累计误差。作为一个迭代类型的算法，，迭代的每一轮采用广义的感机学习规则对参数进行更新估计。其中学习率$\eta \in (0,1)$控制着算法中每次迭代的更新步长，$\eta$太大容易造成迭代的震荡，太小则会影响收敛速度， 算法流程 将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果 计算输出层的误差，将误差逆向传播至隐层神经元 根据隐层神经元的误差对连接券和阈值进行调整 迭代，直到达到某个停止条件，如训练误差小于某个数值 以目标的负梯度方向为参数进行调整。分别计算出输出层、隐层的梯度以及对应的阈值bias，然后去更新神经元之间的权值和阈值。再进行输出层隐层的梯度。。。不断的循环，直到误差小于预设值。 对过拟合的策略由于BP算法强大的学习能力，经常会在训练集上过度学习造成过拟合现象，反而在测试集上的表现不好。通常可以采用”早停”策略：将数据集分为训练集和验证集，训练集用来计算梯度、更新连接权以及阈值，验证集则用来估计误差。训练集误差降低但验证集误差升高时，停止训练，同时返回具有最小验证集误差的连接权和阈值。 全局与局部用E表示神经网络在训练集上的误差，则E是关于连接权w和阈值$\theta$的函数，此时神经网络的训练过程可看作是一个参数的寻优过程，即在参数空间中找一组最优参数使得E最小。 直观的得看，局部最小解(local minimum)是参数空间中的某个点，它相邻的误差函数值均不小于该点的函数值； 全局最小解（global minimum）是指参数空间中所有的点误差函数值都不小于该店的误差函数值。 显然有全局最小解必然是局部最小解，反之未必。参数空间中梯度为零的点，其误差值小于临点的误差函数值，称为局部最小。 搜索方式根据梯度的值决定参数最优搜索的方向是最广泛的办法。例如负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索最优解。若误差函数在当前点的梯度为零，则已达到局部极小。 如果只有一个局部最小点，则为全局最小解。从局部最优找到全局最优的办法就是要从局部最优中挑出来，继续搜索下去。因为搜索到局部最优后，梯度为零，会造成搜索停滞。 取多组不同参数值初始化多个神经网络，取其中误差最小的解作为最终的参数。相当于从不同的初始值开始搜索猜测。 使用模拟退火法（在blog之前的文章中有介绍）。模拟退退火有一定的概率接受比当前解差的解，有助于跳出局部极小。而迭代过程，接受次优解的概率逐渐降低，从而保证了算法的稳定性。 随机梯度下降 其余常见的神经网络RBF网络单隐层前馈神经网络的一种，输出层是对隐层神经元还输出的线性组合。假定输入为d维向量$\vec{x}$输出为实值，可表示为： $\phi(x)=\sum_{i=1}^{q}\omega_i\rho(x,c_i)$ q为隐层神经元个数，$c_i$和$\omega_i$分别是第i个隐层神经元对应的中心和权重。$\rho(x,c_i)$是径向基函数，是某种沿径向对称的标量函数。通常定义为样本x到数据中心$c_i$之间的欧式距离的单调函数。 ART网络竞争学习(competitive learning)是神经网络中常用的无监督学习策略。 网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元状态被抑制。 SOM网络自组织映射，是一种竞争学习型的无监督神经网络。能将高位输入数据降维，同时保持输入数据的拓扑结构。即将高维空间中相似的样本点映射到网络输出层的邻近神经元。 在接受一个训练样本之后，每个输出层神经元会计算该样本与自身携带的权向量之间的距离，距离最近的神经元称为最佳匹配单元。然后调整最佳匹配单元及邻近神经元的权向量，使得这些权向量与当前输入样本距离缩小。这个过程不断迭代，知道收敛。 级连相关级联： 建立层次连接的层级结构。开始训练时，只有几本的输入输出层，随着训练的进行，新的隐层神经元逐渐加入。 相关： 通过最大化新神经元的输出与网络误差之间的相关性来训练相关的参数。 ElmanElman网络是递归神经网络（recurrent neural networks）的一种。递归神经网络可以让一些神经元的输出反馈作为输入信号。 深度学习深度学习的概念源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。 同机器学习方法一样，深度机器学习方法也有监督学习与无监督学习之分．不同的学习框架下建立的学习模型很是不同．例如，卷积神经网络（Convolutional neural networks，简称CNNs）就是一种深度的监督学习下的机器学习模型，而深度置信网（Deep Belief Nets，简称DBNs）就是一种无监督学习下的机器学习模型。 DBN每次训练一层隐节点，训练时将上一层隐节点的输出作为下一层隐节点的输入。整个网络完成后，再进程微调。 CNN节省训练开销的策略是”权共享”，让一组神经元使用相同的连接权。 无论是DBN还是CNN，其多隐层堆叠，每层对上层的处理机制，可以看作是对输入信号逐层加工，从而把初始的与输出目标联系不密切的输入转换呈密切。通过多层处理，逐渐的将初始的低层特征转转成高层特征表示，用简单模型完成复杂的分类任务。 CNN卷积神经网络在图像处理中，往往把图像表示为像素的向量，比如一个1000×1000的图像，可以表示为一个1000000的向量。在上一节中提到的神经网络中，如果隐含层数目与输入层一样，即也是1000000时，那么输入层到隐含层的参数数据为1000000×1000000=10^12，这样就太多了，基本没法训练。所以图像处理要想练成神经网络大法，必先减少参数加快速度。 卷积神经网络有两种神器可以降低参数数目。第一种神器叫做局部感知野。一般认为人对外界的认知是从局部到全局的，而图像的空间联系也是局部的像素联系较为紧密，而距离较远的像素相关性则较弱。因而，每个神经元其实没有必要对全局图像进行感知，只需要对局部进行感知，然后在更高层将局部的信息综合起来就得到了全局的信息。 在上右图中，假如每个神经元只和10×10个像素值相连，那么权值数据为1000000×100个参数，减少为原来的千分之一。而那10×10个像素值对应的10×10个参数，其实就相当于卷积操作。 第二级神器，即权值共享。在上面的局部连接中，每个神经元都对应100个参数，一共1000000个神经元，如果这1000000个神经元的100个参数都是相等的，那么参数数目就变为100了。 怎么理解权值共享呢？我们可以这100个参数（也就是卷积操作）看成是提取特征的方式，该方式与位置无关。这其中隐含的原理则是：图像的一部分的统计特性与其他部分是一样的。这也意味着我们在这一部分学习的特征也能用在另一部分上，所以对于这个图像上的所有位置，我们都能使用同样的学习特征。 更直观一些，当从一个大尺寸图像中随机选取一小块，比如说 8×8 作为样本，并且从这个小块样本中学习到了一些特征，这时我们可以把从这个 8×8 样本中学习到的特征作为探测器，应用到这个图像的任意地方中去。特别是，我们可以用从 8×8 样本中所学习到的特征跟原本的大尺寸图像作卷积，从而对这个大尺寸图像上的任一位置获得一个不同特征的激活值。 如下图所示，展示了一个33的卷积核在55的图像上做卷积的过程。每个卷积都是一种特征提取方式，就像一个筛子，将图像中符合条件（激活值越大越符合条件）的部分筛选出来。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ML学习-决策树]]></title>
    <url>%2F2017%2F03%2F04%2Fml-intro4%2F</url>
    <content type="text"><![CDATA[决策树（decision tree）是一种常见的机器学习方法。目标是生成一个具有强泛化能力的（对未遇到的样本有很高的适应性）树形结构。 决策树包含一个根结点，若干内部结点以及若干叶子结点。叶子结点对应了确定的判断结果，其余的结点都是一个个的属性测试，属性测试分成的不同情况就是当前结点的子结点。决策树是一个递归的过程。 决策树生成学习的过程中，最重要的就是如何选择最优的划分属性。一般而言，随着划分过程的不断进行，决策树分支结点包含的样本应该尽可能的靠近。 信息熵信息熵（information entropy）是度量样本集合纯度最常用的一种指标。假设当前样本集合D中第k类样本比例为$p_{k}$(k=1,2,3,…,|y|)$，则D的信息熵为 $Ent(D)=-\sum\limits_{k=1}^{|y|}p_{k=1}log_2p_{k}$ Ent(D)的值越小，则D的纯度越高. 信息增益 假定离散属性a有V个可能的取指{$a^1,a^2,…,a^V$},若使用a来对样本集合D进行划分，则会产生V个分支结点，其中第v个节点包含了D中所有在属性a上取指为$a^V$的样本，记为$D^v$。根据上师酸楚$D^v$的信息熵，然后考虑不同分支结点包含的样本数目不同，给分支结点赋予权重$|D^v|/|D|$，即样本越多，分支结点的影响越大，此时使用一个统一的计算公式算得属性啊对样本集D进行划分得到的”信息增益”（information gain） $Gain(D,a)=Ent(D)-\sum\limits_{v=1}^{V}\frac{D^v}{D}Ent(D^v)$ 一般而言，信息增益越大，意味着使用属性啊来划分所获得的纯度提升越大。所以，可以使用信息增益Gain作为属性划分的指标。 基尼指数CART决策树使用“基尼指数”选择划分属性。 数据集D的纯度可用基尼值来度量： $Gini(D)=\sum\limits_k^{|y|}\sum\limits_{j\neq k}p_kp_j$ $=1-\sum\limits_k^{|y|}p_{k}^2$ 直观来讲，Gini（D）反映了从数据D中随机抽取两个样本，类别标记不一致的概率。因此Gini（D）越小，数据集D的纯度越高。 属性a的基尼指数定义为： $Gini_index(D,a)=\sum\limits_v^{V}\frac{|D^v|}{|D|}Gini(D^v)$ 计算属性集合A所有属性的基尼指数，取最小值得属性作为最优划分 剪枝处理剪枝（pruning）是决策树学习算法中对付“过拟合”的主要手段。过拟合的定义可以参考系列的第一篇。决策树算法经常会由于过拟合造成分支过多，在泛化性能上造成影响。 决策树剪枝基本策略有两种：预剪枝（prepruning）和后剪枝（postpruning）。 预剪枝：在生成决策树的过程中，对每个结点在划分前进行估计，若当前划分不能对决策树带来泛化性能上的提升，则停止划分并将当前节点标记为叶结点。（训练开销短，保留子树少，易造成欠拟合） 后剪枝：决策树生成后自底向上的对内部结点进行考察。如果当前结点子树替换成叶子结点可以在泛化能力上得到提升，则将子树替换。（训练开销长，保留子树多，欠拟合风险小） 这里使用集精度作为泛化能力的指标。 需要注意的是，虽然在当时结点的集精度没有下降（也就是泛化能力未降低），但是很可能在之后进一步的展开，有欠拟合的风险。 连续值与缺省值处理连续由于连续属性的可取值数目不再有限，因此，不能直接根据连续属性的可取值来对结点进行划分。此时可以使用连续属性离散化技术。 最简单的策略是采用二分法(bi-partition)对连续属性进行处理。 给定样本集D和连续属性a,假定在D上出现了n个不同的取值，将这些值从小到大进行排序，记为${a^1,a^2,…,a^n}$.基于划分点t可将D分为子集$D_t^-$和$D_t^+$其中$D_t^-$包含那些在属性上取值不大于t的样本，而$D_t^+$则包含那些在属性a上取值大于t的样本。 对相邻的属性取值[$a^i，a^{i+1}$]来说结果是相同的，因此在此区间都取值$\frac{a^i+a^{i+1}}{2}$ 对n-1个区间取指作为划分点，分别测试选取最优。 $Gain(D,a)=\max\limits_{t\in T_a}Gain(D,a,t)$ $=\max\limits_{t\in T_a}Ent(D)-\sum\limits_{\lambda \in {-,+}}\frac{\mid D_t^{\lambda}\mid}{\mid D \mid}Ent(D_t^{\lambda})$ Gain(D,a,t)是样本集D基于划分点t二分后的信息增益，我们可以使用Gain(D,a,t)最大化的划分点 缺省嗯，本部分也暂时缺省 多变量决策树我们把每个属性视为坐标空间的一个坐标轴，则d个属性描述的样本就对赢了d维空间中的一个数据点。对样本的分类也就是在这个坐标空间中寻找不同样本之间的分类边界。 决策树形成的分类边界有一个明显的特点：轴平行（axis-parallel），即分类边界由若干个与坐标轴平行的分段组成。 使用斜划分边界可以将决策树模型简化。此时，非叶节点不仅是针对某个属性，而是属性的线性组合进行测试。与传统的决策树不同，多变量决策树试图建立一个合适的线性分类器。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性模型]]></title>
    <url>%2F2017%2F03%2F03%2Fml-intro3%2F</url>
    <content type="text"><![CDATA[示例有d个属性$(x_1 ; x_2 ; x_3… ; x_d)$描述，线性模型试图学得一个通过属性的线性组合来进行预测的函数。 $f(x)=w_1x_1+w_2x_2+…+w_dx_d+b$，w和b确定后，模型就确定了。w直观表达了各属性在预测中的重要性。 线性回归线性回归试图学得$f(x_i)=wx_i+b$，使得$f(x_i) \approx y_i$ 确定w和b的关键是衡量f(x)与y之间的关系。我们可以通过使用均方误差最小化作为衡量标准。 对数几率回归对数几率回归实际上针对的是分类任务，将分类任务的真实标记y和回归模型的预测值联系起来。 分类任务，通过类阶跃函数（阶跃函数不连续），把连续的值近似的分成两类（0或1），并且在坐标原点处变得很陡。 线性判别分析Linear Discriminant Analysis是一种经典的线性学习方法：给定训练样例集，设法将样例投射到一条直线上，1. 使得同样样例的投影点尽可能的接近，2. 异类样例投射点尽可能远。对测试集预测时，将对象投射到直线上预测。 要实现上面的两个目标，分别考虑：对于同类样本投射点接近，计算同类样本点的均值方差A；异类点则考虑两个样本簇中心点的距离差最大|xa-xb|²，然后使用单一的数值，J=A/B，使J尽可能的大。 多分类策略这里简单介绍通过二分策略实现多分类策略，常用的有三种方法，核心是拆解的策略区别： 一对一（OvO）：任意两个对象亮亮配对，产生N*(N-1)/2个预测结果，在这些结果中投票，预测结果最多的视为最终结果 一对多（OvR）：每次从训练集中挑选一个不重复的样例作为正例，其余N-1个样例作为反例，进行N次训练。如果某次训练的结果预测为正类，此次训练的样例即为结果；若有多个样例被预测为正例，考虑事先设置的置信度，选择置信度最大的 多对多（MvM）：每次将若干类作为正类，若干类作为反类。这里提供一种常用的MvM拆分模式，就错输出吗ECOC。ECOC进行M次的划分，也就是M次分类器。分别对测试样本进行预测，这些预测标记组成一个编码，然后编码与每个类别各自的编码进行比较，返回其中距离和最小的作为最终预测结果。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模型评估与选择]]></title>
    <url>%2F2017%2F03%2F01%2Fml-intro2%2F</url>
    <content type="text"><![CDATA[误差与拟合误差学习器的实际预测输出与样本的真是输出之间的差异称为”误差” 学习器在训练集上的误差叫”训练误差” 学习器在新样本的误差叫”泛化误差”（重要） 拟合我们实际希望的，是在新样本上能表现得很好的学习器.为了达到这个 目的，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”，这样才能在遇到新样本时做出正确的判别。 然而，当学习器把训练样本学得“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的普适性质，这样就会导致泛化性能下降。这种现象在机器学习中称为“过合”（overfitting). 与“过拟合”相对的是“欠拟合”（underfitting),这是指对训练样本的一般性质尚未学好。 评估方法留出法将整体数据划分为两个互斥的数据集合，分别作为测试集与训练集。注意测试集与训练集要尽量保证层次、类别上的相似。可以进行多次留出法，然后取误差的平均值。一般取2/3或者3/4的数据作为训练集。 交叉验证 同样是将数据集合互斥划分，这里互斥的划分为k份，相互之间保持层次分布的平衡。 每次使用k-1份数据作为训练集，余下的作为预测集 进行k次实验，取平均误差值 自助法上述的两种方法有一个共同的缺陷就是都把训练集合与整体的样本集合规模有偏差，而且由于每次的偏差不同，造成无法预料的影响。 自助法：给定包含m个样本的数据集D，对他进行采样产生数据集d。每次随机的从D中跳一个样本复制到d中，进行m次，生成了包含m个样本的数据集d。显然，d中可能包含多个重复的样本数据。经过计算，m取无限大时，d中大概有D的63%数据。 之后我们使用d作为训练样本，而D\d作为测试集合。这样，实际的训练与测试都使用了m个样本，且保证了D\d有3成多的非训练样本。 性能度量这里主要介绍两个属性：P（查准率precision）与R（查全率recall） 查全率＝（检索出的相关信息量/系统中的相关信息总量）*100% 用户感兴趣的信息中有多少被检索出来 查准率＝（检索出的相关信息量/检索出的信息总量）*100% 检索出的信息有多少比例是用户感兴趣的 查全率是衡量检索系统和检索者检出相关信息的能力，查准率是衡量检索系统和检索者拒绝非相关信息的能力。 实验证明，在查全率和查准率之间存在着相反的相互依赖关系–如果提高输出的查全率，就会降低其查准率，反之亦然。 以P作为纵轴，R作为横轴作图，简称”P-R曲线”。若一个学习方法的P-R曲线完全包括另外一个，则断言此学习方法更优秀。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ML相关术语]]></title>
    <url>%2F2017%2F02%2F28%2Fml-intro%2F</url>
    <content type="text"><![CDATA[机器学习：研究如何通过计算的手段，利用经验来改善系统自身的性能。 计算机系统中，“经验”通常以“data”形式存在，所以机器学习从数据中产生模型（model）的算法，称为学习算法。模型，即从数据中学到的结果。 通过向学习算法中输入已有的数据，算法产生模型，面对新的case时，模型就可以通过case的特性进行判断。 一组数据的集合称为数据集，其中每条记录是关于一个事件或对象的描述，称为”示例”（instance）或者”样本”（sample）。 描述中不同的性质称为属性。通过属性做成的坐标轴称为属性空间、样本空间或者输入空间。在属性空间中，每个描述都与一个点对应，所以我们也把一个描述称作是”特征向量”。 从数据中学得模型的过程称为”学习”或者”训练”，这个过程通过执行某个学习算法完成。训练样本组成的集合称为”训练集” 训练样例的结果信息称为“样例”。 如果需要预测的是离散值，例如（1、2、3、4、5），称为分类预测（classification）。特别的，离散值只有两个的情况称为二分类（binary classification），多个离散值称为多分类。如果需要预测的结果范围是一个连续值，或者是不可数结果，此时的学习任务称为回归任务（regression）。 聚类：将训练集中的西瓜分为若干组，每组称为一个”簇”；簇是自动形成的，对应一些潜在的概念划分，这些潜在的概念划分我们事先不知道，而且学习过程中使用的训练样本通常不用有标记信息（提前设定的结果） 训练样本有标记信息的学习任务称为监督学习（supervised learning），否则称为无监督学习（unsupervised learning）。分类回归是监督学习的代表，聚类（clustering）是后者的代表。 泛化（generalization）：学得模型适用于新样本的能力。 归纳偏好由于训练样本的数据量无法代表整个样本空间，可能会存在这种情况：预测样本可以匹配到多个训练样本结果，而这些不同的训练结果有不同的输出。表现为分类中属不同类。 此时无法通过匹配的手段确定到底使用哪个训练样本结果，学习算法的”偏好”就很重要了。通过提前设置的偏好，在遇到这种情况时候，算法会自动根据偏好选择合适的预测结果。称为”归纳偏好”（inductive bias） 奥卡姆剃刀奥卡姆剃刀是一种常用的、自然科学研究中最基本的原则，即”若有多个假设与观察一直，则选择最简单的那个”。 如无必要，勿增实体 NFL定理所有问题同等重要的前提下，任意两个学习算法的期望性能是相同的。就是说误差率是相同的。NFL定理的重要定义是要我们认识到，脱离具体问题，空泛的谈论”什么学习算法更好没有意义”。学习算法自身的归纳偏好与问题是否匹配，往往起到决定性作用。 历史进程机械学习将所有样例记住，并在需要预测的时候拿出，实际上是一种检索方法，没有涉及到学习。 符号主义学习这个阶段，代表的学习方法有决策树和基于逻辑学习。 基于连接主义主要是神经网络学习，BP学习方法大放异彩。 基于统计的学习SVM支持向量机的提出 DM与ML数据挖掘（Data Mining）是从海量的数据中发掘知识，主要包括两个支撑技术：数据库管理和机器学习。 数据库领域为数据挖掘提供数据管理技术，而ML和统计学为DM提供数据分析技术。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球通史笔记]]></title>
    <url>%2F2017%2F02%2F13%2Fglobal-history%2F</url>
    <content type="text"><![CDATA[作者说过要“站在月球上来审视人类史”， 这是一本时间跨度长达400万年的历史巨著，所以他给我们的更多的应该是整个地球无尽岁月的点点缩影，让我们按照地理上的分布对不同地区不同时间不同文明有所了解。他更多承担的应该是兴趣入门。“历史的今天”，随时把历史上的重大变故跟当今世界的现状联系在一起，提醒着我们认清所生活的现实世界与历史的内在联系，从而使我们的思想能跨越时空的限制，在历史与现实的两个时空里驰骋，甚至由此产生自己出对历史事件的联想与对比，产生出自己的思想的火花与创作的冲动。由此让阅读历史，成为一种乐趣，成了一个对历史和现实两个世界的疑问同时不断探询和解答的过程。当我们对某个点感兴趣了，自己去查史料扩展自己的视野。匆匆读完一遍，随手记下感想。 《全球通史》之前的几个版本将整本书分为两个大的部分，1500年以前的世界，与1500年以前的世界，千余页的内容显然是无法将地球数十亿年数亿平方公里的人物历史囊括，作者在每个大的章节最后部分都会单独开一章：历史对今天的启示，细细想来，作者实际上是通过对古典文明的灭亡来写古典文明的局限性，古典文明为什么无法像现代一样，出现科技的快速进步？前言推荐中有这样一段话很好的诠释了整本书的内容、风格以及目的：“这里有人类的起源，文明的嬗变，有帝国的更迭，宗教的扩散；有对欧亚大陆诸古代文明和古典文明不同命运的宏观思考，也有对人性善恶本质的哲学分析，对文明是“诅咒”还是“福音”的辨证评价，也有对世界愈加两级分化的人道关怀，对人类历史上诸多灾难的渊源——社会的变革总是滞后于技术变革——的忧虑与警示，不同于那种把自己的观点和观念强加给读者的历史学作品，这本书平心静气，娓娓道来，没有教育人的口吻，却把读者引入到了一种求索的境界，让你不由自主地手不释卷。”作者通过不断的推进，向我们展示了自己严密的逻辑思维、理性分析以及作为一个史学家回首历史的独特视角。 说一点内容性的东西吧，最开始的部分，人类（用《人类简史》上的术语或者说是“智人”）在史前时代，从黑暗中摸索，逐渐进步到会简单思考、群居性、使用工具，可能需要数万年数十万年甚至数百万年，人类从最初的食物采集者身份转变到了食物的生产者，数百万年的时间在史书上用我们现在的视角仅仅数千字就能概括完成，而随着文明的出现，思维的扩展，科技科学的出现，数千字的内容可能只能叙述历史的数千年、数百年、甚至到现在，每年每天都会有许多事情发生。文明的进步在某一层面上来讲也可以这样来看，文明社会遂能使知识不断累积并代代相传，自由与温饱让人们富有创造力，知识加上创造力推动社会的进一步发展。 3–6 世纪，古典文明陷落。西方古典由于地理因素最受蹂躏（日耳曼人、匈奴人、穆斯林、马札尔人、维京人）；印度南方以及中国南方由于距离游牧民族蛮族地理较远，逃过一劫，两大文明的北部虽然遭受了蛮族的入侵，但是很快入侵的蛮族由于当地领先的文明被同化，同时中国原来北方的民族向南迁移，中国南部地区开始汉化。波斯帝国以及拜占庭帝国强大的军事实力完好的度过了此次入侵；盛极一时的古典西方文明，首当其冲的收到了强有力的袭击，彻底消弭。但也正是这次的毁灭，产生出了新的更有活力的文明，作者在文中对这个观点多次的提起。 宋朝期间，中国人在造船业和航海业上取得巨大进步，12世纪末，开始取代穆斯林在东亚和东南亚的海上优势。蒙古人建立元朝（1279-1368年）后，中国的船只体积最大，装备最佳；商人遍布东南亚及印度各港口这一时期，中国在世界经济中居主导地位。进口商品除细纹棉织品外，还有中亚的皮革、马匹以及南亚的优质木材、玉石、香料和象牙等原材料。而出口商品，除矿石外，还有书、画，尤其是瓷器、丝绸等产品。明朝（1368－1644年），中国的航海活动达到极盛。中世纪时期，中国人在欧亚大陆的交流中，通常是捐献者，而非接受者。早些时候的情况可能相反，古典时期，美索不达米亚的车轮、辘轱和滑轮，埃及的握杆和曲柄；波斯的风车和小亚细亚的炼铁等，从各自的发源地向四面八方传播。但在公元后的14个世纪中，我们国家则是技术革新的伟大中心，向欧亚大陆算他地区传播了许多发明。像三大发明，培根这样评价道：我们应该注意到这些发明的力量、功效和结果。它们是：印刷术、火药和磁铁。因为这三大发明在文学方面，在战争方面，在航海方面，改变了整个世界许多事物的面貌和状态、并由此产生无数变化，以致似乎没有任何帝国、任何派别、任何星球，能比这些技术发明对人类事务产生更大的动力和影响。 然而我们可以看到，文明的高度发达在历史上并没有去的长久的繁荣。中世纪的世界，中国是世界上最发的区域，我们有着最美的文化、领先的工艺技术、繁盛的商业以及完善的封建官僚技术，但同样造成了我们的固步自封的思想。当我们发现西方国家之后，上述的优势让我们对他们的文化以及潜力产生轻视，认为这些家伙没什么好学的，但是西方国际却渴望从我们这里学习，落后就要挨打这条定律其实根植于人与人、国与国之间。 人类学家弗朗兹•博亚兹曾经说过，“人类的历史证明，一个社会集团，其文化的进步往往取决于它是否有机会吸取邻近社会集团的经验。一个社会集团所获得的种种发现可以传给其他社会集团；彼此之间的交流愈多样化，相互学习的机会也就愈多。大体上，文化最原始的部落也就是那些长期与世隔绝的部落，因而，它们不能从邻近部落所取得的文化成就中获得好处”。这样，虽然我们有了可以吸取他人经验的条件，却失去了文明进步的进取心。乾隆皇帝曾在答复1793年英国国王乔治三世要求建立外交和贸易关系时，对我们的态度作出了最好的解释：“在统治这个广阔的世界时，我只考虑一个目标，即维持一个完善的统治，履行国家的职责：奇特、昂贵的东西不会引起我的兴趣。……正如您的大使能亲眼看到的那样，我们拥有一切东西。我根本不看重奇特或精巧的物品，因而，不需要贵国的产品。” 古代中国的这种情况在现代人类学家看来可以用一个词解释：遏制领先法则。在转变时期起先最发达和最成功的这回要想改变和保持其领先地位将是最困难的。相反，落后和较不成功的社会则可能更能适应变化，并在转变中逐渐处于领先地位。而现在，随着国家逐渐的发展，韬光养晦、厚积薄发依然经常被国家提到，正是应了一句古话：以史为鉴可以知兴替。下面是一些零散的读书段落小记： 生活、生长的先天因素既是保护层，又是枷锁。 生产的革命促进生产力的解放，进而引起生产关系的转变，上层建筑的破、立，这是新事物发展阶段；进入相持阶段，一切慢慢固化，产生既得利益集团；最后是革新阶段，在没有的生产革命时，重新建立原有生产力与生产关系的格局；在有外来新的生产革命的涌入时，通过大的变革形成各自新的特色。 民族性格与人的性格形成差不多，都是由生活环境决定的。 劳动创造价值，但价值分配却是个复杂问题，主要在于人解决了生存问题、有了高层次生活的感觉之后，上层的人会尝试不劳而获、巧取豪夺，结果会必然造成原有社会的崩溃，这不是由于集权中央不控制、也不是由于既得利益的上层人没有节制，而是由于市场经济自我发展的特点决定的。在市场经济中，劳动创造出了生活必需之外的价值，以闲散资金的形式来表现，这种闲散资金本能的向赚钱行业集中，即向周期短、利润高、少费力的行业投资，最终会伤害生产力。 宗教的产生之初是被剥削阶级组织起来的工具，之后会在斗争、妥协中被统治集团有条件的吸收、篡改，由粘合剂、兴奋剂变成鸦片，由正视现实变成睡梦。 是否促进历史前进与是否受到群众理解是没有比例关系的。但对历史人物的认识是考量群众、社会进步的一个标杆，就像社会散沙度可通过电视随机提问展现一样。 事情都有各自的周期，一类事情有一类的周期。 “大部分群众认可的事情是好事情”，是对“群众”的偶像化。 大势已成，则只能等事物沿着它的轨迹而行，是不以人的意志为转移的。 列强是指进口原材料，出口制成品；当外国的产品比本国的物美价廉时，对外国产品征收高额关税 来扶持本国这项技术的发展；对外要求自由竞争资本主义。如果各不发达国家不想当列弱了，必须实行贸易保护，自力更生，占领工业高地，建立自己的工业体系，这必然会遭到列强的干预和国内食利的腐朽集团的阻挠和镇压。其成败与否的关键在于三点：一是正确的领导党，二是群众的觉悟程度，三是知识分子与群众的结合程度。 贸易的最本质需求是互通有无。其正能量是促进生产力提高时，能更好地实现互通有无；其负能量是为生钱而生钱时，不以互通有无为目的，造成有撑着的、有饿着的、有营养过剩的、有虚胖的。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乌鸦你是谁]]></title>
    <url>%2F2017%2F01%2F25%2F17-01-25%2F</url>
    <content type="text"><![CDATA[不知不觉就走到了这个尴尬的数字期盼着08，期盼着12，却原来已经在冷夜中蹒跚了数千个日日夜夜好嘛，也是把最初的幼稚与青涩用完的时候了吧年纪大了总会变得多愁善感本以为是云淡风轻，看着游客飘来荡去，顺着指尖，还是把最近的心思揉在一起丢到这里每个小站都是我不同的生活态度封存一些不想被熟知的你们探索的琐论杂情这里没有飞来飞去的广告没有生活所迫的编辑夺人眼球的标题我们用心记录所有随心所欲，不会因为假定的时时刻刻deadline画出没有意义的花瓶有的尽是自由的灵魂，祛除的都是非要不可小站匆匆的陌生游客是否就是我所要的自由呢，我不在乎你怎么漂流到这里，也不会深究你是谁我是浅水中的一条河鱼，我就把这当成是我的自由罢对我而言，你就是深夜中扑腾的乌鸦，我们相遇，交谈或相离，不会记下彼此的记号当期盼变成抗拒，当行进变成蹒跚别样的云清风淡，别样的人生海海写在5位数之前，写在solar与lunar之间，写在惊醒与微醺之后不想懂没结果的是为什么不去问黑夜的乌鸦你是谁]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[subprocess模块的使用]]></title>
    <url>%2F2016%2F12%2F18%2Fsubprocess-pipe%2F</url>
    <content type="text"><![CDATA[最近在考虑如何在一个独立的程序上加一个GUI壳子，原来的程序是通过console接受输入输出的，查阅资料发现了subprocess模块，这里记录一下。 引入从名字就可以听出来，subprocess是python管理子进程的模块。运行python的时候，正常情况下我们都是在创建并运行一个进程。通过subprocess可以新建一个子进程执行程序，并通过subprocess提供的api与新创建的子进程联系。 subprocess中最基础也最重要的就是基于Popen()函数，Popen()方法根据参数新建一个进程并执行，后面的一些列参数是对这个新创建的进程的管理。会话消息也就是I/O流，正常情况下有三种stdin、stdout以及stderr。前两个都很好理解，第三个就是标准的错误输出信息。 Popen()方法通过对这三个参数的配置指定子进程I/O方式。一般支持的主要有两种方式：stdxx，这个也是默认的，就还是按原来的走；或者设置为Pipe，管道模式，这种模式下，子进程有一个缓冲区存储这输入输出信息，缓存等待着我们通过API进行数据的操作。这里实际上就是劫持了标准的I/O流。 一些常用方法 terminate() 停止(stop)子进程。在windows平台下，该方法将调用Windows API TerminateProcess（）来结束子进程。 kill() 杀死子进程 communicate(input=None) 与子进程进行交互。向stdin发送数据，或从stdout和stderr中读取数据。可选参数input指定发送到子进程的参数。Communicate()返回一个元组：(stdoutdata, stderrdata)。注意：如果希望通过进程的stdin向其发送数据，在创建Popen对象的时候，参数stdin必须被设置为PIPE。同样，如果希望从stdout和stderr获取数据，必须将stdout和stderr设置为PIPE，这个方法与之前将标准I/O流设置成管道PIPE不同，communicate方法是在进程运行结束返回后将输出信息以及错误信息返回，在程序运行期间，无法通信。 具体程序相关p1=subprocess.Popen(cmd下执行程序的指令,stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.STDOUT) 将输入输出都设置为管道模式，错误信息重定向到输出，这样我们使用API获取输出信息时，能够直接拿到输出信息与错误信息。 获取输出信息 s=p1.stdout.readline()s=s.decode(&#39;gbk&#39;) 从缓冲区中读取一行输出 写入信息并实时的推送到原程序中 p1.stdin.write(s.encode())p1.stdin.flush() 因为劫持的标准I/O流，里面都是byte信息，所以为了能够使用，我们需要将byte转换成str，至于编码解码的编码集，需要根据服务器返回信息的不同测试设置。 实时的获取反馈信息 独立于GUI线程，也不是在主线程中，新建一个专门查询缓冲区的线程，如果缓冲区有未接受的信息，通过Qt的信号-槽模式，将需要传递的信息发给GUI处理函数。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统结构读书笔记]]></title>
    <url>%2F2016%2F12%2F05%2Farchitecturere-readnote%2F</url>
    <content type="text"><![CDATA[《Computer Architecture A Quantitative Approach》部分读书笔记 本书的第二版，相比前面的版本，经过了一些修整。第一版的基础内容，第一章（Fundamentals of Computer Design）和第二章（Performance and Cost）在这个版本中，是在开篇第一章中（Fundamentals of Computer Design）介绍的，编者认为两者放在一起比独立的分开讲解效果更好一些。 介绍计算机出现的几十年间，从20世纪70年代开始，微处理器的性能增长率逐年增长，从最开始的每年25%左右，20世纪70年代末期的35%。 这样的增长速率以及大规模微处理器生产的成本优势，导致微处理器在计算机事业中的因素占比越来越大。同时，计算机市场的两个明显改变使得在一种新型的体系结构下实现了商业成功： 首先，虚拟技术消除了原本的编程语言的装配过程，减少了母必爱代码的兼容性要求；另外标准化的创作、独立的操作系统（例如Unix）以及更低的成本和风险带来了一种新型的体系结构。这些改变使得继往开来，开发了一种新的体系结构集合，我们称它RISC体系结构。 从RISC出现，80年代微处理器的性能增长率达到了50%以上，而且还在不断的提升。 这种亮眼的增长率影响是双重的，首先明显的增强了能够提供给用户的发挥空间，用户可以享受在更低的时间内得到相同的结果；其次，这种恐怖的增长率导致了在计算机设计领域微处理为基础的主导地位：工作站和PC开始成为计算机行业的主要产品，小型机甚至超级计算机也逐渐采用利用多个微处理器代替原本的处理器。 计算机设计的任务计算机设计者的任务客观来见是比较复杂的，一般有下面必须遵守： 确定属性对于新机器的重要程度 在成本约数条件下最大限度的提高性能、设计机器 虽然寥寥几个字，但是涉及到了很多方面：指令集的设计、功能组织、逻辑设计以及最后的实现部分。而实现部分又可能包括集成电路的设计、封装技术、电源甚至是温度管控等。 设计者们设计一台计算机需要同时满足功能需求以及价格和性能上的目标。通常，他们也是功能需求的决策者，这可能是主要的任务。功能需要也许是来自市场方面的特别的特性，也许是计算机应用反向的驱动设计者考虑如何设计计算机。 到之后的优化设计，需要的知识同样很多，编译器、操作系统、逻辑设计和包装等等，这些不仅需要计算机设计人员消耗大量的时间与精力，同时要求有很丰富的经验与知识广度。 优化设计的指标有很多，最常见的指标设计成本和性能，在某些领域中，可靠性和容错性往往时相比成本和性能有更重要的地位，这里我们专注于常规领域，着重考虑机器的成本和性能。 计算机与技术的使用趋势评判一个指令集的成功，一个重要的指标就是指令集必须能够在硬件技术、软件技术和应用特性的改变下表现不俗，所以设计师必须要特别了解计算机以及计算机技术的使用趋势。 计算机使用趋势计算机的设计受两个方面影响：使用方式以及底层的实现技术特性。 使用和实现技术的改变以不同的方式影响计算机设计，包括激励指令集的改变、流水方式还有类似缓存机制技术等等。 软件技术的趋势以及程序是如何使用计算机对指令集结构有着长期的影响。 程序所需的内存每年以1.5倍以上的速率增长，这种快速增长由程序的需求以及DRAM技术驱动。 高级语言逐渐替换汇编语言。这种趋势导致编译器承担更重要的作用，编译器的作者需要跟跟架构师们紧密的合作，构建一个更有竞争力的机器。 实现技术的趋势 集成电路逻辑技术：晶体管集成度每年都会提高约50%（晶体管的摩尔定律），在三年内翻了四倍，尺寸的增加可预测性不高，一般不会超过25%，然而布线技术并没有得到改善，这导致了时钟周期方面的速度提升缓慢。 半导体DRAM集成度每年增长不超过60%，周期改善的相当缓慢，十年里减少了约三分之一，而芯片的带宽随着延迟的减少以及DRAM接口的改善得到提升。 磁盘技术：1990年以前，磁盘的单位密度每年增长只有四分之一，90年以后，磁盘技术有了长足的发展，90年以后每年都有约一半的增加。 以上这些快速变化的技术影响着微处理器的设计，随着速度和技术的增强，有长达5年以上的使用寿命。即使在单个产品周期（两年设计两年生产）范围内，关键的技术也足以影响设计者的决定；实际上，设计者经常会为下一个可能出现的技术设计。 成本和成本趋势数目，商品化的影响 数量是决定成本的关键因素，增加数量会在几个方面上影响成本。首先，他们减少了降低学习曲线（学习曲线学习曲线表示了经验与效率之间的关系，指的是越是经常地执行一项任务，每次所需的时间就越少。）所需的时间，减少时间的比率主要由使用的数目决定；其次，大批量的使用会降低成本，因为他增加了采购和制造的效率。根据经验，数目增加一倍，成本会降低一成。 商品是由多个供应商大量销售并且基本相同的产品。不同的供应商对产品的高度竞争，降低了成本和售价之间的差距，同时也降低了计算机的成本。 一个系统的成本分析 上图是1990s末期彩色台式机的大致成本细目，虽然DRAM等设备的成本会随着时间的推移降低，但是部分设备的成本将会几乎没有变化。此外可以预期，未来的假期将会有更大的存储设备（内存或硬盘），这意味着价格下降比技术改进更慢。 处理器系统仅占成本的6%，虽然在中高端设计中，比例会增加，但是在主要的系统中是类似的。 性能的测量当我们说一台电脑比另一台电脑快时，是什么意思？ 用户可以说，当程序以较少的时间运行时计算机更快；而计算机中心管理员可以说，在一小时内完成更多作业时计算机更快。计算机用户对减少事件的执行时间感兴趣。 大型数据处理中心的经理可能对增加吞吐量感兴趣。 用户每天运行相同程序将是评估计算机性能的理想选择。为了评估新系统，用户需比较工作负载执行时间（用户在机器上运行的程序和操作系统命令的混合）。 然而，这种方法是机器枯燥的，大多数人依靠其他方法来评估，希望这些方法能够预测机器的使用性能。在这种情况下使用四个级别的程序，下面按照预测精度的降序列出。 真实程序。虽然不知道这些程序花费了多少时间，但知道用户可能会运行他们解决实际问题。例如C的编译器，文本处理软件或者CAD工具。 内核。尝试从真实的程序中提取几个小的、关键的片段评估他们的性能。Livemore Loops和Linpack是最出名的例子。与真实的程序不同，没有用户会运行内核程序，因为他们只用于评估性能。这种方法好在隔离机器各个特性的性能，解释实际程序性能差距。 Toy benchmarks。这种方法通常在数十行代码之间，产生用户在运行当前程序前已经知道的结果。像Sieve of Erastosthenes，Puzzle和Quicksort这样的程序很受欢迎，因为它们体积小，易于输入，几乎可以在任何计算机上运行。一般在程序语言开始分配阶段运行。 Synthetic benchmarks。在原理上与内核很相似，这种方法试图匹配一个大的程序集里面的操作以及操作数平均值。Whetstone和Dhrystone是流行的产品。 计算机设计的定量原理加快经常事例也许计算机设计的最重要和最普遍的原则是加快经常使用的cas额，这个原则也适用于确定如何使用资源，因为如果case发生频繁，对一些发生更快的影响想爱你然更大。 改进频繁事件，而不是罕见事件，也有助于性能提升。 此外，频繁的情况通常更简单，并且可以比不常见的情况更快地完成。 Amdahl定律 Amdahl定律：系统中对某一部件采用更快执行方式所能获得的系统性能改进程度，取决于这种执行方式被使用的频率，或所占总执行时间的比例。阿姆达尔定律实际上定义了采取增强（加速）某部分功能处理的措施后可获得的性能改进或执行时间的加速比。简单来说是通过更快的处理器来获得加速是由慢的系统组件所限制。 CPU性能方程大多数计算机使用恒定速率运行的时钟构建。 这些离散时间事件称为时钟周期。计算机设计者通过其长度（例如，2ns）或其速率（例如，500MHz）来指代时钟周期的时间。一个程序的CPU时间可以表示为： cpu time=时钟周期数 * 时钟周期时间 内存分层概念首先，让我们看看硬件设计的一个经验：较小的硬件运行更快。这种简单的经验特别适用于由相同技术构建的存储器，原因有两个。首先，在高速机器中，信号传播是延迟的主要原因; 较大的存储器有更多的信号延迟，并且需要更多的电平来解码地址。第二，大多数技术中，我们可以获得比 较大的存储器 更快的 更小的存储器。这主要是因为设计者可以在更小的设计中使用每个存储器单元更多的功率。 速表明有利于访问这样的数据将提高性能。 因此，我们应该尽量保持最近访问的项目在最快的内存中。 因为较小的存储器将更快，所以我们希望使用较小的存储器来尝试保持最近访问的项目靠近CPU，并且随着我们从CPU远离CPU而逐渐增大（和较慢）的存储器。 此外，对于更靠近CPU的那些存储器，我们还可以采用更昂贵和更高功率的存储器技术，因为它们小得多，并且由于存储器的小尺寸而降低了成本和功率影响。 这种类型的组织称为存储器层次结构。其中有两个重要的层次是缓存和虚拟内存。 （上图是上个世纪的容量与速度，不过到现在依然有参考意义） 缓存是位于靠近CPU的小型快速存储器，其保存最近访问的代码或数据。 当CPU在高速缓存中找到所请求的数据项时，其被称为高速缓存命中。 当CPU在高速缓存中找不到它需要的数据项时，发生高速缓存未命中。 从主存储器检索包含所请求字的固定大小的称为块的数据块，并将其放入高速缓存中。 时间局部性告诉我们，我们可能在不久的将来需要这个词，因此将其放在可以被快速访问的缓存中是有用的。 由于空间局部性，块中的其他数据将很快需要的概率很高。 高速缓存未命中所需的时间取决于存储器的延迟及其带宽，其确定检索整个块的时间。 由硬件处理的高速缓存未命中通常导致CPU暂停或停止，直到数据可用。 同样，并非程序引用的所有对象都需要驻留在主存储器中。 如果计算机具有虚拟内存，则某些对象可能驻留在磁盘上。地址空间通常被分成固定大小的块，称为页面。 在任何时候，每个页面驻留在主内存或磁盘上。 当CPU引用在高速缓存或主存储器中不存在的页面内的项目时，发生apage fault，并且整个页面从磁盘移动到主存储器。由于页面故障需要长时间，因此它们由软件处理，CPU不会停止。发生磁盘访问时，CPU通常切换到其他任务。 高速缓存和主存储器与主存储器和磁盘具有相同的关系。 第二章部分介绍在本章中，我们专注于指令集架构。程序员或编译器写程序可见的机器部分。 本章介绍了指令集架构师可用的各种各样的设计替代方案。特别的，本章重点讨论四个主题。 提出一个指令集替代品的分类，并给出一些定性评估各种方法的优缺点。 提出和分析一些指令集测量，这些测量在很大程度上独立于特定的指令集。 解决语言和编译器的问题，以及它们对指令集架构的影响。 显示了以上想法如何反映在DLX指令集中。 在本章中，研究了各种各样的结构测量方法。这些测量取决于测量的程序和用于进行测量的编译器。这些结果不是绝对的，因为如果使用不同的编译器或不同的程序集进行测量，可能会看到不同的数据。 作者认为，这些章节中所示的测量值合理地表示了一类典型应用。许多测量使用一小组基准来呈现，使得可以合理地显示数据，并且可以看到之间的差异。 一个新机器的架构师想要分析一个大的程序集合，来做出他的决策，所显示的所有测量都是动态的。也就是说，测量事件的频率是通过在执行测量程序期间事件发生的次数来加权计算得到。 指令集结构的分类CPU内部存储器类型是指令结构分类考虑的关键指标，因此在本节中，将重点介绍这部分的替代方案。主要的选择有堆栈，累加器或一组寄存器。 一种可以将存储器作为指令的一部分访问，称为寄存器-存储器架构，一种仅能够使用load/stroe指令访问主存的称之为寄存器-寄存器架构。第三类，目前流通的机器中还未出现，是将所有操作数保存在内存中，称为内存-内存架构。 虽然大多数早期机器使用的是堆栈或累加器式架构，但在1980年后设计的机器几乎无一例外都采用load-store寄存器架构。 出现通用目的寄存器机器的主要原因有两个。首先，CPU内部的寄存器的比存储器更快。第二，寄存器对于编译器来讲更容易使用，并且可以比其他形式的内部存储更有效地使用。 寄存器可以用来保存变量。当变量被分配给寄存器时，存储器的使用就会减少，程序运行速度提高（由于寄存器比存储器快），并且代码密度提高（因为寄存器可以用比存储器位置更少的位命名）。 两种主要的指令集特性划分了通用目的寄存器架构。这两个特性涉及典型算术与逻辑指令（ALU指令）的操作数的性质。第一个涉及ALU指令是否具有两个或三个操作数。在三操作数格式中，指令包含目的地址和两个源操作数。在双操作数格式中，操作数中的一个既是操作的源也是操作之后的结果。通用目的寄存器架构中的第二个区别涉及多少个操作数可以是ALU指令中的存储器地址。典型ALU指令支持的存储器操作数的数目从0到3。 内存地址有两种不同的模式用于排序字内的字节。大端模式与小端模式： 大端模式，是指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中，这样的存储模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，而数据从高位往低位放；这和我们的阅读习惯一致。 小端模式，是指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中，这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低。 在许多机器中，对大于一个字节的对象访问必须对齐。什么是对齐？address of data % sizeof(data type)==0就是对齐，对齐跟数据在内存中的位置有关。如果一个变量的内存地址正好位于它长度的整数倍，他就被称做自然对齐。比如在32位cpu下，假设一个整型变量的地址为0x00000004，那它就是自然对齐的。。不对齐就会造成数据访问花费额外的时钟周期，和额外的指令(编译器或OS附加的)，并且数据经过更长的路径，比如pipeline才能到达CPU（从RAM）。这就是对齐问题。这里的重点是数据的起始地址与数据的大小。 寻址模式 寄存器寻址模式 立即寻址 间接寻址 索引寻址 直接寻址或绝对寻址 内存间接寻址 变址寻址 小结本书第二版发型到现在虽然已经过了不短的时间，但是依然有很多值得我们细细品赏的地方。第一部分，作者没有像其他类似主题的书籍一样，上来就讲体系结构，而是拉着我们，从设计的趋势、设计的目的、设计架构需要考虑的诸多方面娓娓道来，读的过程中很有代入感，好像我们真的就是designer，特别是成本管控方面，原来基本上就没有考虑这一点，这里作者甚至从计算机制造业的视角分析了很多。这看起来跟我们没什么关系，但是实际上是为我们开辟了一个很棒的思路，以前很多模模糊糊的东西现在变得容易理解了。之后第二章开始讲了一些设计上的技术层面，第二章开始也说了，主要是关于指令集的知识，包括指令集结构划分的依据以及原因，字节存储模式、字节对齐的优势以及寻址模式等等，后面的内容由于时间关系没有看到，之后会继续品读，更新在这里。]]></content>
      <categories>
        <category>体系结构</category>
      </categories>
      <tags>
        <tag>体系结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tornado安全技巧]]></title>
    <url>%2F2016%2F11%2F24%2Ftornado-secure%2F</url>
    <content type="text"><![CDATA[安全cookiesTornado的安全cookie使用加密签名验证cookies的值是否被除了服务器之外的程序修改过，未被我们授权的（不知道安全密钥）程序无法在应用不知情下修改cookies 使用安全cookieTornado的set_secure_cookie()和get_secure_cookie()方法设置、请求浏览器的cookies，防止浏览器的恶意修改，在此之前，我们需要在构造函数中指定cookie_secure参数。 成功设定之后，应用在程序内部获取的cookie还是本身的值，在浏览器或抓包工具查看，发现cookie已经被加密，如果不知道密钥，无法获知cookie内容 如果通过恶意代码修改过cookie值，应用使用get_secure_cookie方法会获得None，此时我们可以在应用中判断，增加一些防范机制 12345678910111213141516171819202122232425262728293031323334353637import tornado.httpserverimport tornado.ioloopimport tornado.webimport tornado.optionsfrom tornado.options import define, optionsdefine("port", default=8001, help="run on the given port", type=int)class MainHandler(tornado.web.RequestHandler): def get(self): times = self.get_secure_cookie("count") count = int(times) + 1 if times else 1 countString = "1 time" if count == 1 else "%d times" % count self.set_secure_cookie("count", str(count)) self.write( '&lt;html&gt;&lt;head&gt;&lt;title&gt;Cookie Counter&lt;/title&gt;&lt;/head&gt;' '&lt;body&gt;&lt;h1&gt;You’ve viewed this page %s times.&lt;/h1&gt;' % countString + '&lt;/body&gt;&lt;/html&gt;' )if __name__ == "__main__": tornado.options.parse_command_line() settings = &#123; "cookie_secret": "bZJc2sWbQLKos6GkHn/VB9oXwQt8S0R0kRvJ5/xJ89E=" &#125; application = tortnado.web.Application([ (r'/', MainHandler) ], **settings) http_server = tornado.httpserver.HTTPServer(application) http_server.listen(options.port) tornado.ioloop.IOLoop.instance().start() Tornado将cookie值编码为Base-64字符串 http-only&amp;&amp;sslTornado的cookie功能依附于Python内建的Cokie模块，现在有两种常规的方法增强cookie的安全性，减少被截获的可能。 为cookie设置secure属性只指示浏览器只通过SSL传递cookie self.set_cookie(&#39;foo&#39;,&#39;bar&#39;,secure=True) 开启Http-only功能 self.set_cookie(&#39;foo&#39;,&#39;bar&#39;,httponly=True) 开启httponly之后，浏览器js不能访问cookie 以上两种模式可以同时工作 CSRF CSRF（Cross-site request forgery跨站请求伪造，也被称为“One Click Attack”或者Session Riding，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。CSRF通过伪装来自受信任用户的请求来利用受信任的网站。 举例 攻击通过在授权用户访问的页面中包含链接或者脚本的方式工作。例如：一个网站用户Bob可能正在浏览聊天论坛，而同时另一个用户Alice也在此论坛中，并且后者刚刚发布了一个具有Bob银行链接的图片消息。设想一下，Alice编写了一个在Bob的银行站点上进行取款的form提交的链接，并将此链接作为图片src。如果Bob的银行在cookie中保存他的授权信息，并且此cookie没有过期，那么当Bob的浏览器尝试装载图片时将提交这个取款form和他的cookie，这样在没经Bob同意的情况下便授权了这次事务 假设Alice是Burt’s Books的一个普通顾客。当她在这个在线商店登录帐号后，网站使用一个浏览器cookie标识她。现在假设一个不择手段的作者，Melvin，想增加他图书的销量。在一个Alice经常访问的Web论坛中，他发表了一个带有HTML图像标签的条目，其源码初始化为在线商店购物的URL。比如： &lt;img src=&quot;http://store.burts-books.com/purchase?title=Melvins+Web+Sploitz&quot; /&gt; Alice的浏览器尝试获取这个图像资源，并且在请求中包含一个合法的cookies，并不知道取代小猫照片的是在线商店的购物URL,点击这个url，就会提交一个购买Melvin书籍的请求 防范措施有很多预防措施可以防止这种类型的攻击。首先你在开发应用时需要深谋远虑。任何会产生副作用的HTTP请求，比如点击购买按钮、编辑账户设置、改变密码或删除文档，都应该使用HTTP POST方法。 但是，这并不足够：一个恶意站点可能会通过其他手段，如HTML表单或XMLHTTPRequest API来向你的应用发送POST请求。保护POST请求需要额外的策略。 为了防范伪造POST请求，我们会要求每个请求包括一个参数值作为令牌来匹配存储在cookie中的对应值。我们的应用将通过一个cookie头和一个隐藏的HTML表单元素向页面提供令牌。当一个合法页面的表单被提交时，它将包括表单值和已存储的cookie。如果两者匹配，我们的应用认定请求有效。 由于第三方站点没有访问cookie数据的权限，他们将不能在请求中包含令牌cookie。这有效地防止了不可信网站发送未授权的请求。正如我们看到的，Tornado同样会让这个实现变得简单。 在构造函数中包含xsrf_cookies参数开启XSRF保护： 12345678settings = &#123; "cookie_secret": "bZJc2sWbQLKos6GkHn/VB9oXwQt8S0R0kRvJ5/xJ89E=", "xsrf_cookies": True&#125;application = tornado.web.Application([ (r'/', MainHandler), (r'/purchase', PurchaseHandler),], **settings) 这个应用标识被设置时，Tornado将拒绝请求参数中不包含正确的_xsrf值的POST、PUT和DELETE请求。为了在提交时候自动加上_xsrf值信息，我们在模板中使用如下： 123456&lt;form action="/purchase" method="POST"&gt; &#123;% raw xsrf_form_html() %&#125; &lt;input type="text" name="title" /&gt; &lt;input type="text" name="quantity" /&gt; &lt;input type="submit" value="Check Out" /&gt;&lt;/form&gt; 网页在浏览器中的源码形式一般如下： 1&lt;input type="hidden" name="_xsrf" value="856ada5b160a9e27902f46631ce8e5d3"/&gt; Ajax请求也会需要_xsrf参数，通常是通过脚本在客户端查询浏览器获取cookie值。 123456789101112131415function getCookie(name) &#123; var c = document.cookie.match("\\b" + name + "=([^;]*)\\b"); return c ? c[1] : undefined;&#125;jQuery.postJSON = function(url, data, callback) &#123; data._xsrf = getCookie("_xsrf"); jQuery.ajax(&#123; url: url, data: jQuery.param(data), dataType: "json", type: "POST", success: callback &#125;);&#125;]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tornado2]]></title>
    <url>%2F2016%2F11%2F16%2Ftornado2%2F</url>
    <content type="text"><![CDATA[模板基础与之前的Django类似的是，tornado同样是使用了MVT模式，通过模板渲染网页，tornado服务器端提取数据填充到模板文件中返回给client 前面我们为了测试tornado异步框架以及最简单的request-response流程，没有使用Template，仅仅是简单的直接self.write写入到输出流返回给client py流程实际的开发流程中，都会用到template模板，类似下面：1234567891011121314151617181920212223242526272829import os.pathimport tornado.ioloopimport tornado.optionsimport tornado.webimport tornado.httpserverfrom tornado.options import options,definedefine('port',default=8001,helo='plz run on the given port',type=int)class IndexHandler(tornado.web.RequestHandler): def get(self): self.render('index.html')class PoemHandler(tornado.web.RequestHandler): def post(self): no1=self.get_argument('no1') no2=self.get_argument('no2') no3=self.get_argument('no3') verb=self.get_argument('verb') self.render('poem.html',no1=no1,no2=no2,no3=no3,verb-verb)if __main__=='__main__': tornodo.options.parse_command_line() app=tornado.web.Application( handler=[(r'/',IndexHandler), (r'/poem',PoemHandler)] template_path=os.path.join(os.path.dirname(__file__),'templates') ) http_server=tornado.httpserver.HTTPServer(app) http_server.listen(options.port) tornado.ioloop.IOLoop.instance().start() 使用template之后，使用self.render代替了原有的self.write,render，提交给指定的html模板文件，并在方法中设置会在htlm文件中用到的context，然后tornodo就会把数据添到html文件中，之后把这个转换后的html文件作为response的body部分返回。 这里用到了模板文件，发现这里是直接在render方法中使用文件名，也就是相对路径，因为我们在将所有需要监听的url加入到循环事件之前已经将template_path设置好了： tempalte_path=os.path.join(os.path.dirname(__file____),&#39;templates&#39;) 模板文件前面的os.path.dirname(file)是将当前文件的目录提取出来，如果我们在执行这个程序的时候使用的是相对文件路径，那么返回的当然也是相对路径，总之就是返回可以识别的路径，然后后面加上’templates’这个目录名称，这个目录是提前创建好的，里面有两个模板文件：index.html和poem.html index.html文件是很简单的一个包含form表格的html: 12345678910&lt;!--简单的写一个大题流程--&gt;&lt;body&gt; &lt;form action="/poem" method="post"&gt; &lt;p&gt;&lt;input type="text" name="no1"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="text" name="no2"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="text" name="no3"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="text" name="verb"&gt;&lt;/p&gt; &lt;input type="submit"&gt; &lt;/form&gt;&lt;/body&gt; 可以看到，我们的表单action是/poem，也就是说同构submit按钮提交会转给server_adderss:port/poem这个路径处理，正好对用着我们在Application中设置的url，(r&#39;/poem&#39;,PoemHandler)，这里，实际上index.html完全就是普通的html文件，跟正常的文件没有丝毫区别 然后是使用模板流程的poem.html123456&lt;body&gt; no1 --- &#123;&#123;no1&#125;&#125; no2 --- &#123;&#123;no2&#125;&#125; no3 --- &#123;&#123;no3&#125;&#125; verb --- &#123;&#123;verb&#125;&#125;&lt;/body 这里就用到了模板文件中常用的数据占位符号{} 我们在往上面的PoemHandler类的post方法看看那： 12345def post(self): no1=self.get_argument('no1') no2=self.get_argument('no2') ... self.render('poem.html',no1=no1,no2=no2,no3=no3,verb=verb) 由于是使用的post方法提交的转到的/poem页面，我们这里使用的是post方法处理数据（其他方法没有用） self.get_argument这个方法没什么好讲的，简单通俗，从post发来的信息中听过argument name提取数据，这里的参数名就是index.html表格中的input name=”…” 这个 self.render(&#39;poem.html&#39;,no1=no1....) 这里传递的context一定要设置好，即使我们在这里故意使用了相同的参数name，如果不在render方法中设置，服务器会认为你传递的是空的context，就像IndexHandler中的get方法一样，不需要使用context。 我们在模板文件中用两个大括号包裹的就是设置的context的左值，右值是我们之前处理的数据。 模板扩展tornado中的模板扩展，包括extens和block块使用与Django都很相似，因为有前面的知识，这里我们简单过一下 extends原始的base文件base.html中使用的所有tag、layout、css、js内容都能够在使用扩展命令的其他模板文件中直接使用： { % extends base.html % } 这一点与Django完全一致 block只是继承原始的文件有什么用呢，一定要重写某些部分，够则与原始文件毫无二致，这需要2个步骤： 在原始需要扩展的base.html中的某些需要替换部分使用{ % block block_name % }{ % end % } 在扩展的文件中{ % extends base.html % } 在扩展的文件中重写block_name部分 base.html 12345&lt;!--base.html--&gt;hiahiahia&#123; % block content % &#125; I am the base.html&#123; % end % &#125; override.html 12345&lt;!--override.html--&gt;&#123; % extends "base.html" % &#125;&#123; % block content % &#125;I am the override.html&#123; % end % &#125; override.html文件继承base.html文件内容，在content block块中修改相应的内容 Tips:因为在base.html中我们定义的是完整的html标签，我们不可能破坏了原有的整体布局，当然也可以在块中继续使用html标签、引用css、js等 这样我们在分别请求对应的url后会发现显示的不同的内容 与Django做对比，Django模板中也有block部分，使用也相当相似： { % block content % }{ % endblock % } 在Django中因为要与for循环的结束符号{ % endfor % }作出区别，没有直接使用end，而是选择了endblock，其他的毫无区别]]></content>
      <categories>
        <category>tornado</category>
      </categories>
      <tags>
        <tag>tornado</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[uwsgi]]></title>
    <url>%2F2016%2F11%2F16%2Fuwsgi%2F</url>
    <content type="text"><![CDATA[wsgi先来讲讲Web应用，抛开dns、网络连接这些先不谈，我们只看服务器与浏览器client之间，静态Web应用一般是这样的流程： 浏览器发送一个http请求 服务器收到request，生成或者找到请求的文件 服务器将html文件作为response的body部分返回/无需渲染文件直接返回 浏览器收到响应后，从response取出数据并填充、渲染 类似Apache、Nginx这类static server最擅长干的事情，就是我们提前将浏览器要访问的html页面、static文件（img、css、js）等放到静态服务器的指定位置，服务器接受请求返回文件动态服务器的话因为要根据请求的url解析并生成数据返回给浏览器，上面的一些步骤就需要我们自己实现。 不过，接受HTTP请求、解析HTTP请求、发送HTTP响应都是苦力活，如果我们自己来写这些底层代码，还没开始写动态HTML呢，就得花个把月去读HTTP规范。 正确的做法是底层代码由专门的服务器软件实现，我们用Python专注于生成HTML文档。因为我们不希望接触到TCP连接、HTTP原始请求和响应格式，所以，需要一个统一的接口，让我们专心用Python编写Web业务。 这个接口就是WSGI：Web Server Gateway Interface。 WSGI接口定义非常简单，它只要求Web开发者实现一个函数，就可以响应HTTP请求。 12345#app.pydef application(environ,start_response): start_response('200 OK',[('Content-Type','text/html')]) body='&lt;head&gt;&lt;title&gt;hiahia&lt;/title&gt;&lt;body&gt;&lt;h1&gt;Hello %s&lt;/h1&gt;&lt;/body&gt;&lt;/head&gt;' % (environ['PATH_INFO'][1:] or 'world') return [body.encode('utf-8')] 这个函数是被wsgi服务器调用，跑在wsgi服务器上的，接受两个参数： environ 包含所有HTTP请求信息的dict对象，上面使用的environ[‘PATH_INFO’]就是我们请求的服务器地址，例如服务器跑在本机端口8001上: curl http://localhost:8001/hiahiahia/hiahiahia 那么此时就会返回 Hello hiahiahia/hiahiahia，如果是直接请求/，会返回默认设置的’world’ start_response 发送HTTP响应的函数 application()函数中，调用：start_response(&#39;200 OK&#39;, [(&#39;Content-Type&#39;, &#39;text/html&#39;)])就发送了HTTP响应的Header，注意Header只能发送一次，也就是只能调用一次start_response()函数。start_response()函数接收两个参数，一个是HTTP响应码，一个是一组list表示的HTTP Header，每个Header用一个包含两个str的tuple表示。多个元祖之间以逗号分开，填充到list中 然后，函数的返回值b’Hello, web!‘将作为HTTP响应的Body发送给浏览器。 有了WSGI，我们关心的就是如何从environ这个dict对象拿到HTTP请求信息，然后构造HTML，通过start_response()发送Header，最后返回Body。 整个application()函数本身没有涉及到任何解析HTTP的部分，也就是说，底层代码不需要我们自己编写，我们只负责在更高层次上考虑如何响应请求就可以了。 application()函数必须由WSGI服务器来调用，我们这里简单测试就用python自带的wsgiref 12345#server.pyfrom wsgiref.simple_server import make_serverfrom app import applicationhttpd=make_server('',8001,application)httpd.serve_forever() 无论多么复杂的Web应用程序，入口都是一个WSGI处理函数。HTTP请求的所有输入信息都可以通过environ获得，HTTP响应的输出都可以通过start_response()加上函数返回值作为Body。 uWSGIuwsgi是uWSGI服务器自创的一种协议，是一种线路协议而非类似wsgi的通信协议。 uWSGI是实现了WSGI、uwsgi和http协议的服务器 django+uWSGI+nginx这里吧django、uWSGI和nginx的关系梳理一下，网络上有大把的文章都是在描述这三者怎么搭载、怎么执行的，却没有好好介绍之间的联系： Django实际上只是一个流行的开源框架，因为其高效、便捷全面的开发流程收到欢迎； nginx为Django Project提供反向代理服务，是对外服务的接口，浏览器通过url请求服务器的时候，请求首先会经过nginx，nginx将请求分析，如果是静态文件则直接返回可用的静态文件，动态网页就转发给uwsgi； uwsgi收到请求后处理成wsgi能够接受的格式，wsgi根据配置文件使用app的函数，然后把处理后的数据在打包成uwsgi接受的格式、转发给nginx-&gt;传回给浏览器 从上面的流程中可以看到，实际上nginx做的处理静态文件请求这件事，uwsgi也是能做的，那么为什么还要用nginx呢？ 对于静态文件的处理，nginx要比uwsgi好得多 程序不希望被浏览器访问到，而是通过nginx,nginx只开放某个接口，uwsgi本身则是内网接口，这样运维人员在nginx上加上安全性的限制，可以达到保护程序的作用 nginx可以做反向映射，一个uwsgi服务器可能不能保证程序的运行，放到多个服务器上，这样通过nginx配置文件中配置后，不同的app转发到不同的uwsgi上。 关于反向映射，可以看这张图： 对于普通代理来讲，代理机与client(browser)属于同一个域，服务器将他们视为整体，代理的是client； 反向代理与真正的服务器在一个域，属于同一局域网，client将他们视为整体，代理的是后面多台服务器，主要有cache、安全性以及负载平衡方面的考虑]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 网络IO模式(转)]]></title>
    <url>%2F2016%2F11%2F15%2Fio_multiplexing%2F</url>
    <content type="text"><![CDATA[Linux IO模式-人云思云 IO模式对于一次IO访问，数据会先被拷贝到操作系统的内核缓冲中，然后应用会从缓冲区中获取数据，这中间有两个过程： 等待数据准备（waiting for data to be read） 将数据从内核拷贝到进程中(copying the data from the kernel to the process) 一般有5种网络模式： 阻塞 非阻塞 I/O多路复用 信号驱动 异步I/O 阻塞 I/O（blocking IO）在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样： 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞 I/O（nonblocking IO）linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子： 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 在这种模式下，之前提到的两种过程：等待数据拷贝到内核以及从内核拷贝到应用中，在第一个过程，进程并未被阻塞，依然可以继续进行下去，但是只能去不断的轮询数据是否到达了；第二个过程依然还是阻塞形式。 异步IO 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 I/O 多路复用（ IO multiplexing）IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 asynchronous/synchronous IO是同步IO还是异步IO在POSIX中是这样定义的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。 而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 多路复用的3种方式select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间，异步I/O根本不会在数据复制的过程中接触到这些数据。 selectint select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符，然后再一同使用recvfrom函数从描述符指引的地方拿数据。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。 pollint poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。 12345struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */&#125;; pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epollepoll操作过程需要三个接口，分别如下： 123int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); int epoll_create(int size)创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)函数是对指定描述符fd执行op操作。 epfd：是epoll_create()的返回值。 op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 fd：是需要监听的fd（文件描述符） epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下： int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout) 等待epfd上的io事件，最多返回maxevents个事件。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 工作模式epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 LT模式 LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 ET模式 ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 epoll优点 在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。 IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。 如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。 事件循环nginx和tornado的最高效实现实际上都是基于epoll或类似epoll（mac下是kqueue，windows下只支持select）的事件循环机制 异步事件驱动模型中，把会导致阻塞的操作转化为一个异步操作，主线程负责发起这个异步操作，并处理这个异步操作的结果。由于所有阻塞的操作都转化为异步操作，理论上主线程的大部分时间都是在处理实际的计算任务，少了多线程的调度时间，所以这种模型的性能通常会比较好。 事件驱动编程的架构是预先设计一个事件循环，这个事件循环程序不断地检查目前要处理的信息，根据要处理的信息运行一个触发函数。其中这个外部信息可能来自一个目录夹中的文件，可能来自键盘或鼠标的动作，或者是一个时间事件。这个触发函数，可以是系统默认的也可以是用户注册的回调函数。 事件驱动程序设计着重于弹性以及异步化上面。 基于事件驱动的编程是单线程思维，其特点是异步+回调。异步的实现可以使使用多线程，也可以将任务交给其他进程处理 协程也是单线程，但是它能让原来要使用异步+回调方式写的非人类代码,可以用看似同步的方式写出来。它是实现推拉互动的所谓非抢占式协作的关键。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阻塞/非阻塞&同步/异步]]></title>
    <url>%2F2016%2F11%2F14%2Fasyn_loop%2F</url>
    <content type="text"><![CDATA[同步/异步 The Sockets Networking API 同步和异步的区别在于，做一件事情，消息通知的流程。在同步中，是由发起者（调用者）主动等待消息反应，而异步情况则是有被动者（被调用者）通过反馈机制通知发起者来处理返回的消息 所以区分同步与异步，主要是消息处理前的行为 阻塞/非阻塞阻塞是在调用结果返回之前，当前线程/进程将会被挂起，直到结果返回才会继续执行。 非阻塞情况不会阻塞当前线程，该线程还可以执行。 所以阻塞与非阻塞的关注点应该在于发出请求之后，请求未返回之前这段时间，线程是否有能力（被允许）执行之后的任务 阻塞是由系统自动执行阻塞原语(block)，使自己由运行状态变为阻塞状态。进程进入阻塞状态之后，不会占用CPU资源 coroutine与异步回调 协程coroutine即协程，是实现类异步执行的一种方式。 协程是什么呢，协程实际上是一种比线程更小的执行单元，自带context，协程实现类异步也是通过不断的切换；相比线程，协程仅仅是保持着cpu context，而进程一直维持着cache、断点等很多消耗时间、内存的地方。 协程的一些缺点：虽然相比线程来讲，减少了很多cache等数据维持，实际上context与线程相比并没有太多的提升，如果task是CPU密集型，使用协程可以看到很好的效果，I/O密集型则不会有很大改观，因为依然是阻塞式；协程是非系统层面感知的，无法使用系统的进程调度，我们只能主动的在协程的上层线程中重造调度器来实现协程间的调度； 解决：低速I/O与高速CPU协调问题 异步回调这是一种比较常见的异步使用方式，发起方调用任务，并设置指定的回调函数；调用方和被调用处于不同的线程中，调用方发起并启动新的被调用线程后继续执行后面的task，新线程执行完指定的调用任务后，通过多种消息通知方法通知调用方，这样调用放就能够继续执行异步调用数据。 缺点：将原有逻辑上整体的蛋糕强行分成了两部分甚至更多，这样不是很符合人类的逻辑理解。多个回调之间耦合性太高 异步的实现可以使用多线程，也可以将任务交给其他进程处理]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tornodo入门]]></title>
    <url>%2F2016%2F11%2F14%2Ftornado%2F</url>
    <content type="text"><![CDATA[引言首先来谈谈c10k问题。所谓c10k问题，指的是服务器同时支持成千上万个客户端的问题，也就是concurrent 10000 connection。由于硬件成本的大幅度降低和硬件技术的进步，如果一台服务器同时能够服务更多的客户端，那么也就意味着服务每一个客户端的成本大幅度降低，从这个角度来看，c10k问题显得非常有意义。 Tornado在设计之初就考虑到了性能因素，旨在解决C10K问题，这样的设计使得其成为一个拥有非常高性能的框架。此外，它还拥有处理安全性、用户验证、社交网络以及与外部服务（如数据库和网站API）进行异步交互的工具。 推荐的平台在windows下实现tornado的异步并没有什么障碍，但由于在windows下的异步是靠select来支持的，鉴于windows的最大512的文件操作符限制，异步并行能力理论无法超过甚至接近这个上限（c10k更无从谈起），实际上如果你的tornado中有阻塞操作的话，这个数值还会进一步降低。这样完全发挥不出来tornado的优势。同理，nginx在windows下也有同样的性能尴尬。二来呢，tornado多进程机制在windows下无法使用，手动实现的话又需要多个端口。非常鸡肋，所以一般做测试、运行的话还是推荐在类Unix下，如linux或者max机上，开发时可以拿win平台开发 入门实例与Django类似，使用tornado开发同样是使用re这呢规则表达式对不同请求区分转发： 12345678910111213141516171819202122232425262728293031323334353637import textwrapimport tornado.httpserverimport tornado.ioloopimport tornado.optionsimport tornado.webfrom tornado.options import define, optionsdefine("port", default=8002, help="run on the given port", type=int)class IndexHandler(tornado.web.RequestHandler): def get(self): greeting = self.get_argument('greeting', 'Hello') self.write(greeting + ', friendly user!\r\n')class ReverseHandler(tornado.web.RequestHandler): def get(self, input): self.write(input[::-1]+"\r\n")class WrapHandler(tornado.web.RequestHandler): def post(self): text = self.get_argument('text') width = self.get_argument('width', 40) self.write(textwrap.fill(text, int(width))) if __name__ == "__main__": tornado.options.parse_command_line() app = tornado.web.Application( handlers=[ (r"/reverse/(\w+)", ReverseHandler), (r"/wrap", WrapHandler), (r'/'，IndexHandler） ] ) http_server = tornado.httpserver.HTTPServer(app) http_server.listen(options.port) tornado.ioloop.IOLoop.instance().start() 上面的例子中，使用了两种最常用的http请求方式，get和post，get形式的request数据直接在url后面以?开始&amp;连接=匹配键值对,post方式以postdata的形式封装成数据发送给服务器 IndexHandler获取url中key为’ge=reeting’的value并填充到后面返回给浏览器，请求形式: curl http://localhost:8002/?greeting=clinjie 返回：clinjie, friendly user! 注意的是，如果没有获取到名为greeting的键值，则会使用默认字符串Hello ReverseHandler同样是处理get请求，不过在函数定义的时候有区别：input，这个参数将包含匹配处理函数正则表达式第一个括号里的字符串。如果正则表达式中有一系列额外的括号，匹配的字符串将被按照在正则表达式中出现的顺序作为额外的参数传递进来。 curl http://localhost:8002/reverse/peihao.space 这里re正则parttern为/reverse/(\w+)，显然匹配的是peihao.space，input的值获取之后反转返回给client WrapHandler处理post请求，这里字符串的处理使用的是textwrap模块，可以方便的进行段落填充，并且设置每行的最大值 curl http://localhost:8001/wrap -d text=Lorem+ipsum+dolor+sit+amet,+consectetuer+adipiscing+elit 异步执行上面的例子中，修改IndexHandler类： 123456import timeclass IndexHandler(tornado.web.RequestHandler): def get(slef): time.sleep(10) greeting=self.get_argument('greeting','Hello') self.write(ge=reeting+',*******') 其他不用修改，此时我们按顺序在两个terminal中请求 curl http://localhost:8002/?greeting=clinjie curl http://localhost:8002/reverse/home 可以发现，虽然我们执行的时间间隔非常小，不会超过3s，但是由于第一个请求被阻塞了，第二个很简单可以直接返回数据的请求也无法立刻执行，只能等待第一个请求执行完毕后开始执行后面的。 tornado与其他web framework最出彩的就是对于异步处理支持度很高。 tornado.web.asynchronous注解在类前面使用@tornado.web.asynchronous装饰注解，此后命中匹配这个类的连接将会被认为是长连接(long connection)，保持连接开启。注意这里很重要，tornado默认是在当前方法结束之后就会将连接关闭，但是使用异步情况下，我们将会使用callback function，必须要保持连接开启 直到某些到达状态（例如接受response）时都在等待。由于保证了长连接的状态，我们必须显式的执行self.finish关闭连接，否则连接是不会被关闭的，我们会一直等待，无法收到数据 在类前面加入装饰器之后这个程序还是不能达到我们想要的效果，还要在函数中定义回调函数并在下面实现 curl http://localhost:8002/?greeting=clinjie 修改下： 123456789class IndexHandler(tornado.web.RequestHandler): @tornado.web.asynchronous def get(self): do sth... tornado.ioloop.IOLoop.instance().add_timeout(time.time() + 5, callback=self.on_response) def on_response(self): #self.write(self.greeting+',*******') do sth... self.finish() 终于可以搞了！ 新版本的tornado支持yield生成器，无需定义回调函数： 12345#@tornado.web.asynchronous不用了@tornado.gen.coroutinedef get(self): yield tornado.gen.Task(tornado.ioloop.IOLoop.instance().add_timeout, time.time() + 5) self.write("when i sleep 5s") 上面可以看到，要实现异步执行效果，都没有使用time.sleep(m)方法，因为time.sleep方法是线程阻塞的，而我们使用asynchronous或者coroutine这类装饰器的就是将耗时的工作变成异步回调/协程状态保存的（否则根本就没有意义），这里只能另辟蹊径，使用异步的定时执行器：tornado.ioloop.IOLoop.instance().add_timeout。 基于IOLoop的，当我们get url进入get方法，耗时任务通过异步回调或者协程处理，底层通过epoll或者kqueue、select执行，但是你要来个time.sleep这种阻塞方法那就没得玩了，所以还是通过将定时器加入到IOLoop中实现类似sleep的效果]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Tornodo</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Today]]></title>
    <url>%2F2016%2F11%2F05%2Ftoday%2F</url>
    <content type="text"><![CDATA[每年今日都在回忆去年，看了上个日记，仿佛一切还在昨天。最悠闲的大四上，忙碌的室友，熟悉的街道，那个离开几个月的城市有着无法忘记的记忆。思念我与我思念，有人说要变成memory，有人讲每个人都有secret，还有一个偶然与巧合之间消失不恋。有理想，有期待，还有对未来些许的匆匆惶惶 这边挺好，朝气蓬勃的人群，车来车往的主道，举头能见的四个大门，纤细苗条的北方姑娘和朦朦胧胧的夜晚。每个人都有干劲，有理想，也有对未来的直白愿景。我会在这里成为怎样的人呢，4年前我在深夜问过自己，5岁的自己还是20岁的自己，可选择的不太多，这里的人和事不会让你挥霍，希望自己运气不错，活的纯粹简单。 渐渐融入，让自己改变一些。健身、摄影、读书、记录自己的生活，努力让自己拥有有趣的外壳有趣的人生。时间不多了，认真去做]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy爬取知乎两种思路]]></title>
    <url>%2F2016%2F11%2F03%2Fscrapy_zhihu%2F</url>
    <content type="text"><![CDATA[介绍两种直接爬取知乎的方法，一种是通过CrawlSpider类，从Question页面开始，通过Rule自动填充带爬取页面；第二种是登录知乎首页之后，通过模拟js下拉页面发送ajax请求解析返回json数据填充原有的zhihu首页爬取。实际上还有另外一种，我们使用scrapy splash模块或者selenium工具模拟js操作，这种方法相比第二种方法更直接、简便，之后的文章会有介绍。 在做这些之前，首先你要设置好item的feed以及通用的header。这些在我其他的一些文章中有提到过 爬取question页面知乎的问题页面是不需要登录就可以直接爬取的，有次我尝试登录失败后，返回了错误代码，但是发现这并未影响继续对问题页面的爬虫。 为题页面的url一般类似/question/\d{8}，收尾是8个数字，问题页面会随机出现与本问题有类似、相关共性的其他问题url，这就让我们使用CrawlSpider类有了可能。关于CrawlSpider的前置学习，请参考：Scrapy笔记 通过使用CrawlSpider类支持的rules，制定自动提取的问题界面url规则： 1rules = (Rule(LinkExtractor(allow = [r'/question/\d&#123;8&#125;$',r'https://www.zhihu.com/question/\d&#123;8&#125;$' ]), callback = 'parse_item', follow = True)) 上面的规则允许提取符合为题界面的absolute url或者relative url填充到爬虫队列中，并设置了请求这些url之后response的处理方法，parse_item(self,response)，这里要再说一次，callback直接写parse_item，不要画蛇添足self.parse。 设置一个你感兴趣的问题，放入到start_urls列表中，Scrapy会自动在make_requests_from_url方法执行时搜索符合规则的url，当我们执行scrapy crawl spidernamestart_request后，程序开始调用start_requests方法，方法将start_urls中的url分别调用make_requests_from_url结束。如果我们不是直接就开始对start_url中的url进行解析，可以重写start_requests，并指定requests的回调函数。 做完这些之后，我们就可以仅仅处理item解析的相关操作，不用管获取新的url内容，至于爬取的为题是不是我们感兴趣的，就要看知乎的推荐算法怎么养了。 12345678910111213141516171819202122232425262728293031323334from scrapy.selector import Selectorfrom scrapy.http import Requestfrom douban.items import ZhihuItemimport scrapyfrom scrapy.spiders import CrawlSpider, Rulefrom scrapy.linkextractors import LinkExtractorclass ZhihuSipder(CrawlSpider) : name = "zhihu" allowed_domains = ["zhihu.com"] start_urls = [ "https://www.zhihu.com/question/41472220" ] rules = (Rule(LinkExtractor(allow = [r'/question/\d&#123;8&#125;$',r'https://www.zhihu.com/question/\d&#123;8&#125;$' ]), callback = 'parse_item', follow = True),) headers = &#123; "Accept": "*/*", "Accept-Encoding": "gzip,deflate", "Accept-Language": "en-US,en;q=0.8,zh-TW;q=0.6,zh;q=0.4", "Connection": "keep-alive", "Content-Type":" application/x-www-form-urlencoded; charset=UTF-8", "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36", "Referer": "http://www.zhihu.com/" &#125; def parse_item(self, response): problem = Selector(response) item = ZhihuItem() item['url'] = response.url item['name'] = problem.xpath('//span[@class="name"]/text()').extract() item['title'] = problem.xpath('//span[@class="zm-editable-content"]/text()').extract() item['description'] = problem.xpath('//div[@class="zm-editable-content"]/text()').extract() item['answer']= problem.xpath('//div[@class="zm-editable-content clearfix"]/text()').extract() return item 登陆模拟ajax爬取主页这种方法对于我们来讲可能更加准确，因为他是在zhihu.com主页显示的我们关注过的问题新高票答案，以及关注的领域专栏专栏文章。 由于是一直在www.zhihu.com页面是操作，没有爬取其他页面，所以在使用CrawlSpider类就不太合适了。直接使用原始的scrapy.spider类。 关于知乎的登录，可以参考文章简书-模拟登陆 当然上面文章因为时间较早，zhihu的登录模块已经改了一些东西，但是具体的思路和流程还是可以继续用的。 1234567891011121314151617181920212223242526272829#重写 start_requests方法，登录登录面，注意登录界面与旧版不同def start_requests(self): return [Request("https://www.zhihu.com/#signin", meta = &#123;'cookiejar' : 1&#125;, callback = self.post_login)]#处理知乎防爬虫_xsrf字段 ，使用formRequest发送post信息，注意form的提交url与旧版的不同def post_login(self, response): print('Preparing login') #下面这句话用于抓取请求网页后返回网页中的_xsrf字段的文字, 用于成功提交表单 self.xsrf = Selector(response).xpath('//input[@name="_xsrf"]/@value').extract()[0] #FormRequeset.from_response是Scrapy提供的一个函数, 用于post表单 #登陆成功后, 会调用after_login回调函数 return [FormRequest(url="https://www.zhihu.com/login/email", meta = &#123;'cookiejar' : response.meta['cookiejar']&#125;, formdata = &#123; '_xsrf': self.xsrf, 'email': '******', 'password': '******', 'remember_me': 'true' &#125;, headers=self.headers, callback = self.after_login, dont_filter = True )]def after_login(self, response): #这里注意在header中加入两个字段 self.headers['X-Xsrftoken']=self.xsrf self.headers['X-Requested-With']="XMLHttpRequest" return Request('https://www.zhihu.com',meta = &#123;'cookiejar' : response.meta['cookiejar']&#125;, callback =self.parse,dont_filter = True) 此时我们可以抓取zhihu首次返回的大概10个问题信息，更多的信息需要下拉鼠标ajax发送请求才会返回。 我们通过珠宝工具找到相应的post信息，模拟操作： 12345678910FormRequest(url="https://www.zhihu.com/node/TopStory2FeedList", meta = &#123;'cookiejar' : response.meta['cookiejar']&#125;, formdata = &#123; 'params': '&#123;"offset":%d,"start":%s&#125;' % (self.count*10,str(self.count*10-1)), 'method': 'next', &#125;, headers=self.headers, callback = self.parse, dont_filter = True ) 依然通过FormRequest提交Post信息，注意formdata的params键值为dict，要加上括号，原因可以在前一篇文章中找到答案。offset是获取的问题数目，start是新获取问题的index 刚开始请求时一直提示Bad Request信息，最后发现一定要在header中设置之前获取的_xsrf。 服务器端根据我们的params字段返回不同的bytes形式json数据，我们需要拿到里面的摸个键值，所以要将bytes解码为utf-8，拿到之后在编码为utf-8，因为response只处理bytes形式。 最后，因为response使用xpath方法是对response.text属性操作，当我们获取新的response之后就无法再改变response.text（在python中使用@property标注的属性无法更改）但是我们可以通过response内置的response._set_body()方法修改response的body值，不能使用内置的xpath方法，就改用原始的lxml模块提供的xpath工具，毕竟scrapy内置的xpath底层也是使用lxml模块提供支持，大同小异。其他的一些问题就比较小了，不在这里一一讲： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384from scrapy.http import Request, FormRequestfrom douban.items import ZhihuAnswerItemimport scrapy,json,refrom lxml import etreeclass ZhihuSipder(scrapy.Spider) : name = "zhihuanswer" #allowed_domains = ["zhihu.com"] start_urls = [ "https://www.zhihu.com" ] headers = &#123; ...... &#125; xsrf="" moreinfo=False count=0 def start_requests(self): return [Request("https://www.zhihu.com/#signin", meta = &#123;'cookiejar' : 1&#125;, callback = self.post_login)] def post_login(self, response): print('Preparing login') self.xsrf = Selector(response).xpath('//input[@name="_xsrf"]/@value').extract()[0] print(self.xsrf) #FormRequeset.from_response是Scrapy提供的一个函数, 用于post表单 #登陆成功后, 会调用after_login回调函数 return [FormRequest(url="https://www.zhihu.com/login/email", meta = &#123;'cookiejar' : response.meta['cookiejar']&#125;, formdata = &#123; '_xsrf': self.xsrf, 'email': '******', 'password': '******', 'remember_me': 'true' &#125;, headers=self.headers, callback = self.after_login, dont_filter = True )] def after_login(self, response): print(response.body) self.headers['X-Xsrftoken']=self.xsrf self.headers['X-Requested-With']="XMLHttpRequest" return Request('https://www.zhihu.com',meta = &#123;'cookiejar' : response.meta['cookiejar']&#125;, callback =self.parse,dont_filter = True) def parse(self, response): if self.moreinfo: #使用模拟ajax发送post请求接受的response 编码抓换解析相关 f=json.loads(response.body.decode('utf-8')) for item in range(1,len(f['msg'])-1): f['msg'][0]=f['msg'][0]+f['msg'][item] fs=f['msg'][0].encode('utf-8') response._set_body(fs) else: self.moreinfo=True html=etree.HTML(response.body.decode('utf-8'),parser=etree.HTMLParser(encoding='utf-8')) for p in html.xpath('//div[@class="feed-main"]'): url=p.xpath('div[2]/h2[@class="feed-title"]/a/@href') if url:url=url[0] # 通过决定是否使用if not re.findall('zhuanlan',url) 接受专栏文章或者问题回答，或者删掉这部分，全部接受 if re.findall('zhuanlan',url):continue item = ZhihuAnswerItem() item['url'] = url name=p.xpath('div[2]/div[@class="expandable entry-body"]/div[@class="zm-item-answer-author-info"]/span/span/a/text()') item['name'] = name if name else '匿名用户' item['question'] = p.xpath('div[2]/h2[@class="feed-title"]/a/text()') item['answer']= p.xpath('div[2]/div[@class="expandable entry-body"]/div[@class="zm-item-rich-text expandable js-collapse-body"]/div[@class="zh-summary summary clearfix"]/text()') yield item #维持不同的params self.count=self.count+1 yield FormRequest(url="https://www.zhihu.com/node/TopStory2FeedList", meta = &#123;'cookiejar' : response.meta['cookiejar']&#125;, formdata = &#123; 'params': '&#123;"offset":%d,"start":%s&#125;' % (self.count*10,str(self.count*10-1)), 'method': 'next', &#125;, headers=self.headers, callback = self.parse, dont_filter = True )]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy解决formrequest中formdata为dict问题]]></title>
    <url>%2F2016%2F11%2F02%2Fscrapy_formrequest%2F</url>
    <content type="text"><![CDATA[在Scrapy的FormRequest中直接将formdata设置为dict形式后，scrapy经过字节编码形式的转换，会发出一个非期望的request，例如： 123456FormRequest(url="**************************", meta = &#123;'cookiejar' : response.meta['cookiejar']&#125;, formdata = &#123; 'params': &#123;"offset":10,"start":"10"&#125;, 'method': 'next', &#125;) 我们此时将发送的表单数据，属性params的值设置为dict，原有的请求形式为： params=%7B%22offset%22%3A10%2C%22start%22%3A%2210%22%7D&amp;method=next 经过错误的变换之后，发送的请求变为： params=start&amp;params=offset&amp;method=next 上面的url中%开始的字符是经过bytes变换之后的形式，翻译成我们能看懂的就是： params={&quot;offset&quot;:10,&quot;start&quot;:&quot;10&quot;}&amp;method=next 在Scrapy的源码文件/http/request/form.py中，定义了scrapy是如何将formdata处理： 123456items = formdata.items() if isinstance(formdata, dict) else formdatadef _urlencode(seq, enc): values = [(to_bytes(k, enc), to_bytes(v, enc)) for k, vs in seq for v in (vs if is_listlike(vs) else [vs])] return urlencode(values, doseq=1) 其中seq就是原始的formdata.items()，enc的编码格式，这里我们忽略。经过items()方法执行后，原始的外围的dict格式变成列表形式： dict_items([(&#39;method&#39;, &#39;next&#39;), (&#39;params&#39;, {&#39;start&#39;: &#39;10&#39;, &#39;offset&#39;: 10})]) 再经过_urlencode方法将items转换成 [(b&#39;method&#39;, b&#39;next&#39;), (b&#39;params&#39;, b&#39;start&#39;), (b&#39;params&#39;, b&#39;offset&#39;)] 可以看到就是在调用_urlencode方法的时候出现了问题，上面的方法执行过后，会使字典形式的数据只保留了keys，将字典数据作为的value的key分别当做字典数据value。 幸运的是，网络中dict形式的请求是直接将{&#39;&#39;:&#39;&#39;,&#39;&#39;,&#39;&#39;}这种转换成bytes形式传递，没有再进行其他转换，至于dic的解析则由服务器端处理，所以我们直接将dic的数据外面加上’’，转换成字符串形式。 1234formdata = &#123; 'params': '&#123;"offset":10,"start":"10"&#125;', 'method': 'next', &#125; 此时变成了: dict_items([(&#39;method&#39;, &#39;next&#39;), (&#39;params&#39;, {&#39;start&#39;: &#39;10&#39;, &#39;offset&#39;: 10})])]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy笔记]]></title>
    <url>%2F2016%2F10%2F31%2Fscrapy_notes%2F</url>
    <content type="text"><![CDATA[这里记录两种使用率最高的Spider：Spider和他的子类CrawlSpider. 组件梳理先对整个Scrapy的部件进行梳理： Scrapy Engine引擎负责控制数据流在系统中所有组件中流动，并在相应动作发生时触发事件。 调度器(Scheduler)调度器从引擎接受request并将他们入队，以便之后引擎请求他们时提供给引擎。 下载器(Downloader)下载器负责获取页面数据并提供给引擎，而后提供给spider。 SpidersSpider是Scrapy用户编写用于分析response并提取item(即获取到的item)或额外跟进的URL的类。 每个spider负责处理一个特定(或一些)网站。 更多内容请看 Spiders 。 Item PipelineItem Pipeline负责处理被spider提取出来的item。典型的处理有清理、 验证及持久化(例如存取到数据库中)。 更多内容查看 Item Pipeline 。 下载器中间件(Downloader middlewares)下载器中间件是在引擎及下载器之间的特定钩子(specific hook)，处理Downloader传递给引擎的response（也包括引擎传递给下载器的Request）。 其提供了一个简便的机制，通过插入自定义代码来扩展Scrapy功能。处理下载请求部分 Spider中间件(Spider middlewares)Spider中间件是在引擎及Spider之间的特定钩子(specific hook)，处理spider的输入(response)和输出(items及requests)。 其提供了一个简便的机制，通过插入自定义代码来扩展Scrapy功能，处理解析部分 引擎打开一个网站(open a domain)，找到处理该网站的Spider并向该spider请求第一个要爬取的URL(s)。 引擎从Spider中获取到第一个要爬取的URL并在调度器(Scheduler)以Request调度。 引擎向调度器请求下一个要爬取的URL。 调度器返回下一个要爬取的URL给引擎，引擎将URL通过下载中间件(请求(request)方向)转发给下载器。 一旦页面下载完毕，下载器生成一个该页面的Response，并将其通过下载中间件(返回(response)方向)发送给引擎。 引擎从下载器中接收到Response并通过Spider中间件(输入方向)发送给Spider处理。 Spider处理Response并返回爬取到的Item及(跟进的)新的Request给引擎。 引擎将(Spider返回的)爬取到的Item给Item Pipeline，将(Spider返回的)Request给调度器。 (从第二步)重复直到调度器中没有更多地request，引擎关闭该网站。 SpiderScrapy中所有的Spider都是继承自scrapy.spiders.Spider这个类，所以他有爬虫类的一些共性，以及最常规符合我们思路的爬虫思想。 我们先看一下例子：123456789101112131415161718192021import scrapyfrom scrapy.linkextractors import LinkExtractorfrom douban.items import CsdnItemclass CsdnSpider(scrapy.Spider): name='csdn' allowed_domains=['blog.csdn.net'] start_urls=['http://blog.csdn.net/******/article/list/1'] def parse(self,response): for info in response.xpath('//dl[@class="list_c clearfix"]/dd'): item=CsdnItem() item['title'] = info.xpath('h3/a/text()').extract() item['url'] = info.xpath('h3/a/@href').extract() item['description'] = info.xpath('p[@class="list_c_c"]/text()').extract() item['viewpoint']=info.xpath('div[@class="list_c_b"]/div[@class="list_c_b_l"]/span[1]/text()').extract() yield item next_page = response.xpath('//div[@class="pagelist"]/a[text()="下一页"]/@href') if next_page: url = 'http://blog.csdn.net'+next_page[0].extract() yield scrapy.Request(url, self.parse) 上面的例子是我自己的某博客网站进行爬虫，获取所有文章的标题，url摘要和访问数信息。自定义的CsdnSpider类就是基类的子类，我们对name、allowed_domans和start_urls进行赋值，分别代表项目的唯一爬虫名称、此爬虫爬虫的站点范围和初始爬虫的入口url。 设置之后，当我们开始进行爬虫程序后，scrapy.Spider末默认开始调用start_requests方法，对每个start_urls中的连接使用make_requests_from_url方法，尝试request访问返回Request对象，scrapy的downloader对请求实现，并返回response对象。之后我们需要对response信息提取有用的信息。 在spider类中，默认使用的解析方法是parse，按我们的理解来说，他应该算是抽象方法，也就是必须实现的方法，否则直接抛出Error12def parse(self, response): raise NotImplementedError response对象包含很多常用的属性，类似response.url、response.body等等都是能够直接返回数据，同时可以使用cssselector、xpath等方法对response深层的信息获取。item就是我们我们把需要获取的数据整合成的对象，包含一系列的Field属性保存爬取的数据；出现了yield说明这个函数是一个生成器，对比使用return，yield可以及时的将信息返回给pipline，更重要的是可以在一个生成器中同时生成一个Item和产生新的请求，return无法做到。 上面的例子执行的话可以使用scrapy crawl csdn -o xxx.json -o参数标明使用者选择将所有Item信息输出的文件中保存，后面紧随的就是文件名。 CrawlSpider对比基类，CrawlSpider应该是一种更通用爬虫方法，通过使用Rule结构，CrawlSpider能够自动的在我们爬取的页面中更迭新的url，不用我们提取url信息。 1234567891011121314151617181920212223242526272829303132333435363738from scrapy.selector import Selectorfrom douban.items import CnBlogItemimport scrapyfrom scrapy.spiders import CrawlSpider, Rulefrom scrapy.linkextractors import LinkExtractor'''平时在parse中return item即可返回item，return request则生成新的request请求。如果我们将return换为yield的话即可既返回item又生成新的request。注意一旦使用了yield，那么parse方法中就不能有return了。'''class CnBlogSipder(CrawlSpider) : name = "cnblog" #设置爬虫名称 allowed_domains = ["blog.csdn.net"] start_urls = [ "http://blog.csdn.net/peihaozhu/article/list/1", ] rules = ( Rule(LinkExtractor(allow=('/peihaozhu/article/list/\d+', ),),callback='parse_item',follow=True), ) #制定规则 def parse_item(self, response): sel = response.selector posts = sel.xpath('//dl[@class="list_c clearfix"]/dd') items = [] for p in posts: #content = p.extract() #self.file.write(content.encode("utf-8")) item = CnBlogItem() item["title"] = p.xpath('h3[@class="list_c_t"]/a/text()').extract() item["url"] = p.xpath('h3[@class="list_c_t"]/a/@href').extract() item['description']= p.xpath('p[@class="list_c_c"]/text()').extract() items.append(item) return items rules属性就是我们需要在页面中自动更迭url的提取规则，这里我简单的使用了LinkExtractor提取器，设置了允许规则，标明在匹配到allow字段的url加入到爬取队列，follow字段决定是否将匹配到的继续使用Rule，callback很明显，就是我们提取到的url之后的回调函数，这里要注意下，类似上面的方法名，千万不要写self.parse_item，否则scrapy无法找到对应的函数。也不要使用parse作为我们的回调函数12def parse(self, response): return self._parse_response(response, self.parse_start_url, cb_kwargs=&#123;&#125;, follow=True) parse方法不是空方法，有其他的内置方法是需要依赖这个方法体做出相应动作的。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy中关于Export Unicode字符集问题解决]]></title>
    <url>%2F2016%2F10%2F28%2Fscrapy-unicode%2F</url>
    <content type="text"><![CDATA[使用命令行scrapy crawl spider_name -o filename将制定内容的item信息输出时，scrapy使用默认的feed export对特定的file类型文件支持，例如json文件是JsonLinesItemExporter，xml文件是XmlItemExporter，有时候我们对export的形式或者内容不太满意时，可以自己继承上面的类，自定义export子类。 默认显示的中文是阅读性较差的Unicode字符，我们需要在settings文件中定义子类显示出原来的字符集。1234567891011from scrapy.exporters import JsonLinesItemExporter class CustomJsonLinesItemExporter(JsonLinesItemExporter): def __init__(self, file, **kwargs): super(CustomJsonLinesItemExporter, self).__init__(file, ensure_ascii=False, **kwargs)#这里只需要将超类的ensure_ascii属性设置为False即可#同时要在setting文件中启用新的Exporter类FEED_EXPORTERS = &#123; 'json': 'porject.settings.CustomJsonLinesItemExporter', &#125; 之后使用命令行scrapy crawl spider_name -o filename.json就可以显示出正常可阅读的字符。 Pipeline在Doc中的定义如下： After an item has been scraped by a spider, it is sent to the Item Pipeline which processes it through several components that are executed sequentially 所以我们也可以在Pipeline类中直接定义输出： 123456789101112131415from project.settings import CustomJsonLinesItemExporterclass DoubanPipeline(object): #定义开始爬虫的行为 def open_spider(self,spider): self.file=open('xxx.json','wb') self.exporter=CustomJsonLinesItemExporter(self.file) self.exporter.start_exporting() #定义爬虫结束的行为 def close_spider(self,spider): self.exporter.finish_exporting() self.file.close() #定义爬虫过程中的行为 def process_item(self, item, spider): self.exporter.export_item(item) return item]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pyinstaller打包pyqt5问题解决]]></title>
    <url>%2F2016%2F10%2F23%2Fpyinstaller%2F</url>
    <content type="text"><![CDATA[pyinstaller打包使用pyqt5模块的时候，在win平台下，由于pyinstaller无法准确获取QT动态库文件路径，会报错导致无法打开运行程序，并提示错误信息pyinstaller failed to execute script pyi_rth_qt5plugins此时我们需要在打包的时候直接告诉pyinstaller到哪里去找，这个路径分隔符需要是unix形式： pyinstaller --paths C:/****/Python/Python35-32/Lib/site-packages/PyQt5/Qt/bin -F -w ****.py]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django笔记]]></title>
    <url>%2F2016%2F10%2F14%2Fdjango_note%2F</url>
    <content type="text"><![CDATA[模式整个django大体上使用MTV架构： M–&gt;Model Model主要是建立起实体关系，根据不同Model之间的联系创建数据库，Model是实体，Model的属性是实体的属性，实体间的联系主要由外键控制。 表数据的增删改查就是Model类对象的创建、删除、过滤查找。 Modelname.objects返回类的句柄 V–&gt;View 在urls.py配置文件中通过re匹配，转到view.py文件相应的方法，通过获取数据库中数据，将数据通过属性参数列表传递到模板文件template中。 T–&gt;Template 模板文件一般就是html文件，我们使用正常的html语法编写文件，同时配合传递进来的参数使用 展示界面 filter过滤器我们常用的主要有2中类型： 在view.py文件中使用 view文件中我们通过modelname.objects.filter方法，留下符合条件的对象列表 Article.objects.filter(title__icontains = s) 上面表示返回符合Article Model中对象title属性包含s的对象列表，s是字符串表达式。 在template文件中使用 我们可以在template中调用过滤方法，对待处理的数据过滤处理返回，Django中template支持管道，上一个处理的结果直接作用为下一方法的输入： post.content|read_more|custom_markdown 上面的语句一次通过调用read_more()方法、之后将处理结果作为输出参数传递调用custom_markdown（）方法. 这里的filter方法是绑定到app本身的，不能其他app复用。在本app根目录创建tamplatetags包，里面包含init.py文件。 12345register = template.Library() #自定义filter时必须加上，一个文件只需调用一次@register.filter(is_safe=True) #注册template filter 必需@stringfilter #希望字符串作为参数 #非必需def custom_markdown(value): return mark_safe(markdown.markdown(value,extensions =['markdown.extensions.fenced_code', 'markdown.extensions.codehilite'],safe_mode=True,enable_attributes=True)) staticfile使用静态文件： —-百度去吧 404使用404 —-百度去 使用staticfile要求debug=true，而使用404.html要求debug=false。冲突，我们使用将debug设置为false，此时自带服务器默认不会记在静态文件中的js、css等类型文件，需要在启动server时 winpty python manage.py runserver --insecure 连接mysql环境： Django1.10 Mysql5.5.47 Pyhton3.5.x 首先安装第三方支持模块： pip install pymysql 在projec目录的setting.py中修改： 12345678910DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'blog',#数据库名 'USER':'root',#数据库用户名 'PASSWORD':'',#数据库密码 'HOST':'',#数据库地址不写为本地127.0.0.1 'PORT':'' #数据库端口 默认3306 &#125;&#125; 要注意的是，上面使用的数据库名是已经在mysql中创建好的databasename 最后使用 python manage.py migrate 数据库同步迁移]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[py中函数的使用（二）]]></title>
    <url>%2F2016%2F10%2F08%2Fpy-functions2%2F</url>
    <content type="text"><![CDATA[函数作返回值python支持return一个函数：123456789101112131415161718192021222324def lazy_sum(*args): def sum(): ax=0 for it in args: ax+=it return ax return sumprint(lazy_sum(1,2,3,4,5))#&lt;function lazy_sum.&lt;locals&gt;.sum at 0x00554C90&gt;print(lazy_sum(1,2,3,4,5)())#15def lazy_sum(*args): ax=1 def sum(ax): for it in args: ax+=it return ax return sumprint(lazy_sum(1,2,3,4,5)(2)) lazy_sum返回的是在他函数体重定义的函数sum，内部函数sum可以引用外部函数lazy_sum的参数和局部变量，当lazy_sum返回函数sum时，相关参数和变量都保存在返回的函数中，称之为闭包（closure）。 单纯的调用lazy_sum(list…..)返回的是函数对象，需要对函数调用才行。 装饰器decorator装饰器可以在代码的运行期间动态的增加功能，本质上，装饰器就是一个返回函数的高阶函数。 12345def log(func): def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper 上面就是一个简单的decorator实例，具体的使用如下 123@logdef now(): print('2015-3-25') @log在定义函数now()之前，相当于执行了now=log(now),log函数接收了函数now，在log中的变量名是func，并且最后返回了func(args,**kw)。其中args和kw接受了now函数的所有参数，return wrapper/return func(args,**kw)，是直接执行now(args,kw)之后返回。 所以在now函数定义前面假如@log之后，相当于先执行wrapper函数，在原封不动的执行now函数。 12345678910111213import timedef log(func): def wrapper(*args, **kw): print('call %s():' % func.__name__,time.ctime()) return func(*args, **kw) return wrapper@logdef now(str): print('2015-3-25',str)now('xxxxxxx')#call now(): Sat Oct 8 23:30:38 2016#2015-3-25 xxxxxxx 上面的log、wrapper都是可以改变不是固定格式，@也是根据函数名变化。 1234567891011121314151617#实现调用前、后都输出提示信息import timedef xxx(func): def log1(*args, **kw): print('call %s():' % func.__name__,time.ctime()) func(*args, **kw) time.sleep(1) print('call %s():' % func.__name__,time.ctime()) return log1@xxxdef now(str): print('2015-3-25',str)now('xxxxxxx')#call now(): Sun Oct 9 17:27:38 2016#2015-3-25 xxxxxxx#call now(): Sun Oct 9 17:27:39 2016 如果decorator本身需要传入参数，那就需要编写一个返回decorator的高阶函数，写出来会更复杂。比如，要自定义log的文本：1234567def log(text=None): def decorator(func): def wrapper(*args, **kw): print('%s %s():' % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator 这个3层嵌套的decorator用法如下： 12345678@log('execute')def now(): print('2015-3-25')执行结果如下：&gt;&gt;&gt; now()execute now():2015-3-25 &gt;&gt;&gt; now = log(&#39;execute&#39;)(now)我们来剖析上面的语句，首先执行log(‘execute’)，返回的是decorator函数，再调用返回的函数，参数是now函数，返回值最终是wrapper函数。 以上两种decorator的定义都没有问题，但还差最后一步。因为我们讲了函数也是对象，它有name等属性，但你去看经过decorator装饰之后的函数，它们的name已经从原来的’now’变成了’wrapper’： 12&gt;&gt;&gt; now.__name__'wrapper' 因为返回的那个wrapper()函数名字就是’wrapper’，所以，需要把原始函数的name等属性复制到wrapper()函数中，否则，有些依赖函数签名的代码执行就会出错。 不需要编写wrapper.name = func.name这样的代码，Python内置的functools.wraps就是干这个事的，所以，一个完整的decorator的写法如下： 1234567891011121314151617181920import functoolsdef log(func): @functools.wraps(func) def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper#或者针对带参数的decorator：import functoolsdef log(text): def decorator(func): @functools.wraps(func) def wrapper(*args, **kw): print('%s %s():' % (text, func.__name__)) return func(*args, **kw) return wrapper return decorator 偏函数在介绍函数参数的时候，我们讲到，通过设定参数的默认值，可以降低函数调用的难度。而偏函数也可以做到这一点。举例如下： int()函数可以把字符串转换为整数，当仅传入字符串时，int()函数默认按十进制转换： 12&gt;&gt;&gt; int('12345')12345 但int()函数还提供额外的base参数，默认值为10。如果传入base参数，就可以做N进制的转换： 1234&gt;&gt;&gt; int('12345', base=8)5349&gt;&gt;&gt; int('12345', 16)74565 假设要转换大量的二进制字符串，每次都传入int(x, base=2)非常麻烦，于是，我们想到，可以定义一个int2()的函数，默认把base=2传进去： 12def int2(x, base=2): return int(x, base) 这样，我们转换二进制就非常方便了： 1234&gt;&gt;&gt; int2('1000000')64&gt;&gt;&gt; int2('1010101')85 functools.partial就是帮助我们创建一个偏函数的，不需要我们自己定义int2()，可以直接使用下面的代码创建一个新的函数int2： 123456&gt;&gt;&gt; import functools&gt;&gt;&gt; int2 = functools.partial(int, base=2)&gt;&gt;&gt; int2('1000000')64&gt;&gt;&gt; int2('1010101')85 所以，简单总结functools.partial的作用就是，把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。 注意到上面的新的int2函数，仅仅是把base参数重新设定默认值为2，但也可以在函数调用时传入其他值： 12&gt;&gt;&gt; int2('1000000', base=10)1000000 最后，创建偏函数时，实际上可以接收函数对象、args和*kw这3个参数，当传入： int2 = functools.partial(int, base=2)实际上固定了int()函数的关键字参数base，也就是： int2(‘10010’)相当于： kw = { ‘base’: 2 }int(‘10010’, **kw)当传入： max2 = functools.partial(max, 10)实际上会把10作为*args的一部分自动加到左边，也就是： max2(5, 6, 7)相当于： args = (10, 5, 6, 7)max(*args)结果为10。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[py中函数的使用]]></title>
    <url>%2F2016%2F10%2F07%2Fpy-functions%2F</url>
    <content type="text"><![CDATA[高阶函数python中，函数名可以作为变量使用，也可以作为参数传参进另外的函数中，此时另外的函数就称为高阶函数。 12def abs_add(x,y,f): return f(x)+f(y) 此时调用 12345abs_add(-5,4,abs)#或者xx=absabs_add(-3,4,xx) map/reducepython中有两大内建函数，map与reduce。与大名鼎鼎的google map-reduce机制功能类似。 mapmap()函数接受两个参数，第一个是函数，之后的是一个Iterable。关于Iterable的介绍在前面的文章中已经讲过，一般可以通过for循环的对象就是Iterable的。 map将传入的函数一次作用于序列的每个元素之上，然后再将运算结果作为新的相同的Iterable形式返回。map的函数参数作用是在序列的每个元素上，运算的结果也是有形同长的序列 12345678def f(x): return x*xlist(map(f,range(1,10)))#[1, 4, 9, 16, 25, 36, 49, 64, 81]list(map(str,range(1,10)))#['1', '2', '3', '4', '5', '6', '7', '8', '9'] reducereduce把一个函数作用在一个序列[x1, x2, x3, …]上，这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算。reduce的函数参数是依次作用在元素上，运算的结果也是一个确定的结果，一般不是序列 reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) 123456&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; def fn(x, y):... return x * 10 + y...&gt;&gt;&gt; reduce(fn, [1, 3, 5, 7, 9])13579 上面的运算中，首先使用序列的前两个元素计算结果，然后将结果与后面每个的元素一次次的计算。 123456789#str2intfrom functools import reducedef str2int(s): def fn(x, y): return x * 10 + y def char2num(s): return &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;[s] return reduce(fn, map(char2num, s)) 先用map将序列的每个char元素对应成int，之后再使用reduce将序列联结。 123456789#简化模式from functools import reducedef char2num(s): return &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;[s]def str2int(s): return reduce(lambda x, y: x * 10 + y, map(char2num, s)) filter过滤器filter()也接收一个函数和一个序列，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。filter的函数参数作用是在序列的每个元素上，运算的结果也是有形同长的序列 例如，在一个list中，删掉偶数，只保留奇数，可以这么写： 12345def is_odd(n): return n % 2 == 1list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))# 结果: [1, 5, 9, 15] 把一个序列中的空字符串删掉，可以这么写： 12345def not_empty(s): return s and s.strip()list(filter(not_empty, ['A', '', 'B', None, 'C', ' ']))# 结果: ['A', 'B', 'C'] filter返回的是一个惰性序列，所以要强制计算出所有的元素，使用list方法。 实例下面通过一个简单的小例子展示filter的魅力: 1234567891011121314151617181920212223242526#初始数据源，生成一个3以上的奇数序列def init_odd(): n=1 while True: n=n+2 yield n//过滤器 当x元素不能被n整除的话返回真，也就是说求非n的倍数def ini_gen(n): return lambda x:x%n&gt;0def primes(): yield 2 it=init_odd() while True: #获取当前序列的第一个元素 n=next(it) yield n #生产新的序列,此时ini_gen(n)是一个确定的lambda函数，后面的it是他的参数x it=filter(ini_gen(n),it)list=[]for n in primes(): if(n&lt;100): list.append(n) else:breakprint(list) 上面的代码可能直接硬吃不好理解，实际上是生成素数的序列，这个逻辑的前提是一种求素数序列的思路： 埃拉托斯特尼筛法 首先，列出从2开始的所有自然数，构造一个序列： 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, … 取序列的第一个数2，它一定是素数，然后用2把序列的2的倍数筛掉： 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, … 取新序列的第一个数3，它一定是素数，然后用3把序列的3的倍数筛掉： 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, … 取新序列的第一个数5，然后用5把序列的5的倍数筛掉： 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, … 不断筛下去，就可以得到所有的素数。 sortedsorted(data, key=None, reverse=False) 函数是python的高级函数，可以参数表中的第一个列表进行排序 其中，data是待排序数据，可以使List或者iterator, cmp和key都是函数，这两个函数作用与data的元素上产生一个结果，sorted方法根据这个结果来排序。 key 是带一个参数的函数, 用来为每个元素提取比较值. 默认为 None, 即直接比较每个元素.通常, key 和 reverse 比 cmp 快很多, 因为对每个元素它们只处理一次; 而 cmp 会处理多次. 123456sorted([36, 5, -12, 9, -21])#[-21, -12, 5, 9, 36]#接受排序的函数是绝对值函数，将会对列表内的每个元素进行求绝对值在升序排序sorted([36, 5, -12, 9, -21], key=abs)#[5, 9, -12, -21, 36]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[py中generator的使用]]></title>
    <url>%2F2016%2F10%2F07%2Fpy-generate%2F</url>
    <content type="text"><![CDATA[列表生成器先看一些通过列表生成器生成的列表： 12345678910#python输出全排列[m+n+b for m in "ABC" for n in "ABC" for b in 'ABC']['AA', 'AB', 'AC', 'BA', 'BB', 'BC', 'CA', 'CB', 'CC']&gt;&gt;&gt; [m+n+b for m in 'ABC' for n in 'ABC' for b in 'ABC']['AAA', 'AAB', 'AAC', 'ABA', 'ABB', 'ABC', 'ACA', 'ACB', 'ACC', 'BAA', 'BAB', 'BAC', 'BBA', 'BBB', 'BBC', 'BCA', 'BCB','BCC', 'CAA', 'CAB', 'CAC', 'CBA', 'CBB', 'CBC', 'CCA', 'CCB', 'CCC'] 123456789#python输出符合条件结果[x*x for x in range(1,99) if x%2==0][4, 16, 36, 64, 100, 144, 196, 256, 324, 400, 484, 576, 676, 784, 900, 1024, 1156, 1296, 1444, 1600, 1764, 1936, 2116, 2304, 2500, 2704, 2916, 3136, 3364, 3600, 3844, 4096, 4356, 4624, 4900, 5184, 5476, 5776, 6084, 6400, 6724, 7056, 7396, 7744, 8100, 8464, 8836, 9216, 9604] 可以看出来，列表生成器可以帮助我们很方便的生成一系列原本需要多次循环的列表。然而很多时候，我们并不需要完整的列表，只是需要其中的一部分，此时完整的列表就会造成性能、空间的浪费。 genaratorpython内置的生成器可以帮助我们，生成器是一种一边循环一边计算的机制，实际上generator保存的是需要推算的具体算法。 l=(m+n+b for m in &#39;ABC&#39; for n in &#39;ABC&#39; for b in &#39;ABC&#39;)l=(m*m for m in range(1,50) if m%2==1) 可以看出来,generator的形式与列表生成器很相似，只是列表的外壳是’[]’，而这里变成了’()’。此时我们尝试输出generator的长度，python报错，提示没有这个方法，这是因为generator不提供具体的空间完全保存，只是提供一个迭代的算法过程。 我们通过不断的next(l)可以将所有的元素输出，但是显然这样做太傻了。正确的做法是使用循环： 12for n in l: print(n) 此时循环输出的是除了next(l)后的所有元素。 或者使用list()方法计算出所有的数值. list(l) 函数改编generator来看一个函数形式的斐波那契数列： 1def fib(max):&#10;&#9;n,a,b=0,0,1&#10;&#9;while n&#60;max:&#10;&#9;&#9;n=n+1&#10;&#9;&#9;print(b)&#10;&#9;&#9;a,b=b,a+b&#10;&#9;print(&#39;done&#39;) 函数实际上也是定义了运算规则，我们可以把函数改成generator。 1234567def fib(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1 return 'done' 如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator 函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。 需要注意的是，不管有没有参数，当我们直接使用function name而不是调用形式的话（例如使用fib）依然显示的是函数，无参时使用fib()或者有参时使用fib(n)才算是generator。因为只有此时才能被理解为一个iterator。 捕获next()报错此时我们可以使用next语句或者for循环输出相应数值。 但是用for循环调用generator时，发现拿不到generator的return语句的返回值。如果想要拿到返回值’done’，必须捕获StopIteration错误，返回值包含在StopIteration的value中： 12345678910111213141516&gt;&gt;&gt; g = fib(6)&gt;&gt;&gt; while True:... try:... x = next(g)... print('g:', x)... except StopIteration as e:... print('Generator return value:', e.value)... break...g: 1g: 1g: 2g: 3g: 5g: 8Generator return value: done 题外-迭代器凡是可作用于for循环的对象都是Iterable类型； 1234567891011&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance([], Iterable)True&gt;&gt;&gt; isinstance(&#123;&#125;, Iterable)True&gt;&gt;&gt; isinstance('abc', Iterable)True&gt;&gt;&gt; isinstance((x for x in range(10)), Iterable)True&gt;&gt;&gt; isinstance(100, Iterable)False 凡是可作用于next()函数的对象都是Iterator类型，它们表示一个惰性计算的序列； 123456789&gt;&gt;&gt; from collections import Iterator&gt;&gt;&gt; isinstance((x for x in range(10)), Iterator)True&gt;&gt;&gt; isinstance([], Iterator)False&gt;&gt;&gt; isinstance(&#123;&#125;, Iterator)False&gt;&gt;&gt; isinstance('abc', Iterator)False 集合数据类型如list、dict、str等是Iterable但不是Iterator，不过可以通过iter()函数获得一个Iterator对象。 1234&gt;&gt;&gt; isinstance(iter([]), Iterator)True&gt;&gt;&gt; isinstance(iter('abc'), Iterator)True Python的for循环本质上就是通过不断调用next()函数实现的 生成器不但可以作用于for循环，还可以被next()函数不断调用并返回下一个值，直到最后抛出StopIteration错误表示无法继续返回下一个值 Python的Iterator对象表示的是一个数据流，Iterator对象可以被next()函数调用并不断返回下一个数据，直到没有数据时抛出StopIteration错误。可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过next()函数实现按需计算下一个数据，所以Iterator的计算是惰性的，只有在需要返回下一个数据时它才会计算。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式-结构型]]></title>
    <url>%2F2016%2F10%2F05%2Fjava-design-pattern3%2F</url>
    <content type="text"><![CDATA[上图表示的就是本文介绍的几种设计模式之间关系，其中对象的适配器模式是基础。 我们一个个讲，先看类的适配器模式： 类的适配器模式核心思想就是：有一个Source类，拥有一个方法，待适配，目标接口是Targetable，通过Adapter类，将Source的功能扩展到Targetable里： 1234567891011121314151617181920212223242526272829303132333435363738//Source类public class Source &#123; public void method1() &#123; System.out.println("this is original method!"); &#125; &#125;//targettable接口public interface Targetable &#123; /* 与原类中的方法相同 */ public void method1(); /* 新类的方法 */ public void method2(); &#125;//Adapter类public class Adapter extends Source implements Targetable &#123; @Override public void method2() &#123; System.out.println("this is the targetable method!"); &#125; &#125;//测试public class AdapterTest &#123; public static void main(String[] args) &#123; Targetable target = new Adapter(); target.method1(); target.method2(); &#125; &#125; 这样Targetable接口的实现类就具有了Source类的功能。 对象的适配器模式对象的适配器模式基本思路和类的适配器模式相同，只是将Adapter类作修改，这次不继承Source类，而是持有Source类的实例，以达到解决兼容性的问题。 12345678910111213141516171819202122232425262728293031public class Wrapper implements Targetable &#123; private Source source; public Wrapper(Source source)&#123; super(); this.source = source; &#125; @Override public void method2() &#123; System.out.println("this is the targetable method!"); &#125; @Override public void method1() &#123; source.method1(); &#125; &#125;//测试public class AdapterTest &#123; public static void main(String[] args) &#123; Source source = new Source(); Targetable target = new Wrapper(source); target.method1(); target.method2(); &#125; &#125; 接口的适配器模式有时我们写的一个接口中有多个抽象方法，当我们写该接口的实现类时，必须实现该接口的所有方法，这明显有时比较浪费，因为并不是所有的方法都是我们需要的，有时只需要某一些，此处为了解决这个问题，我们引入了接口的适配器模式，借助于一个抽象类，该抽象类实现了该接口，实现了所有的方法，而我们不和原始的接口打交道，只和该抽象类取得联系，所以我们写一个类，继承该抽象类，重写我们需要的方法就行。 123456789101112131415161718192021222324252627282930313233343536373839404142public interface Targetable &#123; /* 与原类中的方法相同 */ public void method1(); /* 新类的方法 */ public void method2(); &#125;//抽象类实现了接口的所有方法，虽然是空方法体public abstract class Wrapper2 implements Sourceable&#123; public void method1()&#123;&#125; public void method2()&#123;&#125; &#125; public class SourceSub1 extends Wrapper2 &#123; public void method1()&#123; System.out.println("the sourceable interface's first Sub1!"); &#125; &#125; public class SourceSub2 extends Wrapper2 &#123; public void method2()&#123; System.out.println("the sourceable interface's second Sub2!"); &#125; &#125; public class WrapperTest &#123; public static void main(String[] args) &#123; Sourceable source1 = new SourceSub1(); Sourceable source2 = new SourceSub2(); source1.method1(); source1.method2(); source2.method1(); source2.method2(); &#125; &#125; 三种适配器的区别 类的适配器模式：当希望将一个类转换成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可。 对象的适配器模式：当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Wrapper类，持有原类的一个实例，在Wrapper类的方法中，调用实例的方法就行。 接口的适配器模式：当不希望实现一个接口中所有的方法时，可以创建一个抽象类Wrapper，实现所有方法，我们写别的类的时候，继承抽象类即可。 装饰模式装饰模式就是给一个对象增加一些新的功能，而且是动态的，要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例 Source类是被装饰类，Decorator类是一个装饰类，可以为Source类动态的添加一些功能 12345678910111213141516171819202122232425262728293031323334353637383940public interface Sourceable &#123; public void method(); &#125; public class Source implements Sourceable &#123; @Override public void method() &#123; System.out.println("the original method!"); &#125; &#125; public class Decorator implements Sourceable &#123; private Sourceable source; public Decorator(Sourceable source)&#123; super(); this.source = source; &#125; @Override public void method() &#123; System.out.println("before decorator!"); source.method(); System.out.println("after decorator!"); &#125; &#125; //测试类：public class DecoratorTest &#123; public static void main(String[] args) &#123; Sourceable source = new Source(); Sourceable obj = new Decorator(source); obj.method(); &#125; &#125; 装饰模式可以动态的为一个对象增加功能，而且还能动态撤销。继承是无法做到这一点的，只能是静态的增加。 代理模式代理模式就是多一个代理类出来，替原对象进行一些操作，比如我们在租房子的时候回去找中介，为什么呢？因为你对该地区房屋的信息掌握的不够全面，希望找一个更熟悉的人去帮你做，此处的代理就是这个意思。再如我们有的时候打官司，我们需要请律师，因为律师在法律方面有专长，可以替我们进行操作，表达我们的想法。先来看看关系图： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public interface Sourceable &#123; public void method(); &#125; public class Source implements Sourceable &#123; @Override public void method() &#123; System.out.println("the original method!"); &#125; &#125; public class Proxy implements Sourceable &#123; private Source source; public Proxy()&#123; super(); this.source = new Source(); &#125; @Override public void method() &#123; before(); source.method(); atfer(); &#125; private void atfer() &#123; System.out.println("after proxy!"); &#125; private void before() &#123; System.out.println("before proxy!"); &#125; &#125; //测试类：public class ProxyTest &#123; public static void main(String[] args) &#123; Sourceable source = new Proxy(); source.method(); &#125; &#125; 适用范围当我们想要把已有的方法在使用的时候对原有的方法进行改进，有2种思路： 修改原有的方法来适应。这样违反了“对扩展开放，对修改关闭”的原则。 采用一个代理类调用原有的方法，且对产生的结果进行控制。这种方法就是代理模式。 使用代理模式，可以将功能划分的更加清晰，有助于后期维护！ 外观模式外观模式是为了解决类与类之家的依赖关系的，可以将类和类之间的关系配置到配置文件中，而外观模式就是将他们的关系放在一个Facade类中，降低了类类之间的耦合度，该模式中没有涉及到接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class CPU &#123; public void startup()&#123; System.out.println("cpu startup!"); &#125; public void shutdown()&#123; System.out.println("cpu shutdown!"); &#125; &#125; public class Memory &#123; public void startup()&#123; System.out.println("memory startup!"); &#125; public void shutdown()&#123; System.out.println("memory shutdown!"); &#125; &#125; public class Disk &#123; public void startup()&#123; System.out.println("disk startup!"); &#125; public void shutdown()&#123; System.out.println("disk shutdown!"); &#125; &#125; public class Computer &#123; private CPU cpu; private Memory memory; private Disk disk; public Computer()&#123; cpu = new CPU(); memory = new Memory(); disk = new Disk(); &#125; public void startup()&#123; System.out.println("start the computer!"); cpu.startup(); memory.startup(); disk.startup(); System.out.println("start computer finished!"); &#125; public void shutdown()&#123; System.out.println("begin to close the computer!"); cpu.shutdown(); memory.shutdown(); disk.shutdown(); System.out.println("computer closed!"); &#125; &#125; //User类如下：public class User &#123; public static void main(String[] args) &#123; Computer computer = new Computer(); computer.startup(); computer.shutdown(); &#125; &#125; 如果我们没有Computer类，那么，CPU、Memory、Disk他们之间将会相互持有实例，产生关系，这样会造成严重的依赖，修改一个类，可能会带来其他类的修改，这不是我们想要看到的，有了Computer类，他们之间的关系被放在了Computer类里，这样就起到了解耦的作用 桥接模式桥接模式就是把事物和其具体实现分开，使他们可以各自独立的变化。桥接的用意是：将抽象化与实现化解耦，使得二者可以独立变化，像我们常用的JDBC桥DriverManager一样，JDBC进行连接数据库的时候，在各个数据库之间进行切换，基本不需要动太多的代码，甚至丝毫不用动，原因就是JDBC提供统一接口，每个数据库提供各自的实现，用一个叫做数据库驱动的程序来桥接就行了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public interface Sourceable &#123; public void method(); &#125; //分别定义两个实现类：public class SourceSub1 implements Sourceable &#123; @Override public void method() &#123; System.out.println("this is the first sub!"); &#125; &#125; public class SourceSub2 implements Sourceable &#123; @Override public void method() &#123; System.out.println("this is the second sub!"); &#125; &#125; //定义一个桥，持有Sourceable的一个实例：public abstract class Bridge &#123; private Sourceable source; public void method()&#123; source.method(); &#125; public Sourceable getSource() &#123; return source; &#125; public void setSource(Sourceable source) &#123; this.source = source; &#125; &#125; public class MyBridge extends Bridge &#123; public void method()&#123; getSource().method(); &#125; &#125; //测试类：public class BridgeTest &#123; public static void main(String[] args) &#123; Bridge bridge = new MyBridge(); /*调用第一个对象*/ Sourceable source1 = new SourceSub1(); bridge.setSource(source1); bridge.method(); /*调用第二个对象*/ Sourceable source2 = new SourceSub2(); bridge.setSource(source2); bridge.method(); &#125; &#125; 这里我们顺带的将JDBC的模式图展示出来： 组合模式组合模式有时又叫部分-整体模式在处理类似树形结构的问题时比较方便 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class TreeNode &#123; private String name; private TreeNode parent; private Vector&lt;TreeNode&gt; children = new Vector&lt;TreeNode&gt;(); public TreeNode(String name)&#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public TreeNode getParent() &#123; return parent; &#125; public void setParent(TreeNode parent) &#123; this.parent = parent; &#125; //添加孩子节点 public void add(TreeNode node)&#123; children.add(node); &#125; //删除孩子节点 public void remove(TreeNode node)&#123; children.remove(node); &#125; //取得孩子节点 public Enumeration&lt;TreeNode&gt; getChildren()&#123; return children.elements(); &#125; &#125; public class Tree &#123; TreeNode root = null; public Tree(String name) &#123; root = new TreeNode(name); &#125; public static void main(String[] args) &#123; Tree tree = new Tree("A"); TreeNode nodeB = new TreeNode("B"); TreeNode nodeC = new TreeNode("C"); nodeB.add(nodeC); tree.root.add(nodeB); System.out.println("build the tree finished!"); &#125; &#125; 使用场景：将多个对象组合在一起进行操作，常用于表示树形结构中，例如二叉树，数等。 享元模式享元模式的主要目的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，通常与工厂模式一起使用。 FlyWeightFactory负责创建和管理享元单元，当一个客户端请求时，工厂需要检查当前对象池中是否有符合条件的对象，如果有，就返回已经存在的对象，如果没有，则创建一个新对象，FlyWeight是超类。一提到共享池，我们很容易联想到Java里面的JDBC连接池，想想每个连接的特点，我们不难总结出：适用于作共享的一些个对象，他们有一些共有的属性，就拿数据库连接池来说，url、driverClassName、username、password及dbname，这些属性对于每个连接来说都是一样的，所以就适合用享元模式来处理，建一个工厂类，将上述类似属性作为内部数据，其它的作为外部数据，在方法调用时，当做参数传进来，这样就节省了空间，减少了实例的数量。 看个例子： 看下数据库连接池的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ConnectionPool &#123; private Vector&lt;Connection&gt; pool; /*公有属性*/ private String url = "jdbc:mysql://localhost:3306/test"; private String username = "root"; private String password = "root"; private String driverClassName = "com.mysql.jdbc.Driver"; private int poolSize = 100; private static ConnectionPool instance = null; Connection conn = null; /*构造方法，做一些初始化工作*/ private ConnectionPool() &#123; pool = new Vector&lt;Connection&gt;(poolSize); for (int i = 0; i &lt; poolSize; i++) &#123; try &#123; Class.forName(driverClassName); conn = DriverManager.getConnection(url, username, password); pool.add(conn); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /* 返回连接到连接池 */ public synchronized void release() &#123; pool.add(conn); &#125; /* 返回连接池中的一个数据库连接 */ public synchronized Connection getConnection() &#123; if (pool.size() &gt; 0) &#123; Connection conn = pool.get(0); pool.remove(conn); return conn; &#125; else &#123; return null; &#125; &#125; &#125; 通过连接池的管理，实现了数据库连接的共享，不需要每一次都重新创建连接，节省了数据库重新创建的开销，提升了系统的性能.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式-创建型]]></title>
    <url>%2F2016%2F10%2F04%2Fjava-design-pattern2%2F</url>
    <content type="text"><![CDATA[建造者模式工厂类模式提供的是创建单个类的模式，而建造者模式则是将各种产品集中起来进行管理，用来创建复合对象，所谓复合对象就是指某个类具有不同的属性，其实建造者模式就是前面抽象工厂模式和最后的Test结合起来得到的。我们看一下代码：还和前面一样，一个Sender接口，两个实现类MailSender和SmsSender。最后，建造者类如下： 12345678910111213141516171819202122232425262728293031323334353637383940public interface Sender&#123; ......&#125;public class MailSender implements Sender&#123; ......&#125;public class SmsSender implements Sender&#123; ......&#125;public class Builder &#123; private List&lt;Sender&gt; list = new ArrayList&lt;Sender&gt;(); public void produceMailSender(int count)&#123; for(int i=0; i&lt;count; i++)&#123; list.add(new MailSender()); &#125; &#125; public void produceSmsSender(int count)&#123; for(int i=0; i&lt;count; i++)&#123; list.add(new SmsSender()); &#125; &#125; &#125; //测试public class Test &#123; public static void main(String[] args) &#123; Builder builder = new Builder(); builder.produceMailSender(10); &#125; &#125; 建造者模式将很多功能集成到一个类里，这个类可以创造出比较复杂的东西。所以与工程模式的区别就是：工厂模式关注的是创建单个产品，而建造者模式则关注创建符合对象，多个部分。因此，是选择工厂模式还是建造者模式，依实际情况而定。 原型模式Prototype 该模式的思想就是将一个对象作为原型，对其进行复制、克隆，产生一个和原对象类似的新对象。在Java中，复制对象是通过clone()实现的，先创建一个原型类： 1234567public class Prototype implements Cloneable &#123; public Object clonex() throws CloneNotSupportedException &#123; Prototype proto = (Prototype) super.clone(); return proto; &#125; &#125; 一个原型类，只需要实现Cloneable接口，编写调用了super.clone的方法，此处clonex方法可以改成任意的名称，因为Cloneable接口是个空接口，你可以任意定义实现类的方法名，如cloneA或者cloneB，因为此处的重点是super.clone()这句话，super.clone()调用的是Object的clone()方法，而在Object类中，clone()是native的，浅复制。 深浅复制 浅复制：将一个对象复制后，基本数据类型的变量都会重新创建，而引用类型，指向的还是原对象所指向的。 深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。简单来说，就是深复制进行了完全彻底的复制，而浅复制不彻底。 要实现深复制，需要采用流的形式读入当前对象的二进制输入，再写出二进制数据对应的对象。 下面是实现的深复制方法： 12345678910111213/* 深复制 */ public Object deepClone() throws IOException, ClassNotFoundException &#123; /* 写入当前对象的二进制流 */ ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); /* 读出二进制流产生的新对象 */ ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); return ois.readObject(); &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java单例模式]]></title>
    <url>%2F2016%2F10%2F04%2Fjava-singleton-pattern%2F</url>
    <content type="text"><![CDATA[单例模式单例对象（Singleton）是一种常用的设计模式。在Java应用中，单例对象能保证在一个JVM中，该对象只有一个实例存在。这样的模式有几个好处： 某些类创建比较频繁，对于一些大型的对象，这是一笔很大的系统开销。 省去了new操作符，降低了系统内存的使用频率，减轻GC压力。 有些类如交易所的核心交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。（比如一个军队出现了多个司令员同时指挥，肯定会乱成一团），所以只有使用单例模式，才能保证核心交易服务器独立控制整个流程。 单例模式的特点 单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 单例模式确保某个类只有一个实例，而且自行实例化并向整个系统提供这个实例。在计算机系统中，线程池、缓存、日志对象、对话框、打印机、显卡的驱动程序对象常被设计成单例。这些应用都或多或少具有资源管理器的功能。每台计算机可以有若干个打印机，但只能有一个Printer Spooler，以避免两个打印作业同时输出到打印机中。每台计算机可以有若干通信端口，系统应当集中管理这些通信端口，以避免一个通信端口同时被两个请求同时调用。总之，选择单例模式就是为了避免不一致状态，避免政出多头。 懒汉式单线程模式123456789101112//懒汉式单例类.在第一次调用的时候实例化自己 public class Singleton &#123; private Singleton() &#123;&#125; private static Singleton single=null; //静态工厂方法 public static Singleton getInstance() &#123; if (single == null) &#123; single = new Singleton(); &#125; return single; &#125; &#125; 懒汉式单例模式在第一次调用定义的方法时返回实例化的对象，之后调用将会返回此前创造的实例。 Singleton通过将构造方法限定为private避免了类在外部被实例化，在同一个虚拟机范围内，Singleton的唯一实例只能通过getInstance()方法访问。 上面说过，懒汉式单例模式是线程不安全的，下面有3种方法适用于改造： 同步 123456public static synchronized Singleton getInstance() &#123; if (single == null) &#123; single = new Singleton(); &#125; return single; &#125; 使用synchronized关键字之后，多个线程调用getInstance方法会多一层保障，确保程序最多有一个实例存在。 双重检查锁定 12345678910public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; 这里进行了double的检测，一次是在同步块外，一次是在同步块内。为什么在同步块内还要再检验一次？因为可能会有多个线程一起进入同步块外的 if，如果在同步块内不进行二次检验的话就会生成多个实例了。 我们把注意力转到singleton = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 给 singleton 分配内存 调用 Singleton 的构造函数来初始化成员变量 将singleton对象指向分配的内存空间（执行完这步 singleton 就为非 null 了） 但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 singleton，然后使用，然后顺理成章地报错。 此时我们只需要将 singleton 变量声明成 volatile 就可以了。 private volatile static Singleton singleton; 使用 volatile 的主要原因是其一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前 静态内部类 123456789public class Singleton &#123; private static class LazyHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return LazyHolder.INSTANCE; &#125; &#125; 静态内部类的方法同时解决了线程安全以及synchronzied同步引出的性能影响。这种写法仍然使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。 饿汉式单例123456789//饿汉式单例类.在类初始化时，已经自行实例化 public class Singleton1 &#123; private Singleton1() &#123;&#125; private static final Singleton1 single = new Singleton1(); //静态工厂方法 public static Singleton1 getInstance() &#123; return single; &#125; &#125; 饿汉式单例直接在创建的时候就已经实例化了对象，同时将构造函数private，保证了线程安全以及实例的唯一性。 两类单例模式对比 饿汉式 饿汉式单例在类加载过程中就已经创造好了对象的唯一实例，天生线程安全，但是无法类延迟加载。 懒汉式 懒汉式单例只有在第一次使用类的静态函数getInstance（或者其他定义的返回方法）才会创造唯一的实例。，原始的懒汉式单例是非线程安全的。 内部class 这种写法仍然使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。 线程安全如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。 或者说：一个类或者程序所提供的接口对于线程来说是原子操作，或者多个线程之间的切换不会导致该接口的执行结果存在二义性,也就是说我们不用考虑同步的问题，那就是线程安全的。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java类加载器]]></title>
    <url>%2F2016%2F10%2F04%2Fclass_loader%2F</url>
    <content type="text"><![CDATA[ClassLoader一个Java程序之后，不是管是CS还是BS应用，都是由若干个.class文件组织而成的一个完整的Java应用程序，当程序在运行时，即会调用该程序的一个入口函数来调用系统的相关功能。 这些功能都被封装在不同的class文件当中，所以经常从这个class文件中要调用另外一个class文件中的方法，如果另外一个文件不存在的，则会引发系统异常。 程序在启动的时候，并不会一次性加载程序所要用的所有class文件，而是根据程序的需要，通过Java的类加载机制（ClassLoader）来动态加载某个class文件到内存当中的，从而只有class文件被载入到了内存之后，才能被其它class所引用。所以ClassLoader就是用来动态加载class文件到内存当中用的。 分类java默认提供3类classloader： Bootstrap ClassLoader：称为启动类加载器，是Java类加载层次中最顶层的类加载器，负责加载JDK中的核心类库，如：rt.jar、resources.jar、charsets.jar等 Extension ClassLoader：称为扩展类加载器，负责加载Java的扩展类库，默认加载JAVA_HOME/jre/lib/ext/目下的所有jar。 App ClassLoader：称为系统类加载器，负责加载应用程序classpath目录下的所有jar和class文件。 除了Java默认提供的三个ClassLoader之外，用户还可以根据需要定义自已的ClassLoader，而这些自定义的ClassLoader都必须继承自java.lang.ClassLoader类，也包括Java提供的另外二个ClassLoader（Extension ClassLoader和App ClassLoader）在内，但是Bootstrap ClassLoader不继承自ClassLoader，因为它不是一个普通的Java类，底层由C++编写，已嵌入到了JVM内核当中，当JVM启动后，Bootstrap ClassLoader也随着启动，负责加载完核心类库后，并构造Extension ClassLoader和App ClassLoader类加载器。 原理ClassLoader使用的是双亲委托模型来搜索类的，每个ClassLoader实例都有一个父类加载器的引用（不是继承的关系，是一个包含的关系），虚拟机内置的类加载器（Bootstrap ClassLoader）本身没有父类加载器，但可以用作其它ClassLoader实例的的父类加载器。当一个ClassLoader实例需要加载某个类时，它会试图亲自搜索某个类之前，先把这个任务委托给它的父类加载器，这个过程是由上至下依次检查的，首先由最顶层的类加载器Bootstrap ClassLoader试图加载，如果没加载到，则把任务转交给Extension ClassLoader试图加载，如果也没加载到，则转交给App ClassLoader 进行加载，如果它也没有加载得到的话，则返回给委托的发起者，由它到指定的文件系统或网络等URL中加载该类。如果它们都没有加载到这个类时，则抛出ClassNotFoundException异常。否则将这个找到的类生成一个类的定义，并将它加载到内存当中，最后返回这个类在内存中的Class实例对象。 使用双亲委托模型避免重复加载，当父亲已经加载了该类的时候，就没有必要子ClassLoader再加载一次。考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时就被引导类加载器（Bootstrcp ClassLoader）加载，所以用户自定义的ClassLoader永远也无法加载一个自己写的String，除非你改变JDK中ClassLoader搜索类的默认算法。 JVM在判定两个class是否相同时，不仅要判断两个类名是否相同，而且要判断是否由同一个类加载器实例加载的。只有两者同时满足的情况下，JVM才认为这两个class是相同的。就算两个class是同一份class字节码，如果被两个不同的ClassLoader实例所加载，JVM也会认为它们是两个不同class。比如网络上的一个Java类org.classloader.simple.NetClassLoaderSimple，javac编译之后生成字节码文件NetClassLoaderSimple.class，ClassLoaderA和ClassLoaderB这两个类加载器并读取了NetClassLoaderSimple.class文件，并分别定义出了java.lang.Class实例来表示这个类，对于JVM来说，它们是两个不同的实例对象，但它们确实是同一份字节码文件，如果试图将这个Class实例生成具体的对象进行转换时，就会抛运行时异常java.lang.ClassCaseException，提示这是两个不同的类型。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式]]></title>
    <url>%2F2016%2F10%2F03%2Fjava-design-pattern%2F</url>
    <content type="text"><![CDATA[设计模式（Design Patterns）&lt;——&gt; 可复用面向对象软件的基础 设计模式（Design pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理的运用设计模式可以完美的解决很多问题，每种模式在现在中都有相应的原理来与之对应，每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是它能被广泛应用的原因。 设计模式分类按照设计模式的用法用途，我们一般讲java的设计模式分为以下几种： 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 并发型模式 线程池模式 设计模式特性 开闭原则（Open Close Principle） 开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。 里氏代换原则（Liskov Substitution Principle） 里氏代换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。 依赖倒转原则（Dependence Inversion Principle） 这个是开闭原则的基础，具体内容：真对接口编程，依赖于抽象而不依赖于具体。 接口隔离原则（Interface Segregation Principle）这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思，从这儿我们看出，其实设计模式就是一个软件的设计思想，从大型软件架构出发，为了升级和维护方便。所以上文中多次出现：降低依赖，降低耦合。 迪米特法则（最少知道原则）（Demeter Principle） 为什么叫最少知道原则，就是说：一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 合成复用原则（Composite Reuse Principle） 原则是尽量使用合成/聚合的方式，而不是使用继承。 模式解析工厂模式首先介绍普通的工厂模式，建立一个工厂类，对实现了同一接口的一些类进行实例的创建。 创建这些类共同的接口 123public interface Sender&#123; public void Send();&#125; 根据要处理的事件创造不同的实现类 123456789101112public class SmsSender implements Sender&#123; public void Send()&#123; //分别实现方法 System.out.println("sms sender"); &#125;&#125;public class MailSender implements Sender&#123; public void Send()&#123; System.out.println("mail sender"); &#125;&#125; 创建接口的工厂类 工厂类负责对实现了接口的实现类进行实例化 12345678910111213public class SendFactory&#123; public Sender produce(String type)&#123; if("sms".equals(type))&#123; //进行sms对象的实例化 return new SmsSender(); &#125; else if("mail".equals(type))&#123; //进行sms对象的实例化 return new MailSender(); &#125; else System.out.println("plz input correct type string"); &#125;&#125; 进行工厂模式的测试 1234567public class FactoryTest&#123; public static void main(String[] args)&#123; SendFactory factory=new SendFactory(); Sender sender=factory.produce("sms"); sender.Send(); &#125;&#125; -多个工厂方法模式 上面的工厂模式中，工厂类只有一个方法，是根据传递的str参数进行匹配，如果没有传递对正确的str参数，无法执行。多个工厂方法模式改进这一地方，在工厂类中直接根据不同的接口实现类实现不同的方法，在工厂对象中，进行调用不同的方法。 静态工厂方法模式 将工厂类中的接口类对象实例化方法静态化，之后就无需先实例化工厂类，再调用他的接口类实例化方法。可以直接调用静态方法。 工厂模式适合：凡是出现了大量的产品需要创建，并且具有共同的接口时，可以通过工厂方法模式进行创建。在以上的三种模式中，第一种如果传入的字符串有误，不能正确创建对象，第三种相对于第二种，不需要实例化工厂类，所以，大多数情况下，我们会选用第三种——静态工厂方法模式。 Abstract Factory抽象工厂 想要拓展程序，必须对工厂类进行修改，这违背了闭包原则，所以，从设计角度考虑，我们使用抽象工厂模式，创建多个工厂类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。 其中第一项以及第二项的接口类和接口实现类没有变化。 创建多个工厂类 12345678910111213public class SendMailFactory implements Provider &#123; @Override public Sender produce()&#123; return new MailSender(); &#125; &#125; public class SendSmsFactory implements Provider&#123; public Sender produce()&#123; return new SnsSender(); &#125;&#125; 创建多个工厂类的接口 这一步骤实际上应该是在第3步之前完成，所有的工程类都要实现这个接口。这样增加新的功能可以直接添加新的工厂类。 123public interface Provider &#123; public Sender produce(); &#125; 测试 1234567public class Test &#123; public static void main(String[] args) &#123; Provider provider = new SendMailFactory(); Sender sender = provider.produce(); sender.Send(); &#125; &#125; 上面做的好处就是，当我们想要新加一种功能，例如发送图片SendPic，使用抽象工厂就无需对之前的代码进行改编，只需要 创建实现Sender接口的类 创建实现Provider接口的工厂类 1234567891011public class PicSender implements Sender&#123; public void Send()&#123; System.out.println("I send a pic"); &#125;&#125; public class SendPicFactory implements Provider&#123; public void produce()&#123; return new PicSender(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓄水池]]></title>
    <url>%2F2016%2F09%2F21%2Fpolls%2F</url>
    <content type="text"><![CDATA[蓄水池算法给定一个数据流，数据流的长度出事我们未知，需求时等概率的返回摸个数据流数值。从性能方面分析，我们为了节省空间性能，无需在遍历整个数据流之后保存，再进行随即等概率运算。这介绍一中蓄水池算法思想。 就假设数据流的数值是升序进行，1、2、3、4…..，当我们获取第二个数值时，我们手中有两个数值进行选择，1和2，此时我们选择其中的一个抛手，此时进行的第二个数据，我们以1/2的概率处理。假设2被留下；继续读入数据流，读取到3，此时我们又有了两个数据，这是第三个数据，我们规定只有1/3的概率3才能留下，否则看留下的是前两个数字的胜出者，假设3留下；读入最后一个数据4,依照上面，只有1/4的概率，我们才留下4，否则留下前面3个数据的胜出者。我们计算一下这几个数值保留时的概率： 1:(1/1)*(1/2)*(2/3)*(3/4)=1/4 2:(1/2)*(2/3)*(3/4)=1/4 3：(1/3)*(3/4)=1/4 4: 1/4 发现我们的规定是可以满足需求，等概率返回数值。 上面实际上使用了数学上的一个小技巧，多个分数相乘，前分母与后分子相同直接约掉即可，例如(4/5)*(5/6)=4/6等等，由于当前阶段数值留下的概率是(1/数据流index)，而后面每次留下的概率都是(数据流index/数据流index+1)、(数据流index+1/数据流index+2)….所以满足这个思路]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[候鸟]]></title>
    <url>%2F2016%2F09%2F18%2F%E5%80%99%E9%B8%9F%2F</url>
    <content type="text"><![CDATA[冰箱上有字条桌上有菜电锅里面有饭没有人在电话里的独白还在等待一个人的表情怎么安排我也早有预感一起风满生命的窗忘了关吹进意外旅途上的愉快划过一半南方又在呼唤当我醒来飞过那片茫茫人海下个路口直走或转弯长大太慢老得太快等得太久结果太难猜我的故事被风吹散我的明天我从不期待所以现在我只想要寻找一丝最后的温暖包厢里的狂欢曲终人散长夜里的空白消化不完灵魂总是要贪片刻灿烂那双唇的孤单变得野蛮那陌生的阳光照在床单昨夜发生的事不想再猜而枕边的人啊一直在换每一次都以为到了终站飞过那片茫茫人海下个路口直走或转弯长大太慢老得太快等得太久结果太难猜我的故事被风吹散我的明天我从不期待所以现在我只想要寻找一丝最后的温暖]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django初识6]]></title>
    <url>%2F2016%2F09%2F18%2Fdjango_intro6%2F</url>
    <content type="text"><![CDATA[静态文件相关 除了服务端生成的 HTML 以外，网络应用通常需要一些其他的文件——比如图片，脚本和样式表——来帮助渲染网络页面。在 Django 中，我们把这些文件统称为“静态文件”。 django.contrib.staticfile将各个应用的静态文件（和一些你指明的目录里的文件）统一收集起来，这样一来，在生产环境中，这些文件就会集中在一个便于分发的地方。 首先，在 polls 目录下创建一个 static 目录。 Django 将会从这里收集静态文件，就像 Django 在 polls/templates 里寻找模板一样。 Django 的 STATICFILES_FINDERS 设置项是一个列表，它包含了若干个知道如何从不同地点寻找静态文件的搜寻器。其中之一是 AppDirectoriesFinder，它会从 INSTALLED_APPS 中各个应用的 “static” 子目录中寻找文件，比如刚刚创建的 polls/static。 之前的管理页面也使用了相同的目录结构来管理静态文件。 在刚创建的 static 目录下创建一个 polls 目录，再在其中新建文件 style.css。也就是说，你的样式文件的位置是 polls/static/polls/style.css。由于 AppDirectoriesFinder 的存在，你可以在 Django 中使用 polls/style.css 来引用这个文件，就像我们引用模板文件那样。 静态文件命名空间和模板一个样，虽然我们可以直接把样式表放在 polls/static 目录下（而不是再创建一个 polls 子目录），但是这并不是个好主意。Django 将会使用它找到的第一个和名称项匹配文件，当你在另一个应用里也有一个同名的文件的话，Django 将无法区分它们。我们想让 Django 能够找到正确的文件，最简单的方法就是使用命名空间。也就是把静态文件放到一个和应用同名的子目录中。 css文件 在polls/static/polls/style.css文件中编辑： 123li a&#123; color:red;&#125; html模板 load staticfiles语句会从staticfiles模板库里导入static模板标签，static标签会把静态文件引用转换成绝对地址 设置背景图片在static目录下设置专门存放图片的文件夹img,网页的背景图片地址为 polls/static/polls/img/xxx.png 在index。html模板中添加： 1background: url("img/xxx.png")no-repeat center;]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django初识5]]></title>
    <url>%2F2016%2F09%2F17%2Fdjango_intro5%2F</url>
    <content type="text"><![CDATA[测试相关 自动化测试是由某个系统帮你自动完成的。当你创建好了一系列测试，每次修改应用代码后，就可以自动检查出修改后的代码是否还像你曾经预期的那样正常工作。你不需要话费大量时间来进行手动测试。 实例在这个系列文章的第一部分，我们在poll投票应用中定义了一个Question model方法，返回当前投票问题是否是最近创建的，如果创建时间与当前时间相差不到24小时，则返回True. 12def was_published_recently(self): return self.pub_date&gt;=timezone.now()-datetime.timedelta(days=1) 很明显，这里有一个Bug，就是当我们手动修改问题的创建时间（实际操作可以在创建问题的构造函数修改，或者直接在项目后台修改）为未来时间，即timezone.now+的情况，方法依然会返回True. 1234567891011&gt;&gt;&gt; p=Question.objects.get(question_text='debug')&gt;&gt;&gt; p&lt;Question: debug&gt;&gt;&gt;&gt; p.was_published_recently()True&gt;&gt;&gt; p.pub_datedatetime.datetime(2016, 9, 22, 3, 29, 57, tzinfo=&lt;UTC&gt;)&gt;&gt;&gt; from django.utils import timezone&gt;&gt;&gt; timezone.now()datetime.datetime(2016, 9, 17, 3, 43, 47, 450885, tzinfo=&lt;UTC&gt;) 手动将question_text为debug的Question对象pub_date时间修改为当前时间往后数5天，当我们测试was_published_recently()方法时，依然会反悔True.明显，这与我们的设计初衷不符合。 使用代码检测漏洞Django应用的额测试写在应用的test.py文件中，测试系统自动在所有以test开开头的文件中寻找bong执行测试代码。 测试初体验下面我们就在头片应用polls/目录下的test.py文件中尝试test： 123456789import datetimefrom django.utils import timezonefrom .models import Questionclass QuestionMethodTests(TestCase): def test_was_published_recently_with_future_question(self): time=timezone.noew()+datetime.timedelta(days=30) future_question=Question(pub_date=time) self.assertEqual(future_question.was_published_recently(),False) 在网站项目的根目录下启动终端： 12345678910111213141516171819202122$ winpty python manage.py test pollsCreating test database for alias 'default'...F======================================================================FAIL: test_was_published_recently_with_future_question (polls.tests.QuestionMethodTests)----------------------------------------------------------------------Traceback (most recent call last): File "E:\djangosite\mysite\polls\tests.py", line 10, in test_was_published_recently_with_future_question self.assertEqual(future_question.was_published_recently(),False)AssertionError: True != False----------------------------------------------------------------------Ran 1 test in 0.002sFAILED (failures=1)Destroying test database for alias 'default'... python manage.py test polls 将会寻找 poll 应用里的测试代码 它找到了一个 django.test.TestCase 的子类 它创建一个特殊的数据库供测试使用,与我们正常使用的数据库不同，在测试完成之后，数据将会自动销毁 它在类中寻找测试方法——以 test 开头的方法。 在 test_was_published_recently_with_future_question 方法中，它创建了一个 pub_date 值为未来第 30 天的 Question 实例。 然后使用 assertEqual() 方法，发现 was_published_recently() 返回了 True，而我们希望它返回 False 为了做对比，我使用离当前时间前30小时作为问题发布时间： 1234567891011121314def test_was_published_recently_with_future_question(self): time=timezone.now()+datetime.timedelta(hours=30) future_question=Question(pub_date=time) self.assertEqual(future_question.was_published_recently(),False)$ winpty python manage.py test pollsCreating test database for alias 'default'....----------------------------------------------------------------------Ran 1 test in 0.001sOKDestroying test database for alias 'default'... 同时，我们应该修改views.py文件，将显示的返回集合修改。 12345678def get_queryset(self): return Question.objects.order_by('-pub_date')[:5]---&gt;&gt;def get_queryset(self): return Question.objects.filter(pub_date_lte=timezone.now()).order_by('-pub_date')[:5] 更全面的测试实际上，光是问题发布时间方面，如果想要更全面的测试，以上的测试还是不够的，我们需要未来时间的测试，一天之前时间的测试，以及一天之内时间的测试。 我们在上面实现了未来时间的测试，下面是剩余两项的测试： 1234567891011121314151617181920212223242526272829303132from django.test import TestCaseimport datetimefrom django.utils import timezonefrom .models import Questionclass QuestionMethodTests(TestCase): def test_was_published_recently_with_future_question(self): #按照设计，应该返回False time=timezone.now()+datetime.timedelta(days=30) future_question=Question(pub_date=time) self.assertEqual(future_question.was_published_recently(),False) def test_was_published_recently_with_old_question(self): #按照设计，应该返回False time=timezone.now()-datetime.timedelta(days=30) old_question=Question(pub_date=time) self.assertEqual(old_question.was_published_recently(),False) def test_was_published_recently_with_recent_question(self): #应该返回True time=timezone.now()-datetime.timedelta(hours=1) recent_question=Question(pub_date=time) self.assertEqual(recent_question.was_published_recently(),True)$ winpty python manage.py test pollsCreating test database for alias 'default'......----------------------------------------------------------------------Ran 3 tests in 0.003sOKDestroying test database for alias 'default'...]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django初识4]]></title>
    <url>%2F2016%2F09%2F16%2Fdjango_intro4%2F</url>
    <content type="text"><![CDATA[编写简单的vote逻辑框架投票网站，我们在每个需要投票问题的页面上展现出所有可以投票的选项，并且在每个选项前假如radio单选按钮。当按钮结束之后，选择submit跳转到结果显示页面. 问题展示页面在polls/question_id中显示，而与之对应的template是detail.html 上面设计了一个表单，选择一个选项之后提交将会跳转到action。 这里要注意的是csrf_token Cross-site request forgery 跨站请求伪造，也被称为 “one click attack” 或者 session riding，通常缩写为 CSRF 或者 XSRF，是一种对网站的恶意利用。CSRF 则通过伪装来自受信任用户的请求来利用受信任的网站。 CSRF 主流防御方式是在后端生成表单的时候生成一串随机 token ，内置到表单里成为一个字段，同时，将此串 token 置入 session 中。每次表单提交到后端时都会检查这两个值是否一致，以此来判断此次表单提交是否是可信的。提交过一次之后，如果这个页面没有生成 CSRF token ，那么 token 将会被清空，如果有新的需求，那么 token 会被更新。 攻击者可以伪造 POST 表单提交，但是他没有后端生成的内置于表单的 token，session 中有没有 token 都无济于事。 Django内置便捷的csrf_token机制，所以在内部跳转可能会修改数据库数据情况下都要使用csrf_token机制 forloop.counter 指示 for 标签已经循环多少次。 选择提交成功之后，页面会跳转到action目的地址：polls/vote/question_id上，我们编写相应页面显示逻辑 123456789101112131415161718192021from django.shortcuts import get_object_or_404, renderfrom django.http import HttpResponseRedirect, HttpResponsefrom django.core.urlresolvers import reversefrom .models import Choice, Question# ...def vote(request, question_id): p = get_object_or_404(Question, pk=question_id) try: selected_choice = p.choice_set.get(pk=request.POST['choice']) except (KeyError, Choice.DoesNotExist): # 重新显示问题的投票表单 return render(request, 'polls/detail.html', &#123; 'question': p, 'error_message': "You didn't select a choice.", &#125;) else: selected_choice.votes += 1 selected_choice.save() # 成功处理之后 POST 数据之后，总是返回一个 HttpResponseRedirect 。防止因为用户点击了后退按钮而提交了两次。 return HttpResponseRedirect(reverse('polls:results', args=(p.id,))) request.POST 是一个类字典对象，让你可以通过关键字的名字获取提交的数据。 这个例子中，request.POST[‘choice’] 以字符串形式返回选择的 Choice 的 ID。request.POST 的值永远是字符串。 注意，Django 还以同样的方式提供 request.GET 用于访问 GET 数据 —— 但我们在代码中显式地使用 request.POST ，以保证数据只能通过POST调用改动。 如果在 POST 数据中没有提供 choice，request.POST[‘choice’] 将引发一个 KeyError。上面的代码检查 KeyError，如果没有给出 choice 将重新显示Question表单和一个错误信息。 在增加Choice的得票数之后，代码返回一个 HttpResponseRedirect 而不是常用的 HttpResponse。HttpResponseRedirect 只接收一个参数：用户将要被重定向的 URL。 正如上面的Python注释指出的，你应该在成功处理 POST 数据后总是返回一个 HttpResponseRedirect。 这不是 Django 的特定技巧；这是那些优秀网站在开发实践中形成的共识。 在这个例子中，我们在 HttpResponseRedirect 的构造函数中使用 reverse() 函数。这个函数避免了我们在视图函数中硬编码 URL。它需要我们给出我们想要跳转的视图的名字和该视图所对应的URL模式中需要给该视图提供的参数。 在上面的代码中，views.vote函数使用了render(request, &#39;polls/detail.html模板文件，所以我们在相应的模板目录下创建文件，实现界面设计。 上面的html页面代码将会显示当前投票问题的所有选项以及投票结果。choice.votes|pluralize代表如果choice.votes是&gt;=1的情况下，将会返回s，也就是vote复数的情况。 通用视图Web 开发中的一个常见情况：根据 URL 中的参数从数据库中获取数据、载入模板文件然后返回渲染后的模板。 由于这种情况特别常见，Django 提供一种快捷方式，叫做“通用视图”系统。 改良URLconf修改polls/urls.py： 12345678from django.conf.urls import urlfrom . import viewsurlpatterns=[ url(r'^$',views.IndexView.as_view(),name='index'), url(r'^(?P&lt;question_id&gt;[0-9]+)/$',views.DetailView.as_view(),name='detail'), url(r'^(?P&lt;question_id&gt;[0-9]+)/results/$',views.ResultView.as_view(),name='results'), url(r'^(?P&lt;question_id&gt;[0-9]+)/vote/$',views.votes,name='vote')] 其中第二、三个模式的正则表达式匹配模式名字有变成了，同时，需要修改的前三个url逻辑方法都有变化 修改view逻辑删除原来在url函数中注册的index、detail、result逻辑方法。通过通用视图提供的类继承： 12345678910111213141516from django.views import genericclass IndexView(generic.ListView): template_name='polls/index.html' context_object_name='latest_question_list' def get_queryset(self): #返回最心发布的5个问题 return Question.objects.order_by('-pub_date')[:5]class DetailView(generic.DetailView): model=Question template_name='polls/detail.html'class ResultView(generic.DetailView): model=Question template_name='polls/results.html' 在上面的代码中，来年各个视图分别继承自通用VIew中的ListView和DetailView。前者显示一个对象列表，后者显示一个特定类型对象的详细信息。 每个通用视图需要知道他将作用于那个model，这个有类中的model属性设置 DetailView期望从URL中捕获名为’pk’的主键，所以在视图中我们修改了URLconf中question_id为pk 通用模型类中的template属性决定逻辑加载哪个模板，否则的话会选择默认的template加载。例如，DetailView和ListView都会选择&lt;app name&gt;/&lt;model name&gt;_detail.html文件作为模板文件； 之前的逻辑函数都会提供一个包含模板文件中将会使用的变量做上下文语境的context，而在通用模板中，实际上同样需要。我们使用的两种通用模板中，DeatilView模板由于是默认提供的是一个特定类型对象的详细信息，它属于一个特定的类型，所以他会自动生成model对应的对象名作为context，例如Question模型自动生成的对象名为question；ListView通用模板显示一个对象列表，所以默认生成的context是一个列表类型，Question模型生成的对象列表名应为question_list，而我们之前使用的context列表名为latest_question_list，为了不修改模板中的对象名，我们直接在逻辑函数中指定context中对象名字为latest_question_list. 使用context_object_name属性，可以把通用模板的context_name设定，同时由于这个使用了ListView的类没有再使用默认提供的question_list名作为context，我们就不用在类中声明model是谁了。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[string全排列]]></title>
    <url>%2F2016%2F09%2F14%2Ffullset%2F</url>
    <content type="text"><![CDATA[字符串全排列规则最简单的思路就是使用递归实现： 将最左边字符固定，后面的依次全排 上一步的依次安排实际上是一次小集合的字符串全排 将次左边字符固定，剩下的全排 将此次左边固定… 直到最后一个数 第一轮结束，将原始字符串的最左边字符与次左边字符交换位置 按照上面的顺序依次进行 将原始字符串从左数第3位固定到最左边 依次进行 …直到左右进行完毕输出 实例举例来讲：原是字符串为’abc’ a固定，剩下两个准备全排 剩下的两个中b固定，剩下的全排 只剩下一个字符，完成一次输出 一次递归后返回上一步，将c固定 剩下b全排，输出 a固定的虽有结果输出完毕 将b或c固定到首位 按照上面顺序进行全排 实现123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;void callFunc(char * str,int from,int to)&#123; if(to&lt;=1) return ; if(from==to)&#123; for(int i=0;i&lt;strlen(str);i++) cout&lt;&lt;str[i]; cout&lt;&lt;'\n'; &#125; else&#123; for(int i=from;i&lt;to;i++)&#123; swap(str[from],str[i]); callFunc(str,from+1,to); swap(str[i],str[from]); &#125; &#125;&#125;int main()&#123; char s[]=&#123;'a','b','c','d','\0'&#125;; callFunc(s,0,strlen(s)); return 0;&#125; 上面要注意的是，char s[]={&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;}，当使用strlen函数计算字符数组长度是总是输出错误数值11，发现strlen函数使用的查询’\0’字符数组，上面字符数组没有字符串结尾字符，所以函数越界。或者可以直接使用string类型: 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;void callFunc(string str,int from,int to)&#123; if(to&lt;=1) return ; if(from==to)&#123; for(int i=0;i&lt;3;i++) cout&lt;&lt;str[i]; cout&lt;&lt;'\n'; &#125; else&#123; for(int i=from;i&lt;to;i++)&#123; swap(str[from],str[i]); callFunc(str,from+1,to); swap(str[i],str[from]); &#125; &#125;&#125;int main()&#123; string xxx ="abc"; cout&lt;&lt;xxx.size()&lt;&lt;endl; callFunc(xxx,0,3); return 0;&#125; 12345678910111213141516171819StringBuilder sb=new StringBuilder(str); public String swap(String str,int x,int y)&#123; char t=sb.charAt(x); char v=sb.charAt(y); sb.setCharAt(x, v); sb.setCharAt(y, t); return sb.toString() ; &#125;public void strfunc(String str,int from ,int to)&#123; if(from==to)&#123; System.out.println(str); return; &#125; for(int i=from;i&lt;to;i++)&#123; str=swap(str, i, from); strfunc(str, from+1, to); str=swap(str, i, from); &#125; &#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selenium模拟选课]]></title>
    <url>%2F2016%2F09%2F13%2Fselenium%E9%80%89%E8%AF%BE%2F</url>
    <content type="text"><![CDATA[使用selenium+python实现无人看守选课。 用到的一些模块 selenium selenium在前面的文章中曾经介绍过，就是模拟浏览器的一个第三方模块，通过提供的各种方法模拟控制browser，同时提供了无UI的Browserdriver，减少渲染开销，提升运行速度. time 本例中实现暂停扫描功能，防止服务器对IP封锁 re 正则表达模块，获取相关数据 常用的方法 b=webdriver.PhantomJS() 开启Selenium的一个webdriver实例，这里使用的是无UI的PhantomJS，通过它进行对browser的操作 b.get(url) url是我们想要request的网络地址，get方法实际上就是我们在browser中地址栏填入url并回车访问的过程 find_element_by_xpath 一系列的find_element_by方法，通过各种定位方法（Xpath、css-seletor、id、tagname）拿到需要操纵的元素句柄 element.send_keys(value) 在input或者其他可输入标签元素中填入keyword，在使用这个方法之前，建议使用element.clear()清楚之前的所有信息，因为send_keys()方法是直接在后面append element.get_attribute(attr) 获取元素的属性值，例如href、onclick b.page_source 获取当前driver停留页面的源网页代码 re.findall(pattern,str) re正则过滤，pattern是模式串，根据正则规则编写的模式串，str是原始串，也就是需要匹配的串 实现123456789101112131415161718192021222324252627282930from selenium import webdriverimport timeimport recc=webdriver.PhantomJS()#身份认证，一次运行只需要运行一次cc.get('http://auth.bupt.edu.cn/authserver/login?service=http%3a%2f%2fyjxt.bupt.edu.cn%2fULogin.aspx')uname=cc.find_element_by_xpath('//*[@id="username"]')uname.clear()uname.send_keys('*********')passwd=cc.find_element_by_xpath('//*[@id="password"]')passwd.clear()passwd.send_keys('*********')cc.find_element_by_xpath('//*[@id="casLoginForm"]/input[4]').click()xuankeurl='http://yjxt.bupt.edu.cn/Gstudent/Course/PlanCourseOnlineSel.aspx?EID=9kWb0OKGTBF2KzmBt5QNDZLXYu1Fldi6xwxV6Yb1wPA1TrsnKBRXgg==&amp;UID=2016111552'delaylist=[u'班级已全选满',u'选课未开放',u'选课已结束']cc.get(xuankeurl)wantedcourse=cc.find_element_by_xpath('//*[@id="contentParent_dgData_hykFull_42"]')restr=wantedcourse.get_attribute('onclick')jumpurl=(re.findall("classFull\('\?(.+)','classFull'\);",restr))[0]while True: cc.get(xuankeurl) wantedcourse=cc.find_element_by_xpath('//*[@id="contentParent_dgData_hykFull_42"]') if wantedcourse.text in delaylist: print(wantedcourse.text) time.sleep(5) pass else : cc.get('http://yjxt.bupt.edu.cn/Gstudent/Course/PlanClassSelFull.aspx?'+jumpurl) print(cc.page_source) break;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[校园网一键登录注销]]></title>
    <url>%2F2016%2F09%2F12%2Fpy_buptnet%2F</url>
    <content type="text"><![CDATA[通过python的requests模块实现的一键登录、注销、查看校园网 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# -*- coding: utf-8 -*-import requestsimport resession=requests.session()headers = &#123;'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 UBrowser/5.5.10106.5 Safari/537.36', 'Referer' : 'http://10.3.8.211/F.htm', 'Connection':'keep-alive', 'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Encoding':'gzip, deflate'&#125;cookies=&#123; 'myusername':'*****',#username 'username':'******',#username 'smartdot':'*****'#passwd&#125;postData=&#123; 'DDDDD':'*******',#username 'upass':'******',#passwd '0MKKey':''&#125;url='http://10.3.8.211'detectx=session.get('http://10.3.8.211/')detectx.encoding='GB2312'result1=detectx.textif re.findall('上网注销窗',result1): flow=(re.findall("flow='(.*?)'",result1))[0] flow=((float)(flow.strip()))/1024 fee=(re.findall("fee='(.*?)'",result1))[0] fee=(float(fee.strip()))/10000 print('已登陆\n流量使用： '+str(flow)+'MB\n剩余余额 ：'+str(fee)+'元') #str=raw_input('是否注销？') str=input('是否注销？') if str=='yes': session.get('http://10.3.8.211/F.htm') print('注销成功')else : startLogin=session.post(url,data=postData) startLogin.encoding='GB2312' detectx=session.get(url) detectx.encoding='GB2312' result1=detectx.text flow=(re.findall("flow='(.*?)'",result1))[0] flow=((float)(flow.strip()))/1024 fee=(re.findall("fee='(.*?)'",result1))[0] fee=(float(fee.strip()))/10000 print('登陆成功\n流量使用： '+str(flow)+'MB\n剩余余额 ：'+str(fee)+'元') #str=raw_input('是否注销？') str=input('是否注销？') if str=='yes': session.get('http://10.3.8.211/F.htm') print('注销成功') 运行成功之后可以通过pyinstaller将py转换win平台可用exe文件。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django初识3]]></title>
    <url>%2F2016%2F09%2F11%2Fdjango_intro3%2F</url>
    <content type="text"><![CDATA[View视图Django 中的视图的概念是「一类具有相同功能和模板的网页的集合」。比如，在一个博客应用中，你可能会创建如下几个视图： 博客首页——展示最近的几项内容。 内容“详情”页——详细展示某项内容。 以年为单位的归档页——展示选中的年份里各个月份创建的内容。 以月为单位的归档页——展示选中的月份里各天创建的内容。 以天为单位的归档页——展示选中天里创建的所有内容。 评论处理器——用于响应为一项内容添加评论的操作。 而在投票应用中，我们需要下列几个视图： 问题索引页——展示最近的几个投票问题。 问题详情页——展示某个投票的问题和不带结果的选项列表。 问题结果页——展示某个投票的结果。 投票处理器——用于响应用户为某个问题的特定选项投票的操作。 在 Django 中，网页和其他内容都是从视图派生而来。每一个视图表现为一个简单的 Python 函数。Django 将会根据用户请求的 URL 来选择使用哪个视图（更准确的说，是根据 URL 中域名之后的部分）。 re命名组分组 (…) 用来匹配符合条件的字符串。并且将此部分，打包放在一起，看做成一个组，group。 而此group，可以被后续的（正则表达式中）匹配时，所引用。此处我称其为 前向引用，即前面已经通过group定义好的字符串，你在后面需要引用。引用的方式，是通过\N，其中N是对应的group的编号。 group的编号 编号为0的group，始终代表匹配的整个字符串；我们在正则表达式内所看到的，通过括号括起来的group，编号分别对应着1,2,3，… 如果你想要在正则表达式中，匹配左括号’(‘，右括号’)’，其字符本身，则通过添加反斜杠，即’(‘，’)’的方式来匹配。 命名分组 此处的(?P…)，和普通的(?…)基本类似。区别在于，此处由于是给此group命名了，所以，后续（同一正则表达式内和搜索后得到的Match对象中），都可以通过此group的名字而去引用此group。 group的名字，当前需要是正常的Python标识符，即字母，数字，下划线等，即，没有特殊的字符。 同一正则表达式内，每个group的组名，是唯一的，不能重复。 虽然此处group内命名了，但是其仍然和普通的(…) group 分组中一样，可以通过索引号，即group(1),group(2)等等，去引用对应的group的。 很明显，按照正则内被命名的group的顺序，依次地 group(1)==group(name1) group(2)==group(name2) Usage 命了名的group，在当前的正则表达式中，后续被(?P=name)的方式引用； re.sub()中后续通过\g方式被引用。 View 修改views.py文件 123456789101112131415from django.http import HttpResponsedef index(request): return HttpResponse("Hello,World.You're at question %s.")def detail(request,question_id): return HttpResponse("Hello,World.You're at question %s." % question_id) def results(request,question_id): response="You're looking the ewsults of question %s." return HttpResponse(response % question_id)def votes(request,question_id): response="You're voting on question %s." return HttpResponse(response % question_id) 修改urls.py文件 12345678from django.conf.urls import urlfrom . import viewsurlpatterns=[ url(r'^$',views.index,name='index'), url(r'^(?P&lt;question_id&gt;[0-9]+)/$',views.detail,name='detail'), url(r'^(?P&lt;question_id&gt;[0-9]+)/results/$',views.results,name='results'), url(r'^(?P&lt;question_id&gt;[0-9]+)/votes/$',views.votes,name='votes')] urls文件中的re匹配用到了上面的re命名组。将匹配到的[0-9]+也就是多个数字结果命名为questiob_id。同事调用方法里面相应的view函数，在Browser中显示结果。因为之前已经在整个项目的urls.py文件中包括了polls应用的urls: url(r&#39;^polls/&#39;,include(&#39;polls.urls&#39;))，所以不需要在此更新 实践 site_address:port/polls/数字/votes -&gt; You’re voting on question question_id. site_address:port/polls/数字/results -&gt; You’re looking the ewsults of question question_id(也就是匹配的数字). 编写真正的View查询展现可以直接通过查询存储在SQLite数据库中的Data，获取相应的属性数据反映在网页中： 12345678910def index(request): '''latest_question_list=Question.objects.order_by('-pub_date')[:5] template=loader.get_template('polls/index.html') context=&#123; 'latest_question_list':latest_question_list, &#125; return HttpResponse(template.render(context,request))''' latest_question=Question.objects.order_by('-pub_date')[:5] output=''.join([p.question_text+" : "+str(p.pub_date) for p in latest_question]) return HttpResponse(output) 上面实现了将database中所有的question尸体相应属性展现在网页中。 使用template使用template模板可以方便的使用html语言设计页面布局，同事在响应函数中传值使用数据： 在网站项目的templates/目录下新建polls目录 在polls目录下新建index.html index.html文件中填充需要修改设计的部分 同时在view.py中修改pools/index.html对应的view函数： 1234567def index(request): latest_question_list=Question.objects.order_by('-pub_date')[:5] template=loader.get_template('polls/index.html') context=&#123; 'latest_question_list':latest_question_list, &#125; return HttpResponse(template.render(context,request)) 或者我们可以直接使用render函数： 123456789from django.shortcuts import renderfrom .models import Questiondef index(request): latest_question_list = Question.objects.order_by('-pub_date')[:5] context = &#123;'latest_question_list': latest_question_list&#125; return render(request, 'polls/index.html', context) render() 函数的第一个参数是一个请求(HttpRequest)对象，第二个参数是需要载入的模板的名字。第三个参数是需要用于渲染模板的上下文字典，这个参数是可选的。函数返回一个 HttpResponse 对象，内容为指定模板用指定上下文渲染后的结果。 因为url配对情况没有发生变化，所以不需要修改。 404异常手动捕获处理123456def detail(request, question_id): try: question = Question.objects.get(pk=question_id) except Question.DoesNotExist: raise Http404("Question does not exist") return render(request, 'polls/detail.html', &#123;'question': question&#125; 在网站项目的templates目录下新建detail.html文件，由于这里只是简单测试下，所以仅仅需要反馈最简答的信息即可： 此时，当访问的question_id在DataBase中存在时，question将直接显示在页面中。否则会出现404异常页面。 自动捕获可以直接使用django提供的get_object_or_404()函数： 12345678from django.http import HttpResponsefrom .models import Questionfrom django.shortcuts import render,get_object_or_404from django.http import Http404def detail(request, question_id): question = get_object_or_404(Question, pk=question_id) return render(request, 'polls/detail.html', &#123;'question': question&#125;) 去除硬编码以及namespace在templates/polls/目录下的index.html文件中，我们定义了polls 应用的首页模板，当访问site_address/polls/时，默认加载site_address/polls/index.html文件中的模板进行匹配。 &lt;a href="/polls//"&gt; 在前文中，我们直接使用的是这种absolute url，这对于项目的若耦合目标相违背，django提供了url函数通过在urls.py中定义的url name直接连接代替硬编码： 其中url &#39;detail&#39; question.id代表的是文字下面的链接地址，url是函数名，detail是url name，对应的是^()/$，在本例中就是对应polls，随后的question.id就是不同question的id值，此项与上面的对应 其中’detail’代表的是urls.py文件中定义的url name： url(r&#39;^(?P&lt;question_id&gt;[0-9]+)/$&#39;,views.detail,name=&#39;detail&#39;) 之后若是想修改url路径，可以直接在app的urls.py中修改： url(r&#39;^specifics/(?P&lt;question_id&gt;[0-9]+)/$&#39;) 此时原来的网页路径将会迁移到site_address/polls/specifics/数字，显示的是question的id为12时choice_text app_url命名在真实的项目实例中，必然会出现多个app应用，多个app应用的view名称可能会出现重叠，此时就应该加上namespace加以区分。 在mysite/urls.py文件在注册将不同app的urls.py文件时，直接加入namespace. url(r’^polls/‘, include(‘polls.urls’, namespace=”polls”)) 多个app情况下，模板使用时注意加上namespace进行区分 ‘detail’–&gt;’polls:detail’]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django初识2]]></title>
    <url>%2F2016%2F09%2F10%2Fdjango_intro2%2F</url>
    <content type="text"><![CDATA[创建管理员账户作为一个常规的Blog系统，我们需要有能够后台操作的账户。Django提供了便捷的创建用户接口： 1$ python manage.py createsuperuser 在交互式输入相关信息时，要注意密码不能是纯数字形式。 在http://127.0.0.1:8000/admin中输入刚刚创建的用户即可管理项目。 管理页管理应用默认的后台网页中是没有显示我们自行添加的应用的Model，我们可以根据自己需要，插件式自行添加。 modelapp_name.admin.py中添加 admin.site.register(Model.name) 默认添加model时的次序是我们在models.py中创建model时class属性次序。 123from .models import Choice, Questionadmin.site.register(Question)admin.site.register(Choice) 如果想要在Model管理面上增加其他特性或者改变排序方式，需要在admin.py中修改相关设置： 1234567891011121314class QuestionAdmin(admin.ModelAdmin): fields = ['pub_date', 'question_text']#修改次序，类继承自admin.ModelAdminadmin.site.register(Question, QuestionAdmin)#将字段次序修改为字段集合class QuestionAdmin(admin.ModelAdmin): fieldsets = [ (None, &#123;'fields': ['question_text']&#125;), ('Date information', &#123;'fields': ['pub_date']&#125;), ]admin.site.register(Question, QuestionAdmin) 关联对象Django对于ForeignKey有很好的支持机制，为了方便我们在后台操作，我们可以修改当前model的注册代码 123456789101112131415161718from django.contrib import adminfrom .models import Choice, Questionclass ChoiceInline(admin.StackedInline): model = Choice extra = 3class QuestionAdmin(admin.ModelAdmin): fieldsets = [ (None, &#123;'fields': ['question_text']&#125;), ('Date information', &#123;'fields': ['pub_date'], 'classes': ['collapse']&#125;), ] inlines = [ChoiceInline]admin.site.register(Question, QuestionAdmin) 增加的代码将会告诉 Django，Choice（选项） 对象将会在 问题（Question） 的管理界面里被编辑。默认显示3个问题字段以供编辑。 其他特性默认情况下，Django 使用 str() 方法来显示对象。但有时如果我们显示一些其他的字段会很有用。为此，我们可以使用 list_display 选项，它是由需要被显示的字段名组成的元组，这些字段将会作为额外的列显示在列表中。 12345# polls/admin.pyclass QuestionAdmin(admin.ModelAdmin): # ... list_display = ('question_text', 'pub_date') 简单搜索功能 search_fields = [&#39;question_text&#39;] 这将会在对象列表的顶部加一个搜索框。当有人键入内容时，Django 会搜索 question_text 字段。你想搜索多少字段都行 - 尽管搜索过程使用的是数据库查询语句里的 LIKE 关键字，但限制一下搜索结果数量将会让数据库搜索更加轻松。 自定义管理页面Django管理页面是Django自身提供的，通过Django的模板系统可以轻易修改。 下面的例子，我们通过简单的管理主页面模板修改主页面： 创建模板Tempalte目录 在mysite/settings.py中添加DIRS选项 1234567891011121314151617# mysite/settings.pyTEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.join(BASE_DIR, 'templates')], 'APP_DIRS': True, 'OPTIONS': &#123; 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], &#125;, &#125;,] 上述修改将mysite目录下的templates目录加入到模板扫描队列中DIRS 是在载入 Django 模板时会搜索的文件系统上的目录集合。 硬盘创建templates目录 在mysite/下创建templates目录，里面可以根据需要包含整个Django项目的template文件。 编写template 我们只需要在管理页面中尝试修改小部分内容做测试，所以可以在原来模板上做轻微的修改。 在python安装目录下找到django安装路径，并找到django/contrib/admin/templates，将目录下的admin/base_site.html模板复制。我们在项目mysite/templates/目录下创建admin目录，并粘贴刚刚复制的base_site.html文件。根据尝试，修改相应内容。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django初识]]></title>
    <url>%2F2016%2F09%2F06%2Fdjango_intro1%2F</url>
    <content type="text"><![CDATA[项目与应用项目和应用有啥区别？ 应用是一个专门做某件事的网络应用程序 - 比如博客系统，或者公共记录的数据库，或者简单的投票程序。 项目则是一个网站使用的配置和应用的集合。项目可以包含很多个应用。应用可以被很多个项目使用。 创建项目一个 Django 项目实例需要的设置项集合，包括 Django 配置和应用程序设置 start$ django-admin startproject mysite 这行代码将会在当前目录下创建一个 mysite 目录 manage.py：一个让你用各种方式管理 Django 项目的命令行工具 mysite/ 目录包含你的项目，它是一个纯 Python 包。它的名字就是当你引用它内部任何东西时需要用到的 Python 包名。 mysite/init.py：一个用于指明此目录是 Python 包的空白文件 mysite/settings.py：Django 项目的配置文件 mysite/urls.py：Django 项目的 URL 声明，就像是你网站的“目录” mysite/wsgi.py：当你部署项目到一个兼容 WSGI 的服务器上时所需要的入口点 INSTALLED_APPSmysite/settings.py。这是包含着 Django 项目设置的 Python 模块。 文件头部的 INSTALLED_APPS 设置项，这里包括了会在你项目中启用的所有 Django 应用。应用能在多个项目中使用，你也可以打包并且发布应用，让别人使用它们 通常，INSTALLED_APPS 默认包括了以下 Django 的自带应用： django.contrib.admin - 管理员界面。你将会在 教程的第二部分（zh） 使用它。 django.contrib.auth - 验证系统。 django.contrib.contenttypes - 内容类型框架。 django.contrib.sessions - 会话框架。 django.contrib.messages - 消息框架。 django.contrib.staticfiles - 管理静态文件的框架。 默认开启的某些应用需要至少一个数据表，所以，在使用他们之前需要在数据库中创建一些表。请执行以下命令： $ python manage.py migrate migrate 命令检查 INSTALLED_APPS 设置，为其中的每个应用创建需要的数据表,这取决于你的 mysite/settings.py 设置文件和每个应用的数据库迁移文件.migrate 命令只会为在 INSTALLED_APPS 里声明了的应用进行数据库迁移。 launch$ python manage.py runserver 此时开启的是django默认附带的一个简易服务器，默认在本机8000端口内可查看当前网站内容。 App应用可以放在 Python path 中的任何目录里。在本次试验中，将直接在 manage.py 所在的目录里创建test应用，这样它就能够被当做顶级模块被引入，而不是作为 mysite 的子模块. $ python manage.py startapp polls 在当前目录下创建名为polls的应用 123456789101112131415polls/ __init__.py admin.py migrations/ __init__.py models.py tests.py views.py create model在 Django 里写一个数据库驱动的 Web 应用的第一步是定义模型 - 也就是数据库结构设计和附加的其他元数据。 模型是真实数据的简单明确的描述。它包含了储存的数据所必要的字段和行为。 本次简单的投票实例中需要两个model，即Question和Choice. 问题模型包括问题描述和发布时间。选项模型有两个字段，选项描述和当前得票数。每个选项属于一个问题。 编辑 polls/models.py 文件 1234567891011121314# polls/models.pyfrom django.db import modelsclass Question(models.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField('date published')class Choice(models.Model): question = models.ForeignKey(Question) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) 再次编辑 mysite/settings.py，改变 INSTALLED_APPS 设置，使其包含字符串 polls。它现在看起来应该像这样： 1234567891011121314151617INSTALLED_APPS = ( 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'polls',) App migration项目创建polls应用之后： $ python manage.py makemigrations polls 通过 migrations 命令，Django 会检测你对模型文件的修改，并且把修改的部分储存为一次 迁移。 迁移是 Django 对于模型定义（也就是你的数据库结构）的变化的储存形式 - 其实也只是一些你磁盘上的文件。如果你想的话，你可以阅读一下你模型的迁移数据，它被储存在 polls/migrations/0001_initial.py 里。别担心，你不需要每次都阅读迁移文件，但是它们被设计成人类可读的形式，这是为了便于你手动修改它们。 现在，再次运行 migrate 命令，在数据库里创建新定义的模型的数据表 $ python manage.py migrate migrate 命令选中所有还没有执行过的迁移（Django 通过在数据库中创建一个特殊的表 django_migrations 来跟踪执行过哪些迁移）并应用在数据库上 - 也就是将你对模型的更改同步到数据库结构上。 综上所述，改变app的model需要以下几步 编辑 models.py 文件，改变模型（如果是初创建的app，甚至需要在setting文件中扩入installed-apps） 运行 python manage.py makemigrations 为模型的改变生成迁移文件（相当于commit） 运行 python manage.py migrate 来应用数据库迁移（相当于真正的push） 一些基本数据操作在django shell编程模式下： 12345678910111213141516171819202122232425262728293031323334353637&gt;&gt;&gt; from polls.models import Question, Choice # 导入刚刚创建的模型类# 列出当前应用指定Models集合&gt;&gt;&gt; Question.objects.all()[]# 创建新 Question# 在 settings 文件里，时区支持被设为开启状态，所以# pub_date 字段要求一个带有时区信息（tzinfo）# 的 datetime 数据。请使用 timezone.now() 代替# datetime.datetime.now()，这样就能获取正确的时间。&gt;&gt;&gt; from django.utils import timezone&gt;&gt;&gt; q = Question(question_text="What's new?", pub_date=timezone.now())# 想将对象保存到数据库中，必须显式的调用 save()。&gt;&gt;&gt; q.save()# 现在它被分配了一个 ID。注意有可能你的结果是“1L”而不是“1”，# 这取决于你在使用哪种数据库。这不是什么大问题；只是表明# 你所用的数据库后端倾向于将整数转换为 Python 的# long integer 对象。&gt;&gt;&gt; q.id1# 通过属性来获取模型字段的值&gt;&gt;&gt; q.question_text"What's new?"&gt;&gt;&gt; q.pub_datedatetime.datetime(2012, 2, 26, 13, 0, 0, 775217, tzinfo=&lt;UTC&gt;)# 通过改变属性值来改变模型字段，然后调用 save()。&gt;&gt;&gt; q.question_text = "What's up"&gt;&gt;&gt; q.save()# objects.all() 显示数据库中所有 question。&gt;&gt;&gt; Question.objects.all()[&lt;Question: Question object&gt;] 在python3下，对应配套的django框架中我们可以通过改变Model的内置函数__str__()，当调用Model.objects.all()方法时，列出str()方法修改的内容。 在Python2中，想要达到相同的目的，则是需要修改unicode()方法，此时django将会调用py2版本的django模块中内置方法str()函数，str()函数调用unicode()方法。 1234567891011from django.db import modelsclass Question(models.Model): # ... def __str__(self): # Python 2 请改为 __unicode__ return self.question_textclass Choice(models.Model): # ... def __str__(self): # Python 2 请改为 __unicode__ return self.choice_text 下面是使用API的一些小例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&gt;&gt;&gt; from django.utils import timezone&gt;&gt;&gt; current_year = timezone.now().year&gt;&gt;&gt; Question.objects.get(pub_date__year=current_year)&lt;Question: What's up?&gt;# 查找一个不存在的 ID 将会引发异常&gt;&gt;&gt; Question.objects.get(id=2)Traceback (most recent call last): ...DoesNotExist: Question matching query does not exist.# 通过主键来查找数据是非常常见的需求，所以 Django# 为这种需求专门制定了一个参数。# 以下代码等同于 Question.objects.get(id=1)。&gt;&gt;&gt; Question.objects.get(pk=1)&lt;Question: What's up?&gt;# 给这个问题添加几个选项。create 函数会创建一个新的# Choice 对象，执行 INSERT 语句，将 Choice 添加到# Question 的选项列表中，最后返回刚刚创建的# Choice 对象。Django 创建了一个集合 API 来使你可以从# 外键关系的另一方管理关联的数据。# （例如，可以获取问题的选项列表）&gt;&gt;&gt; q = Question.objects.get(pk=1)# 显示所有和当前问题关联的选项列表，现在是空的。&gt;&gt;&gt; q.choice_set.all()[]# 创建三个选项。&gt;&gt;&gt; q.choice_set.create(choice_text='Not much', votes=0)&lt;Choice: Not much&gt;&gt;&gt;&gt; q.choice_set.create(choice_text='The sky', votes=0)&lt;Choice: The sky&gt;&gt;&gt;&gt; c = q.choice_set.create(choice_text='Just hacking again', votes=0)# Choice 对象能通过 API 获取关联到的 Question 对象。&gt;&gt;&gt; c.question&lt;Question: What's up?&gt;# 反过来，Question 对象也可以获取 Choice 对象&gt;&gt;&gt; q.choice_set.all()[&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]&gt;&gt;&gt; q.choice_set.count()3# 查找 API 的关键字参数可以自动调用关系函数。# 只需使用双下划线来分隔关系函数。# 只要你想，这个调用链可以无限长。# 例如查找所有「所在问题的发布日期是今年」的选项# （重用我们之前创建的 'current_year' 变量）&gt;&gt;&gt; Choice.objects.filter(question__pub_date__year=current_year)[&lt;Choice: Not much&gt;, &lt;Choice: The sky&gt;, &lt;Choice: Just hacking again&gt;]# 试试删除一个选项，使用 delete() 函数。&gt;&gt;&gt; c = q.choice_set.filter(choice_text__startswith='Just hacking')&gt;&gt;&gt; c.delete()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django介绍]]></title>
    <url>%2F2016%2F09%2F06%2Fdjango_pre%2F</url>
    <content type="text"><![CDATA[Django 是 Python 编程语言驱动的一个开源模型-视图-控制器（MVC）风格的 Web 应用程序框架。使用 Django，我们在几分钟之内就可以创建高品质、易维护、数据库驱动的应用程序。 下面是简略的django应用流程图 简书作者 用户通过浏览器输入相应的 URL 发起 HTTP 请求（一般是 GET/POST） Django 接受到请求，检测 urls.py 文件，找到和用户输入的 URL 相匹配的项，并调用该 URL 对应的视图函数（view），例如，通常来说 urls.py 文件里的代码是这样的： url(r&#39;^homepage/$&#39;, views.home_page)则当用户输入的 URL 为 www.某个网址.com/homepage 时，django 检测到该 URL 与上面的代码 匹配，于是调用后面的 views.home_page 视图函数，把相应的请求交给该视图函数处理。 视图函数被调用后，可能会访问数据库（Model）去查询用户想要请求的数据，并加载模板文件（Template），渲染完数据后打包成 HttpResponse 返回给浏览器（Http协议） 所以要想我们的django应用工作，我们需要做的事： 编写相应的 url 编写数据库（Model） 编写处理 Http 请求的视图函数（View） 编写需要渲染的模板（Template） model设计数据库结构就是编写 models，数据库中每一个实体对应的表在 django 中对用着 models.py 中的一个类，类的属性对应着数据库表的属性列 View数据库建立完毕后需要编写视图函数（view）来处理 Http 请求。 下面以一个简单Blog为例 12345678910111213141516171819202122232425262728293031from blog.models import Articlefrom blog.models import Categoryfrom django.views.generic import ListViewimport markdown2class IndexView(ListView): # 首页视图,继承自ListVIew，用于展示从数据库中获取的文章列表 template_name = "blog/index.html" # template_name属性用于指定使用哪个模板进行渲染 context_object_name = "article_list" # context_object_name属性用于给上下文变量取名（在模板中使用该名字） def get_queryset(self): #过滤数据，获取所有已发布文章，并且将内容转成markdown形式 article_list = Article.objects.filter(status='p') # 获取数据库中的所有已发布的文章，即filter(过滤)状态为'p'(已发布)的文章。 for article in article_list: article.body = markdown2.markdown(article.body, ) # 将markdown标记的文本转为html文本 return article_list def get_context_data(self, **kwargs): # 增加额外的数据，这里返回一个文章分类，以字典的形式 kwargs['category_list'] = Category.objects.all().order_by('name') return super(IndexView, self).get_context_data(**kwargs) 我们需要把数据库中存储的文章的相关信息取出来展示给用户看 Template 模板标签，一般用大括号包裹两个百分号表示1&#123;% %&#125; 一些常用的有for循环标签、if判断标签等。 模板变量，用variable表示 模板渲染是这些变量会被数据库中相应的值代替，例如article_list = Article.objects.filter(status=&#39;p&#39;)，从数据库中取出了已发布的文章列表，赋给了 article_list 变量。如果模板文件中有如下代码： 12&#123;% for article in article_list %&#125;&#123;&#123;article.title&#125;&#125; 渲染时会循环渲染 n 篇文章，并且 也会被存储在数据库中文章的标题取代。 URL写好了数据库、视图和模板，现在就是当用户在浏览器输入 url 访问我们的 Blog 时要告诉 django 哪个 url 的请求对应哪个视图函数来处理，通过 urls.py 来指定： 12345678910urls.pyurlpatterns = [ ... url(r'^blog/', views.IndexView.as_view()), # 首页调用IndexView ...]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[py2-3(不定时更新)]]></title>
    <url>%2F2016%2F09%2F04%2Fpy2-3%2F</url>
    <content type="text"><![CDATA[input raw_input() 在py2版本中，raw_input接收输入流并直接转换存储为string类型 input() py2版本中，通过根据输入类型不同存储为不同格式。 比如像输入string，需在内容外包裹单引或者双引 py3整合input与raw_input，将所有输入作为string保存 printpy2中print不是将print作为一个方法函数，二十当做语句使用，调用时不能再后面直接() Ps:同样的还有exec语句转换成了exec() 1str= reprPython 有办法将任意值转为字符串：将它传入repr() 或str() 函数。 函数str() 用于将值转化为适于人阅读的形式，而repr() 转化为供解释器读取的形式（如果没有等价的语法，则会发生SyntaxError 异常） 某对象没有适于人阅读的解释形式的话，str() 会返回与repr()等同的值。很多类型，诸如数值或链表、字典这样的结构，针对各函数都有着统一的解读方式。字符串和浮点数，有着独特的解读方式。 str直接将object转换成string repr则更类似于Java中的toString()，将相关类型内容显示 unicode与strunicode、utf-8、ascii编码等相关前置知识可以浏览TYuenCN博客 ANSI是默认的编码方式。对于英文文件是ASCII编码，对于简体中文文件是GB2312编码（只针对Windows简体中文版，如果是繁体中文版会采用Big5码） str和unicode都是basestring的子类，而实际上，str是字节串，由unicode经过编码(encode)后的字节组成。unicode才是真正意义上的字符串，由字符组成 下面是一个基本的转换流程 str -&gt; decode(&#39;the_coding_of_str&#39;) -&gt; unicode unicode -&gt; encode(‘the_coding_you_want‘) -&gt; str decodeThe method decode() decodes the string using the codec registered for encoding. It defaults to the default string encoding. 1234567891011#!/usr/bin/pythonStr = "this is string example....wow!!!";Str = Str.encode('base64','strict');print "Encoded String: " + Strprint "Decoded String: " + Str.decode('base64','strict')Encoded String: dGhpcyBpcyBzdHJpbmcgZXhhbXBsZS4uLi53b3chISE=Decoded String: this is string example....wow!!! encodeThe method encode() returns an encoded version of the string. Default encoding is the current default string encoding. The errors may be given to set a different error handling scheme. 12345678#!/usr/bin/pythonstr = "this is string example....wow!!!";print "Encoded String: " + str.encode('base64','strict')Encoded String: dGhpcyBpcyBzdHJpbmcgZXhhbXBsZS4uLi53b3chISE=]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android中的获取坐标]]></title>
    <url>%2F2016%2F08%2F11%2Fmotion%2F</url>
    <content type="text"><![CDATA[OnTouchListener getRawX()和getRawY() 获得的是相对屏幕的位置 getX()和getY() 获得的永远是view的触摸位置坐标（这两个值不会超过view的长度和宽度）。 View view.getTranslationX() 计算的该view的偏移量。初始值为0，向左偏移值为负，向右偏移值为正。 view.getX() 相当于该view左上角距离父容器左边缘的距离，等于getLeft()+getTranslationX() Width/Height当获取view.getWidth()/view.getHeight()返回值为0时，可能是view控件还未在Activity中准备好，尝试下使用view.getMeasuredWidth()/view.gwtMeasuredHeight()]]></content>
      <categories>
        <category>android</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Application版本更新]]></title>
    <url>%2F2016%2F07%2F30%2Fandroid_application_update%2F</url>
    <content type="text"><![CDATA[get&amp;set版本号set在传统的Eclipse IDE开发中，我们通常只需要在清单文件manifests中写入相应代码即可搞定。 1234&lt;manifest xmlns:android="http://schemas.android.com/apk/res/android" package="your package name" android:versionCode="1" android:versionName="1.1.1"&gt; package属性的值为工程默认包名，一般不用我们重新设置。 android:versionCode属性值为int型，开发者可见，开发版本号 android:versionName属性为String类型，用户可见，我们需要使用的就是这个值。 后两个属性在默认情况下是没有的，我们需要添加版本信息时候，可以自行添加。 在Android Studio中没我们使用Gradle开发工具，版本信息设置与传统Eclipse不同，需要更新Gradle.Scripts中的build.gradle(Module:app)中修改相关代码。 123456defaultConfig &#123; applicationId "your package name" minSdkVersion 14 targetSdkVersion 23 versionCode 2 versionName "1.1.2" 默认5个属性，minSdkVersion为向下兼容最低平台版本；targetSdkVersion为目标平台版本 get123456789101112public String getVersionCode(Context context) &#123; try &#123; PackageManager manager = context.getPackageManager(); PackageInfo info = manager.getPackageInfo(this.getPackageName(), 0); String version = info.versionName; return version; &#125; catch (Exception e) &#123; e.printStackTrace(); return "Can't get application version_name"; &#125; &#125; 版本对比与更新对比12345&lt;update&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;name&gt;2048&lt;/name&gt; &lt;url&gt;https://raw.githubusercontent.com/xxxx/xxxxx/xxxxx/xxxx.apk&lt;/url&gt;&lt;/update&gt; 在服务器中房屋文件update.xml，内容如上。 version 属性值为上文记录的versionName url 属性值为新版本apk文件直接下载地址 xml文件内容转换123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class ParseXmlService &#123; public HashMap&lt;String, String&gt; parseXml(InputStream inStream) throws Exception &#123; HashMap&lt;String, String&gt; hashMap = new HashMap&lt;String, String&gt;(); // 实例化一个文档构建器工厂 DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); // 通过文档构建器工厂获取一个文档构建器 DocumentBuilder builder = factory.newDocumentBuilder(); // 通过文档通过文档构建器构建一个文档实例 Document document = builder.parse(inStream); //获取XML文件根节点 Element root = document.getDocumentElement(); //获得所有子节点 NodeList childNodes = root.getChildNodes(); for (int j = 0; j &lt; childNodes.getLength(); j++) &#123; //遍历子节点 Node childNode = (Node) childNodes.item(j); if (childNode.getNodeType() == Node.ELEMENT_NODE) &#123; Element childElement = (Element) childNode; //版本号 if ("version".equals(childElement.getNodeName())) &#123; hashMap.put("version",childElement.getFirstChild().getNodeValue()); &#125; //下载地址 else if (("url".equals(childElement.getNodeName()))) &#123; hashMap.put("url",childElement.getFirstChild().getNodeValue()); &#125; &#125; &#125; return hashMap; &#125;&#125;``` 返回包含版本信息以及下载地址信息的Map```javaString serviceCode = mHashMap.get("version"); // 版本判断 if (!serviceCode.equals(versionCode)) &#123; return true; &#125; 下载下载等网络相关代码不能在主线程中展开，新开一个线程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152String sdpath = Environment.getExternalStorageDirectory() + "/";mSavePath = sdpath + "download";URL url = null;try &#123; url = new URL(mHashMap.get("url"));&#125; catch (MalformedURLException e) &#123; e.printStackTrace();&#125;// 创建连接HttpURLConnection conn = null;try &#123; conn = (HttpURLConnection) url.openConnection();&#125; catch (IOException e) &#123; e.printStackTrace();&#125;conn.connect();// 获取文件大小int length = conn.getContentLength();// 创建输入流InputStream is = conn.getInputStream();File file = new File(mSavePath);// 判断文件目录是否存在if (!file.exists())&#123; file.mkdir();&#125;File apkFile = new File(mSavePath, mHashMap.get("name"));FileOutputStream fos = new FileOutputStream(apkFile);int count = 0;// 缓存byte buf[] = new byte[1024];// 写入到文件中do&#123; int numread = is.read(buf); count += numread; // 计算进度条位置 progress = (int) (((float) count / length) * 100); // 更新进度 mHandler.sendEmptyMessage(DOWNLOAD); if (numread &lt;= 0) &#123; // 下载完成 mHandler.sendEmptyMessage(DOWNLOAD_FINISH); break; &#125; // 写入文件 fos.write(buf, 0, numread);&#125; while (!cancelUpdate);// 点击取消就停止下载.fos.close();is.close();]]></content>
      <categories>
        <category>android</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[getMeasured]]></title>
    <url>%2F2016%2F07%2F24%2FgetMeasured%2F</url>
    <content type="text"><![CDATA[public final int getMeasuredHeight () Added in API level 1Like getMeasuredHeightAndState(), but only returns the raw width component (that is the result is masked by MEASURED_SIZE_MASK). Returns: The raw measured height of this view. public final int getMeasuredHeightAndState () Added in API level 11Return the full height measurement information for this view as computed by the most recent call to measure(int, int). This result is a bit mask as defined by MEASURED_SIZE_MASK and MEASURED_STATE_TOO_SMALL. This should be used during measurement and layout calculations only. Use getHeight() to see how wide a view is after layout. Returns: The measured width of this view as a bit mask. public final int getHeight () Added in API level 1Return the height of your view. Returns: The height of your view, in pixels. 以上3个View类的方法中，前两个是一类的，只不过返回的数据形式不一样。对比这两类， getMeasuredHeight 返回控件的实际高度； getHeight 返回控件在屏幕中的高度 所以如果控件可以包裹在屏幕内的话，两个函数的返回值相同，而一旦view过大，则getMeasuredHeight()等于getHeight()加上屏幕之外没有显示的高度。]]></content>
      <categories>
        <category>android</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matlab学习(五)]]></title>
    <url>%2F2016%2F07%2F11%2Fmatlab5%2F</url>
    <content type="text"><![CDATA[绘图单变量函数在 MATLAB 中绘图包含下面三个步骤： 定义函数 指定要绘制的函数图形的值范围 调用 MATLAB 的 plot(x, y)函数 当指定函数的值范围时，我们必须告诉 MATLAB 函数使用的变量的增量。使用较少的增量可以使得图形显示更加平滑。如果增量较小，MATLAB 会计算更多的函数值，不过通常不需要取得那么小。我们用一个简单的例子来看看如何做。 我们绘制 0≤x≤10 之间的 y = cos(x)的图形。绘制之前，我们要定义这个区间并告诉MATLAB 我们所使用的增量。区间使用方括号[]以下面的形式定义：[ start : interval : end ] 例如，如果我们要告诉 MATLAB 在 0≤x≤10 上以 0.1 的增量（间隔）递增，我们输入： [0:0.1:10] 用赋值运算符给这个范围内的变量一个名称，也用这种办法告知 MATLAB 相关变量和我们要绘制的函数。因此，要绘制 y = cos(x)，我们输入下面的命令： 12&gt;&gt; x = [0:0.1:4*pi];&gt;&gt; y = cos(x); 注意我们每行都以分号“;”结尾，记住，这会抑制 MATLAB 输出。你不会想让 MATLAB在屏幕中间输出一大串 x 值，因此使用了分号。现在我们可以输入下面的命令绘图了：&gt;&gt; plot(x, y), xlabel(&#39;x&#39;), ylabel(&#39;cos(x)&#39;) fplot上面的例子只是简单的提供了一种图形曲线画法函数，然而当我们遇到需要多个包含变量的函数进行乘除运算时，就会出现： 123456789&gt;&gt; t = [0:0.02:4];&gt;&gt; f = exp(-2*t)*sin(t);Error using * Inner matrix dimensions must agree. &gt;&gt; f=2*sin(t);&gt;&gt; f=2*x*sin(t);Error using * Inner matrix dimensions must agree. 为什么会出现这种情况呢？在Matlab中，x是一个[0:0.02:4]的矩阵，同样sin(x)也是一个矩阵。*是矩阵乘法operator。x是一个长度为200的矩阵，sin(x)也是如此。也就是说，x和sin(x)都是1*200的矩阵，这在矩阵乘法中显然是无法进行的。所以提醒Inner matrix dimensions must agree 此时我们可以使用dot乘，对应元素分别相乘。 exp(-2*x).*sin(x) 或者使用fplot函数： 123456789101112131415161718192021222324252627&gt;&gt; help fplot fplot Plot function fplot(FUN,LIMS) plots the function FUN between the x-axis limits specified by LIMS = [XMIN XMAX]. Using LIMS = [XMIN XMAX YMIN YMAX] also controls the y-axis limits. FUN(x) must return a row vector for each element of vector x. For example, if FUN returns [f1(x),f2(x),f3(x)] then for input [x1;x2] FUN should return [f1(x1) f2(x1) f3(x1); f1(x2) f2(x2) f3(x2)] fplot(FUN,LIMS,TOL) with TOL &lt; 1 specifies the relative error tolerance. The default TOL is 2e-3, i.e. 0.2 percent accuracy. fplot(FUN,LIMS,N) with N &gt;= 1 plots the function with a minimum of N+1 points. The default N is 1. The maximum step size is restricted to be (1/N)*(XMAX-XMIN). fplot(FUN,LIMS,'LineSpec') plots with the given line specification. fplot(FUN,LIMS,...) accepts combinations of the optional arguments TOL, N, and 'LineSpec', in any order. [X,Y] = fplot(FUN,LIMS,...) returns X and Y such that Y = FUN(X). No plot is drawn on the screen. fplot(AX,...) plots into AX instead of GCA. fplot 为你产生尽可能精确的的图象，同时它也帮助我们绕过像这样的错误。调用 fplot 的形式如 fplot(&#39;function string&#39;, [xstart, xend]) 参数 function string 告诉 fplot 你所要绘制的图象函数，而 xstart 和 xend 定义了函数的区间。 &gt;&gt; fplot(&#39;exp(-2*t)*sin(t)&#39;,[0, 4]), xlabel(&#39;t&#39;), ylabel(&#39;f(t)&#39;),title(&#39;阻尼弹力&#39;) 多个函数Matlab支持多个函数在一张图表中显示： 123456&gt;&gt; t = [0:0.01:5];% 接着我们定义两个函数&gt;&gt; f = exp(-t);&gt;&gt; g = exp(-2*t);plot(t,f,t,g,'--') 上面的例子告诉Matlab要绘制 f(t)和 g(t)函数，并且第二个函数曲线使用虚线。 实线 ‘-‘ 虚线 ‘–’ 虚点线 ‘-.’ 点线 ‘:’ &gt;&gt; plot(t,f,&#39;:&#39;,t,g,&#39;--&#39;) 添加图例专业的图象总是附有图例，告诉读者某个曲线是什么。在下面的例子中，假设我们要绘制两个表示势能的函数，它们由双曲三角函数 sinh(x)和 cosh(x)定义，定义域为 0≤x≤2。首先我们定义x： &gt;&gt; x = [0:0.01:2]; 现在我们定义这两个函数，在 MATLAB 中把函数称为 y 并不是什么不可思议的事，所以我们把第二个函数称为 z，因此有： 12&gt;&gt; y = sinh(x);&gt;&gt; z = cosh(x); legend 命令用起来很简单。只需把它加在 plot(x,y)命令后面，并用单引号把要添加为图例的文本引起来。在这个例子中我们有： legend(&#39;sinh(x)&#39;,&#39;cosh(x)&#39;) 我们只需把这一行添加到 plot 命令后面。在这个例子中，我们还包含 x 和 y 标签，第一条曲线用实线而第二条曲线用虚点线： 1&gt;&gt; plot(x,y,x,z,'-.'), xlabel('x'), ylabel('Potential'), legend('sinh(x)','cosh(x)') 颜色设置相比其他类似的开发工具，Matlab画图是也同样支持设置图像颜色。 plot(x,y,&#39;r&#39;,x,z,&#39;b--&#39;) 上面的代码代表第一个函数为红色，第二个以虚线填充的函数为蓝色。 白色 w 黑色 k 蓝色 b 红色 r 青色 c 绿色 g 洋红 m 蓝色 y 设置坐标比例axis命令可以设置绘图范围。通过用下面的方式调用 axis 命令： axis ([xmin xmax ymin ymax])]]></content>
      <categories>
        <category>matlab</category>
      </categories>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KMP笔记]]></title>
    <url>%2F2016%2F07%2F11%2FKMP%2F</url>
    <content type="text"><![CDATA[文章来源：c_cloud KMP 思想 KMP算法是一种改进的字符串匹配算法，由D.E.Knuth，J.H.Morris和V.R.Pratt同时发现，因此人们称它为克努特——莫里斯——普拉特操作（The Knuth-Morris-Pratt Algorithm，简称KMP算法）。KMP算法的关键是利用匹配失败后的信息，尽量减少模式串与主串的匹配次数以达到快速匹配的目的。具体实现就是实现一个next()函数，函数本身包含了模式串的局部匹配信息 首先介绍几个算法的术语： 前缀 前缀指除了最后一个字符以外，一个字符串的全部头部组合 后缀 后缀指除了第一个字符以外，一个字符串的全部尾部组合 部分匹配值部分匹配值就是”前缀”和”后缀”的最长的共有元素的长度。以”ABCDABD”为例 “A”的前缀和后缀都为空集，共有元素的长度为0； “AB”的前缀为[A]，后缀为[B]，共有元素的长度为0； “ABC”的前缀为[A, AB]，后缀为[BC, C]，共有元素的长度0； “ABCD”的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0； “ABCDA”的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为”A”，长度为1； “ABCDAB”的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为”AB”，长度为2； “ABCDABD”的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0 “部分匹配”的实质是，有时候，字符串头部和尾部会有重复。比如，”ABCDAB”之中有两个”AB”，那么它的”部分匹配值”就是2（”AB”的长度）。搜索词移动的时候，第一个”AB”向后移动4位（字符串长度-部分匹配值），就可以来到第二个”AB”的位置。 在KMP算法中，模式字符串向右移动的位数 = 已匹配的字符数 - 对应的部分匹配值 部分匹配的实现下面给出模式串右移位数： 12345678910111213141516void makeNext(const char P[],int next[])&#123; int q,k;//q:模式字符串下标；k:最大前后缀长度 int m = strlen(P);//模式字符串长度 next[0] = 0;//模版字符串的第一个字符的最大前后缀长度为0 for (q = 1,k = 0; q &lt; m; q++)//for循环，从第二个字符开始，依次计算每一个字符对应的next值 &#123; while(k &gt; 0 &amp;&amp; P[q] != P[k])//递归的求出P[0]到P[q]最大的相同的前后缀长度k k = next[k-1]; if (P[q] == P[k])//如果相等，那么最大相同前后缀长度加1 &#123; k++; &#125; next[q] = k; &#125;&#125; 已知前一步计算时最大相同的前后缀长度为k（k&gt;0），即P[0]···P[k-1]； 上面的代码中123456while(k &gt; 0 &amp;&amp; P[q] != P[k])//递归的求出P[0]到P[q]最大的相同的前后缀长度k k = next[k-1]; if (P[q] == P[k])//如果相等，那么最大相同前后缀长度加1 &#123; k++; &#125; 这几步是比较难理解的，实际上这几步就是上面我们手工对字符串”ABCDABD”进行的部分匹配值计算。 “ABCD”的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0； “ABCDA”的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为”A”，长度为1； “ABCDAB”的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为”AB”，长度为2； “ABCDABD”的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0 截取这几步，我们按照从左向右的顺序进行模式匹配，字符串”ABCDABD”依序增加的话，因为前缀与后缀相同的子字符串顺序是一致的，所以部分匹配值增加的话也是根据上一字符串的部分匹配值基础进行。 我们拿到一个字符串计算部分匹配值，如果上一字符串匹配值为0，我们肯定会先将字符串的第一位与最后一位进行匹配，因为此时字符串最多只能可能有1的部分匹配值，否则的话上一字符串匹配值不会是0。 如果上一字符串部分匹配值为k时，我们将字符串的前（k+1）位与后（k+1）位进行匹配，如果匹配成功，则next值为k+1， 如果匹配失败的话： 12while(k &gt; 0 &amp;&amp; P[q] != P[k]) k = next[k-1]; P[k]已经和P[q]失配了，而且P[q-k] ··· P[q-1]又与P[0] ···P[k-1]相同。假设模式串长度length，失配也就是讲模式串的前k位与P[length-k-1:length-2]相同，而P[k]与P[length-1]不同。看来P[0]···P[k-1]这么长的子串是用不了了，那么我要找个同样也是P[0]打头、P[k-1]结尾的子串，即P[0]···Pj-1，看看它的下一项P[j]是否能和P[q]匹配。循环进行，直到k=0，从头再开始。 那么为什么j==next[k-1]呢？上一次k的匹配失败，导致求下一个k值只能在模式串的前next[k-1]字符中寻找，而非next[k]-1。因为前面的寻找依然是一次模式匹配，所以next数组的求值实际上就是一个递归。 “ABCABHABCAB” 部分匹配值为5 “ABCABHABCABC” 继续增加字符时出现失配，j=next[k-1]，也就是求next[4]=2。因为之前的”ABCABH”没法使用了，但是”ABCAB”是匹配过的，”H”无法使用，就在”ABCAB”中寻找匹配度，目的是尝试对下标next[4]与整个模式串的最后一位匹配。]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>模式匹配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matlab学习(四)]]></title>
    <url>%2F2016%2F07%2F10%2Fmatlab4%2F</url>
    <content type="text"><![CDATA[矩阵矩阵是两维数字数组，要在 MATLAB 创建矩阵，输入的行各元素之间用空格或逗号分隔，行末使用分号标记。 123456789&gt;&gt; A = [-1,6; 7, 11]A = -1 6 7 11&gt;&gt; B = [2,0,1;-1,7,4; 3,0,1]B = 2 0 1 -1 7 4 3 0 1 转置123456789101112131415161718192021222324252627&gt;&gt; A = [-1 2 0; 6 4 1]A = -1 2 0 6 4 1&gt;&gt; B = A'B = -1 6 2 4 0 1% 如果矩阵包含有复数元素，那么转置操作会自动计算复数的共轭值：&gt;&gt; C = [1+i, 4-i; 5+2*i, 3-3*i]C = 1.0000 + 1.0000i 4.0000 - 1.0000i 5.0000 + 2.0000i 3.0000 - 3.0000i&gt;&gt; D = C'D = 1.0000 - 1.0000i 5.0000 - 2.0000i 4.0000 + 1.0000i 3.0000 + 3.0000i% 如果要转置复数矩阵的而不计算它的共轭值，那么我们使用（.'）&gt;&gt; D = C.'D = 1.0000 + 1.0000i 5.0000 + 2.0000i 4.0000 - 1.0000i 3.0000 - 3.0000i 乘法与数组类似，矩阵的乘法同样分为两种： 123456789101112131415161718&gt;&gt; A = [12 3; -1 6]; B = [4 2; 9 1];&gt;&gt; C = A .* BC = 48 6 -9 6&gt;&gt; A = [2 1; 1 2]; B = [3 4; 5 6];&gt;&gt;&gt; A * Bans = 11 14 13 16&gt;&gt; A = [1 4; 8 0; -1 3]; B = [-1 7 4; 2 1 -2];&gt;&gt; C = A*BC = 7 11 -4 -8 56 32 7 -4 -10 特殊矩阵单元矩阵是一个对角线为非零元素其它元素为零的方形矩阵。要创建 n×n 的单元矩阵，输入下面的 MATLAB 命令： 123456&gt;&gt; eye(4)ans = 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 下面是创建全0或者全1的矩阵操作： 1234567891011121314151617181920212223242526272829&gt;&gt; zeros(3)ans = 0 0 0 0 0 0 0 0 0&gt;&gt; zeros(2,3)ans = 0 0 0 0 0 0&gt;&gt; ones(3)ans = 1 1 1 1 1 1 1 1 1&gt;&gt; ones(2,3)ans = 1 1 1 1 1 1 矩阵引用在 MATLAB 中，矩阵的单个元素或整列都能够被引用。考虑下面的矩阵： 1234567891011121314151617181920212223242526272829303132333435363738&gt;&gt; A = [1 2 3; 4 5 6; 7 8 9]A = 1 2 3 4 5 6 7 8 9% 单元素选择&gt;&gt; A(2,3)ans = 6% 列元素选择&gt;&gt; A(:,2)ans = 2 5 8% 行元素选择&gt;&gt; A(2,:)ans= 4 5 6&gt;&gt; A(:,2:3)ans = 2 3 5 6 8 9&gt;&gt; E = A([1,1,1,1],:)E = 1 2 3 1 2 3 1 2 3 1 2 3]]></content>
      <categories>
        <category>matlab</category>
      </categories>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matlab学习(三)]]></title>
    <url>%2F2016%2F07%2F10%2Fmatlab3%2F</url>
    <content type="text"><![CDATA[文件存储.mat在Matlab中，为了方便我们在之后的工作中随时进行中断的工作，我们可以在IDE中通过： 点击“文件（File）”下接菜单 选择“保存工作区为（Save Workspace As…）” 输入文件名 点击“保存（Save）”按钮 将当前工作状态保存为.mat文件，之后我们就可以随时、随地在任何安装Matlab软件的计算机上使用当前工作状态。 .m有时候，特别是复杂工程，我们可能无法坐在一个地方把所有的表达式全部输进去。把很长的一系列命令保存到一个文件中，然后仅在命令窗口输入一个简单命令就能执行。这就是创建脚本文件。 脚本文件（script file）就能这样做了。这种类型的文件被称为MATLAB程序，以.M 为扩展名保存。因此，我们也称为 M 文件。我们也可以创建全是 函数（function）的 M 文件 在IDE中点击New Script按钮，新建脚本文件 输入以下示例代码 12x = [1:2:3:4]; %x赋值为数组，元素之间以：或者；间隔y = exp(x) 保存为文件Untitled.m 在Command Window中输入Untitled 显示exp(x)结果2.7183 7.3891 20.0855 54.5982 向量列向量MATLAB 允许你创建列向量和行向量，列向量通过在方括号内把数值用分号（;）隔开来创建，对元素的个数没有限制。 例如，要创建一个含有三个元素的向量，我们写成： 12345678910111213a = [2; 1; 4]a = 2 1 4&gt;&gt; a*3ans = 3 6 9 行向量要创建行向量，我们仍然是把一组数值用方括号括起来，不过这次使用的分隔符是空格（space）或逗号（,）。例如： 123456789&gt;&gt; v = [2 0 4]v =2 0 4% 或者使用逗号：&gt;&gt; w = [1,1,9]w =1 1 9 转置使用转置操作可以进行列向量与行向量之间的相互转换。 在 MATLAB 中，我们用单引号（’）代表转置操作，把列向量与行向量互相转换的例子为： 12345678910111213&gt;&gt; a = [2; 1; 4];&gt;&gt; y = a'y = 2 1 4&gt;&gt; Q = [2 1 3]Q = 2 1 3&gt;&gt; R = Q'R = 2 1 3 其他使用12345678910&gt;&gt; A = [1; 4; 5];&gt;&gt; B = [2; 3; 3];&gt;&gt; D = [A;B]D = 1 4 5 2 3 3 也可能使用行向量来创建新向量。要从带有 m 个元素的行向量 r 和带有 n 个元素的行向量 s 中创建带有 m+n 个元素的行向量 u，我们写成 u = [r, s]。例如： 12345&gt;&gt; R = [12, 11, 9];&gt;&gt; S = [1, 4];&gt;&gt; T = [R, S]T = 12 11 9 1 4 等差元素vector有时需要创建带有等差元素的向量，差值为q为一个实数。创建一个首元素为s，末元素为e的向量x的语法如下： 1234567891011121314151617x = [ s : q : e ]&gt;&gt; x = [0:2:10]x = 0 2 4 6 8 10&gt;&gt; x = [0:0.1:1]x = Columns 1 through 10 0 0.1000 0.2000 0.3000 0.4000 0.5000 0.6000 0.7000 0.8000 0.9000 Column 11 1.0000 这里要注意的是，在数组（包括行向量、列向量）使用幂函数、或者与其他向量一一运算时，与其他operator不同： Inputs must be a scalar and a square matrix.To compute elementwise POWER, use POWER (.^) instead. 也就是说需要在数组变量中加上. 1234567891011&gt;&gt; y=x.^2y = Columns 1 through 10 0 0.0100 0.0400 0.0900 0.1600 0.2500 0.3600 0.4900 0.6400 0.8100 Column 11 1.0000 命令 length 返回向量中包含元素的个数 123length(y)ans= 11 向量乘点乘在MATLAB中，a、b两向量的点乘可以使用dot(a, b)命令计算。 两个向量点乘的结果是数量，也即是说，它只是一个数值。我们使用MATLAB计算一个简单的例子： 1234&gt;&gt; a = [1;4;7]; b = [2;-1;5];&gt;&gt; c = dot(a,b)c = 33 点乘可以用来计算向量的模，所需要的只是把向量同时传递给 dot 命令的两个参数。考虑上一节的向量：&gt;&gt; J = [0; 3; 4];调用 dot 命令我们得到： 123&gt;&gt; dot(J, J)ans = 25 或者我们也可以用下面这种方式计算向量的模： 123&gt;&gt; mag = sqrt(dot(J,J))mag = 5 对于带有复数元素的向量，dot 操作也能正确计算： 1234&gt;&gt; u = [-i; 1 + i; 4 + 4*i];&gt;&gt; dot(u, u)ans = 35 叉乘要计算向量的叉乘，这两个向量必须是的三维的 1234&gt;&gt; A = [1 2 3]; B = [2 3 4];&gt;&gt; C = cross(A, B)C = -1 2 -1]]></content>
      <categories>
        <category>matlab</category>
      </categories>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matlab学习(二)]]></title>
    <url>%2F2016%2F07%2F08%2Fmatlab2%2F</url>
    <content type="text"><![CDATA[辅助指令help工具 help 目录名 显示指定目录中的所有命令及其函数 help lang 将列出与 MATLAB 编程语言的所有命令及其函数 help matfun 将列出与数值线性代数有关的所有矩阵函数 help elfun 列出所有基本函数 help 命令名/函数名/符号 显示指定的命令名/函数名/符号的详细信息 例：显示计算矩阵特征值和特征向量的函数eig的说明 12345678910111213141516help eigEIG Eigenvalues and eigenvectors.E = EIG(X) is a vector containing the eigenvalues of asquarematrix X..........[V,D] = EIG(A,B) produces a diagonal matrix D ofgeneralizedeigenvalues and a full matrix V whose columns are thecorresponding eigenvectors so that A*V = B*V*D.See also CONDEIG, EIGS.Overloaded methodshelp sym/eig.mhelp lti/eig.m lookfor工具首先可以使用上面学到的help工具了解lookfor的功能： lookfor Search all M-files for keyword.lookfor XYZ looks for the string XYZ in the first comment line(the H1 line) of the HELP text in all M-files found on MATLABPATH(including private directories). For all files in which amatch occurs, lookfor displays the H1 line. For example, “lookfor inverse” finds at least a dozen matches,including the H1 lines containing “inverse hyperbolic cosine”“two-dimensional inverse FFT”, and “pseudoinverse”.Contrast this with “which inverse” or “what inverse”, which runmore quickly, but which probably fail to find anything becauseMATLAB does not ordinarily have a function “inverse”. lookfor XYZ -all searches the entire first comment block ofeach M-file. In summary, WHAT lists the functions in a given directory,WHICH finds the directory containing a given function or file, and lookfor finds all functions in all directories that might have something to do with a given key word. lookfor指令机制: 对MATLAB中的每个 M 文件注释区的第一行进行扫描，一旦发现包含要查询的字符串就显示出来提示用户。也可利用此机理建立自己文件的在线帮助。 其他帮助指令 exist 检查指定名字的变量或函数文件的存在性 what 按扩展名分类列出 在搜索路径中 指定目录上的文件名 which 列出指定名字文件所在的目录 数值计算数值矩阵 利用指令reshape创建数值矩阵 12av=1:15 % 产生15个元素的行向量 av 以% 开头的是注释行bm=reshape(av,3,5) % 利用向量 av 创建 3x5 矩阵 bm 12345678910111213&gt;&gt; av=1:15av = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15&gt;&gt; bm=reshape(av,3,5)bm = 1 4 7 10 13 2 5 8 11 14 3 6 9 12 15 利用指令diag产生对角阵 123ar=rand(4,4) % 产生 4x4 的 0-1 均匀分布随即矩阵 ard=diag(ar) % 用矩阵的主对角线元素形成向量 dD=diag(d) % 用向量 d 构成对角矩阵 D 1234567891011121314151617181920212223242526&gt;&gt; ar=rand(4,4)ar = 0.8147 0.6324 0.9575 0.9572 0.9058 0.0975 0.9649 0.4854 0.1270 0.2785 0.1576 0.8003 0.9134 0.5469 0.9706 0.1419&gt;&gt; d=diag(ar)d = 0.8147 0.0975 0.1576 0.1419&gt;&gt; D=diag(d)D = 0.8147 0 0 0 0 0.0975 0 0 0 0 0.1576 0 0 0 0 0.1419 矩阵标识1234567891011121314151617181920212223242526272829303132333435363738394041&gt;&gt; b=[1 2 3 4 5; 6 7 8 9 10 ;11 12 13 14 15]b23=b(2,3)b1=b(1:2,[1 3 5])b2=b([3 1],:)b([1 3],[2 4])=zeros(2)b = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15b23 = 8b1 = 1 3 5 6 8 10b2 = 11 12 13 14 15 1 2 3 4 5b = 1 0 3 0 5 6 7 8 9 10 11 0 13 0 15&gt;&gt; b(1:2)ans = 1 6 b23=b(2,3) b23代表矩阵b中第二行第三列的数值 b1=b(1:2,[1 3 5]) 将变量b1赋值为矩阵b中第一行、第二行中的1、3、5列数值 b2=b([3 1],:) 将b2矩阵赋值为第三行、第一行的所有列数值 b([1 3],[2 4])=zeros(2) 将原来b矩阵中的一三行的二四列赋值为0 条件选择123456789x=[1 2 3 4 5] %产生 1x5 向量x =1 2 3 4 5l=x&lt;=3 %标出数值小于等于3的元素的位置l =1 1 1 0 0x=x(l) %获得元素不超过3的子向量x =1 2 3 数组运算 123456789101112131415161718&gt;&gt; a=[1 2 3; 4 5 6; 7 8 9];b=[1 2 3; 3 2 1;1 4 5];c=[1 1 1;2 3 1;1 0 2];&gt;&gt; c2=c^2c2 = 4 4 4 9 11 7 3 1 5&gt;&gt; c3=a*c2c3 = 31 29 33 79 77 81 127 125 129]]></content>
      <categories>
        <category>matlab</category>
      </categories>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matlab学习]]></title>
    <url>%2F2016%2F07%2F08%2Fmatlab1%2F</url>
    <content type="text"><![CDATA[matlab小序 MALAB译于矩阵实验室MATrix LABoratory是用来提供通往LINPACK 和 EISPACK 矩阵软件包接口的，后来，它渐渐发展成了通用科技计算图视交互系统和程序语言。 MATLAB 的基本数据单位是矩阵 它的指令表达与数学 工程中常用的习惯形式十分相似 比如 矩阵方程 Ax=b 在 MATLAB 中被写成 A*x=b 而若要通过 A,b 求 x 那么只要写 x=A\b 即可。完全不需要对矩阵的乘法和求逆进行编程因此 用MATLAB 解算问题要比用C Fortran 等语言简捷得多。 MATLAB发展到现在已经成为一个系列产品 MATLAB 主包 和各种可选的toolbox工具包主包中有数百个核心内部函数 迄今所有的三十几个工具包又可分为两类功能性工具包和学科性工具包 功能性工具包主要用来扩充 MATLAB 的符号计算功能图视建模仿真功能 文字处理功能以及硬件实时交互功能 这种功能性工具包用于多种学科而学科性工具包是专业性比较强的如控制工具包 Control Toolbox 信号处理工具包(Signal Processing Toolbox)通信工具包(Communication Toolbox)等都属此类。 表达式MATLAB采用表达式语句，用户输入语句由MATLAB系统实时运行。 MATLAB语句有两种常见的形式 表达式 变量=表达式 实时显示1234562001/81ans = 24.7037s=1-1/2+1/3-1/4+1/5-1/6+1/7-1/8;ss = 0.6345 上面两个例子中结果显示的形式不同，第一个表达式无结尾，回车直接显示结果。结尾的分号作用是指令执行结果将不会显示在屏幕上但变量s仍将驻留在内存中。 who与永久变量who和whos这两个指令的作用都是列出在MATLAB工作间中已经驻留的变量名清单。不过 whos在给出变量名的同时，还给出它们的维数及性质。 在MATLAB工作内存中,还驻留几个由系统本身在启动时定义的变量,如下表称为永久变量Permanent variables 或称为预定义变量Predefined variables. 在 MATLAB 启动时自定义的 不会被清除内存变量指令clear所清除 可以重新定义为其他值,但用clear可清除重定义值恢复预定义值 123456a=Inf/infa =NaNx=2*pi/3+2^3/5-0.3e-3x =3.6941 矩阵与复数1234567891011121314A=[1,3;2,4]-i*[5,8;6,9]B=[1+5*i,2+6*i;3+8*i,4+9*i]C=A*BA =1.0000 - 5.0000i 3.0000 - 8.0000i2.0000 - 6.0000i 4.0000 - 9.0000iB =1.0000 + 5.0000i 2.0000 + 6.0000i3.0000 + 8.0000i 4.0000 + 9.0000iC =1.0e+002 *0.9900 1.1600 - 0.0900i1.1600 + 0.0900i 1.3700 上式中，C为矩阵A和矩阵B相乘的结果。 函数MATLAB的函数本质上讲分为三类： 内部函数 系统附带各种工具包中的.m文件所提供的大量函数 用户自己增加的函数 通用函数matlab提供的基本数学函数 特殊函数 基本矩阵函数 特殊矩阵函数 矩阵分解和分析函数 数据分析函数 微分方程求解 多项式函数 非线性方程及其优化函数 数值积分函数 信号处理函数 1234567z=1233.344x=sqrt(log(z))z =1.233344000000000e+003x =2.66786140168028 显示格式matlab中，所有变量默认使用double双精度8byte类型保存。复数形式变量使用两个双精度长度表示。 在结果显示中，虽然默认使用的是format short格式，即只显示short长度的结果，但是运算结果的保存都是双精度。可以通过format命令改变结果显示形式。 1234567891011121314151617181920212223242526272829303132333435363738394041&gt;&gt; x=[4/3 1.2345e-6];&gt;&gt; xx = 1.3333 0.0000&gt;&gt; format short e&gt;&gt; xx = 1.3333e+00 1.2345e-06&gt;&gt; format long&gt;&gt; xx = 1.333333333333333 0.000001234500000&gt;&gt; format long e&gt;&gt; xx = 1.333333333333333e+00 1.234500000000000e-06&gt;&gt; format bank&gt;&gt; xx = 1.33 0.00&gt;&gt; format hex&gt;&gt; xx = 3ff5555555555555 3eb4b6231abfd271]]></content>
      <categories>
        <category>matlab</category>
      </categories>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程刷票]]></title>
    <url>%2F2016%2F07%2F07%2Fshuapiao%2F</url>
    <content type="text"><![CDATA[需求最近突然有朋友对投票刷票有需求，正好自己空了下来，就帮他写了个简单的多线程投票脚本。因为不想考虑过多的session、cookie以及post data，所以直接使用了自动化工具Selenium 简单地说，Selenium就是一个通过执行预先设置的Browser的指令，解放双手，提高工作效率。 不同于通用的流行python网络模块，Selenium更像是市面上流行的按键精灵类似的软件，通过设定特定的工作流程，保证任务的完成。任务的实际执行者是Browser本身。 Selenium对网页的request、response、解析等操作都是另外的伪浏览器进程执行，然后将获取的数据返回。而传统的python网络模块则通过python进程，对网页请求、回应。显然网络模块会更加高效，而对于普通人，Selenium的操作更加直观。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869 &lt;div class="tit"&gt;&lt;span class="r"&gt;总票数：&lt;strong&gt;xxxxxx&lt;/strong&gt;&lt;/span&gt;&lt;h5&gt;标题: 201x年x月份优秀论文评选投票&lt;/h5&gt;&lt;/div&gt; &lt;div class="c_box wrap"&gt;&lt;input type="hidden" name="subjectid" value="7"&gt; &lt;table width="100%" border="1" cellspacing="0" cellpadding="0" class="tp"&gt; &lt;tr&gt; &lt;th&gt;1&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="186" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;******&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;2&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="187" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;*********&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;3&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="188" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;*********&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;4&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="189" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;*********&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;5&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="190" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;*********&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;6&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="191" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;*********&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;7&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="192" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;*********&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;8&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="193" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;*********&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;9&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="194" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;*********&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;10&lt;/th&gt; &lt;td class="tp_tit"&gt;&lt;input type="checkbox" name="radio[]" id="radio" value="195" /&gt;&lt;/td&gt; &lt;td class="ls"&gt;*********&lt;/td&gt; &lt;td class="tdcol3"&gt;&lt;font color=red&gt;*********&lt;/font&gt; 票&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; 分析如上代码所示，在本次投票中，所有的候选人名单都包含在checkbox。我们首先在Selenium中使用Browser Driver定位到需要选中的某个或某几个checkbox，然后将这些checkbox选中。 与以前不同的是，投票网页的checkbox的input标签中，id、name属性都是完全一致的。所以无法通过简单的ById或ByName直接定位。 之后通过绝对地址的次序依次抽丝剥茧获取Xpath,调试出错，不知道什么问题&gt;GG&lt;。然后就发现了input标签中的value属性每个值都不一样。 例如获取第10个input元素的Xpath//input[@value=&quot;195&quot;] 剩下的问题就水到渠成了。放上代码： 实现Selenium实现12345678910from selenium import webdriverdef func(args): c = webdriver.PhantomJS() # Get local session of PhantomJS c.get("http://www.hiahiahia.com.cn/index.php?m=vote&amp;c=index&amp;a=show&amp;show_type=1&amp;subjectid=7&amp;siteid") # Load page ele=c.find_element_by_xpath('//input[@value="195"]') ele.click() print('开始刷票，次序：'+args) submit=c.find_element_by_xpath('//*[@id="myform"]/div[2]/button') submit.click() 多线程套上多线程模板： 12345678910111213import threadingthreads=[]for i in range(0,20): t=threading.Thread(target=func,args=&#123;str(i)&#125;) threads.append(t)for item in threads: item.setDaemon(True) item.start()for item in threads: item.join() requests使用Selenium的效率实在不敢恭维，如果再加上多线程限制，在虚拟机中开大数目的伪浏览器资源，程序很容易崩溃。所以通过抓包之后改成了使用requests模块直接传递数据。 requests.Session()类中自动维持cookies、headers、keep-alive等机制，但是在本次测试中，直接使用都无法达到效果，最后发现在初次get页面时，requests.Session不能直接获取维护cookies。所以改成自己封装cookies。代码如下： 1234567891011121314session=requests.Session()headers = &#123;'Content-type': 'application/x-www-form-urlencoded', 'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 UBrowser/5.6.14087.9 Safari/537.36' ,'Accept-Encoding':'gzip, deflate' ,'Accept':"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"&#125;session.headers.update(headers)m=vote&amp;c=index&amp;a=show&amp;show_type=1&amp;subjectid=7&amp;siteid'cookies=&#123;'logtime':'Yes' ,'Hm_lvt_f8de16968aad3ba4868c06590fea9fb5':'1467943093'&#125;payload = &#123;'radio[]':'193','subjectid':'7'&#125;url='http://www.zzzzzzz.com.cn/index.php?m=vote&amp;c=index&amp;a=post&amp;subjectid=7&amp;siteid'dom=requests.post(url,data=payload,cookies=cookies)session.close()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图的遍历]]></title>
    <url>%2F2016%2F07%2F04%2Fdfs_bfs%2F</url>
    <content type="text"><![CDATA[一般来讲，图的遍历主要分为深度优先遍历（DFS，Depth-First Traversa）和广度优先遍历（BFS,Breadth-First Traversa）。 DFS在G中任选一顶点v为初始出发点(源点)，则深度优先遍历可定义如下： 首先访问出发点v，并将其标记为已访问过； 依次从v出发搜索v的每个邻接点w。若w未曾访问过，则以w为新的出发点继续进行深度优先遍历，直至图中所有和源点v有路径相通的顶点(亦称为从源点可达的顶点)均已被访问为止。 若此时图中仍有未访问的顶点，则另选一个尚未访问的顶点作为新的源点重复上述过程，直至图中所有顶点均已被访问为止。可以看出深度优先遍历是一个递归的过程。 图的深度优先遍历类似于树的前序遍历。采用的搜索方法的特点是尽可能先对纵深方向进行搜索。这种搜索方法称为深度优先搜索(Depth-First Search)。相应地，用此方法遍历图就很自然地称之为图的深度优先遍历。 图例 上图的DFS遍历顺序为： 0-&gt;1-&gt;3-&gt;7-&gt;4-&gt;2-&gt;5-&gt;6 实现 邻接矩阵 1234567891011121314//visited数组维持图中节点是否已经访问//Edge[u][v]维持从u-&gt;v连线的权值，u==v时权值为0，两节点不可达则Maxvoid AdjMWGraph::Depth(int v,int visited[])&#123; visited[v]=1; for(int u=0;u&lt;numV;u++) &#123; if(Edge[v][u]==0||Edge[v][u]==MaxWeight) continue; if(!visited[u]) //继续递归 Delpth(u,visited); &#125;&#125; 时间复杂度O（n2） 邻接表形式 1234567891011121314Void AdjTWGraph::DepthFirst(int v, int visited[])&#123; int vj; Edge *p; visited[v]=1; p=Vertices[v].adj; //取v的邻接边结点 while(p!=NULL) &#123; vj=p-&gt;dest; //取v的邻接点编号 if(visited[vj]==0) DepthFirst(vj, visited); p=p-&gt;next; //取下一个邻接边结点 &#125;&#125; O(n+e) 应用搜索引擎搜索优化、八皇后问题 BFS 从图中某个顶点V0出发，并访问此顶点； 从V0出发，访问V0的各个未曾访问的邻接点W1，W2，…,Wk;然后,依次从W1,W2…,Wk出发访问各自未被访问的邻接点； 重复步骤2，直到全部顶点都被访问为止。 图例依然使用之前的图 上图的DFS遍历顺序为： 0-&gt;1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;6-&gt;7 实现 邻接矩阵形式 123456789101112131415void AdjMWGraph::Depth(int v,int visited[])&#123; sqQueue&lt;int&gt; q; //定义队列queue q.EnQueue(v); //顶点v入队列 while(!q.IsEmpty()) //当队列非空时循环 &#123; v=q.DeQueue(); //出队列得到队头顶点u cout&lt;&lt;endl&lt;&lt;"顶点"&lt;&lt;v+1&lt;&lt;"权值："&lt;&lt;Vertices[col];//访问定点v visited[col]=1;//标记顶点v已访问 for(int col=0;col&lt;numV;col++) //v到col之间可达，同时col节点从未被访问 if(Edge[v][col]&gt;0&amp;&amp;Edge[v][col]&lt;MaxWeight&amp;&amp;visited[col]==0) q.EnQueue(col); &#125;&#125; O（n2） 邻接表形式 1234567891011121314151617181920void AdjTWGraph::BroadFirst(int v, int visited[])&#123; int vj; Edge *p; SqQueue &lt;int&gt; Q; Q.EnQueue(v); while(!Q.IsEmpty()) //队列不空，循环 &#123; v=Q.DeQueue(); //出队并且访问顶点v visited[v]=1; p=Vertices[v].adj; //取v的邻接边结点 while(p!=NULL) &#123; vj=p-&gt;dest; //取v的邻接点编号vj if(visited[vj]==0) Q.EnQueue(vj); //vj未访问，入队 p=p-&gt;next; //取下一个邻接边结点 &#125; &#125;&#125; O（n+e） 应用广度优先生成树、最短路径（Dijkstra）]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ngroke]]></title>
    <url>%2F2016%2F06%2F29%2Fngroke%2F</url>
    <content type="text"><![CDATA[ngrok 是一个反向代理，通过在公共的端点和本地运行的 Web 服务器之间建立一个安全的通道。ngrok 可捕获和分析所有通道上的流量，便于后期分析和重放 为了方便本地服务器简单映射到外网访问，我们可以使用Ngroke服务。只需要几条简单的命令即可使用。 国内ngrok服务 点击进入获取相应平台的最新版本 注册/登录 添加隧道列表 将本地服务器地址、端口号与Ngroke分配的服务器绑定。本地地址： 127.0.0.1 隧道状态页面 添加映射隧道之后，在隧道状态页面获取Ngroke服务器提供的客户端Id。 解压网站提供的客户端压缩包，执行.bat程序 打开本机的服务器容器，并在如webapps\ROOT目录下放入文件，或者webapps目录下放入Web工程 在Ngroke客户端.bat中提供客户端Id，开启映射服务。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（ZT）Verilog]]></title>
    <url>%2F2016%2F05%2F23%2Fabout-verilog-newnote%2F</url>
    <content type="text"><![CDATA[转自 sitongweilai 很多刚学Verilog HDL （硬件描述语言）的朋友肯定会对阻塞赋值和非阻塞赋值比较疑惑，那我们就一起来抛开这层迷雾吧。 首先我们要理解两种变量类型 Net Type（连线型）和 Register Type （寄存器型）。（有些参考书上有分为3种类型，这个无关紧要） Net Type（连线型），从名字上理解就是“导线”呗，导线的这头和导线的另一头始终是直接连通的，这头是什么值，那头就是什么值，所以输出随着输入随时变化的。连线型中 wire 最常见。 Register Type（寄存器型），寄存器就不像普通导线了，它可以把值给存住，你只要给它赋一次值，它都会存住那个值，直到你给它赋一个新的值它才会改变。寄存器型中 reg 最常见。 最常用到的是 wire 和 reg 这两种类型，其他的对我们初学者来说一般很少用到，可以暂时跳过，以后慢慢学下去自然会理解。 注意：wire型变量如果没有赋予初始值，默认初始值为高阻态“Z”。 reg 型变量如果没有赋予初始值，默认初始值为不定态“X”。 在理解这两种基本的数据类型之后，我们来看看verilog语言中的赋值语句。verilog语言中的赋值语句有两种，一种是持续赋值语句（assign语句），另一种是过程赋值语句（always语句）。 持续赋值语句（assign语句）主要用于对wire型变量的赋值，因为wire（线型）的值不能存住，需要一直给值，所以需要用持续赋值。 例如：assign c = a + b; 只要a和b有任意变化，都可以立即反映到c上，也就是说c的值是根据a，b的值随时变化的。 过程赋值语句（always语句）主要用于reg 型变量的赋值 ，因为always语句被执行是需要满足触发条件的，所以always过程块里面的内容不是每时每刻都被执行，因此需要将被赋值的对象定义成寄存器类型，以便这个值能被保持住。 过程赋值又分为 阻塞赋值 “=” 和 非阻塞赋值 “&lt;=” 两种。这里的非阻塞赋值符号 “&lt;=” 与 “小于等于” 符号相同，他们在不同的语境下表示不同含义，要注意区分，例如在“if-else”等判断语句中，一般都表示为“小于等于”。 接下来对这两种赋值作具体讲解… ① 阻塞赋值 “=“ 。 阻塞赋值和我们平时理解的赋值差不多，不用太多解释，就是按照语句的顺序，一句句往下顺序执行。一个赋值语句执行完，然后执行下一个赋值语句。 ② 非阻塞赋值 “&lt;=” 。非阻塞赋值就比较特别了，在同一个always过程块中，非阻塞赋值语句都是同时并发执行的，并且在过程块结束时才执行赋值操作。也就是说，在同一个always过程块中，非阻塞赋值语句被执行没有先后顺序，在过程快结束时，大家一起被赋值。 给大家举一个具体的例子： 12345678910111213141516171819202122232425262728293031 module test (clk, a1, a2, b1, b2, c1, c2); // test为module名称，括号内的是端口列表，包含所有输入输出的变量名称 input clk, a1, a2; // 定义输入变量，这里没有定义位宽，默认为1位宽度 output b1, b2, c1, c2; // 定义输出变量，这里没有定义位宽，默认为1位宽度 reg b1 = 0 , b2 = 0, c1 = 0 , c2 = 0; // 注意！因为这些变量将会在always过程块中被赋值，所以必须定义成 reg 型 // 注意！这里省略了对输入信号clk, a1, a2 的类型定义，它们默认为1位的wire 型（因为输入信号是随时要变化，所以必须用wire型） always @ (posedge clk) // always 用 clk 上升沿触发 begin b1 = a1; // 这里采用的是阻塞赋值 c1 = b1; endalways @ (posedge clk) // always 用 clk 上升沿触发 begin b2 &lt;= a2; // 这里采用的是非阻塞赋值 c2 &lt;= b2; end endmodule // endmodule 别忘了，与 module 成对使用 我们只需给输入信号赋值，输出信号根据输入信号的变化而变化。]]></content>
      <categories>
        <category>verilog</category>
      </categories>
      <tags>
        <tag>verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android全局变量]]></title>
    <url>%2F2016%2F05%2F21%2Fandroid-application%2F</url>
    <content type="text"><![CDATA[帮别人做一个小玩意儿时候遇到的问题，需要常常在不同activity、service之间传递一个数据变量。最前考虑的是入门时使用的Bundle对象。 Bundle类用作携带数据，它类似于Map，用于存放key-value名值对形式的值。相对于Map，它提供了各种常用类型的putXxx()/getXxx()方法，如:putString()/getString()和putInt()/getInt()，putXxx()用于往Bundle对象放入数据，getXxx()方法用于从Bundle对象里获取数据。Bundle的内部实际上是使用了HashMap类型的变量来存放putXxx()方法放入的值. 使用方法: 1234Bundle bundle = new Bundle();app.setB(name);bundle.putString("username", name);it.putExtra("bundle", bundle); 在Activity跳转之前，将已经存储数据的Bundle对象绑定到Intent对象上，然后在跳转之后的Activity界面内： 123Intent intent = getIntent();Bundle bundle = intent.getBundleExtra("bundle");String name = bundle.getString("username"); 获取存储的数据。 后来想到了应该会与全局的变量可以使用吧，毕竟Application域是在整个app运行间都在的。 Step1 123456789101112131415public class applicationData extends Application &#123; private String username; public String getB()&#123; return this.username; &#125; public void setB(String c)&#123; this.username= c; &#125; @Override public void onCreate()&#123; username = "undefined"; super.onCreate(); &#125;&#125; 新建继承自Application类，然后根据自己需要存储获取的数据自行修改setter/getter方法。 Step2 在程序清单manifests文件内，将android:name的值修改或增添为前面新建的继承Application的类名称： 12&lt;application android:name="applicationData" Step3 12345applicationData app;//直接从程序运行中获取Application实例，此时app会自动调用applicationData的onCreate函数app=(applicationData)getApplication();app.setB("input you will set");String value=app.getB();]]></content>
      <categories>
        <category>adnroid</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android中SQLite基础操作]]></title>
    <url>%2F2016%2F05%2F20%2Fandroid-sqlite-rawsql%2F</url>
    <content type="text"><![CDATA[记录基本的android使用SQLite方法： 目前比较主流的方法是，使用继承自SQLiteOpenHelper类的对象创建数据库并管理数据库版本。 当创建实例之后，除了自动运行构造函数，这个继承自SQLiteOpenHelper的类还会自动调用onCreate方法。 123456789101112public void onCreate(SQLiteDatabase db) &#123; db.execSQL("create table if not exists tb_user" + "(_id integer primary key autoincrement," + "username varchar(20)," + "password varchar(20))"); db.execSQL("create table if not exists tb_userInfo" + "(_id integer primary key autoincrement," + "username varchar(20)," + "suggestions text)"); db.execSQL("insert into tb_user(username, password) values('chuangwailinjie', '123456')"); db.execSQL("insert into tb_user(username, password) values('peihao', '1234567')"); &#125; 通过SQLiteDatabase对象可以直接执行相应的SQL语句。上面的例子就是创建了两个表，同时在表tb_user中插入了两条信息。 对SQLite数据库的读操作： 12345678910111213dbhelper= new DbHelper(serInfo.this, "userInfo",null,1);SQLiteDatabase db=dbhelper.getReadableDatabase();Cursor cursor = db.rawQuery("select suggestions from tb_userInfo WHERE username=?",new String[]&#123;username&#125;);if (cursor.moveToFirst() == false)&#123; //为空的Cursor 也就是没有返回结果，找不到 tv_suggestions.setText("undefined");&#125;else&#123; cursor.moveToFirst(); tv_suggestions.setText(cursor.getString(0)); cursor.close();&#125;db.close(); 对SQLite数据库的写操作： 123SQLiteDatabase Db=dbhelper.getWritableDatabase();Db.execSQL("insert into tb_user(username, password) values(?,?)", new Object[]&#123;name,password &#125;);Db.close();]]></content>
      <categories>
        <category>adnroid</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[属于你的文件]]></title>
    <url>%2F2016%2F05%2F18%2Fxdy%2F</url>
    <content type="text"><![CDATA[六层空间的叠叠瓦瓦，11月8小时的温柔似玉 念念忘忘的油纸伞片，27度6分钟的暖暖如花]]></content>
      <categories>
        <category>随感</category>
      </categories>
      <tags>
        <tag>随感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS连接Sql Server]]></title>
    <url>%2F2016%2F05%2F18%2Fvs%E8%BF%9E%E6%8E%A5sqlserver%2F</url>
    <content type="text"><![CDATA[最近在帮同学搞一个小项目时遇到的关于VS2013连接微软公司的DBS SqlServer遇到的问题，这里mark以下，防止以后遗忘。 当我尝试调试这个半成品的时候，出现了下面的问题。 上面提示VS在于SQL Server建立连接时出现了问题，无法正确找到服务器，所以与数据服务器建立连接也就无从谈起了。 在services.msc程序中确保SQL Server的支撑服务已经正常启动，再次尝试，依旧如此。 在asp.net项目中的Web.config文件中： 12345678910111213&lt;configuration&gt; &lt;appSettings&gt; &lt;add key="ConnectionString" value="workstation id=.;integrated security=SSPI;data source=MSSQLSERVER;initial catalog=BookShop"/&gt; &lt;/appSettings&gt; &lt;connectionStrings&gt; &lt;add name="db_NetShopConnectionString1" connectionString="workstation id=.;integrated security=SSPI;data source=MSSQLSERVER;initial catalog=BookShop" providerName="System.Data.SqlClient" /&gt; &lt;/connectionStrings&gt; &lt;system.web&gt; &lt;compilation debug="true"/&gt; &lt;authentication mode="Forms"/&gt; &lt;/system.web&gt;&lt;/configuration&gt; integrated security标准的值有3种： True的时候，连接语句前面的 UserID, PW 是不起作用的，即采用windows身份验证模式。 False或省略该项的时候，按照 UserID, PW 来连接。 sspi ，差不多相当于 True，建议用这个代替 True。 initial catalog与database在这个Web.config中的连接字符串中的作用是一致的。 一个一个排查下去，既然已经设置为windows身份验证模式不需要设置用户、密码，可以看到只剩下data source这个属性还没有排查。data source设置的值为SQL Server的实例名称，根据在论坛上搜索的信息，不同版本的SQL Server实例名有差别。 在SQL Server中新建查询1select @@SERVERNAME; 返回的结果一般是数据库实例名称，也是计算机名。但是更改代码之后，错误依旧。 之后依次根据服务中的SQL Server括号中实例名等等都无效。 最后在国外的论坛中找到结果：尝试使用(local)、127.0.0.1就可以正常使用。 12string myStr = ConfigurationManager.AppSettings["ConnectionString"].ToString();SqlConnection myConn = new SqlConnection(myStr);]]></content>
      <categories>
        <category>C#</category>
      </categories>
      <tags>
        <tag>C#</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（ZT）机器学习与数据挖掘]]></title>
    <url>%2F2016%2F04%2F28%2Fdata-dip%2F</url>
    <content type="text"><![CDATA[文章摘录自周志华老师《机器学习与数据挖掘》. 机器学习是人工智能的核心研究领域之一， 其最初的研究动机是为了让计算机系统具有人的学习能力以便实现人工智能，因为众所周知，没有学习能力的系统很难被认为是具有智能的。目前被广泛采用的机器学习的定义是“利用经验来改善计算机系统自身的性能”。事实上，由于“经验”在计算机系统中主要是以数据的形式存在的，因此机器学习需要设法对数据进行分析，这就使得它逐渐成为智能数据分析技术的创新源之一，并且为此而受到越来越多的关注。 “数据挖掘”和“知识发现”通常被相提并论，并在许多场合被认为是可以相互替代的术语。对数据挖掘有多种文字不同但含义接近的定义，例如“识别出巨量数据中有效的、新颖的、潜在有用的、最终可理解的模式的非平凡过程”。其实顾名思义，数据挖掘就是试图从海量数据中找出有用的知识。大体上看数据挖掘可以视为机器学习和数据库的交叉，它主要利用机器学习界提供的技术来分析海量数据，利用数据库界提供的技术来管理海量数据。因为机器学习和数据挖掘有密切的联系，受主编之邀，本文把它们放在一起做一个粗浅的介绍。 1980 年夏天，在美国卡内基梅隆大学举行了第一届机器学习研讨会；同年，《策略分析与信息系统》连出三期机器学习专辑；1983 年，Tioga出版社出版了R.S. Michalski、J.G. Carbonell和T.M.Mitchell主编的《机器学习：一种人工智能途径》，书中汇集了 20 位学者撰写的 16 篇文章，对当时的机器学习研究工作进行了总结，产生了很大反响；1986 年，《Machine Learning》创刊；1989 年，《Artificial Intelligence》出版了机器学习专辑，刊发了一些当时比较活跃的研究工作，其内容后来出现在J.G. Carbonell主编、MIT出版社 1990 年出版的《机器学习：风范与方法》一书中。总的来看，20 世纪 80 年代是机器学习成为一个独立的学科领域并开始快速发展、各种机器学习技术百花齐放的时期。 R.S. Michalski等人中把机器学习研究划分成“从例子中学习”、“在问题求解和规划中学习”、“通过观察和发现学习”、“从指令中学习”等范畴；而E.A. Feigenbaum在著名的《人工智能手册》中，则把机器学习技术划分为四大类，即“机械学习”、“示教学习”、“类比学习”、“归纳学习”。机械学习也称为“死记硬背式学习”，就是把外界输入的信息全部记下来，在需要的时候原封不动地取出来使用，这实际上没有进行真正的学习；示教学习和类比学习实际上类似于R.S. Michalski等人所说的“从指令中学习”和“通过观察和发现学习”；归纳学习类似于“从例子中学习”，即从训练例中归纳出学习结果 c 。20 世纪 80 年代以来，被研究得最多、应用最广的是“从例子中学习”（也就是广义的归纳学习），它涵盖了监督学习（例如分类、回归）、非监督学习（例如聚类）等众多内容。下面我们对这方面主流技术的演进做一个简单的回顾。 在 20 世纪 90 年代中期之前，“从例子中学习”的一大主流技术是归纳逻辑程序设计（Inductive Logic Programming），这实际上是机器学习和逻辑程序设计的交叉。它使用 1 阶逻辑来进行知识表示，通过修改和扩充逻辑表达式（例如Prolog表达式）来完成对数据的归纳。这一技术占据主流地位与整个人工智能领域的发展历程是分不开的。如前所述，人工智能在 20 世纪 50 年代到 80 年代经历了“推理期”和“知识期”，在“推理期”中人们基于逻辑知识表示、通过演绎技术获得了很多成果，而在知识期中人们基于逻辑知识表示、通过领域知识获取来实现专家系统，因此，逻辑知识表示很自然地受到青睐，而归纳逻辑程序设计技术也自然成为机器学习的一大主流。归纳逻辑程序设计技术的一大优点是它具有很强的知识表示能力，可以较容易地表示出复杂数据和复杂的数据关系。尤为重要的是，领域知识通常可以方便地写成逻辑表达式，因此，归纳逻辑程序设计技术不仅可以方便地利用领域知识指导学习，还可以通过学习对领域知识进行精化和增强，甚至可以从数据中学习出领域知识。事实上，机器学习在 20 世纪 80 年代正是被视为“解决知识工程瓶颈问题的关键”而走到人工智能主舞台的聚光灯下的，归纳逻辑程序设计的一些良好特性对此无疑居功至伟。 然而，归纳逻辑程序设计技术也有其局限，最严重的问题是由于其表示能力很强，学习过程所面临的假设空间太大，对规模稍大的问题就很难进行有效的学习，只能解决一些“玩具问题”。因此，在 90 年代中期后，归纳程序设计技术方面的研究相对陷入了低谷。 机器学习之所以备受瞩目，主要是因为它已成为智能数据分析技术的创新源之一。但是机器学习还有一个不可忽视的功能，就是通过建立一些关于学习的计算模型来帮助人们了解“人类如何学习”。 数据挖掘的对象早就不限于数据库，而可以是存放在任何地方的数据，甚至包括Internet上的数据。 数据挖掘受到了很多学科领域的影响，其中数据库、机器学习、统计学无疑影响最大。粗糙地说，数据库提供数据管理技术，机器学习和统计学提供数据分析技术。由于统计学界往往醉心于理论的优美而忽视实际的效用，因此，统计学界提供的很多技术通常都要在机器学习界进一步研究，变成有效的机器学习算法之后才能再进入数据挖掘领域。从这个意义上说，统计学主要是通过机器学习来对数据挖掘发挥影响，而机器学习和数据库则是数据挖掘的两大支撑技术。 从数据分析的角度来看，绝大多数数据挖掘技术都来自机器学习领域。但能否认为数据挖掘只不过就是机器学习的简单应用呢？答案是否定的。一个重要的区别是，传统的机器学习研究并不把海量数据作为处理对象，很多技术是为处理中小规模数据设计的，如果直接把这些技术用于海量数据，效果可能很差，甚至可能用不起来。因此，数据挖掘界必须对这些技术进行专门的、不简单的改造。例如，决策树是一种很好的机器学习技术，不仅有很强的泛化能力，而且学得结果具有一定的可理解性，很适合数据挖掘任务的需求。但传统的决策树算法需要把所有的数据都读到内存中，在面对海量数据时这显然是无法实现的。为了使决策树能够处理海量数据，数据挖掘界做了很多工作，例如通过引入高效的数据结构和数据调度策略等来改造决策树学习过程，而这其实正是在利用数据库界所擅长的数据管理技术。实际上，在传统机器学习算法的研究中，在很多问题上如果能找到多项式时间的算法可能就已经很好了，但在面对海量数据时，可能连O(n 3 )的算法都是难以接受的，这就给算法的设计带来了巨大的挑战。 为一个独立的学科领域，必然会有一些相对“独特”的东西。对数据挖掘来说，这就是关联分析。简单地说，关联分析就是希望从数据中找出“买尿布的人很可能会买啤酒”这样看起来匪夷所思但可能很有意义的模式。 实际上，在面对少量数据时关联分析并不难，可以直接使用统计学中有关相关性的知识，这也正是机器学习界没有研究关联分析的一个重要原因。关联分析的困难其实完全是由海量数据造成的，因为数据量的增加会直接造成挖掘效率的下降，当数据量增加到一定程度，问题的难度就会产生质变，例如，在关联分析中必须考虑因数据太大而无法承受多次扫描数据库的开销、可能产生在存储和计算上都无法接受的大量中间结果等，而关联分析技术正是围绕着“提高效率”这条主线发展起来的。]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大量数据排序问题-ASCII]]></title>
    <url>%2F2016%2F04%2F27%2Fmess-data-sort%2F</url>
    <content type="text"><![CDATA[问题引出这个问题最开始是在一个朋友遇到的需求: 已知：300万个随机的char（即取值范围为0-127），有大量的重复。求：最快的排序方法，将这300万个char，按照从大到小的顺序排列。内存最好在9M之内. 刚开始拿到这个问题的时候，由于我本身只对几个简单的常规排序有印象，搜索下来，发现这个问题使用这些方法都不太合适。内存限制在9M，也就是9369216B的内存。300w个char类型数据在C家族中占用的内存大小是3000000B。 分析有几位朋友提出使用Bucket sort、或者链表之类的数据结构。链表的情况下，需要付出额外的内部空间保持指针指向，对于内存的限制就不能很好的体现。这里我的想法是一次性读入300w的数据，所以下面的展开也都是在这个基础上。 桶排序是个很不错的方法。 工作的原理是将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。桶排序是鸽巢排序的一种归纳结果。当要被排序的数组内的数值是均匀分配的时候，桶排序使用线性时间（Θ（n））。但桶排序并不是 比较排序，他不受到 O(n log n) 下限的影响。 这边先来看一个类似的例子。 高考海量数据排序 一年的全国高考考生人数为500 万，分数使用标准分，最低100 ，最高900 ，没有小数，要求对这500 万元素的数组进行排序。 对500W数据排序，如果基于比较的先进排序，平均比较次数为O(5000000*log5000000)≈1.112亿。但是我们发现，这些数据都有特殊的条件： 100=&lt;score&lt;=900。那么我们就可以考虑桶排序这样一个“投机取巧”的办法、让其在毫秒级别就完成500万排序。 方法：创建801(900-100)个桶。将每个考生的分数丢进f(score)=score-100的桶中。这个过程从头到尾遍历一遍数据只需要500W次。然后根据桶号大小依次将桶中数值输出，即可以得到一个有序的序列。而且可以很容易的得到100分有xxx人，501分有xxx人。实际上，桶排序对数据的条件有特殊要求，如果上面的分数不是从100-900，而是从0-2亿，那么分配2亿个桶显然是不可能的。所以桶排序有其局限性，适合元素值集合并不大的情况。 这个问题让我想到了《编程珠玑》的引言部分，著者因为内存的限制，通过使用位图BitMap为整型数据排序，实际上跟这两个问题都是异曲同工。 解决我们申请128个变量（对应ASCII的128个数据），遍历300w 的数据，并对他们计数，保存在变量中。最后这128个变量中保留的就是每个ASCII码对应出现的次数。这个类似于Bucket Sort中的木桶。只不过桶排序有一个限制条件，所有数据必须是相同的整数。 然后遍历这128个变量，例如a[22]中保留的是ASCII中第23个数据出现的次数。则在相应位置设置a[22]个22. 1234567891011121314151617181920212223#include&lt;iostream&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#define Random(x) (rand() % x)using namespace std;int _tmain(int argc, _TCHAR* argv[])&#123; char value[1000000]; int countx[128]; memset(countx, 0, sizeof(countx)); for (int i = 0; i &lt; 1000000; i++)&#123; value[i] = Random(128); countx[value[i]]++; &#125; int court = 0; for (int i = 0; i &lt; 128; i++)&#123; for (int x = 0; x &lt; countx[i]; x++) value[court++] = i; &#125; cout &lt;&lt; "success" &lt;&lt; '\n'; return 0;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP介绍-二维苹果收集]]></title>
    <url>%2F2016%2F04%2F26%2FDP-intro-002%2F</url>
    <content type="text"><![CDATA[问题引出 平面上有N*M个格子，每个格子中放着一定数量的苹果。你从左上角的格子开始，每一步只能向下走或是向右走，每次走到一个格子上就把格子里的苹果收集起来，这样下去，你最多能收集到多少个苹果。 分析问题最红需要我们求出整个格子里最终能收集到多少苹果，这个问题直接求解是没有办法的。我们可以换个办法依次趋近这个问题的结果。 当前位置（x，y）能够获取的苹果数目最多是多少。 这个问题就比较好说了，因为到达当前位置的前置节点只有两个，也就是他的上方位置或左侧位置（先不讨论边界问题）。我们从格子的起点开始，每次获取当前位置上侧、左侧位置节点的苹果数目对比即可。 毫无疑问，现在这个已经被我们分解的多个子问题的问题集已经符合DP问题的基本条件： 最优化原理（最优子结构性质） 无后效性 子问题的重叠性 以s[length][length]记录每个格子包含的苹果数目，dp[length][length]记录到达当前节点最多获取的苹果数目，即子问题的状态。问题的状态转移方程： dp[x][y] = max( if(x&gt;0) dp[x-1][y] , if(y&gt;0) dp[x][y-1]) 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include&lt;iostream&gt;#include&lt;string.h&gt;using namespace std;int a[100][100];int dp[100][100];int m,n;//递归版本void dp_fun(int x,int y)&#123; dp[x][y] = a[x][y]; int max = 0; if(x &gt; 0 &amp;&amp; max &lt; dp[x-1][y]) max = dp[x-1][y]; if(y &gt; 0 &amp;&amp; max &lt; dp[x][y-1]) max = dp[x][y-1]; dp[x][y] += max; if(x&lt;m-1) dp_fun(x+1,y); if(y&lt;n-1) dp_fun(x,y+1); return;&#125; /*递推版本 调用dp_fun(m,n);void dp_fun(int x,int y)&#123; /*dp[0][0]=a[0][0]; for(int i=1;i&lt;x;i++) dp[i][0]=dp[i-1][0]+a[i][0]; for(int i=1;i&lt;y;i++) dp[0][i]=dp[0][i-1]+a[0][i]; for(int i=1;i&lt;x;i++) for(int j=1;j&lt;y;j++)&#123; int max_value=dp[i][j-1]&gt;dp[i-1][j]?dp[i][j-1]:dp[i-1][j]; dp[i][j]=a[i][j]+max_value; &#125;*/ for(int i=1;i&lt;x;i++) a[i][0]=a[i-1][0]+a[i][0]; for(int i=1;i&lt;y;i++) a[0][i]=a[0][i-1]+a[0][i]; for(int i=1;i&lt;x;i++) for(int j=1;j&lt;y;j++)&#123; int max_value=a[i][j-1]&gt;a[i-1][j]?a[i][j-1]:a[i-1][j]; a[i][j]+=max_value; &#125; return;&#125;*/int main()&#123; memset(dp,0,sizeof(dp)); //m、n代表格子的数目，在本例中&lt;=100 cin&gt;&gt;m&gt;&gt;n; for(int i=0;i&lt;m;i++) for(int j=0;j&lt;n;j++) cin&gt;&gt;a[i][j]; dp_fun(0,0); for(int i=0;i&lt;m;i++) &#123; for(int j=0;j&lt;n;j++) cout&lt;&lt;dp[i][j]&lt;&lt;"\t"; cout&lt;&lt;endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java操作Ini文件]]></title>
    <url>%2F2016%2F04%2F25%2Fjava-iniFile%2F</url>
    <content type="text"><![CDATA[这个问题最开始是一个朋友面试时面试官让他解决的问题，他拿来请教我，我正好借此机会了解了下这种数据、配置存储文件。 ini 文件是Initialization File的缩写，即初始化文件，是windows的系统配置文件所采用的存储格式，统管windows的各项配置，一般用户就用windows提供的各项图形化管理界面就可实现相同的配置了。但在某些情况，还是要直接编辑ini才方便，一般只有很熟悉windows才能去直接编辑。开始时用于WIN3X下面，WIN95用注册表代替，以及后面的内容表示一个节，相当于注册表中的键。 具体FormatINI文件由节（Section）、参数Item：键（key）、值（value）组成。 data 1234[section name]参数（键=值）name=value 注解 注解使用分号表示（;）。在分号后面的文字，直到该行结尾都全部为注解。123; comment textINI文件的数据格式的例子（配置文件的内容） [Section1 Name]KeyName1=value1KeyName2=value2 因为INI文件可能是项目中共用的，所以使用[Section Name]段名来区分不同用途的参数区。 Java操作在常规的WIn平台下，ini文件的默认编码格式是ANSI。 不同的国家和地区制定了不同的标准，由此产生了 GB2312、GBK、GB18030、Big5、Shift_JIS 等各自的编码标准。这些使用多个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码。在简体中文Windows操作系统中，ANSI 编码代表 GBK 编码；在繁体中文Windows操作系统中，ANSI编码代表Big5；在日文Windows操作系统中，ANSI 编码代表 Shift_JIS 编码。不同 ANSI 编码之间互不兼容，当信息在国际间交流时，无法将属于两种语言的文字，存储在同一段 ANSI 编码的文本中。 ANSI在我们国内的具体编码实现实际上是GB2312（或GBK），所以我们对这种格式的文本数据进行操作即可。 Java INI Package (JavaINI) 是一个 Java 语言用来读写 INI 文件的工具包.Project Location，以下称为Ini开源包. Ini开源包默认的编码格式是ASCII，也就是默认只操作范围内的128个字符，这会大大限制Ini开源包的功能。通过修改org.dtools.ini包的IniFileWriter类改属性值ENCODING，修改成适合我们的编码。GB2312、GBK在国内使用，因为win平台建立的ini文件默认就是ANSI编码，所以推荐修改为这两种编码格式。如果想要国际化，则可将ENCODING修改为UTF-8即可。 读操作 123456789101112131415161718IniFile ini = new BasicIniFile(false);//不使用大小写敏感public void readContent()&#123; IniFileReader reader = new IniFileReader(ini, file); try &#123; reader.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; //获取ini文件的所有Section for(int i=0;i&lt;ini.getNumberOfSections();i++)&#123; IniSection sec = ini.getSection(i); //获取每个Section的Item System.out.println("---- " + sec.getName() + " ----"); for(IniItem item : sec.getItems())&#123; System.out.println(item.getName() + " = " + item.getValue()); &#125; &#125; &#125; 写操作 123456789101112131415161718192021222324252627public void writeContent()&#123; //创建一个数据Section，在本例中Section名为 config IniSection dataSection = new BasicIniSection( "config" ); ini.addSection( dataSection ); //在上面的Section中添加Item，包括name、sex、age IniItem nameItem = new IniItem( "name" ); nameItem.setValue("clinjie"); dataSection.addItem( nameItem ); IniItem ageItem = new IniItem( "age" ); ageItem.setValue("999999"); dataSection.addItem( ageItem ); IniItem sexItem = new IniItem( "sex" ); sexItem.setValue("男"); dataSection.addItem( sexItem ); //将数据写入到磁盘 IniFileWriter writer=new IniFileWriter(ini, file); try &#123; writer.write(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP介绍-最长递增子序列]]></title>
    <url>%2F2016%2F04%2F23%2FDP-intro-001%2F</url>
    <content type="text"><![CDATA[最长递增子序列系列是DP动态规划中简单、经典的入门题目。类似最长非递减子序列、导弹拦截问题、最长公共子序列问题等等。这在我们逐渐了解、认知动态规划的过程中可以给我们提高很大的帮助。 设有由n个不相同的整数组成的数列，记为:a[0]、a[1]、……、a[n-1]且a(i)&lt;&gt;a(j) (i&lt;&gt;j) 例如{2,3,4,5,6,343,5,36,45,64,56,564} 若存在i1&lt;i2&lt;i3&lt; … &lt; ie 且有a[i1]&lt;a[i2]&lt; … &lt;a[ie]则称为长度为e的递增子序列序列。如上例中3，18，23，24就是一个长度为4的递增序列，同时也有3，7，10，12，16，24长度为6的递增序列 问题的引出与思路要解决这个问题，按我们正常人的习惯性思维没我们往往会通过在下标从小到大逐渐增加，一步步的计算前n个数值（子数组，子序列最后的一个数值必须是a[n-1]）中的最长递增子序列，所以前n数值最长子序列未必会比前n-1最长子序列结果要大，这是需要我们注意的。 换句话说。我们需要在前n-1个数值中循环找出比第n个数值小、且成递增规律的序列。假如当前的数值比上个子序列的最后一个数值都要大，那么就可以直接在上个子问题结果的基础上加1。当然，这不是要我们局限于紧邻的上个子问题，而是前面所有子问题都要对比，然后将这些结果再取最大值。实际上，值已经引出了状态转移方程。 显然，这些子问题相互重叠、每次的结果都会影响下一个子数组结果，但是前面子数组的结果不会在改变。 现在想想上篇文章DP动态规划简介中提出的DP动态规划的三大条件： 最优化原理（最优子结构性质） 最优化原理可这样阐述：一个最优化策略具有这样的性质，不论过去状态和决策如何，对前面的决策所形成的状态而言，余下的诸决策必须构成最优策略。简而言之，一个最优化策略的子策略总是最优的。一个问题满足最优化原理又称其具有最优子结构性质。 无后效性 将各阶段按照一定的次序排列好之后，对于某个给定的阶段状态，它以前各阶段的状态无法直接影响它未来的决策，而只能通过当前的这个状态。换句话说，每个状态都是过去历史的一个完整总结。这就是无后向性，又称为无后效性。 子问题的重叠性 动态规划将原来具有指数级时间复杂度的搜索算法改进成了具有多项式时间复杂度的算法。其中的关键在于解决冗余，这是动态规划算法的根本目的。动态规划实质上是一种以空间换时间的技术，它在实现的过程中，不得不存储产生过程中的各种状态，所以它的空间复杂度要大于其它的算法。 在这个问题中都得到了完善的支撑，而且这个思想也很适合解决这个系列的问题，高效、简便。 解决过程我们使用一些列变量记录前n个子序列的结果。再具体的实现中，我们通常使用数组数据结构记录。数组opt[length]中opt[i]记录原始数据中前i+1个数值（子数组）的最长递增子序列长度数值。 就以前面seq={2,3,4,5,6,343,5,36,45,64,56,564}提过的数据来看： opt[0]: opt[0]代表的是原始数据中前1个数值的最长递增长度值，只有一个数值，显然seq[0]=2就是目前这个子问题的path，opt[0]=1。用上篇文章提到的术语，当前子问题的状态就是opt[0]=1 opt[1]: opt[1]代表的是原始数据中前2个数值的最长递增长度值，seq[1]&gt;seq[0]，所以根据前面托出的状态转移方程，可以得出opt[1]=opt[0]+1=2. opt[2]: opt[2]代表的是原始数据中前3个数值的最长递增长度值，seq[2]&gt;seq[1]，由于前面序列的连续递增，所以根据前面托出的状态转移方程，可以得出opt[2]=opt[1]+1=3. opt[3]: opt[3]代表的是原始数据中前4个数值的最长递增长度值，seq[3]&gt;seq[2]，由于前面序列的连续递增，所以根据前面托出的状态转移方程，可以得出opt[3]=opt[2]+1=4. opt[4]: opt[4]代表的是原始数据中前5个数值的最长递增长度值，seq[4]&gt;seq[3]，由于前面序列的连续递增，所以根据前面托出的状态转移方程，可以得出opt[4]=opt[3]+1=5. opt[5]: opt[5]代表的是原始数据中前6个数值的最长递增长度值，seq[5]&gt;seq[4]，由于前面序列的连续递增，所以根据前面托出的状态转移方程，可以得出opt[5]=opt[4]+1=6. opt[6]: opt[6]代表的是原始数据中前7个数值的最长递增长度值，seq[6]&lt;seq[5]，突如其来的变化让我们突然没了思绪。跳过seq[5]怎么样？seq[6]&lt;seq[4]，不行，再跳过直接到seq[2]，现在因为seq[6]&gt;seq[2]，由于前面序列的连续递增，根据前面托出的状态转移方程，可以得出opt[6]=opt[2]+1=4.这些逻辑很容易理解。但是如果前面的数据源并不是连续递增的，我们还是应该老老实实的遍历、比照大小得出结果。 实现1234567891011121314151617181920212223242526272829303132333435int main()&#123; int seq[] = &#123;2,3,4,5,6,343,5,36,45,64,56,564&#125;; const int length=sizeof(seq)/sizeof(int); int opt[length]=&#123;0&#125;; int path[length]=&#123;0&#125;; int i, j, maxa = 0,maxb=0; for(i=0; i&lt;length; i++) opt[i] = 1; //计算子序列状态，path是为了还原最长子序列的辅助数组 for(i=1;i&lt;length;i++) for(j=0;j&lt;i;j++) if(seq[i]&gt;seq[j]&amp;&amp;opt[j]+1&gt;opt[i]) &#123; opt[i]=opt[j]+1; path[i]=j; &#125; for(i=0;i&lt;length;i++) if(maxa&lt;opt[i])&#123; maxa=opt[i]; maxb=i; &#125; //还原递增最长子序列 for(j=0,i=maxb;i&gt;=0;)&#123; opt[maxa-1-j]=seq[i]; i=path[i]; if(++j==maxa)break; &#125; for(i=0;i&lt;maxa;i++) cout&lt;&lt;opt[i]&lt;&lt;' '; return 0;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP介绍]]></title>
    <url>%2F2016%2F04%2F22%2FDP-intro%2F</url>
    <content type="text"><![CDATA[动态规划(dynamic programming)是运筹学的一个分支，是求解决策过程(decision process)最优化的数学方法。20世纪50年代初美国数学家R.E.Bellman等人在研究多阶段决策过程(multistep decision process)的优化问题时，提出了著名的最优化原理(principle of optimality)，把多阶段过程转化为一系列单阶段问题，利用各阶段之间的关系，逐个求解，创立了解决这类过程优化问题的新方法——动态规划 动态规划算法通常基于一个递推公式和n个初始状态。当前子问题的解将由前子问题的解推出。使用动态规划来解题只需要多项式时间复杂度。 基本思想动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。与分治法类似，基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。 与分治法不同的是，适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的。若用分治法来解这类问题，则分解得到的子问题数目太多，有些子问题被重复计算了很多次。如果我们能够保存已解决的子问题的答案，而在需要时再找出已求得的答案，这样就可以避免大量的重复计算。可以用一个表来记录所有已解的子问题的答案。不管该子问题以后是否被用到，只要它被计算过，就将结果记录下来，方便之后使用。这就是动态规划法的基本思路。 动态规划程序设计是对解最优化问题的一种途径、一种方法，而不是一种特殊算法。不像搜索或数值计算那样，具有一个标准的数学表达式和明确清晰的解题方法。动态规划程序设计往往是针对一种最优化问题，由于各种问题的性质不同，确定最优解的条件也互不相同，因而动态规划的设计方法对不同的问题，有各具特色的解题方法，而不存在一种万能的动态规划算法，可以解决各类最优化问题。 适用条件 最优化原理（最优子结构性质） 最优化原理可这样阐述：一个最优化策略具有这样的性质，不论过去状态和决策如何，对前面的决策所形成的状态而言，余下的诸决策必须构成最优策略。简而言之，一个最优化策略的子策略总是最优的。一个问题满足最优化原理又称其具有最优子结构性质。 无后效性 将各阶段按照一定的次序排列好之后，对于某个给定的阶段状态，它以前各阶段的状态无法直接影响它未来的决策，而只能通过当前的这个状态。换句话说，每个状态都是过去历史的一个完整总结。这就是无后向性，又称为无后效性。 子问题的重叠性 动态规划将原来具有指数级时间复杂度的搜索算法改进成了具有多项式时间复杂度的算法。其中的关键在于解决冗余，这是动态规划算法的根本目的。动态规划实质上是一种以空间换时间的技术，它在实现的过程中，不得不存储产生过程中的各种状态，所以它的空间复杂度要大于其它的算法。 经典问题 有面值为1元、3元和5元的硬币若干枚，如何用最少的硬币凑够x元？ 我们最先想到的算法一般是贪婪算法，每次减去能够减掉的最大数值，最后得出结果。 当然这在上面问题这种问题上是成立的，因为有面值是基数1元，这显然不能代表普遍性。当提供的面值是2、3、5时，要求x=11，我们发现直接粗暴地套用贪婪原理并不奏效，x-5-5=1，此时无法进行下一步，需要提供回溯。 所以说，在有些时候这类问题可以通过贪婪算法解决，但是大部分情况，我们无法直接获得想要的结果。 很明显，这个问题可以分解为: 求解凑齐x-1数值的硬币枚数+1 求解凑齐x-3数值的硬币枚数+1 求解凑齐x-5数值的硬币枚数+1 最终的结果就是这三种情况的最小值，而这三种情况又可以继续分别分解。解决的路径跟递归很相似，但是相当容易套圈~ 所以我们开始尝试顺人类认知的从小数值递推到x. 现在我们在开始看上一部分DP适用条件 最优化原理 无后效性 子问题的重叠性 第一个条件显而易见的符合，第二个条件，当我们求出x-1、x-3、x-5这些结果之后，这些步骤的最终结果只是为了能够得到x的最优解，求解之后跟x+1、x+3后续再无瓜葛，这就符合了无后效性。第三个条件，从我开始分解这道问题的时候就能够得出结论。 解决术语介绍按照DP的知识，有下面几个重要的术语： 阶段：把所给求解问题的过程恰当地分成若干个相互联系的阶段，以便于求解，过程不同，阶段数就可能不同．描述阶段的变量称为阶段变量。在多数情况下，阶段变量是离散的，用k表示。此外，也有阶段变量是连续的情形。如果过程可以在任何时刻作出决策，且在任意两个不同的时刻之间允许有无穷多个决策时，阶段变量就是连续的 状态：状态表示每个阶段开始面临的自然状况或客观条件，它不以人们的主观意志为转移，也称为不可控因素。在上面的例子中状态就是某阶段的出发位置，它既是该阶段某路的起点，同时又是前一阶段某支路的终点。 决策：一个阶段的状态给定以后，从该状态演变到下一阶段某个状态的一种选择（行动）称为决策。在最优控制中，也称为控制。在许多问题中，决策可以自然而然地表示为一个数或一组数。不同的决策对应着不同的数值。描述决策的变量称决策变量，因状态满足无后效性，故在每个阶段选择决策时只需考虑当前的状态而无须考虑过程的历史。决策变量的范围称为允许决策集合 策略：由每个阶段的决策组成的序列称为策略。对于每一个实际的多阶段决策过程，可供选取的策略有一定的范围限制，这个范围称为允许策略集合。允许策略集合中达到最优效果的策略称为最优策略。 状态转移方程：给定k阶段状态变量x(k)的值后，如果这一阶段的决策变量一经确定，第k+1阶段的状态变量x(k+1)也就完全确定，即x(k+1)的值随x(k)和第k阶段的决策u(k)的值变化而变化，那么可以把这一关系看成(x(k)，u(k))与x(k+1)确定的对应关系，用x(k+1)=Tk(x(k),u(k))表示。这是从k阶段到k+1阶段的状态转移规律，也就是状态转移方程。 状态上面在Encyclopedia上提到的解读可能比较抽象，状态就是问题分解得到子问题的当前解。 具体到这个例子，就是当x=[0、1、2、3、4、5、6、7、8、9、...x-1、x]这些问题的解。 我们通过基础的数据结构数组S表示子问题解，也就是原来问题的状态。 s[0] 求解需要多少枚硬币可以凑齐0元，显然，s[0]=0 s[1] 需要多少枚硬币可以凑齐1元，s[1]=1，需要1枚1元硬币 s[2] 需要多少枚硬币可以凑齐2元，s[2]=s[2-1]+1=s[1]+1=2。需要上面子问题状态再加上1枚1元硬币 s[3] 需要多少枚硬币可以凑齐3元，此时的情况就比较复杂了。我们有两种选择，当然是基于原来的状态求出。 以s[2]的状态基础在加一枚1元硬币。s[3]=s[3-1]+1 以s[0]的状态再加一枚3元硬币。s[3]=s[3-3]+1 现在的问题就是如何确定所有选择。从前面的疾苦==记录可以看出，我都是有意识的在下标上做文章，故意将s[0]===s[3-3]，这就是关键。每次我们获取当前状态，不是要从紧邻的上一个状态递推，而是根据提供给我们的硬币数值得到可能凑到当前数值的情况。 2元再加一枚1元硬币是如此，0元再加一枚3元硬币也是如此。当要求解s[5]的时候情况更加多变。候选变成了[s[4]+1,s[2]+1,s[0]+1]。每个子问题的求解都要尝试可能的求解路径状态。 4+1是一种情况，2+3、0+5是另外的情况。 那么s[3]的结果是哪一个呢，根据问题需要求解最小的硬币枚数，显然结果是Min(s[2]+1,s[0]+1)，是s[3]=1，需要1枚三元硬币 s[4] 需要多少枚硬币可以凑齐4元，s[4]=Min(s[3]+1,s[1]+1)，s[4]=2,需要一枚3元硬币的基础上再加一枚1元硬币。 上面在s[3]的求解过程中，实际上已经脱出了该问题的状态转移方程。 s[x]=Min(s[x-j]+1)，其中j是提供的硬币面值。 实现12345678x=input('plz input the value of x')s=np.arange(int(x))x_coins=(1,3,5)for item in range(1,x-1): for i in x_coins: if item&gt;=i and s[item-i]+1&lt;s[item]: s[item]=s[item-i]+1print(s)]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Sdk获取更新]]></title>
    <url>%2F2016%2F04%2F21%2Fandroid-sdk%2F</url>
    <content type="text"><![CDATA[最近好多朋友、同学陆陆续续开始了他们的毕设阶段，得益于国内蓬勃爆炸发展的移动终端产业，有相当一部分小伙伴们的课题都是基于android platform这个世界占比最大的开源移动操作系统app开发。他们也陆陆续续遇到了新的问题。 恰好我曾经作为初学者遇到过相同的问题，我将这些问题记录下来，希望可以分享我的知识、经验与见解。 Android SDK更新由于国内Google的IP受到GFW限制，所以无法通过唱过方法直接获取sdk更新，一般有两种办法。 Android SDK在线更新镜像服务器可以通过国内或者准许服务器的镜像获取更新，常用稳定的镜像有下面： 南阳理工学院镜像服务器地址: mirror.nyist.edu.cn 端口：80 中国科学院开源协会镜像站地址: 12345IPV4/IPV6: mirrors.opencas.cn 端口：80IPV4/IPV6: mirrors.opencas.org 端口：80IPV4/IPV6: mirrors.opencas.ac.cn 端口：80 上海GDG镜像服务器地址: sdk.gdgshanghai.com 端口：8000 北京化工大学镜像服务器地址: 12345IPv4: ubuntu.buct.edu.cn/ 端口：80IPv4: ubuntu.buct.cn/ 端口：80IPv6: ubuntu.buct6.edu.cn/ 端口：80 大连东软信息学院镜像服务器地址: mirrors.neusoft.edu.cn 端口：80 腾讯Bugly 镜像: android-mirror.bugly.qq.com 端口：8080 tips: 腾讯镜像使用方法:http://android-mirror.bugly.qq.com:8080/include/usage.html 温馨提示，注意选择合适的版本更新~使用方法 启动 Android SDK Manager ，打开主界面，依次选择『Tools』、『Options…』，弹出『Android SDK Manager - Settings』窗口； 在『Android SDK Manager - Settings』窗口中，在『HTTP Proxy Server』和『HTTP Proxy Port』输入框内填入上面镜像服务器地址(不包含http://，如下图)和端口，并且选中『Force https://… sources to be fetched using http://...』复选框。设置完成后单击『Close』按钮关闭『Android SDK Manager - Settings』窗口返回到主界面； 依次选择『Packages』、『Reload』。 直接下载离线包一种更轻松的方法就是下载正确版本的离线包，首先明确开发的程序在哪一个Level（可以直接换算成android版本，如4.4、5.1），下载对应的文件，复制到本地sdk manager设置的目录位置。 直接下载带sdk的IDEGoogle公司官方推出的Android平台开发环境Android Studio是一款相当棒的开发软件，我平时使用的开发环境就是AS，相比Eclipse，他可以显著提高我的工作效率、学习进程。同时，因为Google已经宣布了不再对Eclipse进行Plugins更新维护，AS将会是以后的Android开发趋势。 这里直接提供当前最新的一次稳定版更新： Win平台AS2.0稳定版 戳我 AS的一次Relase包括两种形式： 带最新SDK版本 纯IDE 想要使用最新的SDK可以下载附带最新SDK的IDE. 一些你会用到的Docs Android Api中文版 Android Api-zh Android API指南中文版 Gudie-zh]]></content>
      <categories>
        <category>android</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[宅福利-Tumblr]]></title>
    <url>%2F2016%2F04%2F20%2Ftumblr%2F</url>
    <content type="text"><![CDATA[本篇文章是洗白种子文件的兄弟篇，也是为了安利一个宅男宅女极好的网站–汤不热. Tumblr（中文名：汤博乐）成立于2007年，是目前全球最大的轻博客网站，也是轻博客网站的始祖。Tumblr（汤博乐）是一种介于传统博客和微博之间的全新媒体形态，既注重表达，又注重社交，而且注重个性化设置，成为当前最受年轻人欢迎的社交网站之一。雅虎公司董事会2013年5月19日决定，以11亿美元收购Tumblr。 tumblr是纯粹基于兴趣的社交网站，产品形态好用只是一个方面，更重要的是，可以只关注自己感兴趣的人和博客，而且不必为了维持真实好友关系和自己被期望的网络形象而去做一些自己不想做的事（比如逃避家长监控） 好了，不装x，目前国内青年使用Tumblr频率最高的动机不是为了寻觅上面叹为观止的写真、艺术创造，而是为了解决青春期荷尔蒙沉淀过多问题。Tumblr上面有大量的喜闻乐见的po主，他们经常更新自己的站点，包括一颗赛艇的pic和video。而且，最重要的，到目前为止，GFW还没有明确的将网站放到黑名单… 当你有了Tumblr博主账号之后，你可以轻松的访问获取他发布的每一条资源分享。然而可能因为服务器的缘故，国内请求受限，速度很慢，好吧，编程改变世界.| 12345678910111213141516171819202122232425262728293031323334353637import reimport requestsfrom lxml import etreeRes=set()Res1=set()blogname=input('plz input the username:')def func(keys): dom=etree.HTML(requests.get('http://'+blogname+'.tumblr.com/').text) title=(dom.xpath('//title/text()'))[0] global outputfile outputfile= open(title+'-result.txt','w') for key in keys: baseurl = 'http://'+blogname.strip()+'.tumblr.com/api/read?type='+key+'&amp;num=50&amp;start=' #pic start = 0 #start from num zero while True: url = baseurl + str(start) pagecontent = requests.get(url).text if key=='photo': result=re.findall('&lt;photo-url .*?&gt;(.*?)&lt;/photo-url&gt;',pagecontent) for item in result: Res.add(item) else: result=re.findall('source src="(.*?)"',pagecontent) for item in result: Res1.add(item) if (len(result) &lt; 50): break else: start += 50func(('video','photo'))if Res: for item in Res: outputfile.writelines(item+'\n')if Res1: for item in Res1: outputfile.writelines(item+'\n')outputfile.close() 运行上面的代码，输入正确的站主name，就可以在当前目录下的result.txt文件写入所有的pic和video。 听过实验，pic会有很多的重复内容，因为会返回原图的不同尺寸url，这里我没有对他进行排重获取高分辨率，因为我懒。 下载戳我]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[verilog过程块与赋值]]></title>
    <url>%2F2016%2F04%2F18%2Fverilog-setvalue%2F</url>
    <content type="text"><![CDATA[过程块 always过程块 模板： 12345678always @(&lt;敏感信号表达式&gt;)begin //过程赋值 //if语句 //case语句 //while、repeat、for语句 //task、function调用end 当敏感信号表达式的值改变时候，就执行一遍块内语句。同时always过程块是不能够嵌套使用的。 关键字posedge与negedge关键字分别是上升沿以及下降沿 例如：同步时序电路的时钟信号为clk，clear为异步清零信号。敏感信号可写为： 12345//上升沿触发，高电平清0有效always @(posedge clk or posedge clear)//上升沿触发，低电平清0有效always @(posedge clk or negedge clear) 例如当negedge clear表示当clear==0时 1234567always @(posedge clk or negedge clear) begin if(!clear)//当clear==0时候，always会由事件驱动 qout=0; else qout=in; end initial过程块 initial模板： 123456initialbegin 语句1； 语句2； ......end 对变量和存贮器初始化 123456initialbegin reg1=0; for(addr=0;addr&lt;size;addr=addr+1) memory[addr]=0;end initial语句主要面向功能模拟，通常不具有可综合性。 模拟0时刻开始执行，只执行一次 同一模块内的多个initial过程块，模拟0时刻开始并行执行。 initial与always语句一样，是不能嵌套使用的。即在initial语句中不能再次嵌套initial语句块。 连续赋值用连续赋值语句表达的是： assign val=newval; 任何一个输入的改变都将立即导致输出更新； 12345module orand(out,a,b,c,d,e); input a,b,c,d,e; output out; assign out=3&amp;(a|b)&amp;(c|d);endmodule 过程赋值语句过程赋值语句常用于对reg变量进行赋值。一般分为两种，阻塞赋值与非阻塞赋值 阻塞与非阻塞赋值赋值的类型选择取决于建模的逻辑类型。 在时序块的RTL代码中使用非阻塞赋值&lt;=。非阻塞赋值在块结束后才完成赋值操作。此赋值方式可以避免在仿真出现魔仙和竞争现象。 在组合的RTL代码中使用阻塞赋值=。使用阻塞赋值方式对一个变量进行赋值时，此变量的值在赋值语句执行完后才能之后就立即改变。 compare使用非阻塞赋值方式进行赋值时，各个赋值语句同步执行；因此通常在一个时钟沿对临时变量进行赋值，而在另一个时钟沿对其进行采样。因为在相同的时钟沿采样赋值，采样的还是原来的值，赋值操作是在块结束时进行。 阻塞赋值 下面模块会综合成为触发器 12345678910module block(clk,a,b);input clk,a;output b;reg b;always @(posedge clk) begin y=a; b=y; endendmodule 非阻塞赋值 下面的模块会综合成两个触发器 12345678910module block(clk,a,b);input clk,a;output b;reg b;always @(posedge clk) begin y&lt;=a; b&lt;=y; endendmodule 上图左侧是阻塞赋值的综合结果，右侧则为非阻塞赋值。相比左侧，右侧的例子会造成一个时钟周期的延迟。]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Xilinx的Synthesize]]></title>
    <url>%2F2016%2F04%2F18%2Fise-synthesize%2F</url>
    <content type="text"><![CDATA[所谓综合，就是讲HDL语言、原理图等设计输入翻译成由与、或、非们和RAM、触发器登记本逻辑单元的逻辑连接（即网表）。并根据目标和要求（约束条件）优化生成的逻辑连接。 ISE-XSTXST是Xilinx公司自己的综合（Synthsize）工具。当我们完成输入、仿真以及管脚分配之后就可以进行综合和实现。 双击Synthesize-XST，就可以完成综合。一般而言，会有三种结果： 仿真完成 Warn警告 ERROR错误 Warn会在Synthesize-XST出现黄色警示，而Error有红色标识。 综合完成之后可以通过使用XST的View RTLSchematics工具查看RTL级结构图。 Synthesize Proprtties [Optimization Goal]：优化的目标。该参数决定了综合工具对设计进行优化时，是以面积还是以速度作为优先原则。面积优先原则可以节省器件内部的逻辑资源，即尽可能地采用串行逻辑结构，但这是以牺牲速度为代价的。而速度优先原则保证了器件的整体工作速度，即尽可能地采用并行逻辑结构，但这样将会浪费器件内部大量的逻辑资源，因此，它是以牺牲逻辑资源为代价的。 [Optimization Effort]：优化器努力程度。这里有[normal]和[high]两种选择方式。对于[normal]，优化器对逻辑设计仅仅进行普通的优化处理，其结果可能并不是最好的，但是综合和优化流程执行地较快。如果选择[high]，优化器对逻辑设计进行反复的优化处理和分析，并能生成最理想的综合和优化结果，在对高性能和最终的设计通常采用这种模式；当然在综合和优化时，需要的时间较长。 [Use Synthesis Constraints File]：使用综合约束文件。如果选择了该选项，那么综合约束文件XCF有效。 [Synthesis Constraints File]：综合约束文件。该选项用于指定XST综合约束文件XCF的路径。 [Global Optimization Goal]：全局优化目标。可以选择的属性包括有[AllClockNets]、[Inpad To Outpad]、[Offest In Before]、[Offest Out After]、[Maximm Delay]。该参数仅对FPGA器件有效，可用于选择所设定的寄存器之间、输入引脚到寄存器之间、寄存器到输出引脚之间，或者是输入引脚到输出引脚之间逻辑的优化策略。 [Generate RTL Schematic]：生成寄存器传输级视图文件。该参数用于将综合结果生成RTL视图。 [Write Timing Constraints]：写时序约束。该参数仅对FPGA有效，用来设置是否将HDL源代码中用于控制综合的时序约束传给NGC网表文件，该文件用于布局和布线。 HDL语言选项 [FSM Encoding Algorithm]：有限状态机编码算法。该参数用于指定有限状态机的编码方式。选项有[Auto]、[One-Hot]、[Compact]、[Sequential]、[Gray]、[Johnson]、[User]、[Speed1]、[None]编码方式，默认为[Auto]编码方式。 [Safe Implementation]：将添加安全模式约束来实现有限状态机，将添加额外的逻辑将状态机从无效状态调转到有效状态，否则只能复位来实现，有[Yes]、[No]两种选择，默认为[No]。 [Case Implementation Sytle]：条件语句实现类型。该参数用于控制XST综合工具解释和推论Verilog的条件语句。其中选项有[None]、[Full]、[Parallel]、[Full-Parallel]，默认为[None]。 对于这四种选项，区别如下：（1）[None]，XST将保留程序中条件语句的原型，不进行任何处理；（2）[Full]，XST认为条件语句是完整的，避免锁存器的产生；（3）[Parallel]，XST认为在条件语句中不能产生分支，并且不使用优先级编码器；（4）[Full-Parallel]，XST认为条件语句是完整的，并且在内部没有分支，不使用锁存器和优先级编码器。 [RAM Extraction]：存储器扩展。该参数仅对FPGA有效，用于使能和禁止RAM宏接口。默认为允许使用RAM宏接口。 [RAM Style]：RAM实现类型。该参数仅对FPGA有效，用于选择是采用块RAM还是分布式RAM来作为RAM的实现类型。默认为 [Auto]。 [ROM Extraction]：只读存储器扩展。该参数仅对FPGA有效，用于使能和禁止只读存储器ROM宏接口。默认为允许使用ROM宏接口。 [ROM Style]：ROM实现类型。该参数仅对FPGA有效，用于选择是采用块RAM还是分布式RAM来作为ROM的实现和推论类型。默认为[Auto]。 [Mux Extraction]：多路复用器扩展。该参数用于使能和禁止多路复用器的宏接口。根据某些内定的算法，对于每个已识别的多路复用/选择器，XST能够创建一个宏，并进行逻辑的优化。可以选择[Yes]、[No]和[Force]中的任何一种，默认为[Yes]。 [Mux Style]：多路复用实现类型。该参数用于胃宏生成器选择实现和推论多路复用/选择器的宏类型。可以选择[Auto]、[MUXF]和[MUXCY]中的任何一种，默认为[Auto]。 [Decoder Extraction]：译码器扩展。该参数用于使能和禁止译码器宏接口，默认为允许使用该接口。 [Priority Encoder Extraction]：优先级译码器扩展。该参数用于指定是否使用带有优先级的编码器宏单元。 [Shift Register Extraction]：移位寄存器扩展。该参数仅对FPGA有效，用于指定是否使用移位寄存器宏单元。默认为使能。 [Logical Shifter Extraction]：逻辑移位寄存器扩展。该参数仅对FPGA有效，用于指定是否使用逻辑移位寄存器宏单元。默认为使能。 [XOR Collapsing]：异或逻辑合并方式。该参数仅对FPGA有效，用于指定是否将级联的异或逻辑单元合并成一个大的异或宏逻辑结构。默认为使能。 [Resource Sharing]：资源共享。该参数用于指定在XST综合时，是否允许复用一些运算处理模块，如加法器、减法器、加/减法器和乘法器。默认为使能。如果综合工具的选择是以速度为优先原则的，那么就不考虑资源共享。 [Multiplier Style]：乘法器实现类型。该参数仅对FPGA有效，用于指定宏生成器使用乘法器宏单元的方式。选项有[Auto]、Block]、[LUT]和[Pipe_LUT]。默认为[Auto]。选择的乘法器实现类型和所选择的器件有关。 特殊选项Xilinx特殊选项用于将用户逻辑适配到Xilinx芯片的特殊结构中，不仅能节省资源，还能提高设计的工作频率 [Add I/O Buffers]：插入I/O缓冲器。该参数用于控制对所综合的模块是否自动插入I/O缓冲器。默认为自动插入。 [Max Fanout]：最大扇出数。该参数用于指定信号和网线的最大扇出数。这里扇出数的选择与设计的性能有直接的关系，需要用户合理选择。 [Register Duplication]：寄存器复制。该参数用于控制是否允许寄存器的复制。对于高扇出和时序不能满足要求的寄存器进行复制，可以减少缓冲器输出的数目以及逻辑级数，改变时序的某些特性，提高设计的工作频率。默认为允许寄存器复制。 [Equivalent Register Removal]：等效寄存器删除。该参数用于指定是否把寄存器传输级功能等效的寄存器删除，这样可以减少寄存器资源的使用。如果某个寄存器是用Xilinx的硬件原语指定的，那么就不会被删除。默认为使能。 [Register Balancing]：寄存器配平。该参数仅对FPGA有效，用于指定是否允许平衡寄存器。可选项有[No]、[Yes]、 [Forward]和[Backward]。采用寄存器配平技术，可以改善某些设计的时序条件。其中，[Forward]为前移寄存器配平，[Backward]为后移寄存器配平。采用寄存器配平后，所用到的寄存器数就会相应地增减。默认为寄存器不配平。 [Move First Flip-Flop Stage]：移动前级寄存器。该参数仅对FPGA有效，用于控制在进行寄存器配平时，是否允许移动前级寄存器。如果[Register Balancing]的设置为[No]，那么该参数的设置无效。 [Move Last Flip-Flop Stage]：移动后级寄存器。该参数仅对FPGA有效，用于控制在进行寄存器配平时，是否允许移动后级寄存器。如果[Register Balancing]的设置为[No]，那么该参数的设置无效。 [Pack I/O Registers into IOBs]：I/O寄存器置于输入输出块。该参数仅对FPGA有效，用于控制是否将逻辑设计中的寄存器用IOB内部寄存器实现。在Xilinx系列FPGA的IOB中分别有输入和输出寄存器。如果将设计中的第一级寄存器或最后一级寄存器用IOB内部寄存器实现，那么就可以缩短IO引脚到寄存器之间的路径，这通常可以缩短大约1~2ns的传输时延。默认为[Auto]。 [Slice Packing]：优化Slice结构。该参数仅对FPGA有效，用于控制是否将关键路径的查找表逻辑尽量配置在同一个Slice或者CLB模块中，由此来缩短LUT之间的布线。这一功能对于提高设计的工作频率、改善时序特性是非常有用的。 默认为允许优化Slice结构。 [Optimize Instantiated Primitives]：优化已例化的原语。该参数控制是否需要优化在HDL代码中已例化的原语。默认为不优化。 以上三个部分分别用于设置综合的全局目标和整体策略、HDL硬件语法规则以及Xilinx特有的结构属性。]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[雌雄同体]]></title>
    <url>%2F2016%2F04%2F17%2F22%2F</url>
    <content type="text"><![CDATA[春天是他最爱的季节当微风随意吹乱他的头发他并不在意身边世界的吵杂只想著自己生命中的变化还有十五分钟才午休从早到晚没有想像中那么好过安定的日子不一定就是幸福忘不掉他在心里做过的梦他今年农历三月六号刚满二十二刚甩开课本要离开家看看这世界却发现许多烦恼要面对oh yeah他常会想望能回到那年他一十二只需要好好上学生活单纯没忧愁他就像一朵蓓蕾满怀希望秋天是忽然间就来临青春虽然有本钱可以洒脱一场恋爱二十二个月后结束才知道有些感情不值得赌九月天气还是有点热他想公车再不来就走一走路他开始明白等待未必有结果一个人也能走上梦的旅途他今年农历三月六号刚满二十二刚甩开课本要离开家看看这世界却发现许多烦恼要面对oh yeah他常会想望能回到那年他一十二只需要好好上学生活单纯没忧愁他一直满怀希望人生偶尔会走上一条陌路像是没有指标的地图别让他们说你该知足只有你知道什么是你的幸福他常会想望能回到那年他一十二只需要好好上学生活单纯没忧愁他笑著想过未来oh 他应该得到幸福如此的简单的梦有没有实现]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gray Code]]></title>
    <url>%2F2016%2F04%2F16%2FGray-code%2F</url>
    <content type="text"><![CDATA[The gray code is a binary numeral system where two successive values differ in only one bit. Given a non-negative integer n representing the total number of bits in the code, print the sequence of gray code. A gray code sequence must begin with 0. For example, given n = 2, return [0,1,3,2]. Its gray code sequence is: 123400 - 001 - 111 - 310 - 2 Note:For a given n, a gray code sequence is not uniquely defined. For example, [0,2,3,1] is also a valid gray code sequence according to the above definition. For now, the judge is able to judge based on one instance of gray code sequence. Sorry about that. 123456789public class Solution &#123; public List&lt;Integer&gt; grayCode(int n) &#123; List list=new LinkedList&lt;&gt;(); int length=1&lt;&lt;n; for(int i=0;i&lt;length;i++) list.add(i^(i&gt;&gt;1)); return list; &#125;&#125; 格雷码的是特点是：相邻两数的格雷码，仅仅有一位二进制发生变化。而且在其范围内的最小值和最大值，也仅仅有一位二进制发生变化。 1234567891011121314000^000--&gt;000001^000--&gt;001010^001--&gt;011011^001--&gt;010100^010--&gt;110101^010--&gt;111110^011--&gt;101111^011--&gt;100 每两个数字作为一组，每组之间都只会差一个数字，即最后一位，第一个是0，第二个是1.组内的两个数字与之异或的数字是相同的，所以保证了组内变换后两个数字一定会有差别，而且只会有一位差别. 组与组之间靠近的两个数字，后面一个将前面一个数字最右方连续的1全部置为0，然后在连续1前面一位置为1，而与他们异或的格式也很是类似。全都相对于本身右移一位，结果两两异或，数字相同的（1与1、0与0）结果为0，只在原本自身相对变化的两位出现交替，后面一个数字比前面一个数字在最前方多了一个1. 这样组内、组间都与前面数字差一位，保证了Gray Code的间隔都为1，而最大的数字与最小的数字也只差一位，因为异或的特性，使后面部分都变为了0. 递归生成码表 这种方法基于格雷码是反射码的事实，利用递归的如下规则来构造：1位格雷码有两个码字 (n+1)位格雷码中的前2n个码字等于n位格雷码的码字，按顺序书写，加前缀0 (n+1)位格雷码中的后2n个码字等于n位格雷码的码字，按逆序书写，加前缀1]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Router源代码架构--Filt_sink]]></title>
    <url>%2F2016%2F04%2F15%2Frouter-source-file-architecture-Filt_sink%2F</url>
    <content type="text"><![CDATA[Filt_sink源码结构 先来讲flit_sink，也就是汇聚节点（网关）的微片控制模块。整个大模块下分4个相对小的模块结构。 chi-rtr_channel_input 接收端信道接口 input channel interface gnt_ivc_arb 通用仲裁，指出哪一个虚拟信道 generic arbiter fb 微片缓冲 flit buffer fco 发送端的流量控制接口 output port flow control chi 接收端信道接口 信道接口分管的模块比较多: link_activityq 活动链表队列寄存器 flit_dataq 微片数据队列寄存器 flit_validq 微片验证寄存器 flit_ctrlq 微片控制信号队列寄存器 flit_sel_out_ivc_dec indicate which VC the current flit (if any) belongs to，指明目前的微片属于哪个虚拟信道。从one-hot编码转换成二进制 flit_headq 头微片队列寄存器 flit_head_out_sel 指明头微片 flit_ctrq 微片数目队列计算器 flit_counter flit_tail_out_sel 指明尾微片 gnt_ivc_arb仲裁最后获取的是仲裁的虚拟信道结果 gnt_lod leading one detector前导1检测方法 rr_arb 轮询调度仲裁 prefix_arb 基于轮询调度的前缀树 matrix_arb-c_matrix_arbiter 矩阵仲裁 flit buffer微片缓冲 微片缓冲是NoC Router接收端非常重要的一部分: has_tail_ivcq 指出哪个虚拟信道有尾微片 push_mask_dec 掩码压栈解码 tailq 尾微片队列寄存器 pop_mask_dec 掩码出栈解码 pop_tail_sel 尾微片选择 samqc controller for statically allocated multi-queue. 已分配的多静态队列的控制器 push_addr_sel 压栈地址选择 damqc 已分配的动态队列控制器 pop_addr_sel 出栈地址选择 empty_sel 空的虚拟信道选择 pop_dataq 数据寄存器出栈 read_addrq 读地址 bf buffer file 缓存的寄存器文件 pop_next_addr_sel 下个出栈的地址选择 fco输出端流控 发送端流量控制模块的下属模块很简洁，主要包括： cred_validq 信用验证 cred_vc_enc 虚拟信道信用编码 cred_vcq 虚拟信道信用]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Verilog的testbench笔记]]></title>
    <url>%2F2016%2F04%2F14%2Frouter-global-functions%2F</url>
    <content type="text"><![CDATA[记录下Router这个工程的几个全局函数. clogb12345678function integer clogb(input integer argument); integer i; begin clogb = 0; for(i = argument - 1; i &gt; 0; i = i &gt;&gt; 1) clogb = clogb + 1; endendfunction 函数的逻辑相当简单，计算二进制参数能够右移的数目，换算成十进制，就是计算能够除2多少次。这个逻辑大家都不回陌生，就是对数函数。以2为底的对数函数。 例如： res=clog(8) 参数为8，结果为3.显而易见，这个函数是典型的向上取整。 croot123456789101112131415function integer croot(input integer argument, input integer base); integer i; integer j; begin croot = 0; i = 0; while(i &lt; argument) begin croot = croot + 1; i = 1; for(j = 0; j &lt; base; j = j + 1) i = i * croot; end endendfunction 函数有两个参数，一个是传入的需要计算的参数argument，另外则是base基数。整个函数的逻辑就是base个croot相乘，看是否能够大于argument。croot逐次增加，直到满足要求。同样的，函数也是向上取整 argument:10~16 base:2 croot=4 argument:9~27 base:3 croot=3 显然，函数的逻辑是将argument开base根. pop_count12345678function integer pop_count(input integer argument); integer i; begin pop_count = 0; for(i = argument; i &gt; 0; i = i &gt;&gt; 1) pop_count = pop_count + (i &amp; 1); endendfunction 判断参数最低位是否为1，然后将参数右移，继续判断，判定正确则加1. 1234567891011121314151:12:13:24:15:26:27:38:19:210:211:312:213:314:315:4 suffix_length1234567891011121314function integer suffix_length(input integer value1, input integer value2); integer v1, v2; begin v1 = value1; v2 = value2; suffix_length = 0; while(v1 != v2) begin suffix_length = suffix_length + 1; v1 = v1 &gt;&gt; 1; v2 = v2 &gt;&gt; 1; end endendfunction 计算两个传入的参数从最低位开始到最高位有多少位数不相同。]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Verilog的testbench笔记]]></title>
    <url>%2F2016%2F04%2F13%2Fverilog-testbench-note%2F</url>
    <content type="text"><![CDATA[并行块在测试中经常会用到 fork...join块。使用并行块能表示以同一个时间起点算起的多个时间的运行，并行的执行复杂的过程结构，如循环或任务。 eg 1234567891011module inilne_tb;reg [7:0] data_bus; initial fork data_bus=8'b00; #10 data_bus=8'h45; //以下的两个repeat开始执行时间不同，但可以并行同时执行 #20 repeat(10) #10 data_bus=data_bus+1; #25 repeat(5) #20 data_bus=data_bus&lt;&lt;1; #140 data_bus=8'h0f; joinendmodule 0时刻对data_bus赋初始值 10个单位时间之后对data_bus重新赋值 从20单位时间开始，每10个单位时间数据自加 从25单位时间开始，没20个单位时间数据左移，与上一条指令并行执行 140单位时间再赋值 建立时钟虽然有时候在设计中会包含时钟，但时钟通常在测试模块中。可以使用门级和行为级建立时钟模型。行为描述一般使用的人较多。 简单的对称方波12345reg clk;always begin #peroid/2 clk=0; #peroid/2 clk=1;end 简单带延迟的对称方波时钟1234567reg clk;initial begin clk=0; #(peroid) forever #(peroid/2) clk=!clk;end 不规则形123456789reg clk;initial begin #(peroid+1) clk=1; #(peroid/2-1) forever begin #(peroid/4) clk=0; #(3*peroid/4) clk=1; endend 将会产生一个带延迟的，占空比不为1，同时投脉冲不规则的时钟。 Verilog高级结构task一般用于编写测试模块或者行为描述的模块。其中可以包含时间控制（如： #delays,@,wait）；也可以包含input、output、inout端口定义和参数；同时也可以调用其他任务或函数。 1234567891011121314151617181920212223module bus_ctrl_tb; reg[7:0] data; reg data_valid,data_rd; cpu ul(data_valid,data,data_in); initial begin //在模块中调用task cpu_driver(8'b0000_0000) cpu_driver(8'b0000_0000) cpu_driver(8'b0000_0000) end //定义task task cpu_driver; input [7:0] data_in; begin #30 data_valid=1; wait(data_rd==1); #20 data=data_in; wait(data_rd==0); #20 data=8'hzz; #30 data_valid=0; end endtaskendmodule 在测试模块中使用任务可以提高程序代码的效率，可以用任务把多次重复的操作包装起来。 同时要注意的是，模块的任务中，用于定时控制的信号，例如clk绝对不能作为任务的输入。因为输入值只想任务内部传递第一次，而定时控制一般来讲绝对不止一次传递控制。 不要在程序的不同部分同时调用一个任务。这是因为任务只有一组本地变量，同一时刻调用两次相同的任务将会导致错误。这种情况同时发生在使用定时控制的任务中。 123456789101112parameter MAX_BITS=8;reg[MAX_BITS:1] D;task reverse_bits;//双向总线端口被当做寄存器类型inout [7:0] data;integer K; for(K=0;K&lt;MAX_BITS;K=K+1) reverse_bits[MAX_BITS-(K+1)]=data[K];endtaskalways @ (posedge clk) reverse_bits(D); 上面的代码可以看出，在task定义过程中，有直接使用reverse_bits[MAX_BITS-(K+1)]=data[K];，也就是说，在Verilog中与函数一样，task、function调用都是直接将参数代替函数名直接改变。上面的调用 reverse_bits(D)等价于: 1234inout [7:0] data;integer K; for(K=0;K&lt;MAX_BITS;K=K+1) D[MAX_BITS-(K+1)]=data[K]; 任务只含有一个双向总线（inout）端口和一个内部变量，没有其他输入端口、输出端口和定时控制，没有引用模块变量。 在任务调用时候，任务的输入变量（端口）在任务内部被当做寄存器类型变量处理（D）。 123456789101112131415module mult(clk,a,b,out,en_mult); input clk,en_mult; input [3:0]a,b; output [7:0] out; reg[15:0] out; always @ (posedge clk) //任务调用 multme(a,b,out); task multme; input [3:0] xme,tome; output [7:0] result; wait(en_mult) result=xme*tome; endtaskendmodule 模块中定义的任务含有输入，输出，时间控制和一个内部变量，并且引用了一个本模块的变量。任务调用时候参数的顺序应该与任务定义声明的变量顺序相同。 function函数不能包含定时控制，但是可以在包含定时控制的过程块中调用函数。 在模块中，使用名为func的函数时，是将它作为名为func的寄存器类型变量来处理。 1234567891011121314module orand(a,b,c,d,e,out); input [&amp;;0] a,b,c,d,e; output[7:0] out; reg[7:0] out; always @(a,b,c,d,e); out=func(a,b,c,d,e); function [7:0] func; input [7:0] a,b,c,d,e; if(e==1) func=(a|b)&amp;(c|d); else func=0; endfunctionendmodule 不包含任何定时控制语句 至少一个输入，不能含有任何输出和总线口 只返回一个值，值的变量名与函数名同名，数据类型默认为reg 传递给函数的参数顺序与函数输入口声明的顺序相同 函数定义必须在模块定义内 函数不能调用任务（因为任务可能包含时间控制），反之可以 虽然函数只能返回一个值，但是他的返回值可以直接赋给一个由多个子信号拼购成的信号变量。{o1,o2,o3,o4}=func(a,b,c,d,e) 在函数定义时，如果在函数名之前定义了位宽，则函数就可以返回多bit构成的矢量。如果定义函数的语句比较多时，可以使用begin...end块。 函数名前面的位宽代表了返回值（一般就是以函数名为名的reg）的位宽。 若把函数定义为整型、实型或时间类型，就可以返回相应类型的数据。可以在任何类型的表达式中调用函数。 123456789101112131415module checksub(neg,in_a,in_b);output neg;input a,b;reg neg; function integer subtr; input [7:0] in_a,in_b; subtr=in_a-in_b; endfunctionalways @(a or b) begin if(subtr(a,b)&lt;0) neg=1; else neg=0; elseendmodule]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[太聪明]]></title>
    <url>%2F2016%2F04%2F12%2F%E5%A4%AA%E8%81%AA%E6%98%8E%2F</url>
    <content type="text"><![CDATA[总以为谜一般难懂的我在你了解了以后其实也没什么我总是忽冷又忽热隐藏我的感受只是怕爱你的心被你看透猜的没错想得太多不会有结果被你看穿了以后我更无处可躲我开始后悔不应该太聪明的卖弄只是怕亲手将我的真心葬送我猜着你的心要再一次确定遥远的距离都是因为太过聪明要猜着你的心要再一次确定混乱的思绪都是因为太想靠近你猜的没错想得太多不会有结果被你看穿了以后我更无处可躲我开始后悔不应该太聪明的卖弄只是怕亲手将我的真心葬送我猜着你的心要再一次确定遥远的距离都是因为太过聪明要猜着你的心要再一次确定混乱的思绪都是因为太想靠近你猜的没错想得太多不会有结果被你看穿了以后我更无处可躲我开始后悔不应该太聪明的卖弄只是怕亲手将我的真心葬送]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[testbench实例]]></title>
    <url>%2F2016%2F04%2F12%2Fverilog-testbench-001%2F</url>
    <content type="text"><![CDATA[本文介绍在ISE开发环境下，由两个16bit加法器构成的、可以完成4个16bit输入的18bit输出加法器。 IP核IP Core就是预先设计好、经过严格测试和优化过的电路功能模块，如乘法器、FIR滤波器、PCI接口等，并且一般采用参数可配置的结构，方便用户根据实际情况来调用这些模块。随着FPGA规模的增加，使用IP core完成设计成为发展趋势。 IP Core生成器（Core Generator）是Xilinx FPGA设计中的一个重要设计工具，提供了大量成熟的、高效的IP Core为用户所用，涵盖了汽车工业、基本单元、通信和网络、数字信号处理、FPGA特点和设计、数学函数、记忆和存储单元、标准总线接口等8大类。 IP核生成器的使用在这里，我们使用ISE提供的IP Core生成器创建3个加法器IP Core。包含2个16bit 2输入加法器与1个17bit 2输入加法器。 点击工程器件，右键新建源文件。选择IP Core，填写基本信息后，在IP Core目录中选择Math Function-&gt;Adders Subtracter 填写基本的IP Core属性。16bit输入的加法器，输出时17bit；同理17bit输入、输出时18bit。 IP Core在综合时被认为是黑盒子，综合器不对IP Core做任何编译。IP Core的仿真主要是运用Core Generator的仿真模型来完成的，会自动生成扩展名为.v的源代码文件。设计人员只需要从该源文件中查看其端口声明，将其作为一个普通的子程序进行调用即可。 逻辑生成1234567891011121314151617181920212223242526272829`timescale 1ns / 1psmodule add( input clk, input [15:0] a1, input [15:0] a2, input [15:0] b1, input [15:0] b2, output [17:0] c );wire [16:0] ab1,ab2;adder adder16_1( .a(a1), .b(a2), .s(ab1), .clk(clk)); adder adder16_2( .a(b1), .b(b2), .s(ab2), .clk(clk));adder17 adder7( .a(ab1), .b(ab2), .s(c), .clk(clk));endmodule 这里定义了两个wire类型变量存储16bit输入的加法器输出结果，同时作为17bit加法器的输入。 上图是RTL级结构。 TestBench文件编写1234567891011121314151617181920212223242526272829303132333435363738394041424344454647`timescale 1ns / 1psmodule ttt; // Inputs reg clk; reg [15:0] a1; reg [15:0] a2; reg [15:0] b1; reg [15:0] b2; // Outputs wire [17:0] c; // Instantiate the Unit Under Test (UUT) add uut ( .clk(clk), .a1(a1), .a2(a2), .b1(b1), .b2(b2), .c(c) ); initial begin // Initialize Inputs clk = 0; a1 = 0; a2 = 0; b1 = 0; b2 = 0; // Wait 100 ns for global reset to finish #100; // Add stimulus here forever begin #5; clk=~clk; if(clk==1)begin a1=a1+1; a2=a2+1; b1=b1+1; b2=b2+1; end end endendmodule 上面设置的激励规定了输入初始值全为0，同时每隔10ns，4个模块15bit变量输入值加1。在仿真中可以看到仿真结果，由于每一级都会产生一个时钟周期的延迟，最终会有2个时钟周期的延迟。 Tips要注意的是，在IP Core创建的时候，一定要确保所有输入端口都有用到。我刚开始生成的时候，多选择了C_in输入，导致在综合是由Warn提醒，同时在测试时，输出仿真失败，显示红色警告。18bit的输出结果最低2bit一直是xx.这里一定要注意。对于FPGA仿真而言，每一个值都应该有初始值设置。]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Verilog的testbench入门]]></title>
    <url>%2F2016%2F04%2F11%2Fverilog-testbench-intro%2F</url>
    <content type="text"><![CDATA[基础知识Test bench即Verilog需要编写的测试文件。在module设计完成、综合之后我们需要通过测试文件完成对设计module的测试。 Test bench大致分为下面三个部分: 时钟控制 clock control 一般采用always实现 实例化instantiate要测试的module 对实例的输入赋值 与待测模块的接口: 与输出端口相连接的变量定义为reg 与输出端口相连的定义为wire 初始化变量Verilog中使用initialblock初始化变量。 时钟的产生always # 10 clk=~clk; 产生时钟 initial repeat(13) #5 clk=~clk 控制只产生13个时钟 同步数据initial forever @ (posedge clk) #3 x=$random; 为了降低多个输入同时翻转的概率，对时序电路的输入一般采用素数作为时间间隔 随机数据initial repeat(5) #7 x=$random; a=$random%60; //产生-59到59之间的随机数 a={$random}%60; //产生0到59之间的随机数 产生随机事件间隔1234always begin t=$random #(t) x=$random; end 数据缓存123initial buffer = 16'b1110_0001_1011_0101;//将测试数据进行初始化always@(posedge clk) #1 &#123;x,buffer&#125;=&#123;buffer,x&#125;//可以在控制的数据下输入信号x 读取数据文件123reg [7:0] mem1[0:1024];//定义一个1KB的存储initial begin $readmemh(data1.dat,mem1) 简单的实例123456789101112131415161718192021222324252627282930313233343536`timescale 1ns / 10ps`include "adder.v"module test; // Inputs reg a,b; wire sum,count; // 实例化待测试模块 add uut ( .sum(sum), .c(count), .b(b), .a(a) ); initial begin // Initialize Inputs a=0; //没经过20个单位时间，a取反 forever #20 a=~a; end initial begin // Initialize Inputs b=0; //没经过10个单位时间，b取反 forever #10 b=~b; end initial begin //监控输出 $monitor()$time,,,"%d+%d=&#123;%d,%d&#125;",a,b,count,sum; #40 $stop; endendmodule Tip $monitor 出输出打印显示 $stop 停止当前仿真 ￥finish 结束仿真 时钟产生 使用initial语句 12345reg clock;initial begin clock=0; forever #10 clock=~clock;end 使用always语句 12345reg clock;initial clock=0;always #10 clock=~clock;]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Verilog中的timescale]]></title>
    <url>%2F2016%2F04%2F10%2Fverilog-timescale%2F</url>
    <content type="text"><![CDATA[在Verilog HDL 模型中，所有时延都用单位时间表述。使用`timescale编译器指令将时间单位与实际时间相关联。该指令用于定义时延的单位和时延精度。 `timescale编译器指令格式为： timescale time_unit / time_precision time_unit 单位时间 time_precision 时间精度 time_unit 和time_precision 由值1、10、和100以及单位s、ms、us、ns、ps和fs组成。 1234567`timescale 1ns/ 100ps module AndFunc (Z, A, B); output Z; input A, B; and # (5.22, 6.17 ) Al (Z, A, B); //规定了上升及下降时延值。 endmodule 编译器指令定义时延以ns为单位，并且时延精度为 0.1 ns（100 ps）。因此，时延值(#5.22)即代表5.22ns，5.22对应5.2 ns, 时延6.17对应6.2 ns。如果用如下的`timescale程序指令代替上例中的编译器指令, 1`timescale 10ns/1ns 则基础的时间单位为10ns，精度1ns。5.22代表52.2ns，固定到精度上就是52ns。同理，6.17转换为62ns。 在编译过程中，timescale指令影响这一编译器指令后面所有模块中的时延值，直至遇到另一timescale指令或resetall指令。当一个设计中的多个模块带有自身的`timescale编译指令时将发生什么？在这种情况下，模拟器总是定位在所有模块的最小时延精度上，并且所有时延都相应地换算为最小时延精度。 在verilog中是没有默认timescale的。一个没有指定timescale的verilog模块就有可能错误的继承了前面编译模块的无效timescale参数。所以在verilog的LRM中推荐在每个module的前面指定timescale,并且相 应的在最后加一个resetall来确保timescale的局部有效。]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ISE数字设计入门体验]]></title>
    <url>%2F2016%2F04%2F09%2FIse-wizard%2F</url>
    <content type="text"><![CDATA[ISE数字设计 一个典型的使用ISE设计的数字系统一般包含以下步骤: 工程的建立 模块设计 设计综合和查看综合结果 工程设计仿真 分频器的设计 用户约束的添加和设计是实现 布局布线结果查看 设计下载到FPGA芯片 PROM文件的生成和下载到PROM中 源文件类型 如上图，在添加新的源文件时候，会根据我们目的的不同选择文件类型。这些文件类型从上往下依次是： 块存储器映像文件 在线逻辑分析仪Chipscope定义和连接文件 实现约束文件 IP生成向导 存储器文件 原理图文件 用户文档文件 Verilog模块模板文件 Verilog测试平台模板文件 VHDL模块模板文件 VHDL库模板文件 VHDL包模板文件 VHDL测试平台模板文件 片上系统设计向导 three-bit-counter新建一个VHDL模块模板文件之后，根据我们要设计的3位计数器设计逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142library IEEE;use IEEE.STD_LOGIC_1164.ALL;use IEEE.STD_LOGIC_ARITH.ALL;use IEEE.STD_LOGIC_UNSIGNED.ALL;-- Uncomment the following library declaration if using-- arithmetic functions with Signed or Unsigned values--use IEEE.NUMERIC_STD.ALL;-- Uncomment the following library declaration if instantiating-- any Xilinx primitives in this code.--library UNISIM;--use UNISIM.VComponents.all;entity top is//此处添加端口声明语句port( clk : in std_logic; rst : in std_logic; counter : out std_logic_vector(2 downto 0));end top;architecture Behavioral of top is//内部信号量声明语句signal counter_tmp : std_logic_vector(2 downto 0);begin//添加信号连接counter&lt;=counter_tmp;process(clk,rst)//3bit 8进制计数器模块begin if(rst='0')then counter_tmp&lt;="000"; elsif rising_edge(clk)then counter_tmp&lt;=counter_tmp+1; end if;end process;end Behavioral; 设计的综合ISE综合工具在对设计的综合过程中，主要执行以下三个步骤： 语法检查过程，检查设计文件语法是否有错误 编译过程，翻译和优化HDL代码，将其转化为综合工具可以识别的元件序列。 映射过程，将这些可以识别的元件序列转化为可识别的目标技术的基本原件。 在ISEden主页面的处理子串口的Synthesis工具可以完成: 查看RTL原理图 查看技术原理图 检查语法 产生综合后仿真模型 进行行为仿真 在ISE主页面的Design区域选中Simulation选项.选中已经添加的逻辑模块右键添加测试文件. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061LIBRARY ieee;USE ieee.std_logic_1164.ALL; -- Uncomment the following library declaration if using-- arithmetic functions with Signed or Unsigned values--USE ieee.numeric_std.ALL; ENTITY test ISEND test; ARCHITECTURE behavior OF test IS -- Component Declaration for the Unit Under Test (UUT) COMPONENT top PORT( clk : IN std_logic; rst : IN std_logic; counter : OUT std_logic_vector(2 downto 0) ); END COMPONENT; --Inputs signal clk : std_logic := '0'; signal rst : std_logic := '0'; --Outputs signal counter : std_logic_vector(2 downto 0); -- Clock period definitions constant clk_period : time := 10 ns; BEGIN -- Instantiate the Unit Under Test (UUT) uut: top PORT MAP ( clk =&gt; clk, rst =&gt; rst, counter =&gt; counter );//添加rst信号 process begin rst&lt;='0'; wait for 100 ns; rst&lt;='1'; wait for 1 ms; end process; //生成clk信号 process begin clk&lt;='0'; wait for 20 ns; clk&lt;='1'; wait for 20 ns; end process;END; 完成之后点击子任务区域的SImulate Behavioral Model，手动Zoom Out测试。 为了在硬件上看到灯的变化所反映的计数器工作状态，需要在top.vhd文件添加分频时钟代码。]]></content>
      <categories>
        <category>ISE</category>
      </categories>
      <tags>
        <tag>ISE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小记(3)]]></title>
    <url>%2F2016%2F04%2F08%2F%E5%B0%8F%E8%AE%B03%2F</url>
    <content type="text"><![CDATA[过了17岁的青涩无知，祛了十多岁朝气蓬勃的精神气儿。逐渐长大接近这个社会的真实，逐渐接受麻木的驯服。一个接一个憧憬的或事物，每一个我所认知的、欣赏的人物。这可是我们当中最好的一批人啊，却也跟我一样肮脏、黑暗。不自觉的每个任性闪光，最终都会在挖掘之后令人作呕。 23分的黑色阳光洒在白皙纯真的脸庞，每一寸都是黑色。乘着城堡下遮盖的柔软龙猫，不想要看到任何物质。每个生物都如此污秽，我无法接受你。越来越快在齿轮的碾压下破碎的理想，编织成三伏天的网。 自私虚伪。人生不如意之八八九九，心切切不可闻。坐上西部的老爷车，飞向没有卢瑟与温拿的理想世界。十四岁写下的种种缺诬，一百四十年不会削减的向阳花。 谎言杀死自由，情话强奸温柔。那些或清晰或模糊的片段，随着离去的大风，依旧留在二十岁的铁轨。像当初分开时的那种情节，有时候还是想回到过去。黑暗的不是人间，是完善的人格。回到90岁的中世纪世界,不是卢瑟夫的狂想，我不爱它。 .]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android之Context、this]]></title>
    <url>%2F2016%2F04%2F07%2Fcontext%2F</url>
    <content type="text"><![CDATA[Contextcontext不是函数而是一个类。如果不太了解面向对象，可以把“类”看做一种数据类型，就像int，不过类型为“类”的数据（称为对象）可能储存远比int多的信息，比如这里的类型为Context的对象就储存关于程序、窗口的一些资源。 有些函数调用时需要一个Context参数，比如Toast.makeText，因为函数需要知道是在哪个界面中显示的Toast。再比如，ButtonmyButton = new Button(this); 这里也需要Context参数（this），表示这个按钮是在“this”这个屏幕中显示的。 Android开发使用（纯粹的）面向对象语言，一切都是对象，就连我们写的函数都是对象的函数。 小例123456789101112131415161718192021222324252627282930313233343536373839public class MainActivity extends Activity&#123; @Override public void onCreate(Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); Toast.makeText(this, "OK!", Toast.LENGTH_LONG).show(); Button button1 = (Button)findViewById(R.id.button1); button1.setOnClickListener(new Button.OnClickListener()&#123; public void onClick(View v) &#123; Toast.makeText(MainActivity.this, "Hello, world!", Toast.LENGTH_LONG).show(); &#125; &#125;); &#125; &#125; 这里OnCreate就是MainActivity的对象的函数（MainActivity是类），所以这个函数中的this就表示当前的、包含这个函数的MainActivity对象。 MainActivity extends Activity，意思是MainActivity 继承 Activity，即MainActivity 是 Activity 的一种，所有的MainActivity 都是 Activity。同样，在Android文档中Activity继承ContextThemeWrapper，ContextThemeWrapper继承ContextWrapper，ContextWrapper继承Context。所以this这个MainActivity也是Context，把this传入Toast.makeText表示“OK!”是在当前的MainActivity对象（也是Context）中显示的。 对于显示”Hello,world!”的Toast.makeText，这个函数在onClick中，而onClick是new Button.OnClickListener(){…}这个没有名字的类的函数，this表示匿名类的对象，不表示MainActivity对象，所以这里用MainActivity.this，强制选择外面一层MainActivity的this。在activity和 service中使用的this，的确可以代替context，因为activity和service本身就是继承于context类的，也就是说，那里面的this，就是一个context。 再来说上面这个context为什么不能用。因为toast是一个view，每一个view被添加的时候都需要一个token，activity中的context就包含了当前activity窗口的token，所以能够使用，而onReceive中的context，并不是隶属于某个应用程序进程的，而是属于系统的context，所以这里会报错。 将this替换成为context是因为此类继承自BroadcastReceiver，并非继承自Activity. activity继承自context,activity.this可以当做一个context。而BroadcastReceiver直接继承自Object，它的this不再属于context，不能当做上下文，成为函数的参数 Context的类型应用程序创建Context实例的情况有如下几种情况： 创建Application 对象时， 而且整个App共一个Application对象 创建Service对象时 创建Activity对象时 因此应用程序App共有的Context数目公式为： 总Context实例个数 = Service个数 + Activity个数 + 1（Application对应的Context实例） 并不是所有的context实例都是等价的。根据Android应用的组件不同，你访问的context推向有些细微的差别。 Application 是一个运行在你的应用进程中的单例。在Activity或者Service中，它可以通过getApplication()函数获得，或者人和继承于context的对象中，通过getApplicationContext()方法获得。不管你是通过何种方法在哪里获得的，在一个进程内，你总是获得到同一个实例。 Activity/Service 继承于ContextWrapper，它实现了与context同样API，但是代理这些方法调用到内部隐藏的Context实例，即我们所知道的基础context。任何时候当系统创建一个新的Activity或者Service实例的时候，它也创建一个新的ContextImpl实例来做所有的繁重的工作。每一个Activity和Service以及其对应的基础context，对每个实例来说都是唯一的。 BroadcastReciver 它本身不是context，也没有context在它里面，但是每当一个新的广播到达的时候，框架都传递一个context对象到onReceive()。这个context是一个ReceiverRestrictedContext实例，它有两个主要函数被禁掉：registerReceiver()和bindService()。这两个函数在BroadcastReceiver.onReceive()不允许调用。每次Receiver处理一个广播，传递进来的context都是一个新的实例。 ContentProvider 它本身也不是一个Context，但是它可以通过getContext()函数给你一个Context对象。如果ContentProvider是在调用者的的本地（例如，在同一个应用进程），getContext()将返回的是Application单例。然而，如果调用这和ContentProvider在不同的进程的时候，它将返回一个新创建的实例代表这个Provider所运行的包。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gulp介绍]]></title>
    <url>%2F2016%2F04%2F06%2FGulp-intro%2F</url>
    <content type="text"><![CDATA[介绍什么是Gulpgulp.js是一种基于流的，代码优于配置的新一代构建工具.官方文档 Gulp和Grunt类似。但相比于 Grunt 的频繁的 I/O 操作，Gulp 的流操作，能更快地完成构建 Gulp特性 使用方便 通过代码优于配置的策略，Gulp可以让简单的任务简单，复杂的任务更可管理。 构建快速 通过流式操作，减少频繁的 IO 操作，更快地构建项目。 插件高质 Gulp 有严格的插件指导策略，确保插件能简单高质的工作。 易于学习 少量的API，掌握Gulp可以毫不费力。构建就像流管道一样，轻松加愉快。 Gulp安装Gulp是基于Node.js的，故要首先安装 Node.js。 npm install -g gulp 然后按以下清单文件安装 123456gulpgulp-htmlcleangulp-htmlmingulp-imagemingulp-minify-cssgulp-uglify 方法是同样的,npm install xxx --save，xxx即为清单列表文件名 其中gulp是工程的核心程序，Gulp采用插件方式进行工作，下面的5个文件就是基于Gulp的插件.Gulp插件列表 使用Gulp优化Hexo建立gulpfile.js1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556var gulp = require('gulp'); //Plugins模块获取 var minifycss = require('gulp-minify-css'); var uglify = require('gulp-uglify'); var htmlmin = require('gulp-htmlmin'); var htmlclean = require('gulp-htmlclean'); var imagemin = require('gulp-imagemin') // 压缩 public 目录 css文件 gulp.task('minify-css', function() &#123; return gulp.src('./public/**/*.css') .pipe(minifycss()) .pipe(gulp.dest('./public')); &#125;); // 压缩 public 目录 html文件 gulp.task('minify-html', function() &#123; return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest('./public')) &#125;); // 压缩 public/js 目录 js文件 gulp.task('minify-js', function() &#123; return gulp.src('./public/**/*.js') .pipe(uglify()) .pipe(gulp.dest('./public')); &#125;); // 压缩图片任务 // 在命令行输入 gulp images 启动此任务 gulp.task('images', function () &#123; // 1. 找到图片 gulp.src('./photos/*.*') // 2. 压缩图片 .pipe(imagemin(&#123; progressive: true &#125;)) // 3. 另存图片 .pipe(gulp.dest('dist/images')) &#125;); // 执行 gulp 命令时执行的任务 gulp.task('default', [ 'minify-html','minify-css','minify-js','images' ]); 运行要运行gulp任务，只需切换到存放gulpfile.js文件的目录，然后在终端中执行gulp命令就行了，gulp后面可以加上要执行的任务名，例如gulp task1，如果没有指定任务名，则会执行任务名为default的默认任务。]]></content>
      <categories>
        <category>Gulp</category>
      </categories>
      <tags>
        <tag>Gulp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitignore忽略规则]]></title>
    <url>%2F2016%2F04%2F05%2Fgitignore%2F</url>
    <content type="text"><![CDATA[.gitignore 配置文件用于配置不需要加入版本管理的文件，配置好该文件可以为我们的版本管理带来很大的便利，以下是个人对于配置 .gitignore 的一些心得。 配置语法 以斜杠“/”开头表示目录； 以星号“*”通配多个字符； 以问号“?”通配单个字符 以方括号“[]”包含单个字符的匹配列表； 以叹号“!”表示是跟踪（不忽略）某个文件或目录。； #此为注释 – 将被 Git 忽略 [ ^abc]：代表必须不是a,b,c中任一字符 [abc]：代表a,b,c中任一字符即可 {ab,bb,cx}：代表ab,bb,cx中任一类型即可 {!ab}：必须不是此类型 此外，git 对于 .ignore 配置文件是按行从上到下进行规则匹配的，意味着如果前面的规则匹配的范围更大，则后面的规则将不会生效； 示例 fd1/*说明：忽略目录 fd1 下的全部内容；注意，不管是根目录下的 /fd1/ 目录，还是某个子目录 /child/fd1/ 目录，都会被忽略； /fd1/*说明：忽略根目录下的 /fd1/ 目录的全部内容； 3.1234/*!.gitignore!/fw/bin/!/fw/sf/ 4. 12345*.a #忽略所有 .a 结尾的文件!lib.a #但 lib.a 除外/TODO #仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODObuild/ #忽略 build/ 目录下的所有文件doc/*.txt #会忽略 doc/notes.txt 但不包括 doc/server/arch.txt 说明：忽略全部内容，但是不忽略 .gitignore 文件、根目录下的 /fw/bin/ 和 /fw/sf/ 目录 Tip规则很简单，但是有时候在项目开发过程中，突然心血来潮想把某些目录或文件加入忽略规则，按照上述方法定义后发现并未生效。原因是.gitignore只能忽略那些原来没有被track（跟踪过）的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未track状态），然后再提交。 123git rm -r --cached .gitignore #从版本库中删除文件，但不从硬盘删除git add .gitignoregit commit -m 'update .gitignore' 或者直接 git rm &lt;file&gt; #从版本库中删除文件，同时在硬盘中剔除]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[router-source-analysis]]></title>
    <url>%2F2016%2F04%2F04%2Frouter-source-analysis001%2F</url>
    <content type="text"><![CDATA[constant value在分析第一个Verilog HDL Router中的check模块之前，首先在前面声明一下代码中会使用到的常量值： 123456789101112131415161718192021// disable error reporting`define ERROR_CAPTURE_MODE_NONE 0// don't hold errors`define ERROR_CAPTURE_MODE_NO_HOLD 1// capture first error only (subsequent errors are blocked) `define ERROR_CAPTURE_MODE_HOLD_FIRST 2// capture all errors `define ERROR_CAPTURE_MODE_HOLD_ALL 3`define ERROR_CAPTURE_MODE_LAST `ERROR_CAPTURE_MODE_HOLD_ALL// asynchronous reset`define RESET_TYPE_ASYNC 0// synchronous reset`define RESET_TYPE_SYNC 1`define RESET_TYPE_LAST `RESET_TYPE_SYNC 实现reg在Router的check的错误警报模块中，具体实现这一功能的还是寄存器。上面的代码分别定义了一些错误警示以及错误重置的类型。 1234567891011121314151617181920212223/*some input output var define ......*/case(reset_type) `RESET_TYPE_ASYNC: always @(posedge clk, posedge reset) if(reset) q &lt;= reset_value; else if(active) q &lt;= d; `RESET_TYPE_SYNC: always @(posedge clk) if(reset) q &lt;= reset_value; else if(active) q &lt;= d; endcase endgenerate 首先有一个case选择器，选择重置信号的类型是同步还是异步重置。 async 异步类型的重置，会接受在时钟的上升沿会接受两个信号，分别是时序电路中必须的时钟信号，以及重置信号。当是上升沿时reset=1信号触发了事件，将输出结果赋值为想要重置的值，否则保持输出结果保持为输入值不变。 sync 同步类型的时序时间触发参数只有clk时钟参数。当此时的reset信号电平为高，则赋值reset值，否则保持不变。 同步与异步类型的区别保证了同步类型的重置信号只有在时钟上升沿时有可能会发生reset值重置，而异步类型只要reset信号为高电平即可触发。 error模块1234567891011121314151617181920212223242526generate if(capture_mode != `ERROR_CAPTURE_MODE_NONE) begin wire [0:num_errors-1] errors_s, errors_q; case(capture_mode) `ERROR_CAPTURE_MODE_NO_HOLD: begin assign errors_s = errors_in; end `ERROR_CAPTURE_MODE_HOLD_FIRST: begin // assign errors_s = ~|errors_q ? errors_in : errors_q; end `ERROR_CAPTURE_MODE_HOLD_ALL: begin assign errors_s = errors_q | errors_in; end endcase 当有错误信息时，获取到捕捉的错误信息类型。根据先前在constant常量文件中定义的信息，error_s变量对应的是上面寄存器中的d变量，表示输入信号。 ~| 表示或非位运算，做一次或者多次‘或’运算之后，再做一次非运算。有1出0，全0出1。 上面是Verilog HDL中运算符的优先级顺序。 根据捕获到的不同错误类型，将error_s的值对应赋值，分别赋值为: errors_s = errors_in 直接赋值为error模块的输入值 errors_s = ~|errors_q ? errors_in : errors_q 当errors_q的值==0时，依然赋值为输入值，否则只要errors_q的值&gt;0，有过改变就将它赋给errors_s。 errors_s = errors_q | errors_in 赋值为当前erroes_q与errors_in的逻辑或运算结果。 其中errors_q是errors模块的实际输出结果，errors_in是模块的输入，errors_s时中间计算根据错误类型计算的输入值。]]></content>
      <categories>
        <category>NoC</category>
      </categories>
      <tags>
        <tag>NoC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoC路由算法]]></title>
    <url>%2F2016%2F04%2F03%2FNoC-router-alg%2F</url>
    <content type="text"><![CDATA[NoC的图谱结构必须保证每个节点可以发送数据包到其他节点。当没有完善的拓扑结构的时候，路由算法决定数据包从原地址开始选择那一条路径到目的地址。所以，有效的数据算法对NoC网路性能的好坏是至关重要的。 路由算法可以按照不同的标准分为不同的几类。比如说源路由（SOurce Routing）和分布式路由（Distrubuted Routing），确定路由（Deterministic Routng）和自适应路由（Adaptive Routing）。 确定路由（Deterministic Routing）确定路由是一种常见的路由，它的路由路径只与起点地址和终点地址有关，给定起点和终点地址，路由路径就被确定了，与当前的网络状态无关。而在确定路由中，使用最多的就是维序路由（Dimension-Ordered Routing）,因为他有着非常简单易实现的路由逻辑。 在维序路由中，每个数据包一次只在一个维上路由，当在这个维上到达了恰当的坐标之后，才按由低维到高维的顺序在另外的维上路由。因为数据包是按照着严格的单调的维数变化的顺序在通道内路由，所以维序路由也是没有死锁的。按照在不同拓扑结构的网络中路由，维序路由包括了2D Mesh中的XY路由和在超立方体（HyperCube）中的E-cube路由。 XY路由关于XY路由算法的具体原理方法，我已经在缓存与XY路由算法一文中有过详细介绍。 具体举例来说，一个源地址（1，2），目的地址（3，4）的微片，采用XY路由算法的路径是不会改变的。 (1,2)-&gt;(2,2)-&gt;(3,2)-&gt;(3,4)-(3,4) E-cube 路由E-cube路由和XY路由很相似，都是先在一个方向（维）上路由，然后再在其它方向（维）上路由。具体来说，前面提到了在n维立方体中，每个节点是用一个nbit的二进制编号表示的。每个节点n条输出的通道，其中第i条通道就对应的第i维。在E-cube路由算法中，数据包的头部携带了目的节点的地址 d。当n维立方体中的一个节点v收到一个数据包时·，E-cube路由算法计算路由向量c=d xor v（xor是逻辑运算符号异或）。如果c=0，说明数据包已经到达了目的地，则传给IP核。否则数据包被送往第k纬的输出通道，其中k是c里面最右面或者最左边的‘1’的那一维度。 举例来说，一个由s=Ol10产生的数据包要传向目的地为d=l101的节点。首先计算路由向量cl=d xor s=1101 xor 0110=1011。取最右边的不为零的一位为k，则k=l，说明这是的数据包将会被送往第1维上的通道。然后到达了vl=011l。 再计算路由向量c2=d xor v1=1101 xor 0111=1010，得出k=2，然后送到第2维的通道上。 随即到达v2=0101，再一次计算c3=d xor v2=1101 xor 0101=1000,得出k=4，接着把数据包送到第4维的通道上。 最后到达了目的地d=llOl。 最终，得出的路由过程是：011O一＞011l一＞0101一＞1101 从上面的路由过程可以看出，虽然E-cube路由与XY路由是在不同维数的网络中路由，但是它们都有很相似的共同点：即一次只在一个方向（维数）上路由，直到在该方向（维数）上当到达了与目的地址相同的节点，再按照单调的顺序改变方向在其它维上路由，XY路由是由X方向改变到Y方向的顺序，E-cube路由是从低维到高维（或者从高维到低维）的顺序。而这正是维序路由算法的典型特征。 自适应路由（Adaptive Routing）确定路由优点是，路由算法简单，在网络低拥塞环境下能获得较低延迟。但是由于其不能响应动态的网络状态变化，所以当网络拥塞增加时，性能迅速降低。 所谓的自适应路由，就是指数据包的路由路径不只与起点地址和终点地址有关，还要考虑网络的状态。也就是说，有同一对起／终点的地址的数据包，在不同的网络状态下，它们的路由路径也可能不同。 自适应路由的优点是采用自适应路由的路径，避免了网络拥塞，可以得到更高的网络带宽饱和值；但是它的路由逻辑较复杂，在网络低拥寨的情况下开销较大，而且还存在死锁问题。 在片上网络中，由于路由器结构所限，一般都采用的是比较简单的自适应算法，如带有一定自适应性的维序路由。所以，下面将着重介绍一下这种算法。 自适应性的维序路由一般的维序路由是在维序路由中，每个数据包一次只在一个维上路由，当在这个维上到达了恰当的坐标之后，才按由低维到高维的顺序在另外的维上路由。 而这里带有一定自适应性的维序路由则是，当数据包沿某一维（如X方向），从最低维到最高维路由的过程中发生阻塞的时候，即向另一维（Y方向）发出传送请求，如果请求得到应答则向该方向传送数据，否则又转回X方向请求，如此循环，直到请求得到应答。同时规定，不允许数据向远离目的节点的方向运动，所以这种带有一定自适应性的维序路由也是没有死锁的。 下面以4×4的2DMesh网络中的带有一定自适应性的XY路由为例，具体解释一下这种算法的路由过程。 假设一个数据包路由的起点为（1,4），终点为（4,1）。如果按照一般的XY路由的话，它的路由路径应该是（1,4）一＞（2,4)一＞（3,4）一＞（4,4）一＞（4,3）一＞（4,2）一＞（4,1）。这时如果假设数据包在节点（3,4）发生了阻塞，不能继续向（4,4）发送。如果按照原来的XY路由，数据包就不能在往下发送，被阻塞在了（3，4）中。这时如果采用的是带有一定适应性的XY路由，在向节点（4,4)发送传送请求没有被允许之后，则它就会向Y维方向上的（3,3）节点发送传送请求，被允许之后，数据包就被发往节点（3,3）了。到达（3,3）后，又会先向X维方向上的（4,3)发送请求。就这样最终的路由路径为（1,4）一＞（2,4）一＞（3,4）一＞（3,3）一＞（4,3）一＞（4,2)一＞（4,1）。 从上面的路由路径可以看出，带有一定自适应性的XY路由和一般的XY路由的差别就是在某个节点发生阻塞之后，它可以不按照先X维再Y维的顺序路由，而可以是向另一个维发送数据包。这样就可以从一定程度上缓解网络的拥塞]]></content>
      <categories>
        <category>NoC</category>
      </categories>
      <tags>
        <tag>NoC</tag>
        <tag>Router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib快速绘图（2）]]></title>
    <url>%2F2016%2F04%2F01%2Fmatplotlib2%2F</url>
    <content type="text"><![CDATA[matplotlib 是python最著名的绘图库，它提供了一整套和matlab相似的命令API，十分适合交互式地进行制图。而且也可以方便地将它作为绘图控件，嵌入GUI应用程序中。 它的文档相当完备，并且 Gallery页面 中有上百幅缩略图，打开之后都有源程序。因此如果你需要绘制某种类型的图，只需要在这个页面中浏览/复制/粘贴一下，基本上都能搞定。 在Linux下比较著名的数据图工具还有gnuplot，这个是免费的，Python有一个包可以调用gnuplot，但是语法比较不习惯，而且画图质量不高。 而 Matplotlib则比较强：Matlab的语法、python语言、latex的画图质量（还可以使用内嵌的latex引擎绘制的数学公式）。 绘制一组幂函数matplotlib的pyplot子库提供了和matlab类似的绘图API，方便用户快速绘制2D图表 先从一个简单的例子开始讨论。假设要在一个图形中显示一组幂函数。这组幂函数的基不同，分别为10，自然对数 e 和2。可以用如下 Python 脚本去描绘这组曲线，生成的图形如下 1234567891011121314151617from matplotlib.pylab import * import numpy as np x = linspace(-6, 6, 300) f1 = np.power(9, x) f2 = np.power(e, x) f3 = np.power(2, x) plot(x, f1, 'red', x, f2, 'blue', x, f3, 'pink', linewidth=2.5) axis([-6, 4, -0.5, 10])text(1, 7.5, r'$10^x$', fontsize=14)text(2.2, 7.5, r'$e^x$', fontsize=14)text(3.2, 7.5, r'$2^x$', fontsize=14)title('A simple example', fontsize=14)savefig('power.png')show() 程序的第一行装载了 pylab 模块。接下来的几行语句（至 savefig 之前）运行 Matlab 程序，因为 linspace， plot，axis, text, title 这些函数在 pylab 中也存在。这个例子展示了 Matplotlib 中几个比较常用的绘图函数，如 plot，axis，title 等的用法。其中 plot 是一个功能十分强大的函数, 通过改变它的参数选项，可以灵活地修改图形的各种属性，比如选用的线型，颜色，宽度等。 显示图形中的数学公式Matplotlib 可以支持一部分 TeX 的排版指令，因此用户在绘制含有数学公式的图形时会感到很方便并且可以得到比较满意的显示效果，所需要的仅仅是一些 TeX 的排版知识。下面的这个例子显示了如何在图形的不同位置上, 如坐标轴标签，图形的标题以及图形中适当的位置处，显示数学公式。相应的 Python 程序如下. 123456789101112131415from matplotlib.pylab import *def f(x, c): m1 = sin(3*pi*x) m2 = exp(-c*x) m3 = sin(x) return multiply(m1, m2,m3)x = linspace(0, 4, 100)sigma = 0.6plot(x, f(x, sigma), 'r', linewidth=2)xlabel(r'time t', fontsize=16)ylabel(r'Amplitude $f(x)$', fontsize=16)title(r'$f(x)$ is damping with x', fontsize=16)text(2.0, 0.5, r'$f(x) = \rm&#123;sin&#125;(3 \pi x^2) e^&#123;\sigma x&#125;$', fontsize=20)savefig('latex.png', dpi=75)show() 从程序中可以看出，在 Matplotlib 中进行有关数学公式的排版是很简单的。与 TeX 排版时的约定一样，要插入的公式部分由一对美元符号 $ 来进行标识，而具体的排版命令与 TeX 一样。在任何可以显示文本的地方（如轴的标签，标题处等）都可以插入需要的公式。需要注意的是，数学公式所在的字符串开始之处有一个标记 r，表示该字符串是一个 raw string。这是因为排版公式时，字符串所包含的内容必须按照 TeX 的规范，而不是其他的规范，来进行解析。所以使用 raw string 可以避免其它规则解释字符串中某些特殊字符所带来的歧义。从生成的图形可以看到，公式显示的效果是比较美观的。 另外在这对美元符号之间如果想要使用正常的字符，可以插入\rm{}，并在括号里添加文字，一些特殊的字体如math.pi，可以在美元符号内使用\pi,幂级数角标使用{}. GLP 集合计算结果的可视化Python 是一种比较适合用来进行科学计算的脚本语言，如果利用了 Numeric 及 Numarray 模块，它的计算能力还能得到进一步的增强。 Matplotlib 也充分利用了这两个模块，可以高质量地完成计算结果可视化的工作。下面是一个计算和显示两维好格子点 GLP (Good Lattice Point Set)集合的例子。 GLP 集合是一种用算法产生的伪随机数的集合,它在一些优化计算中很有用，详细的介绍可以在参考文献里找到。下面的 Python 程序先定义了一个函数 glp(n1, n2) 用以产生需要的 GLP 集合, 接着利用 Matplotlib 来显示它的分布情况（应该是均匀分布的）。 1234567891011121314151617181920from matplotlib.pylab import *def glp(n1, n2): q = zeros((2, n2), float) h1 = 1; h2 = n1 for i in arange(n2-1): q[0][ i] = (fmod(h1*(i+1), n2)-0.5)/n2 q[1][ i] = (fmod(h2*(i+1), n2)-0.5)/n2 q[0][n2-1] = (n2-0.5)/n2 q[1][n2-1] = (n2-0.5)/n2 return qn1 = 454; n2 = 745q = glp(n1, n2)x = q[0, :]y = q[1, :]#y. 表示yello dotplot(x, y, 'y.', linewidth=2)axis([0, 1, 0, 1])title(r'$\rm&#123;GLP \ set \ with&#125; \ n_1 = 454, \ n_2 = 745$')savefig('glp.png')show() 最初我们是用 Matlab 来完成这个工作的，现在用 Python 来实现一样很简洁。程序中函数 glp 的实现主要是利用了模快 Numeric，计算得到的结果用 plot 函数直接加以显示，十分方便。这个例子（包括上一个例子）显示了，在利用 Python 进行某些科学及工程计算时，Matplotlib 往往能简洁高效地完成计算结果可视化的工作。]]></content>
      <categories>
        <category>matplotlib</category>
      </categories>
      <tags>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Virtual Channel Ruter]]></title>
    <url>%2F2016%2F04%2F01%2FVirtual%20Channel%2F</url>
    <content type="text"><![CDATA[VC与WormHole的对比虚信道路由器通过引入虚信道技术，将一个物理信道分成逻辑上的多个虚信道。多个虚信道对物理信道分时复用，通过对虚信道的合理调度，当网络中发生数据分组阻塞时，阻塞的分组被缓存在某一条虚信道的缓存中，其它分组能够使用其它的虚信道继续进行传输。 虚信道路由器是对基本虫孔路由器的改进，它解决了虫孔路由器的阻塞问题，能够提高物理信道的利用率，显著增加片上网络的性能。虚信道路由器需要为每条虚信道提供一个独立的缓存空间，虚信道数目增加一条，路由器的缓存空间需要相应增加一倍。 上图左侧是基本虫孔路由器出现的阻塞问题。路由器1中的分组A要去往路由器3的南输入端口，需要经过路由器l的东输出端口（即路由器2的西输入端口）离开，而路由器2的西输入端口被分组B占用，分组A不能使用，被阻塞在路由器l，尽管路由器3的南输入端口是空闲的，但是分组A将无法到达。 上图右侧是使用虚信道架构的路由器结构传输，可以是双虚信道或多虚信道，分组A将会通过红色的通道到达路由器3。 VC结构 如图是传统的5端口虚信道路由器整体结构。它有5个输入端口与5个输出端口，每个输入端口支持n个虚信道（Virtual Channel，简称VC），每个VC维持一个用于缓存数据的FIFO队列，其中4个端口表示东、南、西、北四个方向，与相邻的4个路由器相连，另外一个表示本地端口，与IP核相连。 另外还包含计算模块（Routing Computation Unit，简称RC）、虚信道分配（Virtual Channel Allocator，简称VA）模块、开关分配（Switch Allocator，简称SA）模块及交叉开关（Crossbar）。虚信道采用的是虫孔交换机制，同时使用缓冲队列放置在输入端口的交换结构。 虚信道路由器的工作过程与虫孔路由器基本相同，不同之处在于多了一个虚信道分配操作。当头微片路由计算完成后，这时候由于一个输出端口有多个输出虚信道，该头微片只能占用其中一个，所以需要经过虚信道分配为其分配一个空闲的输出虚信道后，才能进行后面的开关分配和开关传输。 另外虚信道路由器通过引入虚信道技术，将一个物理信道分成逻辑上的多个虚信道，多个虚信道对物理信道分时复用，意味着该头微片所在的分组不能时时占用物理信道，也就不能时时占用与该物理信道相连的输出端口，因此该头微片所在分组的其它微片也需要每个时钟周期都参与开关分配，而不能直接使用头微片开关分配的结果，即虚信道路由器中开关分配以微片为单位进行，每个微片因为不能时刻占据对应的输出端口，所以每次都要使用开关分配与其他分组的微片进行仲裁判定,这是另外一个不同点。 从上面的描述中我们可以看出，虚信道路由器其实也可以分为一条控制路径和一条数据路径。控制路径由路由计算单元（RC）、虚信道分配单元（VA）和开关分配单元（SA）组成。 与虫孔路由器不同，虚信道路由器的控制路径为该头微片所在的分组预约的是一个输出端口中的一个输出虚信道，其它分组微片不能使用该输出虚信道，直到该头微片的整个分组传输完成，但是其它分组微片可以使用剩下的未被占用的输出虚信道。 数据路径由输入缓存和交叉开关构成，分组微片到来后由输入缓存存储，经过控制路径分配到输出端口后，经交叉开关转发到目的节点。 同时虚信道路由器的工作是按4级流水方式工作，分别是路由计算（RC）、虚信道分配（VA）、开关分配（SA）和开关传输（ST）。以分组包含4个微片为例，其中路由信息只包含在头微片中，所以头微片VA成功后，体微片和尾微片可以直接使用VA的结果，跳过路由计算和虚信道分配阶段，直接进入开关分配阶段。 VC的一些缺点传统虚信道路由器按4级流水线的方式工作，一个微片经过传统虚信道路由器需要经过虚信道分配与开关分配两个操作，这导致分配所花费的时延占了微片通过路由器所需总时延的一半。 一个输入端口有多个输入虚信道，每个输入虚信道都有可能发出一个请求，那么一个输入端口同时就有多个输入虚信道请求。而VA有可能同时为这些输入虚信道请求各自成功分配到相同的一个输出虚信道，接着VA又将这些分配成功的输入虚信道请求送入SA。这时SA的第一阶段仲裁是从这些成功的请求中选择一个，这导致了矛盾，即VA同时分配成功多个输入虚信道请求，而SA又只从这些请求中选择一个，导致了VA工作的浪费。 传统虚信道路由器的虚信道分配采用两阶段的仲裁结构，其中第二阶段总共有PV个PV:l仲裁器。例如，VC路由器的5个输入端口，每个端口分时复用2个虚拟信道，则每个信道都要与其余（52-1）个信道竞争相同的输出虚拟信道，而这些虚拟的输出信道共有（52）个，所以一共有（52个52：1）的仲裁器。仲裁器的大小和数目都会随着端口数P或者虚信道数V的变大而急剧增加，因此虚信道分配模块所占路由器资源比重较大。]]></content>
      <categories>
        <category>NoC</category>
      </categories>
      <tags>
        <tag>NoC</tag>
        <tag>Router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存与XY路由算法]]></title>
    <url>%2F2016%2F03%2F31%2FNoC-FIFO%2F</url>
    <content type="text"><![CDATA[FIFO形式 上图是一副常规的NoC Router结构图。FC指Flow Control流控机制，数据交换逻辑将开关分配单元仲裁结果进行链接，也就是将输入端口的FIFO与它请求的输出端口链接行程传输通道。FIFO，缓存，或者说当前的缓存主要使用的技术就是FIFO，first in first out的队列缓冲。 魂村是片上网络路由器中必不可少的单元，用于存储数据。目前的路由器中缓存与交叉开关存在3中相对位置关系： 缓存队列在交叉开关的前面 位于输入端口中，同时输出端口无缓存 缓存队列在交叉开关的后面 位于输出端口中，输入端口无缓存 缓存队列在交叉开关的前后两方 输入/输出端口都有缓存队列 当前的片上网络路由器多半使用的就是第一种结构，即FIFO放置在输入端口内的交换结构。到达的数据分组首先存储在输入缓存中，然后经过路由计算、调度算法决定输入缓存中的数据分组如何通过交叉开关传送到输出端口，即缓存功能在交叉开关传输之前。 这种结构对于构建大容量的交换结构十分经济，可扩展性好，但是当不同的输入端口的缓存队列都有微片要传递到同一个输出端口时，在一个时间段内，这种交换结构只允许一个被调度输出，另外的会处于阻塞状态。 第二个是缓存队列放置在输出端口的交换结构。数据到达输入端口先通过交叉开关传输到相应的输出端口的缓存队列中进行排队，即缓存功能在交叉开关传输之后。这种结构避免了由交换开关内部冲突引发的延迟，可以方便地提供吞吐量、速率以及时延等方面的服务质量保障，但是要求交叉开关具有很高的传输带宽，如果出现N个输入端口同时竞争同一个输出端口时，输出缓存需要一次性完成N次写入，交叉开关内部就需要一个加速比为N的交换结构，因此，这种结构复杂且不易扩展。 最后显示的是在交叉开关的输入和输出端口都具有缓存队列的结构。该结构是上述两种结构的一种折衷，通过适当的加速，可以避免交换开关拥塞引发的延迟，但是调度过程中需要同时考虑输入调度与输出调度，而且新加的缓存增加了路由器资源，因此该结构过于复杂。 简单的XY路由算法路由算法确定数据分组在网络中按照何种路径从源节点传输到目的节点。通常简答的路由器采用的都是XY维序路由算法，该算法是一种确定性路由算法，只要给定源地址与目的地址，就能唯一确定条路由路径。它将网络中所有路由器都用一个2维坐标（X,Y）表示，分组中的地址信息也是用2维坐标（X,Y）表示。 设当前路由器的坐标为（cur_x,cur_y），分组中目的地址为（dst_x,dst_y）。如果cur_xdst_x，则将数据包向西转发；如果cur_x=dst_x and cur_ydst_y则将数据分组向南转发；如果cur_x=dst_x and cur_y=dst_y，那么说明数据分组到达了目的地。 目的路由器就通过本地端口将数据分组发往与之相连的处理单元。这样分组总是先沿X轴方向走完，才沿Y轴方向传输。]]></content>
      <categories>
        <category>NoC</category>
      </categories>
      <tags>
        <tag>NoC</tag>
        <tag>Router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo-文章版权追加]]></title>
    <url>%2F2016%2F03%2F30%2Fappend-copyright%2F</url>
    <content type="text"><![CDATA[目前，网络中出现了一些不和谐因素，某些网站多次剽窃Hexo博友的原创文章。在对这些侵犯博友权益的网站提出谴责的同时，聪明的各位Geek们应该如何增强版权意识呢. 最简单的办法就是在自己的部落格文章里添加水印，即使这些网站通过爬虫私自收录我们的文章，读者也能在文章中轻易的发现原作者。 由于这种办法容易影响读者的阅读体验，我采用的是在每篇文章下面增加版权声明，将本篇文章的信息、初次刊登网站、作者信息追加进文章里面。 article结构cd到your_theme\layout\_partial\下，访问article.ejs，在合适的位置添加 123&lt;% if(!index) &#123; %&gt; &lt;%- partial('declare') %&gt; &lt;% &#125; %&gt; 将会在非目录页面下执行名为declare的脚本。 具体显示内容还是在your_theme\layout\_partial\下面，创建一个名为declare.ejs的文件，在里面填写 123456789&lt;! -- 添加版权信息 --&gt;&lt;div class="article-footer-copyright"&gt;&lt;center&gt;本文由&lt;b&gt;&lt;a href="&lt;%= config.root %&gt;index.html" target="_blank" title="&lt;%= config.author %&gt;"&gt;&lt;%= config.author %&gt;&lt;/a&gt;&lt;/b&gt;创作和发表,采用&lt;b&gt;BY&lt;/b&gt;-&lt;b&gt;NC&lt;/b&gt;-&lt;b&gt;SA&lt;/b&gt;国际许可协议进行许可&lt;/center&gt;&lt;center&gt;转载请注明作者及出处,本文作者为&lt;b&gt;&lt;a href="&lt;%= config.root %&gt;index.html" target="_blank" title="&lt;%= config.author %&gt;"&gt;&lt;%= config.author %&gt;&lt;/a&gt;&lt;/b&gt;,本文标题为&lt;b&gt;&lt;a href="&lt;%- config.root %&gt;&lt;%- post.path %&gt;" target="_blank" title="&lt;%= post.title %&gt;"&gt;&lt;%= post.title %&gt;&lt;/a&gt;&lt;/b&gt;&lt;/center&gt;&lt;center&gt;本文链接为&lt;b&gt;&lt;a href="&lt;%- config.root %&gt;&lt;%- post.path %&gt;" target="_blank" title="&lt;%= post.title %&gt;"&gt;&lt;%- config.url %&gt;/&lt;%- post.path %&gt;&lt;/a&gt;&lt;/b&gt;.&lt;/center&gt;&lt;/div&gt;&lt;! -- 添加版权信息 --&gt; 当然，你也可以自己DIY，修改显示的文字。 修改CSS样式编写类对应的CSS代码 cd到your_theme\source\css\_partial下面，创建copyright.styl 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849.article-footer-copyright &#123; border-top: 1px solid #d3d3d3; margin: 10px auto; padding-left: 2em; width: 80%;&#125;.article-footer-copyright span,.copyright abbr &#123; color: #3d3d3d;&#125;div.copyright &#123; font-weight: bold; color: #fcb297; padding: 0.3em 0.5em; margin: 0 0 1em 0; border-bottom: none; background-color: #74a474; -moz-border-radius: 1em; -webkit-border-radius: 1em; -webkit-border-radius: 1em; border-radius: 1em; -moz-box-shadow: inset 0px 1px 0px 0px #eee; -webkit-box-shadow: inset 0px 1px 0px 0px #eee; -webkit-box-shadow: inset 0px 1px 0px 0px #eee; box-shadow: inset 0px 1px 0px 0px #eee; background: -webkit-gradient(linear, left top, left bottom, color-stop(0.05, #aad2f0), color-stop(1, #8bc1ed)); background: -webkit-gradient(linear, left top, left bottom, color-stop(0.05, #aad2f0), color-stop(1, #8bc1ed)); background: -webkit-gradient(linear, left top, left bottom, color-stop(0.05, #aad2f0), color-stop(1, #8bc1ed)); background: -webkit-gradient(linear, left top, left bottom, color-stop(0.05, #aad2f0), color-stop(1, #8bc1ed)); background: -moz--webkit-linear-gradient(center top, #aad2f0 5%, #8bc1ed 100%); background: -moz--moz-linear-gradient(center top, #aad2f0 5%, #8bc1ed 100%); background: -moz--ms-linear-gradient(center top, #aad2f0 5%, #8bc1ed 100%); background: -moz-linear-gradient(center top, #aad2f0 5%, #8bc1ed 100%);/* filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#aad2f0', endColorstr='#8bc1ed'); */ background-color: #74a474; border: 1px solid #dcdcdc; text-shadow: 1px 1px 0px #eee;&#125;div.article-footer-copyright &#123; margin-top: 2em; padding: 0.8em; border: 1px solid #d3d3d3; background-color: #ffffcc;&#125;.article-footer-copyright p &#123; line-height: 140%; margin: 10px; font-size: 100%;&#125; 可以根据喜好修改格式。最后别忘了@import &#39;_partial/copyright]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>front end</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WormHole Router]]></title>
    <url>%2F2016%2F03%2F30%2Frouter-wormhole%2F</url>
    <content type="text"><![CDATA[如图是5端口虫孔路由器的结构，由5个输入端口、路由计算单元、开关分配单元、交叉开关和5个输出端口构成，其中4个端口与东、南、西、北4个方向的相邻路由器相连，剩下的是本地端口和IP核相连。虫孔路由器采用的是虫孔交换机制，同时使用缓存队列放置在输入端口的交换结构，输入缓存采用FIFO结构，缓存深度D表示输入缓存能够容纳的微片数目。 工作过程虫孔路由器的工作工程如下，当头微片（head filt）到达路由器时，头尾片首先会被存入输入端口的缓存队列中，同时路由计算单元会提取头微片中的路由信息，包括源节点和目的节点地址、分组长度、时间戳等等。并根据当前路由器与目的路由器之间的相对位置，执行相应的路由算法为该头微片所在的分组选择一个相应的输出端口。 路由计算单元计算出分组在路由器中的输出端口后，会向开关分配单元发送输出端口请求。开关分配单元根据流量控制机制传回的流量控制信息，将该头微片的输出端口请求与其他和该头微片去往相同的输出端口的来自不同输入端口的请求进行竞争仲裁。 开关分配单元完成开关分配后，会记录分配的结果，并根据该分配结果配置交叉开关，如果该头微片仲裁成功，那么交叉开关将链接该头微片所在的输入端口与它请求的输出端口，形成一个传输通道。同时开关分配单元会向该头微片所在的缓存发出读数据信号，接着该头微片从缓存中被独处，通过这条传输通道离开当前路由器。开关分配以分组为单位进行，当该头微片成功进行开关分配后，这个输出豆蔻被预约下来，后续的与它属于同一个分组的其他体微片和尾微片不再进行开关分配，直接进行开关传输，从头微片建立好的通道陆续从该输出端口离开当前路由器，当分组的尾微片经过交叉开关传输之后，分组对该输出端口的预约被释放，其他分组这是才能通过开关分配竞争这个输出端口。 路由计算单元 路由计算单元主要是提起头微片的路由信息，并根据当前路由器与目的路由器之间的相对位置，计算出分组的输出端口。 开关分配单元 开关分配单元根据流量控制机制传回的流控信息，将该头微片的输出端口请求与其他不同输入端口相同输出端口的微片通过仲裁机制进行竞争仲裁。并记录分配结果。并完成开关分配 交叉开关 交叉开关将开关分配单元行程的分配结果链接，也就是将输入端口（FIFO）与它请求的输出端口行程传输通道。同时开关分配单元会向头微片所在的缓存发出读数据信号，头微片沿传输通道传输。 工作流程从上面的描述中可以看出，虫孔路由器其实可以分为一条控制路径和一条数据路径。控制路径路由计算单元和开关分配单元组成，通过控制路径为该头微片所在的分组的其他微片预约一个输出端口，其他分组微片不能使用，直到该头微片的整个分组传输完后才能使用。数据路径由输入缓存和交叉开关构成，分组微片到来后由输入缓存存储，经过控制路径分配到输出端口，经过交叉开关转发到目的节点。很明显，虫孔路由器的工作是按照3级流水方式工作。 分别由路由计算（RC）、开关分配（SA）以及开关传输（ST）。头微片SA成功后，体微片和尾微片可以直接使用SA的结果，跳过路由计算和开关分配阶段，直接进入开关传输阶段。]]></content>
      <categories>
        <category>router</category>
      </categories>
      <tags>
        <tag>router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Noc Topology]]></title>
    <url>%2F2016%2F03%2F29%2Frouter-topology%2F</url>
    <content type="text"><![CDATA[NoC的拓扑结构就是指NoC中各个节点的连接方式。通常NoC拓扑结构分为两类，一类是直接型网络拓扑，另一类是间接性网络拓扑。 直接型在直接网络中，节点处理器（IP）直接地通过网络彼此连接。常见的直接型拓扑包括网状拓扑（Mesh）、花式拓扑（Torus）等。 2D Mesh 2D Mesh结构是一种最简单，最直观的拓扑结构，如图。每个节点连接一个资源和四个相邻的路由器，每个资源通过一个网络接口（Net-Interface NI）连接着一个路由器。其中的资源可以是一个处理器核，内存，一个用户自定义硬件模块或者其他任何可以插入插槽并且可以和网络接口相配的IP（intellectual property）模块。路由器和路由器之间，路由器和资源之间是由一对输入和输出通道连接。通道是由两条单向的点对点总线组成。 2D Mesh结构规则简单，但是边沿和定点位置节点的相对闭塞性，会极大的影响网络性能。 2D Torus 2D Torus结构可以看成是对2D Mesh的一种扩展，即在边界的节点上增加了一条长的环路。因此，网络中所有的节点的度都为4，对于一个n*n的Torus网络，其中m、n为每个维度的节点数，若m==n，则称为规则的Torus。 2D Torus拓扑在物理形式上与2D Mesh相似，但由于其存在很多环路，所以在路由算法和路由仲裁方面都要复杂的多。2D Torus拓扑的各个路由节点都是规则的，每个路由的节点结构都一样，所以扩展性也要比2D Mesh提高很多。 间接性在间接性网络中，节点处理器通过一个（或者更多个）的中间开关节点相互连接。间接型拓扑包括蝶形拓扑、Banyan、Fat-Tree拓扑等。]]></content>
      <categories>
        <category>router</category>
      </categories>
      <tags>
        <tag>router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[路由器架构]]></title>
    <url>%2F2016%2F03%2F28%2Frouter_know%2F</url>
    <content type="text"><![CDATA[Noc小记Noc是由Router和Channel组成的网络结构。其中router主要用来控制网络中数据传输，channel是连通片上系统中各处理核之间进行点对点数据传输的通路。 NoC采用分组交换的方式进行通信，片上网络中各处理核之间通过发送请求和接收相应消息的方式通信。在网络中传输的消息由头（head）、传输数据和尾（tail）组成。投中包含接收方的地址信息，router根据这个地址建立从传输方到达接收方的传输路径。传输数据即通信中核间要传输的信息。尾用来表示一个消息传输完毕。由于一个完整的传输数据往往包含的数据量很大，这样对片上网络的通信效率不利，于是我们将传输数据分割成更小的数据段，在对数据段添加头和尾构成数据包。 一般的Router有以下单元组成： 计算单元 分配单元 交叉单元 输入单元 其中路由计算涉及路由算法，输入单元涉及流控机制与交换机制，分配单元涉及流控机制与仲裁机制 ，而交叉开关涉及路由器的整体布局。 wormhole目前虫孔路由器(wormhole router)和虚信道路由器(virtual channel router)主要使用的都是虫孔交换机制。虫孔交换机制将数据分组划分为更小的微片，链路每次只能通过一个微片。微片的种类又分 为头微片(hed filt)，体微片和尾微片(tail filt)，并且允许一个分组只由一个微片组成。只有头微片包含分组的路由信息〈源节点和目的节点地址、分组长度、时间戳等）。 因此在传输分组数据时，由头微片根据路由信息为整个分组建立一条路由器内部的数据路径，体微片和尾微片沿着头微片建立的数据路径传输，其他分组的微片不能使用该路径，尾微片传输完毕后，路由器释放头微片建立的数据路径供其它分组传输使用。通过头微片这样逐跳的在路由器中建立的链路，整个分组最 终传输到目的地址。当头微片发生阻塞时，分组中的其它所有微片也都将停止前进，其中头微片缓存在当前路由器，其它微片就地缓存在它们自己所位于的若干个中间路由器中 。 flow control上网络路由器与Internet路由器最大的区别在于它不支持重传，这意味着片上网络路由器不允许丢失数据分组，因此片上网络路由器需要精确的流量控制机制防止当下行路由器缓存空间满的时候，上行路由器还在持续发送数据而产生丢失数据分组现象。片上网络路由器常用的流控机制有3种，分别是基于credit的流控机制、基于握手的流控机制和on/off 流控机制 。 credit基于 credit 的流控机制在每个路由器的输出端口处设置一个计数器，计数器中的值表示下行路由器输入端口中可用缓存的数目。上行路由器每发送一个微片它自己的计数器值就减1，当计数器的值减到0时就表示下行路由器输入端口中缓存队列己满，不能再继续发送，数据将在上行路由器中等待。当下行路由器中有 数据发送出去，意味着缓存被释放，就向上行路由器传回一个credit，上行路由器接收到credit后，计数器的值加1。基于credit的流控机制通过计数器的值是否为0能清楚的知道下行路由器是否满.不仅能防止丢失数据分组，同时能充分利用缓存资源，是当前主要的流控机制。 on-off由于基于credit的流控机制需要计数器，开销较大。一种改进的流控机制是on/off 流控机制，它在路由器中设置两个门限值 on 和 off ，当下行路由器中空闲缓存数目大于 off 时，发送1位比特信息通知上行路由器处于 “关” 状态，停止发送数据，当下行路由器的空闲缓存数目大于 on 时，发送l位比特信息通知上行路由器处于 “开” 状态，继续发送数据 。on/off 流控机制仅用l位比特信息来通知上行 路由器是否可以继续发送，而且回传信号次数也较基于 credit 流控机制少，但是它的缺点是由于 on/off 值的设定，不能充分利用缓存资源 。 handshake另一种改进的流控机制是基于握手的流控机制，它的工作原理是当上行路由器有数据发送时，先往下行路由器发送一个 req 信号，下行路由器收到 req 请求信号后，判断自己的缓存是否满，并返回一个 ack 应答信号，上行路由器接收的 ack 信号后，根据 ack 的值判断是否要发送数据。该机制虽然简单，但是一个明显的不足之处在于，该流控机制需要2个时钟周期来完成操作，比基于credit 的流控机制多了 1个时钟周期，增加了数据在网络中的传输时延。 仲裁机制片上网络能支持数据的并行传输，这必然会引起不同信息之间的竞争冲突，具体到路由器就是多个输入端口的数据请求同一个输出端口离开时，产生的端口竞争，而在虚信道路由器中除了上述竞争外，还存在多个输入虚信道请求同一个输出虚信道的虚信道分配竞争 。目前路由器常用的仲裁机制有固定优先级、动态优先级和轮询仲裁机制。 固定优先级 固定优先级的仲裁机制就是给每条线路分配固定的优先级，如果某条优先级高的线路一直有请求，那么其他优先级低的线路的请求将一直不会有响应。如图所示，端口A中一直有请求，并且他的优先级为3最高，因此他一直被相应，知道在时钟周期3他的请求变为0，才接着响应有请求切优先级最高的B端口，到了时钟周期7端口A又有请求，这时候A又被响应。可以看到尽管C端口一直有请求，但是由于他的优先级比较低，所以一直得不到相应。 动态优先级 动态优先级的仲裁机制与固定优先级的仲裁机制的原理基本相同，不同之处在于每条线路的优先级是动态变化的。每次也是相应优先级最高的请求。 轮询仲裁机制基本思想是当前仲裁成功的请求在下一时钟周期仲裁中的优先级最低，最高优先级赋予相邻的下一个仲裁请求，这样一次轮询。如图，开始初始化一个仲裁顺序为A-B-C，那么首先选定A端口开始轮询仲裁，由于A端口没有请求，因此直接跳到B，接着到C，接着轮询A，发现A端口有请求，响应A端口。]]></content>
      <categories>
        <category>router</category>
      </categories>
      <tags>
        <tag>router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模拟退火]]></title>
    <url>%2F2016%2F03%2F27%2FSA%2F</url>
    <content type="text"><![CDATA[模拟退火算法概述模拟退火算法来源于固体退火原理，将固体加温至充分高，再让其徐徐冷却，加温时，固体内部粒子随温升变为无序状，内能增大，而徐徐冷却时粒子渐趋有序，在每个温度都达到平衡态，最后在常温时达到基态，内能减为最小。根据Metropolis准则，粒子在温度T时趋于平衡的概率为e-ΔE/(kT)，其中E为温度T时的内能，ΔE为其改变量，k为Boltzmann常数。用固体退火模拟组合优化问题，将内能E模拟为目标函数值f，温度T演化成控制参数t，即得到解组合优化问题的模拟退火算法：由初始解i和控制参数初值t开始，对当前解重复“产生新解→计算目标函数差→接受或舍弃”的迭代，并逐步衰减t值，算法终止时的当前解即为所得近似最优解，这是基于蒙特卡罗迭代求解法的一种启发式随机搜索过程。退火过程由冷却进度表(Cooling Schedule)控制，包括控制参数的初值t及其衰减因子Δt、每个t值时的迭代次数L和停止条件S。 流程图 代码实现伪代码12345678910111213Simulated-Annealing() Create initial solution S repeat for i=1 to iteration-length do Generate a random transition from S to Si If ( C(S) &lt;= C(Si) ) then S=Si else if( exp(C(S)-C(Si))/kt &gt; random[0,1) ) then S=Si Reduce Temperature t until ( no change in C(S) ) C(S): Cost or Loss function of Solution S java实例实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package space.peihao; import java.io.BufferedReader; import java.io.File; import java.io.FileReader; import java.io.IOException; import java.util.Arrays; import java.util.Random; /** * @author Dukie 下午02:22:13 2010 * */ public class Anneal &#123; private static double[][] city; private static int[] currPath; private static int[] bestPath; private static double shortesDistance; private static int numOfCity = 20; //trace item private static int iterator = 0; public void printInfo() &#123; System.out.println("bestPath: " + Arrays.toString(bestPath)); System.out.println("shortest distance: " + shortesDistance); System.out.println("iterator times: " + iterator); &#125; private void init() throws IOException &#123; city = new double[numOfCity][numOfCity]; currPath = new int[numOfCity]; bestPath = new int[numOfCity]; shortesDistance = 0; loadCity(); int lenth = currPath.length; for (int i = 0; i &lt; lenth; i++) &#123; currPath[i] = i; &#125; &#125; private void loadCity() throws IOException &#123; //DistanceMatrix.csv" a file stores the distance info. File file = new File("E:\\TSP\\DistanceMatrix.csv"); inputGraph(file, city); &#125; private void inputGraph(File file, double[][] city) throws IOException &#123; BufferedReader in = new BufferedReader(new FileReader(file)); String str = ""; int length = 0; while ((str = in.readLine()) != null) &#123; str = str.replaceAll(", ", ","); String[] line = str.split(","); for (int j = 0; j &lt; numOfCity; j++) // ten cities city[length][j] = Double.parseDouble(line[j]); length++; &#125; &#125; /** * key function * @throws IOException */ public void anneal() throws IOException &#123; double temperature = 10000.0D; double deltaDistance = 0.0D; double coolingRate = 0.9999; double absoluteTemperature = 0.00001; init(); double distance = getToatalDistance(currPath); int[] nextPath; Random random = new Random(); while (temperature &gt; absoluteTemperature) &#123; nextPath = generateNextPath(); deltaDistance = getToatalDistance(nextPath) - distance; if ((deltaDistance &lt; 0) || (distance &gt; 0 &amp;&amp; Math.exp(-deltaDistance / temperature) &gt; random.nextDouble())) &#123; currPath = Arrays.copyOf(nextPath, nextPath.length); distance = deltaDistance + distance; &#125; temperature *= coolingRate; iterator++; System.out.println("iterator: " + iterator + " path: " + Arrays.toString(currPath)); &#125; shortesDistance = distance; System.arraycopy(currPath, 0, bestPath, 0, currPath.length); &#125; /** * calculate total distance * @param currPath * @return */ private double getToatalDistance(int[] currPath) &#123; int length = currPath.length; double totalDistance = 0.0D; for (int i = 0; i &lt; length - 1; i++) &#123; totalDistance += city[currPath[i]][currPath[i + 1]]; &#125; totalDistance += city[currPath[length - 1]][0]; return totalDistance; &#125; /** * swap two elements in the old array to genreate new array * @return */ private int[] generateNextPath() &#123; int[] nextPath = Arrays.copyOf(currPath, currPath.length); Random random = new Random(); int length = nextPath.length; int fistIndex = random.nextInt(length - 1) + 1; int secIndex = random.nextInt(length - 1) + 1; while (fistIndex == secIndex) &#123; secIndex = random.nextInt(length - 1) + 1; &#125; int tmp = nextPath[fistIndex]; nextPath[fistIndex] = currPath[secIndex]; nextPath[secIndex] = tmp; return nextPath; &#125; &#125; 上述代码就是为了解决旅行商问题。旅行商按一定的顺序访问N个城市的每个城市,使得每个城市都能被访问且仅能被访问一次,最后回到起点,而使花费的代价最小。本例中从第0个城市开始然后回到原点. Tips模拟退火算法与初始值无关，算法求得的解与初始解状态S(是算法迭代的起点)无关；模拟退火算法具有渐近收敛性，已在理论上被证明是一种以概率l 收敛于全局最优解的全局优化算法；模拟退火算法具有并行性。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[verilog笔记]]></title>
    <url>%2F2016%2F03%2F24%2Fverilog_date%2F</url>
    <content type="text"><![CDATA[模块模块介绍 模块是Verilog HDL语言的基本单元，数字系统是用模块的形式来描述。 模块是描述某个设计的功能、结构和其他模块通信的外部端口。 Verilog HDL中的各个模块是并行运行的 模块可以调用其他模块的实例 模块结构1234567891011module &lt;模块名&gt;(&lt;端口列表&gt;) 端口说明（input，output，inout） 参数定义（可选） 数据类型定义//wire、reg、task、function 连续赋值语句（assign）//组合逻辑 过程块（always和initial） -行为描述语句 低层模块实例//调用其它模块 任务和函数 延时说明块endmodule 语句模块描述方式Verilog有三种建模方式，分别是 结构化描述方式 数据流描述方式 行为描述方式 结构型描述通过实例进行描述的方法，将预定义的基本原件实例嵌入语言中，监控实例的输入，一单任何一个发生变化便重新运算并输出。 数据流型描述是一种描述组合逻辑功能的方法，用assign连续赋值语句来实现。 连续赋值语句完成如下的组合功能：等式右边的所有变量受持续监控，每当这些变量中有任何一个发生变化，整个表达式被重新赋值并送给等式左端。 行为级描述是通过描述行为特性来实现，关键词是always，含义是一单敏感变量发货时能变化，就重新一次进行赋值，有无限循环之意。这种描述方法常用来实现时序电路，也可用来描述组合功能。 Tip用户可以混用上述三种描述方法，但需要说明的是，模块中门的实例、模块实例语句、assign语句和always语句是并发执行的，即执行顺序和书写次序无关。 Verilog HDL区分大小写 Verilog HDL关键字一般为小写 其中数据流描述方式经常使用连续赋值语句，某个值被赋给某个网线变量。 assign [delay] net_name = expression; 注意在各assign 语句之间，是并行执行的，即各语句的执行与语句之间的顺序无关。 行为描述方式经常使用always、initial语句赋值。使用reg进行寄存器的声明。always是指一直在重复运行，由always后面括号的变量变化时触发。在always以及end之间是串行顺序执行的。 数据流型描述是一种描述组合逻辑功能的方法，用assign连续赋值语句来实现。 常量数字语法： &lt;位宽&gt;&#39;&lt;进制&gt;&lt;数值&gt; 其中位宽是指对应二进制的位数 需要注意的是，尾款小于相应数值的实际位数时，相应的高位部分被忽略。4&#39;D61与4&#39;B1101相同。因为十进制下61==111101，这里要求二进制4bit，所以是1101. parameter语法: 1234567parameter 参数名1=表达式，参数名2=表达式，......；例：parameter count_bits=8;parameter sel=8,code=8'ha3;parameter datawidth=8;addwidth=datawidth*2; 使用常量的目的: 便于阅读 便于修改 变量 网络型 nets type 指硬件电路中的各种连接，输出始终根据输入的变化更新其值的变化。 寄存器型 register type 常指硬件中电路中具有状态保持作用的器件，如触发器、寄存器等等。 nets type中最主要的就是wire型变量，常用来表示用assign语句赋值的组合逻辑信号。可以取值为0，1，x（不定值），z（高阻） 注意，Verilog HDL模块中的输入输出信号类型缺省时，自动定义为wire型变量。 语法：wire 数据1，数据2，……数据n. 例子： 12345wire a,b,c //定义了三个wire型变量wire[7:0] databus //定义了8bit宽wire型向量数据总线wire[20:1] addrbus //定义了20bit宽的wire型向量地址总线 这里记录下register type中的reg型，常用的寄存器型变量 语法： reg 数据1，数据2，数据3……; 例子： 12345reg a,b;reg[8:1] data //定义可8bit宽的reg型向量reg[7:0] mymem[1023:0] //定义了1024字节（8bit*1024）的存储器 常用语句 赋值 连续赋值语句、过程赋值语句 条件语句 if-else语句、case语句 循环语句 forever、repeat、while、for语句 结构说明语句 initial、always、task、function语句 编译预处理语句 ‘define ‘include ‘timescale语句 过程块 always过程块 模板： 12345678always @(&lt;敏感信号表达式&gt;)begin //过程赋值 //if语句 //case语句 //while、repeat、for语句 //task、function调用end 当敏感信号表达式的值改变时候，就执行一遍块内语句。同时always过程块是不能够嵌套使用的。 关键字posedge与negedge关键字分别是上升沿以及下降沿 例如：同步时序电路的时钟信号为clk，clear为异步清零信号。敏感信号可写为： 12345//上升沿触发，高电平清0有效always @(posedge clk or posedge clear)//上升沿触发，低电平清0有效always @(posedge clk or negedge clear) 例如当negedge clear表示当clear==0时 1234567always @(posedge clk or negedge clear) begin if(!clear)//当clear==0时候，always会由事件驱动 qout=0; else qout=in; end initial过程块 initial模板： 123456initialbegin 语句1； 语句2； ......end 对变量和存贮器初始化 123456initialbegin reg1=0; for(addr=0;addr&lt;size;addr=addr+1) memory[addr]=0;end initial语句主要面向功能模拟，通常不具有可综合性。 模拟0时刻开始执行，只执行一次 同一模块内的多个initial过程块，模拟0时刻开始并行执行。 initial与always语句一样，是不能嵌套使用的。即在initial语句中不能再次嵌套initial语句块。 赋值语句 连续赋值语句assign常用于对wire型变量进行赋值 123input a,b;output c;assign c=a&amp;b; a,b信号的任何变化，都将随时反映到c上来。 过程赋值语句常用于对reg型变量进行赋值 一般分为两种方式： 非阻塞赋值：一条非阻塞赋值语句的执行是不会阻塞下一条语句的执行，也就是收本条非阻塞赋值语句的执行完毕之前，下一条语句也可以开始执行。非阻塞赋值语句在块结束时才一同完成赋值操作，在一块内非阻塞赋值语句并行执行。赋值符号&lt;= 阻塞赋值：该语句结束时就完成赋值操作，前面的语句没有完成之前，后面的语句是不能执行的，在一块内非阻塞赋值语句顺序执行。赋值符号= 非阻塞赋值： 12345678910module non_block (c, a,b,clk);output c,b;input a,clk;reg c,b;always @(posedge clk) begin b&lt;=a; c&lt;=b; endendmodule 由于是非阻塞赋值，bc在clk上升沿同时进行状态变化。所以b&lt;=a;c&lt;=b;语句在同时执行，所以c的值是b上一个上升沿的值，b的值被赋值为a上一个上升沿的值。 阻塞赋值： 12345678910module block (c, a,b,clk);output c,b;input a,clk;reg c,b;always @(posedge clk) begin b=a; c=b; endendmodule 顺序执行有c==b 条件语句if-else语句块 pass case语句 1234567case （&lt;敏感表达式&gt;） 值1：语句或语句块1 ；//case分支项 值2：语句或语句块2 ； …… 值n：语句或语句块n ； default：语句或语句块n+1；//可省略endcase Tips 若没有列出所有条件分支，编译器认为条件不满足时，会引进触发器保持原值。 时序电路可利用上述特性来保持状态。 组合电路必须列出所有条件分支，否则会产生隐含触发器。 8bit二进制乘法器 integer 12345678910111213module mult_for (outcome,a,b);parameter size=8 ;output[2*size:1] outcome;input[size:1] a,b; //乘数reg[2*size:1] outcome; //积integer i;always @(a or b) begin outcome=0; for (i=1;i&lt;=size;i=i+1) if(b[i]) outcome=outcome+( a&lt;&lt;(i-1) ) ; endendmodule task、functiontask定义格式： 12345task&lt;任务名&gt; 端口与类型说明 局部变量说明 语句或语句块endtask 调用格式： &lt;任务名&gt;(port1，port2，port3,......) 函数function定义格式: 12345function &lt;返回值位宽或类型&gt; &lt;函数名&gt; 输入端口与类型说明 局部变量说明 语句或语句块endfunction 调用格式: &lt;函数名&gt; (&lt;输入表达式1&gt;,&lt;输入表达式2&gt;,&lt;输入表达式3&gt;,......) 1234567891011121314151617module function_example(i,out);input[7:0] in;output[2:0] out;reg[2:0] out; function[2:0] gefun; input[7:0] x; //输入端口说明 reg[2:0] count; integer i; begin count=0; for(i=0;i&lt;=7;i=i+1) if(x[i]==1'b0)count=count+1; gefun=count; end endfunction always @(in) out=gefun(in);//这里要注意的是 in要与x位宽相同endmodule Verilog中函数function声明，在声明的最后一句一般都是对结果赋值。也就是对函数名赋值。如上例中，函数名gefun，在声明最后一句就是对gefun的赋值。 编译预处理 `define `include `timescale 编译指令以”`”反引号开头。不同于整数的单引号，预编译使用的是反引号，一般在键盘的左上角。 顺序与并行 assign语句之间:并行执行（同时执行） 过程块之间（always、initial）：并行执行 assign语句与过程块之间：并行执行 过程块（initial、always）内部 串行块（begin-end）：顺序执行—非阻塞语句类似于并行语句 并行快（fork-join）：并行执行]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog HDL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[verilog实例]]></title>
    <url>%2F2016%2F03%2F23%2Fverilog_instance%2F</url>
    <content type="text"><![CDATA[模块（module）是Verilog 的基本描述单位，用于描述某个设计的功能或结构及与其他模块通信的外部端口。 模块在概念上可等同一个器件就如我们调用通用器件（与门、三态门等）或通用宏单元（计数器、ALU、CPU）等，因此，一个模块可在另一个模块中调用。 一个电路设计可由多个模块组合而成，因此一个模块的设计只是一个系统设计中的某个层次设计，模块设计可采用多种建模方式。 小程序加法器12345678module addr(a,b,cin,count,sum); input [2,0]a; input [2,0]b; input cin; output count; output [2,0]sum; assign &#123;count,sum&#125;=a+b+cinendmodule 上面的程序描述的是一个3位加法器，可以看出来，程序从module开始，以endmodule结束。 input [2,0]a 表示声明一个3bit的输入变量，命名为a assign {count，sum}=a+b+cin 表明为线网类型赋值，{}是连接符号，count是1bit，sum是3bit，所以连接之后是4bit，最高位是count。等式右边是2个3bit相加，再加上一个1bit的，实现的全加器。 比较器123456module compare （equal，a，b）；input [1:0] a,b; // declare the input signal ;output equare ; // declare the output signal;assign equare = (a == b) ? 1:0 ;/ * if a = b , output 1, otherwise 0；*/endmodule 逻辑部分是一个三目运算符号，有C语言基础的都可以看懂。 三态驱动器123456789101112131415module mytri (din, d_en, d_out); input din; input d_en; output d_out; // -- Enter your statements here -- // assign d_out = d_en ? din :'bz;endmodulemodule trist (din, d_en, d_out); input din; input d_en; output d_out; // --statements here -- // mytri u_mytri(din,d_en,d_out);endmodule 该例描述了一个三态驱动器。其中三态驱动门在模块 mytri 中描述，而在模块trist 中调用了模 mytri 。模块mytri 对trist 而言相当于一个已存在的器件，在trist 模块中对该器件进行实例化，实例化名 u_mytri 。 模块结构 模块内容是嵌在module 和endmodule两个语句之间。每个模块实现特定的功能，模块可进行层次的 套，因此可以将大型的数字电路设计分割成大小不一的小模块来实现特定的功能，最后通过由顶层模块调用子模块来实现整体功能，这就是Top-Down的设计思想. 模块包括接口描述部分和逻辑功能描述部分。这可以把模块与器件相类比。 模块的端口定义部分： 如上例： module addr (a, b, cin, count, sum); 其中module 是模块的保留字，addr 是模块的名字，相当于器件名。（）内是该模块的端口声明，定义了该模块的管脚名，是该模块与其他模块通讯的外部接口，相当于器件的pin 。模块的内容，包括I/O说明，内部信号、调用模块等的声明语句和功能定义语句。I/O说明语句如： input [2:0] a; input [2:0] b; input cin; output count; 其中input 、output、inout 是保留字，定义了管脚信号的流向，[n:0]表示该信号的位宽（总线或单根信号线）。 逻辑功能描述部分如： assign d_out = d_en ? din :’bz;mytri u_mytri(din,d_en,d_out); 功能描述用来产生各种逻辑（主要是组合逻辑和时序逻辑，可用多种方法进行描述），还可用来实例化一个器件，该器件可以是厂家的器件库也可以是我们自己用HDL设计的模块（相当于在原理图输入时调用一个库元件）。在逻辑功能描述中，主要用到assign 和always 两个语句。 对每个模块都要进行端口定义，并说明输入、输出口，然后对模块的功能进行逻辑描述，当然，对测试模块，可以没有输入输出口。 Verilog HDL 的书写格式自由，一行可以写几个语句，也可以一个语句分几行写。具体由代码书写规范约束。 除endmodule 语句外，每个语句后面需有分号表示该语句结束。 全加器一位全加器 如上图是一位全加器 这里先说明下什么是全加器，并说下全加器半加器的区别： 半加器不考虑低位过来的进位，只计算2个一位二进制数相加。产生一个本位和，还有一个向高位的进位信号。 全加器考虑低位过来的进位，计算2个一位二进制数相加。产生一个本位和，还有一个向高位的进位信号。 即半加器有二个输入，二个输出。全加器有三个输入，2个输出。 123456789101112131415module FA_struct (A, B, Cin, Sum, Count); input A; input B; input Cin; output Sum; output Count; wire S1, T1, T2, T3; // -- statements -- // xor x1 (S1, A, B); xor x2 (Sum, S1, Cin); and A1 (T3, A, B ); and A2 (T2, B, Cin); and A3 (T1, A, Cin); or O1 (Cout, T1, T2, T3 );endmodule 该实例显示了一个全加器由两个异或门、三个与门、一个或门构成。S1、T1、T2、T3则是门与门之间的连线。代码显示了用纯结构的建模方式，其中xor 、and、or 是Verilog HDL 内置的器件。以 xor x1 (S1, A, B) 该例化语句为例：xor 表明调用一个内置的异或门，器件名称xor ，代码实例化名x1（类似原理图输入方式）。括号内的S1，A，B 表明该器件管脚的实际连接线（信号）的名称，其中 A、B是输入，S1是输出。其他同。 两位全加器两位的全加器可通过调用两个一位的全加器来实现。该设计的设计层次示意图和结构图如下： 1234567891011121314151617181920212223module Four_bit_FA (FA, FB, FCin, FSum, FCout ) ; parameter SIZE = 2; input [SIZE:1] FA; input [SIZE:1] FB; input FCin; output [SIZE:1] FSum; output FCout; wire FTemp; FA_struct FA1( .A (FA[1]), .B (FB[1]), .Cin (FCin) , .Sum (FSum[1]), .Cout (Ftemp) ); FA_struct FA2( .A (FA[2]), .B (FB[2]), .Cin (FTemp) , .Sum (FSum[2]), .Cout (FCount ) );endmodule 除了低位的进位Fcin，输入FA与FB都是两位，将输入的两位分别放到两个一位全加器上面，就好像我们在做两位数加法时，也是将个位、十位分别相加，再加上进位。 该实例用结构化建模方式进行一个两位的全加器的设计，顶层模块Four_bit_FA 调用了两个一位的全加器 FA_struct 。在这里，以前的设计模块FA_struct 对顶层而言是一个现成的器件，顶层模块只要进行例化就可以了。注意这里的例化中，端口映射（管脚的连线）采用名字关联，如 .A （FA[2]） ，其中.A 表示 调用器件的管脚A，括号中的信号表示接到该管脚A的电路中的具体信号。wire 保留字表明信号Ftemp 是属线网类型（下面有具体描述）。 Verilog建模Verilog有三种建模方式，分别是 结构化描述方式 数据流描述方式 行为描述方式 其中数据流描述方式经常使用连续赋值语句，某个值被赋给某个网线变量。 assign [delay] net_name = expression; 注意在各assign 语句之间，是并行执行的，即各语句的执行与语句之间的顺序无关。 行为描述方式经常使用always、initial语句赋值。使用reg进行寄存器的声明。always是指一直在重复运行，由always后面括号的变量变化时触发。在always以及end之间是串行顺序执行的。 数据流型描述是一种描述组合逻辑功能的方法，用assign连续赋值语句来实现。]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog HDL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的numpy]]></title>
    <url>%2F2016%2F03%2F17%2Fnumpy%2F</url>
    <content type="text"><![CDATA[NumpyNumPy系统是Python的一种开源的数值计算扩展。这种工具可用来存储和处理大型矩阵，比Python自身的嵌套列表（nested list structure)结构要高效的多（该结构也可以用来表示矩阵（matrix））。据说NumPy将Python相当于变成一种免费的更强大的MatLab系统。 NumPy（Numeric Python）提供了许多高级的数值编程工具，如：矩阵数据类型、矢量处理，以及精密的运算库。专为进行严格的数字处理而产生。多为很多大型金融公司使用，以及核心的科学计算组织如：Lawrence Livermore，NASA用其处理一些本来使用C++，Fortran或Matlab等所做的任务。 多维数组多维数组的类型是：numpy.ndarray 使用numpy.array方法 以list或tuple变量为参数产生一维数组： 123456&gt;&gt;&gt; print(np.array([1,2,3,4]))[1 2 3 4]&gt;&gt;&gt; print(np.array((1.2,2,3,4)))[ 1.2 2. 3. 4. ]&gt;&gt;&gt; print type(np.array((1.2,2,3,4)))&lt;type 'numpy.ndarray'&gt; 以list或tuple变量为元素产生二维数组： 123&gt;&gt;&gt; print(np.array([[1,2],[3,4]]))[[1 2] [3 4]] 指定数据类型 例如numpy.int32, numpy.int16, and numpy.float64等： 12&gt;&gt;&gt; print np.array((1.2,2,3,4), dtype=np.int32)[1 2 3 4] 使用numpy.arange方法 123456789101112&gt;&gt;&gt; print(np.arange(15))[ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14]&gt;&gt;&gt; print type(np.arange(15))&lt;type 'numpy.ndarray'&gt;&gt;&gt;&gt; print np.arange(15).reshape(3,5)[[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14]]&gt;&gt;&gt; print type(np.arange(15).reshape(3,5))&lt;type 'numpy.ndarray'&gt; 使用numpy.linspace方法 例如，在从1到3中产生9个数： 123&gt;&gt;&gt; print(np.linspace(1,3,10))[ 1. 1.22222222 1.44444444 1.66666667 1.88888889 2.11111111 2.33333333 2.55555556 2.77777778 3. ] 使用numpy.zeros，numpy.ones，numpy.eye 可以构造特定的矩阵 12345678910111213141516&gt;&gt;&gt; print(np.zeros((3,4)))[[ 0. 0. 0. 0.] [ 0. 0. 0. 0.] [ 0. 0. 0. 0.]]&gt;&gt;&gt; print(np.ones((4,3)))[[ 1. 1. 1.] [ 1. 1. 1.] [ 1. 1. 1.] [ 1. 1. 1.]]&gt;&gt;&gt; print(np.eye(4))[[ 1. 0. 0. 0.] [ 0. 1. 0. 0.] [ 0. 0. 1. 0.] [ 0. 0. 0. 1.]] 创建一个三维数组： 123456789101112&gt;&gt;&gt; print(np.ones((3,3,3)))[[[ 1. 1. 1.] [ 1. 1. 1.] [ 1. 1. 1.]] [[ 1. 1. 1.] [ 1. 1. 1.] [ 1. 1. 1.]] [[ 1. 1. 1.] [ 1. 1. 1.] [ 1. 1. 1.]]] 获取数组的属性1234567891011&gt;&gt;&gt; a = np.zeros((2,3,2))&gt;&gt;&gt; print(a.ndim) #数组的维数3&gt;&gt;&gt; print(a.shape) #数组每一维的大小(2, 3, 2)&gt;&gt;&gt; print(a.size) #数组的元素数12&gt;&gt;&gt; print(a.dtype) #元素类型float64&gt;&gt;&gt; print(a.itemsize) #每个元素所占的字节数8 数组索引，切片，赋值 1234567891011121314&gt;&gt;&gt;a = np.array( [[2,3,4],[5,6,7]] )&gt;&gt;&gt; print(a)[[2 3 4] [5 6 7]]&gt;&gt;&gt; print(a[1,2]) #index从0开始7&gt;&gt;&gt; print a[1,:][5 6 7]&gt;&gt;&gt; print(a[1,1:2])[6]&gt;&gt;&gt; a[1,:] = [8,9,10] #直接赋值&gt;&gt;&gt; print(a)[[ 2 3 4] [ 8 9 10]] 使用for操作元素 123456&gt;&gt;&gt; for x in np.linspace(1,3,3):... print(x)...1.02.03.0 基本的数组运算 先构造数组a、b： 12345678&gt;&gt;&gt; a = np.ones((2,2))&gt;&gt;&gt; b = np.eye(2)&gt;&gt;&gt; print(a)[[ 1. 1.] [ 1. 1.]]&gt;&gt;&gt; print(b)[[ 1. 0.] [ 0. 1.]] 数组的加减乘除 123456789101112131415161718192021&gt;&gt;&gt; print(a &gt; 2)[[False False] [False False]]&gt;&gt;&gt; print(a+b)[[ 2. 1.] [ 1. 2.]]&gt;&gt;&gt; print(a-b)[[ 0. 1.] [ 1. 0.]]&gt;&gt;&gt; print(b*2)[[ 2. 0.] [ 0. 2.]]&gt;&gt;&gt; print((a*2)*(b*2))[[ 4. 0.] [ 0. 4.]]&gt;&gt;&gt; print(b/(a*2))[[ 0.5 0. ] [ 0. 0.5]]&gt;&gt;&gt; print((b*2)**4)[[ 16. 0] [ 0 16.]] 使用数组对象自带的方法 12345678&gt;&gt;&gt; a.sum() #a的元素个数4.0&gt;&gt;&gt; a.sum(axis=0) #计算每一列（二维数组中类似于矩阵的列）的和array([ 2., 2.])&gt;&gt;&gt; a.min()1.0&gt;&gt;&gt; a.max()1.0 使用numpy下的方法 1234567891011121314&gt;&gt;&gt; np.sin(a)array([[ 0.84147098, 0.84147098], [ 0.84147098, 0.84147098]])&gt;&gt;&gt; np.max(a)1.0&gt;&gt;&gt; np.floor(a)array([[ 1., 1.], [ 1., 1.]])&gt;&gt;&gt; np.exp(a)array([[ 2.71828183, 2.71828183], [ 2.71828183, 2.71828183]])&gt;&gt;&gt; np.dot(a,a) ##矩阵乘法array([[ 2., 2.], [ 2., 2.]]) 合并数组 使用numpy下的vstack和hstack函数： 123456789101112&gt;&gt;&gt; a = np.ones((2,2))&gt;&gt;&gt; b = np.eye(2)&gt;&gt;&gt; print(np.vstack((a,b)))#顾名思义 v--vertical 垂直[[ 1. 1.] [ 1. 1.] [ 1. 0.] [ 0. 1.]]&gt;&gt;&gt; print(np.hstack((a,b)))#顾名思义 h--horizonal 水平[[ 1. 1. 1. 0.] [ 1. 1. 0. 1.]] 看一下这两个函数有没有涉及到浅拷贝这种问题： 123456789&gt;&gt;&gt; c = np.hstack((a,b))&gt;&gt;&gt; print c[[ 1. 1. 1. 0.] [ 1. 1. 0. 1.]]&gt;&gt;&gt; a[1,1] = 5&gt;&gt;&gt; b[1,1] = 5&gt;&gt;&gt; print c[[ 1. 1. 1. 0.] [ 1. 1. 0. 1.]] 可以看到，a、b中元素的改变并未影响c。 深拷贝数组 数组对象自带了浅拷贝和深拷贝的方法，但是一般用深拷贝多一些： 1234567&gt;&gt;&gt; a = np.ones((2,2))&gt;&gt;&gt; b = a&gt;&gt;&gt; print(b is a)True&gt;&gt;&gt; c = a.copy() #深拷贝&gt;&gt;&gt; c is aFalse 基本的矩阵运算 转置： 1234567&gt;&gt;&gt; a = np.array([[1,0],[2,3]])&gt;&gt;&gt; print(a)[[1 0] [2 3]]&gt;&gt;&gt; print(a.transpose())[[1 2] [0 3]] 迹： 12&gt;&gt;&gt; print(np.trace(a))4 numpy.linalg关于矩阵运算的方法 &gt;&gt;&gt; import numpy.linalg as nplg 特征值、特征向量： 123&gt;&gt;&gt; print nplg.eig(a)(array([ 3., 1.]), array([[ 0. , 0.70710678], [ 1. , -0.70710678]])) 矩阵对象numpy模块中的矩阵对象为numpy.matrix，包括矩阵数据的处理，矩阵的计算，以及基本的统计功能，转置，可逆性等等，包括对复数的处理，均在matrix对象中。 class numpy.matrix(data,dtype,copy): 返回一个矩阵，其中data为ndarray对象或者字符形式； dtype:为data的type； copy:为bool类型。 1234567891011&gt;&gt;&gt; a = np.matrix('1 2 7; 3 4 8; 5 6 9')&gt;&gt;&gt; a #矩阵的换行必须是用分号(;)隔开，内部数据必须为字符串形式(‘ ’)，矩matrix([[1, 2, 7], #阵的元素之间必须以空格隔开。[3, 4, 8],[5, 6, 9]])&gt;&gt;&gt; b=np.array([[1,5],[3,2]])&gt;&gt;&gt; x=np.matrix(b) #矩阵中的data可以为数组对象。&gt;&gt;&gt; xmatrix([[1, 5],[3, 2]]) 矩阵对象的属性 matrix.T transpose ：返回矩阵的转置矩阵 matrix.H hermitian (conjugate) transpose ：返回复数矩阵的共轭元素矩阵 matrix.I inverse ：返回矩阵的逆矩阵 matrix.A base array ：返回矩阵基于的数组 矩阵对象的方法 all([axis, out]) :沿给定的轴判断矩阵所有元素是否为真(非0即为真) any([axis, out]) :沿给定轴的方向判断矩阵元素是否为真，只要一个元素为真则为真。 argmax([axis, out]) :沿给定轴的方向返回最大元素的索引（最大元素的位置）. argmin([axis, out]): 沿给定轴的方向返回最小元素的索引（最小元素的位置） argsort([axis, kind, order]) :返回排序后的索引矩阵 astype(dtype[, order, casting, subok, copy]):将该矩阵数据复制，且数据类型为指定的数据类型 byteswap(inplace) Swap the bytes of the array elements choose(choices[, out, mode]) :根据给定的索引得到一个新的数据矩阵（索引从choices给定） clip(a_min, a_max[, out]) :返回新的矩阵，比给定元素大的元素为a_max，小的为a_min compress(condition[, axis, out]) :返回满足条件的矩阵 conj() :返回复数的共轭复数 conjugate() :返回所有复数的共轭复数元素 copy([order]) :复制一个矩阵并赋给另外一个对象，b=a.copy() cumprod([axis, dtype, out]) :返回沿指定轴的元素累积矩阵 cumsum([axis, dtype, out]) :返回沿指定轴的元素累积和矩阵 diagonal([offset, axis1, axis2]) :返回矩阵中对角线的数据 dot(b[, out]) :两个矩阵的点乘 dump(file) :将矩阵存储为指定文件,可以通过pickle.loads()或者numpy.loads()如:a.dump(‘d:\a.txt’) dumps() :将矩阵的数据转存为字符串. fill(value) :将矩阵中的所有元素填充为指定的value flatten([order]) :将矩阵转化为一个一维的形式，但是还是matrix对象 getA() :返回自己，但是作为ndarray返回 getA1()：返回一个扁平（一维）的数组（ndarray） getH() :返回自身的共轭复数转置矩阵 getI() :返回本身的逆矩阵 getT() :返回本身的转置矩阵 max([axis, out]) ：返回指定轴的最大值 mean([axis, dtype, out]) :沿给定轴方向，返回其均值 min([axis, out]) ：返回指定轴的最小值 nonzero() :返回非零元素的索引矩阵 prod([axis, dtype, out]) :返回指定轴方型上，矩阵元素的乘积. ptp([axis, out]) :返回指定轴方向的最大值减去最小值. put(indices, values[, mode]) :用给定的value替换矩阵本身给定索引（indices）位置的值 ravel([order]) :返回一个数组，该数组是一维数组或平数组 repeat(repeats[, axis]) :重复矩阵中的元素，可以沿指定轴方向重复矩阵元素，repeats为重复次数 reshape(shape[, order]) :改变矩阵的大小,如：reshape([2,3]) resize(new_shape[, refcheck]) :改变该数据的尺寸大小 round([decimals, out]) :返回指定精度后的矩阵，指定的位数采用四舍五入，若为1，则保留一位小数 searchsorted(v[, side, sorter]) :搜索V在矩阵中的索引位置 sort([axis, kind, order]) :对矩阵进行排序或者按轴的方向进行排序 squeeze([axis]) :移除长度为1的轴 std([axis, dtype, out, ddof]) :沿指定轴的方向，返回元素的标准差. sum([axis, dtype, out]) ：沿指定轴的方向，返回其元素的总和 swapaxes(axis1, axis2):交换两个轴方向上的数据. take(indices[, axis, out, mode]) :提取指定索引位置的数据,并以一维数组或者矩阵返回(主要取决axis) tofile(fid[, sep, format]) :将矩阵中的数据以二进制写入到文件 tolist() :将矩阵转化为列表形式 tostring([order]):将矩阵转化为python的字符串. trace([offset, axis1, axis2, dtype, out]):返回对角线元素之和 transpose(*axes) :返回矩阵的转置矩阵，不改变原有矩阵 var([axis, dtype, out, ddof]) ：沿指定轴方向，返回矩阵元素的方差 view([dtype, type]) :生成一个相同数据，但是类型为指定新类型的矩阵。 举例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&gt;&gt;&gt; a = np.asmatrix('0 2 7; 3 4 8; 5 0 9')&gt;&gt;&gt; a.all()False&gt;&gt;&gt; a.all(axis=0)matrix([[False, False, True]], dtype=bool)&gt;&gt;&gt; a.all(axis=1)matrix([[False],[ True],[False]], dtype=bool)Astype方法&gt;&gt;&gt; a.astype(float)matrix([[ 12., 3., 5.],[ 32., 23., 9.],[ 10., -14., 78.]])Argsort方法&gt;&gt;&gt; a=np.matrix('12 3 5; 32 23 9; 10 -14 78')&gt;&gt;&gt; a.argsort()matrix([[1, 2, 0],[2, 1, 0],[1, 0, 2]])Clip方法&gt;&gt;&gt; amatrix([[ 12, 3, 5],[ 32, 23, 9],[ 10, -14, 78]])&gt;&gt;&gt; a.clip(12,32)matrix([[12, 12, 12],[32, 23, 12],[12, 12, 32]])Cumprod方法&gt;&gt;&gt; a.cumprod(axis=1)matrix([[ 12, 36, 180],[ 32, 736, 6624],[ 10, -140, -10920]])Cumsum方法&gt;&gt;&gt; a.cumsum(axis=1)matrix([[12, 15, 20],[32, 55, 64],[10, -4, 74]])Tolist方法&gt;&gt;&gt; b.tolist()[[12, 3, 5], [32, 23, 9], [10, -14, 78]]Tofile方法&gt;&gt;&gt; b.tofile('d:\\b.txt')compress()方法&gt;&gt;&gt; from numpy import *&gt;&gt;&gt; a = array([10, 20, 30, 40])&gt;&gt;&gt; condition = (a &gt; 15) &amp; (a &lt; 35)&gt;&gt;&gt; conditionarray([False, True, True, False], dtype=bool)&gt;&gt;&gt; a.compress(condition)array([20, 30])&gt;&gt;&gt; a[condition] # same effectarray([20, 30])&gt;&gt;&gt; compress(a &gt;= 30, a) # this form aso existsarray([30, 40])&gt;&gt;&gt; b = array([[10,20,30],[40,50,60]])&gt;&gt;&gt; b.compress(b.ravel() &gt;= 22)array([30, 40, 50, 60])&gt;&gt;&gt; x = array([3,1,2])&gt;&gt;&gt; y = array([50, 101])&gt;&gt;&gt; b.compress(x &gt;= 2, axis=1) # illustrates the use of the axis keywordarray([[10, 30],[40, 60]])&gt;&gt;&gt; b.compress(y &gt;= 100, axis=0)array([[40, 50, 60]])]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Numpy</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib快速绘图]]></title>
    <url>%2F2016%2F03%2F17%2FMatplotlib%E5%BF%AB%E9%80%9F%E7%BB%98%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[Matplotlibmatplotlib 是python最著名的绘图库，它提供了一整套和matlab相似的命令API，十分适合交互式地行制图。而且也可以方便地将它作为绘图控件，嵌入GUI应用程序中。 优势作为python上最有名气的绘图库: Matlab的语法 python语言 latex的画图质量 可以使用内嵌的latex引擎绘制的数学公式 快速绘图matplotlib实际上是一套面向对象的绘图库，它所绘制的图表中的每个绘图元素，例如线条Line2D、文字Text、刻度等在内存中都有一个对象与之对应。 为了方便快速绘图matplotlib通过pyplot模块提供了一套和MATLAB类似的绘图API，将众多绘图对象所构成的复杂结构隐藏在这套API内部。我们只需要调用pyplot模块所提供的函数就可以实现快速绘图以及设置图表的各种细节。pyplot模块虽然用法简单，但不适合在较大的应用程序中使用。 为了将面向对象的绘图库包装成只使用函数的调用接口，pyplot模块的内部保存了当前图表以及当前子图等信息。当前的图表和子图可以使用plt.gcf()和plt.gca()获得，分别表示“Get Current Figure”和“Get Current Axes”。在pyplot模块中，许多函数都是对当前的Figure或Axes对象进行处理 plt.plot()实际上会通过plt.gca()获得当前的Axes对象ax，然后再调用ax.plot()方法实现真正的绘图 柱状图横向 1234567891011121314import matplotlib.pyplot as pltplt.rcdefaults()import numpy as nppeople = ('James', 'Durant', 'Kobe', 'Wade', 'Curry','Magic','Hardan')y_pos = np.arange(len(people))performance = 3 + 10 * np.random.rand(len(people)) #随机产生len(people)个 [0,1）的数error = np.random.rand(len(people))plt.barh(y_pos, performance, xerr=error, align='center', alpha=0.4)#这里是产生横向柱状图 barh h--horizontalplt.yticks(y_pos, people)plt.xlabel('Performance')plt.title('How efficient do you want to go today?')plt.savefig("barh.png",format="png") 纵向 12345678910people = ('James', 'Durant', 'Kobe', 'Wade', 'Curry','Magic','Hardan')x_pos = np.arange(len(people))performance = 5 + 10 * np.random.rand(len(people)) #随机产生len(people)个 [0,1）的数error = np.random.rand(len(people))/4plt.bar(x_pos, performance, xerr=error, align='center', alpha=0.4)plt.xticks(x_pos, people)plt.ylabel('Performance')plt.title('How efficient do you want to go today?')plt.savefig("bar.png",format="png") 解析plt.rcdefaults() 恢复 rc 的默认设置 barh() 主要功能 ：做一个横向条形图，横向条的矩形大小为: left, left + width, bottom, bottom + height bar() 主要功能 ：做一个纵向条形图，纵向条的矩形大小为: left, left + width, bottom, bottom + height 参数 ：barh ( bottom , width , height =0.8, left =0, ** kwargs ) ：bar ( bottom , width , height =0.8, left =0, ** kwargs ) 返回类型 ：一个 class 类别，matplotlib.patches.Rectangle实例 参数说明： bottom: Bars 的垂直位置的底部边缘 width: Bars 的长度 可选参数： height: bars 的高度 left: bars 左边缘 x 轴坐标值 color: bars 颜色 edgecolor: bars 边缘颜色 linewidth: bar 边缘宽度;None 表示默认宽度;0 表示不 i 绘制边缘 xerr: 若不为 None,将在 bar 图上生成 errobars yerr: 若不为 None,将在 bar 图上生成 errobars ecolor: 指定 errorbar 颜色 capsize: 指定 errorbar 的顶部(cap)长度 align: edge (默认) | center:edge以底部为准对齐;center以 y 轴作为中心 log: [False|True] False (默认),若为 True,使用 log 坐标 图形填充 123456789import numpy as npimport matplotlib.pyplot as pltx = np.linspace(0, 1)y = np.sin(3 * np.pi * x) * np.exp(-7 * x)plt.fill(x, y, 'c')plt.grid(True)plt.savefig("fill.png",format="png") Tip： grid 表示是否显示图轴网格。函数原型 matplotlib.pyplot.grid(b=None, which=’major’, axis=’both’, **kwargs) 调用形式： grid(self, b=None, which=’major’, axis=’both’, **kwargs) 主要参数： b： [True|False]或者是布尔数组、或[‘on’,‘off’] 表示网格是否开启 which： [major(默认)|minor|both] 选择主、次网格开启方式 axis： [both(默认)|x|y] 选择使用网格的数轴 12345x = np.linspace(0, 3 * np.pi, 100)y1 = np.sin(x)y2 = np.sin(3 * x)plt.fill(x, y1, 'b', x, y2, 'c', alpha=0.7)plt.savefig("features.png",format="png") Tip： alpha 表示透明度，0表示全透明，1表示完全不透明。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[洗白BT文件]]></title>
    <url>%2F2016%2F03%2F16%2Falter_torrent%2F</url>
    <content type="text"><![CDATA[写在前面接着上篇文章，torrent文件编码.在torrent文件编码这篇文章的开始我就说过，种子文件对于青年男士有着巨大的诱惑力。我也不例外，由于国内文化教育方面抓的比较紧，所以某些领域的文件信息无法通过种子文件离线下载、进入高速通道。这个实现的原理很简单，直接通过扫描种子文件的tracker、服务器地址显然不可取，那就遍历torrent包含的文件名吧，这些文件往往会有很多露骨的字眼，净网行动进行了这么多年，文化教育领域对付这一套显然很有心得。 下面我们就先看一下torrent文件包含的文件吧，当然不是通过BT下载器：） libtorrent不造轮子，从我做起。网络上已经有大牛们制作的torrent库，其中最流行的应该就是libtorrent。 LibTorrent 是一个C++ 语言的 BitTorrent 开发库，支持 Linux/Unix 系统。旨在提供高性能和良好代码风格的 BT 开发包。该开发包与其他包不同的是，它直接通过网络堆栈抓取文件页，因此性能是官方客户端的三倍。 libtorrent的python版本： Building the libtorrent python bindings will produce a shared library (DLL) which is a python module that can be imported in a python program. libtorrent API的中文翻译戳这里,当然没有python版本的API文件，不过既然已经安装了libtorrent的python binding，熟悉C++的API也是必做的一步。有条件的筒子们还是建议去读英文版的API吧Here，虽然我也不知道为什么这样推荐。 库安装win平台的msi文件 推荐直接使用msi文件安装，libtorrent支持python2.x版本，直接使用libtorrent组织提供的python bind无法正常安装 torrent_info上篇文章已经介绍了torrent文件包含的基本结构，一般来讲，简单的torrent文件有以下内容: info 包含文件的信息files、torrent显示的文件名name、发行商publisher-url。注意这里torrent文件名并不是那个我们可以简单通过重命名定义的name，而是torrent指向的那个大的文件或者文件夹名。 comment 种子文件的注释 encoding 目前一般为utf-8 creation date 该关键字对应的值存放的是种子文件创建的时间 announce-list 存放的是备用Tracker的URL created by 值存放生成种子文件的BT客户端软件的信息，如客户端名、版本号 nodes 包含一系列ip和相应端口的列表，是用于连接DHT初始node。 announce Tracker的URL 其中我们最常用的信息就是info字段，里面包含我们需要的大部分信息。 种子文件分为单文件种子以及多文件种子： 单文件 name 要下载的文件名字 length 要下载文件的大小（单位为byte） piece length 要下载文件按照piece length指定大小分片，此处指明单个分片大小。 pieces 存储每个分片的SHA1值(每个SHA1的hash长度为20byte) 多文件 files 表示该torrent为多文件形式，每个文件都是dictionary类型数据表示。 name 表示多个文件存储在以name命名的文件夹。 length 要下载文件的大小（单位为byte） path 指出要下载文件存储相对于name字段表示的文件夹的位置。 假设name为dir1，此时： 如果path值为file1.rmvb，表示file1.rmvb的存储路径为dir1\file1.rmvb 如果path值为dir2\file1.rmvb，表示file1.rmvb的存储路径为dir1\dir2\file1.rmvb piece length 要下载文件安装piece length指定大小分片，此处指明单个分片大小。 pieces 存储每个分片的SHA1值（每个SHA1的hash长度为20字节） 下面是子啊python下使用libtorrent库对torrent文件的操作: 12345678910111213141516# -*- coding: utf-8 -*-import libtorrent as ltbt=lt.torrent_info(filepath)bt.files()#返回一个包含文件的列表bt.nodes()#返回DHT初始nodebt.name()#返回torrent文件名bt.pieces()#分片SHA1值 洗白123456789101112131415161718192021222324252627282930313233343536373839404142434445s= lt.bdecode(open(filepath, 'rb').read())#通过对应的解码算法获取torrent文件的内容# 修改说明文件for item in s: if len(re.findall('comment.*?',item)): s[item]=str(s[item].__hash__())#修改torrent文件名，保持了原来的文件格式def alertFileName(dic): for i in dic: if len(re.findall('(name).*?',i)): if dic[i].find('.')&lt;0: dic[i]='[peihao.space]'+str(b'x')+str(path.__hash__()) else : tem=dic[i].split('.') tem[len(tem)-1]=(re.findall('(\w+).*?',tem[len(tem)-1]))[0] dic[i]='[peihao.space]'+str(b'a')+str(tem[0].__hash__())+"."+tem[len(tem)-1]#判断种子文件是否是多文件结构def isMultiFiles(dict): for i in dict['info']: if i=='files': return True return False#深度修改所有包含文件的名字 并保持原有文件格式def deepSetFilesName(dict): for item in dict:#item是一个个包含文件信息的序列 for info in item: if len(re.findall('(path).*?',info)): for i in range(0,len(item[info])): path=item[info][i] if path.find('.')&lt;0: item[info][i]='[peihao.space]'+str(b'x')+str(path.__hash__()) else : tem=path.split('.') tem[len(tem)-1]=(re.findall('(\w+).*?',tem[len(tem)-1]))[0] item[info][i]='[peihao.space]'+str(b'a')+str(tem[0].__hash__())+"."+tem[len(tem)-1]# 种子转磁力链def bt2mag(name): bt=lt.torrent_info(name) return "magnet:?xt=urn:btih:%s&amp;dn=%s" % (bt.info_hash(), bt.name()) 效果将生成的种子洗白程序用Tk造了一个壳子，效果如下 原来的torrent内容: generate之后内容: 程序下载戳这里1 或者这里:) 有多个版本python时，使用各自版本的Script一定要注意，像如果我要使用pyinstaller这个软件生成exe，最好在环境变量中先将想使用的有关python版本的路径放置在最前面 1pyinstaller -i=favicon.ico -F -w torrent.py 因为这里不止要保证pyinstaller的版本正确（可以用 绝对路径/pyinstaller.exe确认），隐式的python版本没办法显式设定，所以把在环境变量中的路径先更新，使用完之后在还原即可。]]></content>
      <categories>
        <category>torrent</category>
      </categories>
      <tags>
        <tag>torrent</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[torrent文件编码]]></title>
    <url>%2F2016%2F03%2F14%2Ftorrent%2F</url>
    <content type="text"><![CDATA[Torrent小记由于某些众所周知的原因，我对torrent文件(也就是我们常说的种子文件)产生了浓厚的兴趣，这里是官方百科对torrent文件的定义： torrent文件本质上是文本文件，包含Tracker信息和文件信息两部分。Tracker信息主要是BT下载中需要用到的Tracker服务器的地址和针对Tracker服务器的设置，文件信息是根据对目标文件的计算生成的，计算结果根据BitTorrent协议内的B编码规则进行编码。所以，torrent文件就是被下载文件的“索引”。 既然是文本文件，使用文本编辑器，意料之中的失败，打开之后是大片大片的乱码，当然主要是中文乱码… 数字以及字母信息还是显示的相当完整的。也许当我打开一个纯英文Tracker信息的torrent文件时，就可以很清楚的了解其中的内容了。现在先来看一下torrent文件的编码格式. bencoding编码BT种子文件使用了一种叫bencoding的编码方法来保存数据。 bencoding现有四种类型的数据：srings(字符串)，integers(整数)，lists(列表)，dictionaries(字典) 编码规则如下： strings(字符串) 123456编码为：&lt;字符串长度&gt;：&lt;字符串&gt;例如： 4:test 表示为字符串"test"4:例子 表示为字符串“例子”字符串长度单位为字节没开始或结束标记 integers(整数) 123456789编码为：i&lt;整数&gt;e开始标记i，结束标记为e例如： i1234e 表示为整数1234i-1234e 表示为整数-1234整数没有大小限制i0e 表示为整数0i-0e 为非法以0开头的为非法如： i01234e 为非法 lists(列表) 1234编码为：l&lt;bencoding编码类型&gt;e开始标记为l,结束标记为e列表里可以包含任何bencoding编码类型，包括整数，字符串，列表，字典。例如： l4:test5abcdee 表示为二个字符串["test","abcde"] dictionaries(字典) 123456编码为d&lt;bencoding字符串&gt;&lt;bencoding编码类型&gt;e 开始标记为d,结束标记为e关键字必须为bencoding字符串值可以为任何bencoding编码类型例如： d3:agei20ee 表示为&#123;"age"=20&#125;d4:path3:C:\8:filename8:test.txte 表示为&#123;"path"="C:\","filename"="test.txt"&#125; Torrent文件基本结构种子具体文件结构如下： 全部内容必须都为bencoding编码类型。 如果字典用{}表示，列表用[]表示，字符用””表示，目录类型的BT文件大致是这样的 12345678910111213141516171819202122232425&#123;"announce"="http://btfans.3322.org:8000/announce" ;tracker 服务器的URL(字符串)"announce-list"=["http://..","http://.."] ;备用tracker服务器列表(列表)"creation date"=1175204110 ;种子创建的时间，Unix标准时间格式"encoding"="GBK" ;编码"comment"="备注""created by"="创建人信息"&#123;"info"=&#123;"files"=[&#123;"filehash"="SHA1 Hash","length"=168099584,"path"=["01.rmvb"]&#125;, &#123;...&#125;, &#123;...&#125; ] "name"="保存目录名" "piece length"=2097152 ；每个块的大小，单位字节(整数) "pieces"="每个块的SHA1 Hash的值的顺序排列(二进制格式,长度为"20 X 块数")" &#125;&#125;&#125; 其中，filehash为20个字节的二进制的SHA1 Hash 需要下载文件的主要信息保存在&#39;info&#39;值中，可以逐字解码。]]></content>
      <categories>
        <category>torrent</category>
      </categories>
      <tags>
        <tag>torrent</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Verilog小叙(三)]]></title>
    <url>%2F2016%2F03%2F09%2Fverilog_hdl3%2F</url>
    <content type="text"><![CDATA[好的，接着上篇文章Verilog小叙(二) 数据流建模之前的介绍中，我们已经初步了解到数据流描述方式，本节对数据流的建模方式进一步讨论，主要讲述连续赋值语句、阻塞赋值语句、非阻塞赋值语句，并针对一个系统设计频率计数器的实例进行讲解。 连续赋值语句数据流的描述是采用连续赋值语句(assign )语句来实现的。语法如下：assign net_type = 表达式；连续赋值语句用于组合逻辑的建模。 等式左边是wire 类型的变量。等式右边可以是常量、由运算符如逻辑运算符、算术运算符参与的表达。如下几个实例： 1234567wire [3:0] Z, preset,clear; //线网说明assign z = preset &amp; clear; //连续赋值语句wire cout, cin ;wire [3:0] sum, a, bB;. . .assign &#123;cout,sum&#125; = a + b + cin;assign mux = (s == 3)? d : 'bz; 注意如下几个方面： 连续赋值语句的执行是：只要右边表达式任一个变量有变化，表达式立即被计算，计算的结果立即赋给左边信号。 连续赋值语句之间是并行语句，因此与位置顺序无关。 Tips：实际电路中赋值语句的执行其实会有ps级别的延迟，这个延迟是线、门器件本身特性造成的，不过只要是同步电路，那么ps级别延迟就可以忽略不计，因为后续的寄存器是在时钟上升沿采样，ps级别延迟和一个典型的时钟周期来比，完全不用考虑。 阻塞赋值语句“=”用于阻塞的赋值，凡是在组合逻辑（如在assign 语句中）赋值的请用阻塞赋值。阻塞赋值“=”在begin 和end 之间的语句是顺序执行，属于串行语句说明：always语句的敏感变量如果不含有时钟，即always（*）这样描述，那么也属于组合逻辑，需要使用阻塞赋值。一个组合逻辑的例子： 12345678always @(*) beginif ( new_vld_after == 1'b1 )port_win = new_port_after ;else if ( new_vld_before ==1'b1 )port_win = new_port_before ;elseport_win = last_sel_port ;end//阻塞赋值在begin-end之间串行执行 非阻塞赋值语句“&lt;=”用于阻塞的赋值，凡是在时序逻辑（如在always语句中）赋值的请用非阻塞赋值，非阻塞赋值“&lt;=”在begin和end之间的语句是并行执行，属于并行执语句。 Tips： 时序逻辑值的是带有时钟的always块逻辑，只有always带有时钟，那么这个逻辑才能是寄存器。一个时序逻辑的例子：123456always @(posedge sys_clk or negedge sys_rst_n) beginif (sys_rst_n ==1'b0)clk_cnt &lt;= 26'b0;elseclk_cnt &lt;= clk_cnt + 26'b1;end 数据流建模具体实例以上面的频率计数器为例，其中的AND2模块我们用数据流来建模。 AND2模块对应文件AND2.v 的内容如下： 123456789module AND2 (A0, A1, Y);input A0;input A1;output Y;wire A0;wire A1;wire Y;assign Y = A0 &amp; A1;//连续赋值语句endmodule 行为建模在第四节中，我们已经对行为描述方式有个概念，这里对行为建模进一步的描述，并通过一个系统设计频率计数器加以巩固。 简介行为建模方式是通过对设计的行为的描述来实现对设计建模，一般是指用过程赋值语句（initial语句和always语句）来设计的称为行为建模。 顺序语句块语句块提供将两条或更多条语句组合成语法结构上相当于一条语句的机制。这里主要讲Verilog HDL的顺序语句块(begin . . . end)：语句块中的语句按给定次序顺序执行。顺序语句块中的语句按顺序方式执行。每条语句中的时延值与其前面的语句执行的模拟时间相关。一旦顺序语句块执行结束，跟随顺序语句块过程的下一条语句继续执行。顺序语句块的语法如下： 123begin [:block_id&#123;declarations&#125;]procedural_statement (s)end 例如：123456789// 产生波形:begin #2 Stream = 1; #5 Stream = 0; #3 Stream = 1; #4 Stream = 0; #2 Stream = 1; #5 Stream = 0;end 假定顺序语句块在第10个时间单位开始执行。两个时间单位后第1条语句执行，即第12个时间单位。此执行完成后，下1条语句在第17个时间单位执行(延迟5 个时间单位)。然后下1条语句在第20个时间单位执行，以此类推。该顺序语句块执行过程中产生的波形如图： 过程赋值语句Verilog HDL中提供两种过程赋值语句initial和always语句，用这两种语句来实现行为的建模。这两种语句之间的执行是并行的，即语句的执行与位置顺序无关。这两种语句通常与语句块（begin ….end）相结合，则语句块中的执行是按顺序执行的。 initial 语句 initial语句只执行一次，即在设计被开始模拟执行时开始（0时刻）。通常只用在对设计进行仿真的测试文件中，用于对一些信号进行初始化和产生特定的信号波形。语法如下：（大家只要先有个概念就可以） 123456789101112initial[timing_control] procedural_statementprocedural_statement 是下列语句之一：procedural_assignment(blocking or non-blocking) //阻塞或非阻塞性过程赋值语句procedural_continuous_assignmentconditional_statementcase_statementloop_statementwait_statementdisable_statementevent_triggertask_enable (user or system) 例子如上产生一个信号波形： 123456789initialbegin#2 Stream = 1;#5 Stream = 0;#3 Stream = 1;#4 Stream = 0;#2 Stream = 1;#5 Stream = 0;end 说明：initial只能使用在仿真中，是不可综合语法，很多初学者在开始的时候以为initial是可以综合的。 always 语句 always语句与initial语句相反，是被重复执行，执行机制是通过对一个称为敏感变量表的事件驱动来实现的，下面会具体讲到。always 语句可实现组合逻辑或时序逻辑的建模。例子1： 1234initialclk = 0 ；always#5 clk = ~clk； 因为always 语句是重复执行的，因此，clk是初始值为0 的，周期为10 的方波。例子2： D触发器 1234567//并行执行always @ ( posedge clk or negedge rst ) begin if （ rst == 1’b0 ）//当rst为0时 q &lt;= ‘ b 0; else q &lt;= d;end 上面括号内的内容称为敏感变量，即整个always 语句当敏感变量有变化时被执行，否则不执行。因此，当rst为0时，q被复位，在时钟上升沿时，d被采样到q。 例子3： 2选一的分配器 always @( sel ，a ，b）c = sel ? a ：b； 这里的sel ，a，b 同样称为敏感变量，当三者之一有变化时，always 被执行，当sel 为 1 ，c被赋值为a ，否则为b 。描述的是一个组合逻辑 mux 器件。说明：Verilog 2001语法定义敏感变量可以使用“*”代替，例子3的2 选一的分配器可以这样写：：12always @(*）c = sel ? a ：b； 此处强烈建议大家使用*替代敏感变量，减少错误发生。 Tips: 对组合逻辑的always 语句，敏感变量建议使用*替代。 对组合逻辑器件的赋值采用阻塞赋值 “=”。 时序逻辑器件的赋值语句采用非阻塞赋值 “&lt;=”； 状态机有限状态机英文名字，Finite State Machine，简称状态机，缩写为FSM。 有限状态机是指输出取决于过去输入部分和当前输入部分的时序逻辑电路。有限状态机又可以认为是组合逻辑和寄存器逻辑的一种组合。状态机特别适合描述那些发生有先后顺序或者有逻辑规律的事情，其实这就是状态机的本质。状态机就是对具有逻辑顺序或时序规律的事件进行描述的一种方法 根据状态机的输出是否与输入条件相关，可将状态机分为两大类，即摩尔 (Moore) 型状态机和米勒 (Mealy) 型状态机。 Mealy状态机：时序逻辑的输出不仅取决于当前状态，还取决于输入。 Moore状态机：时序逻辑的输出只取决于当前。 根据实际写法，状态机还可以分为一段式、二段式和三段式状态机。 一段式： 把整个状态机写在一个always模块中， 并且这个模块既包含状态转移，又含有组合逻辑输入 /输出 。 二段式： 状态切换用时序逻辑，次态输出和信号输出用组合逻辑。 三段式： 状态切换用时序逻辑，次态输出用组合逻辑，信号输出用时序逻辑。 Tips： 实际应用中三段式使用最多，也最为可靠，避免了状态和输入输出的干扰，推荐大家使用第三种写法，我们实际项目中基本全部是第三种写法。本文也着重讲解三段式。 Mealy状态机 下一个状态 = F(当前状态，输入信号)； 输出信号 = G(当前状态，输入信号)； Moore状态机 下一个状态 = F(当前状态，输入信号)； 输出信号 = G(当前状态)； 三段式状态机两段式直接采用组合逻辑输出，而三段式则通过在组合逻辑后再增加一级寄存器来实现时序逻辑输出。这样做的好处是可以有效地滤去租个逻辑输出的毛刺，同时可以有效地进行时序计算与约束，另外对于总线形式的输出信号来说，容易使总线数据对齐，从而减小总线数据间的偏移，减小接收端数据采样出错的频率。三段式状态机的基本格式是： 第一个always语句实现同步状态跳转； 第二个always语句实现组合逻辑； 第三个always语句实现同步输出。 Verilog描述状态机需要注意的事项： 定义模块名和输入出端口； 定义输入、输出变量或寄存器； 定义时钟和复位信号； 定义状态变量和状态寄存器； 用时钟沿触发的always块表示状态转移过程； 在复位信号有效时给状态寄存器赋初始值； 描述状态的转换过程：符合条件，从一个状态到另外一个状态。否则留在原状态； 验证状态转移的正确性，必须完整和全面。 一个三段式状态机例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677module divider7_fsm (//inputinput sys_clk , //系统时钟input sys_rst_n , //系统复位，以n结尾-低为有效//outputoutput reg clk_divide_7 // 七分Clock);//reg definereg [6:0] curr_st ; // 状态机目前的状态reg [6:0] next_st ; // 状态机下一时刻状态reg clk_divide_7 ; // 时钟七分频//wire define//parameter define//one hot code designparameter S0 = 7'b0000000;parameter S1 = 7'b0000001;parameter S2 = 7'b0000010;parameter S3 = 7'b0000100;parameter S4 = 7'b0001000;parameter S5 = 7'b0010000;parameter S6 = 7'b0100000;/********************************************** Main Program***********************************************///同步状态跳转 时钟上升沿或下降沿系统复位为低是事件驱动always @(posedge sys_clk or negedge sys_rst_n) begin if (sys_rst_n ==1'b0) begin curr_st &lt;= 7'b0;//非阻塞赋值，并行 end else begin//系统时钟上升沿 curr_st &lt;= next_st; endend//实现组合逻辑always @(*) begin case (curr_st) S0: begin next_st = S1; end S1: begin next_st = S2; end S2: begin next_st = S3; end S3: begin next_st = S4; end S4: begin next_st = S5; end S5: begin next_st = S6; end S6: begin next_st = S0; end default: next_st = S0; endcaseend//control divide clock offset实现同步输出always @(posedge sys_clk or negedge sys_rst_n) begin if (sys_rst_n ==1'b0) begin clk_divide_7 &lt;= 1'b0; end else if ((curr_st == S0) | (curr_st == S1) | (curr_st == S2) | (curr_st == S3)) clk_divide_7 &lt;= 1'b0; else if ((curr_st == S4) | (curr_st == S5) | (curr_st == S6)) clk_divide_7 &lt;= 1'b1; else ;endendmodule//end of RTL code 说明： 本状态机采用独热码设计，简称one-hot code，独热码编码的最大优势在于状态比较时仅仅需要比较一个位，从而一定程度上简化了译码逻辑。 一般状态机状态编码使用二进制编码、格雷码、独热码。 各种编码比较: 二进制编码、格雷码编码使用最少的触发器，消耗较多的组合逻辑，而独热码编码反之。独热码编码的最大优势在于状态比较时仅仅需要比较一个位，从而一定程度上简化了译码逻辑。虽然在需要表示同样的状态数时，独热编码占用较多的位，也就是消耗较多的触发器，但这些额外触发器占用的面积可与译码电路省下来的面积相抵消。 Binary（二进制编码）、gray-code（格雷码）编码使用最少的触发器，较多的组合逻辑，而one-hot（独热码）编码反之。one-hot 编码的最大优势在于状态比较时仅仅需要比较一个bit，一定程度上从而简化了比较逻辑，减少了毛刺产生的概率。另一方面，对于小型设计使用gray-code和binary编码更有效，而大型状态机使用one-hot更高效。 行为建模具体实例以上面的LED流水灯为例，采用行为建模方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556module LED (//inputinput sys_clk , //系统时钟input sys_rst_n , //系统复位，低电平有效//outputoutput reg [7:0] LED );//Parameter defineparameter WIDTH = 8 ;parameter SIZE = 8 ;parameter WIDTH2 = 18 ;parameter Para = 100000;//Reg definereg [SIZE-1:0] counter ;reg [WIDTH2-1:0] count ;//Wire define//*****************************************************//** Main Program//**//*****************************************************// count for add counteralways @(posedge sys_clk or negedge sys_rst_n) begin if (sys_rst_n ==1'b0) count &lt;= 18'b0; else count &lt;= count + 18'b1;end// counter for delay time to LED displayalways @(posedge sys_clk or negedge sys_rst_n) begin if (sys_rst_n ==1'b0) counter &lt;= 8'b0; else if ( count == Para) counter &lt;= counter + 8'b1; else ;end// ctrlLED pipeline display when counter is equal 10 or 20 ....always @(posedge sys_clk or negedge sys_rst_n) begin if (sys_rst_n ==1'b0) LED &lt;= 8'b0; else begin case (counter) 8'd10 : LED &lt;= 8'b10000000 ; 8'd20 : LED &lt;= 8'b01000000 ; 8'd30 : LED &lt;= 8'b00100000 ; 8'd40 : LED &lt;= 8'b00010000 ; 8'd50 : LED &lt;= 8'b00001000 ; 8'd60 : LED &lt;= 8'b00000100 ; 8'd70 : LED &lt;= 8'b00000010 ; 8'd80 : LED &lt;= 8'b00000001 ; default : LED &lt;= 8'b00000000 ; endcase endend]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog HDL</tag>
        <tag>仿真</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[session教务数据]]></title>
    <url>%2F2016%2F03%2F08%2Fnet_auth%2F</url>
    <content type="text"><![CDATA[前言 之前写过一篇文章校园网上网认证,是讲我在校园里通过python实现子的那个上网登录，后来我在这个基础上增加了账号密码存储功能。到这里可能大家又会想到这是上一篇的延续，实际上并不是。在那篇文章里面，我在尝试了几种网络模块之后选择了Requests，它基于urllib3，隐式的在内部实现了很多特性。 在Selenium模拟测试教务数据这篇文章中，我说过，尝试了很长时间，一直不能通过python网络模块模拟获取教务信息，在那时候我就知道是因为cookie机制的不熟悉，因为在requests使用了cookie之后可以访问需要cookie的第一个界面，但之后需要相同cookie的页面全都无法访问。见猎心起，我用了大名鼎鼎的Selenium模拟浏览器登录，并成功获取了想要的信息。 这几天，查阅文档时候，偶然发现了Requests模块的session对象，会话对象可以跨请求保持某些参数。它也会在同一个Session实例发出的所有请求之间保持cookies。这正是我需要的！ 基本方法跨请求保持1234567s = requests.Session()s.get('http://httpbin.org/cookies/set/sessioncookie/123456789')r = s.get("http://httpbin.org/cookies")print(r.text)# '&#123;"cookies": &#123;"sessioncookie": "123456789"&#125;&#125;' 在不同的请求里，可以发现cookie没有变化，这就是跨请求保持参数。 会话层数据合并123456s = requests.Session()s.auth = ('user', 'pass')s.headers.update(&#123;'x-test': 'true'&#125;)# both 'x-test' and 'x-test2' are sents.get('http://httpbin.org/headers', headers=&#123;'x-test2': 'true'&#125;) 会话也可用来为请求方法提供缺省数据。这是通过为会话对象的属性提供数据来实现的,任何你传递给请求方法的字典都会与已设置会话层数据合并。方法层的参数覆盖会话的参数。 剔除参数有时你会想省略字典参数中一些会话层的键。要做到这一点，你只需简单地在方法层参数中将那个键的值设置为 None ，那个键就会被自动省略掉。 一些经验任何时候调用requests.*()你都在做两件主要的事情。其一，你在构建一个 Request 对象， 该对象将被发送到某个服务器请求或查询一些资源。其二，一旦 requests 得到一个从 服务器返回的响应就会产生一个 Response 对象。该响应对象包含服务器返回的所有信息， 也包含你原来创建的 Request 对象。如下是一个简单的请求，从Wikipedia的服务器得到 一些非常重要的信息: r = requests.get(&#39;http://en.wikipedia.org/wiki/Monty_Python&#39;) 如果想访问服务器返回给我们的响应头部信息，可以这样做: r.headers 然而，如果想得到发送到服务器的请求的头部，我们可以简单地访问该请求，然后是该请求的头部: r.request.headers 将Selenium版本改进有了上面的内容，我们可以很轻松的通过会话对象(requests.session())保持cookie，进而访问我需要的教务信息。 123456789101112131415161718192021222324252627282930313233343536373839404142# -*- coding: utf-8 -*-import requestsimport timefrom lxml import etreetimes=time.time()#新建一个会话对象myRequests=requests.session()#设置重复的request headerheaders = &#123;'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:44.0) Gecko/20100101 Firefox/44.0', 'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', 'Accept-Encoding':'gzip, deflate', 'Content-Type': 'application/x-www-form-urlencoded'&#125;myRequests.headers.update(headers)posturl='****************'postData = &#123;'UserStyle' : 'student', 'user':'********', 'password' : '********'&#125;#在这里增添不同的请求参数request1 = myRequests.post(posturl, postData, headers=&#123;'Referer' : '*******'&#125;)geturl='*******************'request3=myRequests.get(geturl,headers=&#123;'Referer' : '*************'&#125;)request3.encoding='gb2312'#网页信息处理、排版dom=etree.HTML(request3.text)names=dom.xpath('/html/body/table/tr/td[3]/text()')socres=dom.xpath('/html/body/table/tr/td[5]/text()')rates=dom.xpath('/html/body/table/tr/td[7]/text()')assert(len(names) == len(socres)==len(rates))results=zip(names,socres,rates)for item in results: print(item[0],item[1].strip(),item[2])print(time.time()-times) 上面就是烦扰我很长时间的问题，通过会话对象session可以很容易的管理跨请求的一些参数。通过时间对比，网络顺畅情况下，程序跑一遍可以达到数百毫秒，而使用Selenium最快的伪浏览器模拟，也需要3s以上。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Verilog小叙(二)]]></title>
    <url>%2F2016%2F03%2F08%2Fverilog_hdl2%2F</url>
    <content type="text"><![CDATA[好的，接着上篇文章Verilog小叙(一) 常量Verilog HDL中有三种常量：整型、实型、字符串型。下划线符号“_”可以随意用在整数或实数中，它们就数量本身没有意义。它们能用来提高易读性；唯一的限制是下划线符号不能用作为首字符。下面主要介绍整型和字符串型。 整型整型数可以按如下两种方式书写： 简单的十进制数格式 基数格式 简单的十进制格式这种形式的整数定义为带有一个可选的“+”（一元）或“－”（一元）操作符的数字序列。下面是这种简易十进制形式整数的例子。32 十进制数32－15 十进制数－15 基数表示法这种形式的整数格式为：[size ] ‘base valuesize 定义以位计的常量的位长；base 为o或O（表示八进制），b或B（表示二进制），d或D（表示十进制），h 或H （表示十六进制）之一；value 是基于base 的值的数字序列。值x和z以及十六进制中的a 到f 不区分大小写。下面是一些具体实例：123456785 'o37 //5位八进制数（二进制11111）4 'd2 //4位十进制数（二进制0011）4 'b1x_01 //4位二进制数7 'hx //7位x(扩展的x), 即xxxxxxx4 'hz //4位z(扩展的z) , 即zzzz4 'd-4 //非法：数值不能为负3' b 001 //非法：和基数b之间不允许出现空格(2+3)'b10 //非法：位长不能够为表达式 注意，x（或z）在十六进制值中代表4位x（或z），在八进制中代表3位x（或z ），在二进制中代表1位x（或z）。基数格式计数形式的数通常为无符号数。这种形式的整型数的长度定义是可选的。如果没有定义一个整数型的长度，数的长度为相应值中定义的位数。下面是两个例子：‘o 7219 3位八进制数‘h AF8 4位十六进制数 如果定义的长度比为常量指定的长度长，通常在左边填0补位。但是如果数最左边一位为x 或z，就相应地用x 或z 在左边补位。例如：10&#39;b10左边添0占位,000000001010&#39;bx0x1左边添x占位, xxxxxxx0x1如果长度定义得更小，那么最左边的位相应地被截断。例如：3 &#39; b1001_0011与3&#39;b011相等5&#39;H0FFF与5&#39;H1F相等 字符串型字符串是双引号内的字符序列。字符串不能分成多行书写。例如：&quot;INTERNAL ERROR&quot;&quot; REACHED－&gt;HERE &quot;用8位ASCII值表示的字符可看作是无符号整数。因此字符串是8位ASCII 值的序列。为存储字符串“INTERNAL ERROR”，变量需要8x14位。 reg [1:8*14] Message; Message = &quot;INTERNAL ERROR&quot; 数据类型Verilog HDL 主要包括两种数据类型 线网类型(net type) 寄存器类型（reg type） 线网类型 wire 和 tri 定义 线网类型主要有wire 和tri两种。线网类型用于对结构化器件之间的物理连线的建模.如器件的管脚，内部器件如与门的输出等。以上面的加法器为例，输入信号A，B是由外部器件所驱动，异或门X1的输出S1是与异或门X2输入脚相连的物理连接线，它由异或门X1所驱动。简单地讲，S1由X1驱动。由于线网类型代表的是物理连接线，因此它不存贮逻辑值。必须由器件所驱动。通常由assign进行赋值。如 assign A = B ^ C；当一个wire 类型的信号没有被驱动时，缺省值为Z（高阻）。信号没有定义数据类型时，缺省为 wire 类型。如上面一位全加器的端口信号 A，B，SUM等，没有定义类型，故缺省为wire 线网类型。两者区别tri主要用于定义三态的线网。 寄存器类型 定义reg 是最常用的寄存器类型，寄存器类型通常用于对存储单元的描述，如D型触发器、ROM等。存储器类型的信号当在某种触发机制下分配了一个值，在分配下一个值之时保留原值。reg 类型定义语法如下： 1234567891011reg [msb: lsb] reg1, reg2, . . . reg N;msb 和lsb 定义了范围，并且均为常数值表达式。范围定义是可选的；如果没有定义范围，缺省值为1 位寄存器。例如：reg [3:0] Sat; // Sat 为4 位寄存器。reg Cnt; //1 位寄存器。reg [1:32] Kisp, Pisp, Lisp ;//寄存器类型的值可取负数，但若该变量用于表达式的运算中，则按无符号类型处理，如：reg A ；.....A = -1；....则A的二进制为1111，在运算中，A总按 无符号数15来看待。 寄存器类型的存储单元建模举例用寄存器类型来构建两位的D触发器如下： 123456789101112reg [1：0] dout ；.....always@(posedge clk)dout &lt;= din;....用寄存器数组类型来建立存储器的模型，如对2个8位的RAM建模如下：reg [7：0] mem[0：1] ；对存储单元的赋值必须一个个第赋值，如上2个8位的RAM的赋值必须用两条赋值语句：.....mem[0] = ’ h 55；mem[1] = ’ haa；.... 书写规范建议对数组类型，请按降序方式，如[7：0] ；Tips:reg的类型不一定是寄存器，只有带有时钟的always块才能是寄存器，不带时钟的always块是组合逻辑。 运算符和表达式Verilog HDL中的操作符可以分为下述类型： 算术操作符 关系操作符 相等操作符 逻辑操作符 按位操作符 归约操作符 移位操作符 条件操作符 连接和复制操作符 下表显示了所有操作符的优先级和名称。操作符从最高优先级（顶行）到最低优先级（底行）排列。同一行中的操作符优先级相同。 算术运算符在常用的算术运算符主要是 ： 加法（二元运算符）：“+”； 减法 （二元运算符）：“-”； 乘法（二元运算符）：“*”； 在算术运算符的使用中，注意如下两个问题： 算术操作结果的位数长度 算术表达式结果的长度由最长的操作数决定。在赋值语句下，算术操作结果的长度由操作符左端目标长度决定。考虑如下实例： 12345reg [3:0] arc, bar, crt;reg [5:0] frx;. . .arc = bar + crt;frx = bar + crt; 第一个加的结果长度由bar，crt 和 arc 长度决定，长度为4位。第二个加法操作的长度同样由frx 的长度决定（frx 、bat 和crt 中的最长长度），长度为6位。在第一个赋值中，加法操作的溢出部分被丢弃；而在第二个赋值中，任何溢出的位存储在结果位frx [ 4 ]中。在较大的表达式中，中间结果的长度如何确定？在Verilog HDL 中定义了如下规则：表达式中的所有中间结果应取最大操作数的长度（赋值时，此规则也包括左端目标）。考虑另一个实例：wire [4:1] box, drt;wire [5:1] cfg;wire [6:1] peg;wire [8:1] adt;. . .assign adt = (box + cfg) + (drt + peg) ;表达式右端的操作数最长为6 ，但是将左端包含在内时，最大长度为8 。所以所有的加操作使用8 位进行。例如：box 和cfg 相加的结果长度为8 位。 有符号数和无符号数在设计中，请先按无符号数进行。关系运算符 关系运算符有： ?&gt;（大于） ?&lt;（小于） ?&gt;=（不小于） ?&lt;=（不大于） = = （逻辑相等） = （逻辑不等） 关系操作符的结果为真（1 ）或假（0 ）。如果操作数中有一位为X 或Z ，那么结果为X 。例：23 &gt; 45结果为假（0 ），而：52 &lt; 8’hxFF结果为x 。如果操作数长度不同，长度较短的操作数在最重要的位方向（左方）添0 补齐。例如：‘b1000 &gt; = ‘b01110等价于：‘b01000 &gt; = ‘b01110结果为假（0 ）。在逻辑相等与不等的比较中，只要一个操作数含有x 或z，比较结果为未知 （x），如：假定：Data = ‘b11x0;Addr = ‘b11x0;那么：Data = = Addr 比较结果不定，也就是说值为x 。 逻辑运算符逻辑运算符有：&amp;&amp; (逻辑与)|| (逻辑或)！(逻辑非)用法为：（表达式1） 逻辑运算符 （表达式2） ….这些运算符在逻辑值0（假） 或1（真） 上操作。逻辑运算的结果为0 或1 。例如, 假定：crd = ‘b0; //0 为假dgs = ‘b1; //1 为真那么：crd &amp;&amp; dgs 结果为0 (假)crd || dgs 结果为1 (真)！dgs 结果为0 (假) 按位逻辑运算符 按位运算符有：?~（一元非）：（相当于非门运算）?&amp;（二元与）：（相当于与门运算）?|（二元或）： （相当于或门运算）?^（二元异或）：（相当于异或门运算）?~ ^, ^ ~（二元异或非即同或）：（相当于同或门运算）这些操作符在输入操作数的对应位上按位操作，并产生向量结果。例如，假定,A = ‘b0110;B = ‘b0100;那么：A | B 结果为0110A &amp; B 结果为0100如果操作数长度不相等, 长度较小的操作数在最左侧添0补位。例如,‘b0110 ^ ‘b10000与如下式的操作相同：‘b00110 ^ ‘b10000结果为’b10110。 条件运算符条件操作符根据条件表达式的值选择表达式，形式如下：cond_expr ? expr1 : expr2如果cond_expr 为真(即值为1 )，选择expr1 ；如果cond_expr 为假(值为0 )，选择expr2 。如果cond_expr 为x 或z ，结果将是按以下逻辑expr1 和expr2 按位操作的值： 0 与0 得0 ，1 与1 得1 ，其余情况为x 。如下所示:wire [2:0] student = marks &gt; 18 ? grade_a : grade_c;计算表达式marks &gt; 18; 如果真,grade_a 赋值为student；如果marks &lt; =18, grade_c 赋值为student 。 连接运算符连接操作是将小表达式合并形成大表达式的操作。形式如下：{expr1, expr2, . . .，exprN}实例如下所示：wire [7:0] Dbus;assign Dbus [7:4] = {Dbus [0], Dbus [1], Dbus[2], Dbus[ 3 ]};//以反转的顺序将低端4 位赋给高端4 位。assign Dbus = {Dbus [3:0], Dbus [7:4]};//高4 位与低4 位交换。由于非定长常数的长度未知, 不允许连接非定长常数。例如,下列式子非法：{Dbus,5} //不允许连接操作非定长常数。 条件语句if 语句的语法如下：123456if(condition_1)procedural_statement_1&#123;else if(condition_2)procedural_statement_2&#125;&#123;elseprocedural_statement_3&#125; 如果对condition_1 求值的结果为个非1，那么procedural_statement_1 被执，如果condition_1 的值为0 、x 或z ，那么procedural_statement_1 不执行。如果存在一个else 分支，那么这个分支被执行。 123456789101112if (sum &lt; 60) begingrade = c;//串行语句total_c = total _c + 1;endelse if(sum &lt; 75) begingrade = b;total_b = total_b + 1;endelse begingrade = a;total_a = total_a + 1;end 若为if - if 语句，请使用块语句 begin — end ： 123456if(clk == 1) beginif (reset== 1)q = 0;elseq = d;end 对if语句，除非在时序逻辑中，if 语句需要有else语句。若没有缺省语句，设计将产生一个锁存器，锁存器在asic设计中有诸多的弊端。如下一例：if （t == 1）q = d；没有else 语句，当t为1（真）时，d 被赋值给q，当t为0（假）时，因为没有else 语句，电路保持 q 以前的值，这就形成一个锁存器。 case语句 case 语句是一个多路条件分支形式，其语法如下：123456case(case_expr)case_item_expr&#123; ,case_item_expr&#125; :procedural_statement. . .. . .[default:procedural_statement]endcase case 语句首先对条件表达式case_expr 求值，然后依次对各分支项求值并进行比较，第一个与条件表达式值相匹配的分支中的语句被执行。可以在1 个分支中定义多个分支项；这些值不需要互斥。缺省分支覆盖所有没有被分支表达式覆盖的其他分支。 123456789101112131415161718case (HEX)4'b0001 : led = 7'b1111001; // 14'b0010 : led = 7'b0100100; // 24'b0011 : led = 7'b0110000; // 34'b0100 : led = 7'b0011001; // 44'b0101 : led = 7'b0010010; // 54'b0110 : led = 7'b0000010; // 64'b0111 : led = 7'b1111000; // 74'b1000 : led = 7'b0000000; // 84'b1001 : led = 7'b0010000; // 94'b1010 : led = 7'b0001000; // a4'b1011 : led = 7'b0000011; // b4'b1100 : led = 7'b1000110; // c4'b1101 : led = 7'b0100001; // d4'b1110 : led = 7'b0000110; // e4'b1111 : led = 7'b0001110; // fdefault : led = 7'b1000000; // 0endcase case 的缺省项必须写，防止产生锁存器。 只有组合逻辑才可能产生锁存器，时序逻辑不会产生锁存器。 结构建模模块定义结构我们已经了解到，一个设计实际上是由一个个module 组成的。一个模块module 的结构如下：module module_name (port_list) ;Declarations_and_Statementsendmodule在结构建模中，描述语句主要是实例化语句，包括对Verilog HDL 内置门如与门（and）异或门（xor）等的例化，如全加器的xor 门的调用；及对其他器件的调用，这里的器件包括FPGA厂家提供的一些宏单元以及设计者已经有的设计。在实际应用中，实例化语句主用指后者，对内置门建议不采纳，而用数据流或行为级方式对基本门电路的描述。端口队列port_list 列出了该模块通过哪些端口与外部模块通信，在Verilog 2001语法中还包括输入输出、wire/reg类型、位宽定义。 模块端口模块的端口可以是输入端口、输出端口或双向端口。缺省的端口类型为线网类型（即wire 类型）。输入端口默认为wire类型，不需要定义，输出或双向端口能够声明为wire/reg 型，使用reg必须显式声明，使用wire也强烈建议显式声明。Verilog 2001语法中的输入输出包括端口名、输入输出、wire/reg类型、位宽定义，极大的减少了端口声明占用的代码行数。当前已经非常普及。例子： 123456module LED (//inputinput sys_clk , //system clock;input sys_rst_n , //system reset, low is active;//outputoutput reg [7:0] LED ); 该例子包括输入、输出、姓名名称、位宽、输出的信号类型。 实例化语句一个模块能够在另外一个模块中被引用，这样就建立了描述的层次。模块实例化语句形式如下： module_name instance_name(port_associations); 信号端口可以通过位置或名称关联； 但是关联方式不能够混合使用。端口关联形式如下： PortName //通过位置。 .PortName (port_expr) //通过名称。 建议使用名称进行关联。 1234567// instantance RR_CORERR_CORE U_RR_CORE (.rr_en ( rr_en ),.port_vld ( key ),.last_sel_port ( last_sel_port ),.port_win ( port_win )); port_expr 可以是以下的任何类型： 标识符（reg 或net ）如 .C（T3），T3为wire型标识符。 位选择 ，如 .C（D[0]），C端口接到D信号的第0bit 位。 部分选择 ，如 .Bus （Din[5：4]）。 上述类型的合并，如 .Addr（{ A1，A2[1：0]}。 表达式（只适用于输入端口），如 .A （wire Zire = 0 ）。 建议：在例化的端口映射中请采用名字关联，这样，当被调用的模块管脚改变时不易出错。 悬空端口的处理在我们的实例化中，可能有些管脚没用到，可在映射中采用空白处理，如： 1234567DFF U_DFF_0 (.q(qs),.qbar ( ), //管脚悬空.data (d ) ,.preset ( ), // 该管脚悬空.clock (ck)); //名称对应方式。 对输入管脚悬空的，则该管脚输入为高阻 Z，输出管脚被悬空的，该输出管脚废弃不用。建议：大规模电路设计的时候，悬空的端口最好使用XX_nc（wire类型）进行显式声明，提高检视代码的效率。 不同端口长度的处理当端口和局部端口表达式的长度不同时，端口通过无符号数的右对齐或截断方式进行匹配。 12345678910module Child (Pba, Ppy) ;input [5:0] Pba;output [2:0] Ppy;. . .endmodulemodule Top;wire [1:2] Bdl;wire [2:6] Mpr;Child C1 (Bdl, Mpr) ;endmodule 在对Child 模块的实例中，Bdl[2]连接到Pba[ 0 ]，Bdl[1] 连接到Pba[ 1 ]，余下的输入端口Pba[5]、Pba[4]、Pba[2]和Pba[3]悬空，因此为高阻态z 。与之相似，Mpr[6]连接到Ppy[0]，Mpr[5]连接到Ppy[1]，Mpr[4] 连接到Ppy[2]。 结构化建模具体实例对一个数字系统的设计，我们采用的是自顶向下的设计方式。可把系统划分成几个功能模块，每个功能模块再划分成下一层的子模块。每个模块的设计对应一个module，一个module 设计成一个verilog HDL 程序文件。因此，对一个系统的顶层模块，我们采用结构化的设计，即顶层模块分别调用了各个功能模块。下面以一个实例（一个频率计数器系统）说明如何用HDL进行系统设计。在该系统中，我们划分成如下三个部分：2输入与门模块，LED显示模块，4位计数器模块。系统的层次描述如下： 顶层模块CNT_BCD，文件名CNT_BCD.v，该模块调用了低层模块 AND2、CNT_4b和HEX2LED 。顶层模块CNT_BCD对应的设计文件 CNT_BCD.v 内容为：1234567891011121314151617181920212223242526272829module CNT_BCD (// ------------ Port declarations --------- //input CLK,input GATE,input RESET,output wire [3:0] BCD_A,output wire [3:0] BCD_B,output wire [3:0] BCD_C,output wire [3:0] BCD_D) ;// ----------- Signal declarations -------- //wire NET104;wire NET124;wire NET132;wire NET80;// -------- Component instantiations -------//CNT_4b U0(.CLK(CLK),.ENABLE(GATE),.FULL(NET80),.Q(BCD_A),.RESET(RESET));AND2 U6(.A0(NET104),.A1(NET124),.Y(NET132));endmodule Tips: 这里的AND2是为了举例说明，在实际设计中，对门级不要重新设计成一个模块，同时对涉及保留字的（不管大小写）相类似的标识符最好不用。]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog HDL</tag>
        <tag>仿真</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的map_reduce]]></title>
    <url>%2F2016%2F03%2F07%2FMap_Reduce%2F</url>
    <content type="text"><![CDATA[提起map和reduce想必大家并不陌生，Google公司2003年提出了一个名为MapReduce的编程模型，用于处理大规模海量数据，并在之后广泛的应用于Google的各项应用中，2006年Apache的Hadoop项目正式将MapReduce纳入到项目中。 好吧，闲话少说，今天要介绍的是Python函数式编程中的另外两个内建函数map()和reduce()，而不是Google的MapReduce。 map格式：map( func, seq1[, seq2...] ) Python函数式编程中的map()函数是将func作用于seq中的每一个元素，并用一个列表给出返回值。如果func为None，作用同zip()。 seq只有一个时将func函数作用于这个seq的每个元素上，得到一个新的seq。下图说明了只有一个seq的时候map()函数是如何工作的 可以看出，seq中的每个元素都经过了func函数的作用，得到了func(seq[n])组成的列表。 下面举一个例子进行说明。假设我们想要得到一个列表中数字%3的余数，那么可以写成下面的代码。 12345# 使用mapprint map( lambda x: x%4, range(9) ) # [0, 1, 2, 3, 0, 1, 2, 3, 0] #使用列表解析print [x%4 for x in range(9)] # [0, 1, 2, 3, 0, 1, 2, 3, 0] seq多于一个map可以并行地对每个seq执行如下图所示的过程： 也就是说每个seq的同一位置的元素在执行过一个多元的func函数之后，得到一个返回值，这些返回值放在一个结果列表中。 下面的例子是求两个列表对应元素的积，可以想象，这是一种可能会经常出现的状况，而如果不是用map的话，就要使用一个for循环，依次对每个位置执行该函数。 print map( lambda x, y: x * y, [4, 5, 6],[1, 2, 3] ) # [4, 10, 18] 上面是返回值是一个值的情况，实际上也可以是一个元组。下面的代码不止实现了乘法，也实现了加法，并把积与和放在一个元组中。 print map( lambda x, y: ( x * y, x + y),[4, 5, 6],[1, 2, 3]) # [(4, 5), (10, 7), (18, 9)] 还有就是上面说的func是None的情况，它的目的是将多个列表相同位置的元素归并到一个元组，在现在已经有了专用的函数zip()了。 123print map( None, [1, 2, 3], [4, 5, 6] ) # [(1, 4), (2, 5), (3, 6)] print zip( [1, 2, 3], [4, 5, 6] ) # [(1, 4), (2, 5), (3, 6)] reduce格式：reduce( func, seq[, init] ) reduce函数即为化简，它是这样一个过程：每次迭代，将上一次的迭代结果（第一次时为init的元素，如没有init则为seq的第一个元素）与下一个元素一同执行一个二元的func函数。在reduce函数中，init是可选的，如果使用，则作为第一次迭代的第一个元素使用。 简单来说，可以用这样一个形象化的式子来说明： reduce( func, [1, 2, 3, 4] ) = func( func(1, 2), 3, 4) 下面是reduce函数的工作过程图： 举个例子来说，阶乘是一个常见的数学方法，Python中并没有给出一个阶乘的内建函数，我们可以使用reduce实现一个阶乘的代码。 12n = 5print reduce(lambda x, y: x * y, range(1, n + 1)) # 120 那么，如果我们希望得到2倍阶乘的值呢？这就可以用到init这个可选参数了 123m = 2n = 5print reduce( lambda x, y: x * y, range( 1, n + 1 ), m ) # 240]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Verilog小叙(一)]]></title>
    <url>%2F2016%2F03%2F06%2Fverilog_hdl%2F</url>
    <content type="text"><![CDATA[前言当前业界的硬件描述语言中主要有VHDL 和Verilog HDL。根据当前ASIC/FPGA设计现有的特点、现状，Verilog HDL 语言已经成为决定的主导语言，使用Verilog HDL，可以统一ASIC/FPGA设计平台，简化流程。 设计方法学数字电路设计方法当前的数字电路设计从层次上分可分成以下几个层次： 算法级设计：利用高级语言如C语言及其他一些系统分析工具（如MATLAB）对设计从系统的算法级方式进行描述。算法级不需要包含时序信息。 RTL级设计：用数据流在寄存器间传输的模式来对设计进行描述。 门级：用逻辑级的与、或、非门等门级之间的连接对设计进行描述。 开关级：用晶体管和寄存器及他们之间的连线关系来对设计进行描述。 算法级是高级的建模，一般对特大型设计或有较复杂的算法时使用，特别是通讯方面的一些系统，通过算法级的建模来保证设计的系统性能。在算法级通过后，再把算法级用RTL级进行描述。门级一般对小型设计可适合。开关级一般是在版图级进行。 最常使用的是RTL级别的设计，90%以上的数字电路都是采用RTL级别进行设计。 硬件描述语言硬件描述语言HDL（Hardware Description Language ）是一种用形式化方法来描述数字电路和数字逻辑系统的语言。数字逻辑电路设计者可利用这种语言来描述自己的设计思想，然后利用EDA工具进行仿真，再自动综合到门级电路，最后用ASIC或FPGA实现其功能。举个例子，在传统的设计方法中，对2输入的与门，我们可能需到标准器件库中调个74系列的器件出来，但在硬件描述语言中，“&amp; ”就是一个与门的形式描述，“C = A &amp; B”就是一个2输入与门的描述。而“and”就是一个与门器件。硬件描述语言发展至今已有二十多年历史，当今业界的标准中（IEEE标准）主要有VHDL和Verilog HDL 这两种硬件描述语言。 设计方法学当前的ASIC设计有多种设计方法，但一般地采用自顶向下的设计方法。随着技术的发展，一个芯片上往往集成了几十万到几百万个器件，传统的自底向上的设计方法已不太现实。因此，一个设计往往从系统级设计开始，把系统划分成几个大的基本的功能模块，每个功能模块再按一定的规则分成下一个层次的基本单元，如此一直划分下去。通过自顶向下的设计方法，可实现设计的结构化，使一个复杂的系统设计可由多个设计者分工合作；还可以实现层次化的管理。 Verilog简介简介Verilog HDL 语言最初是于1983 年由Gateway Design Automation 公司为其模拟器产品开发的硬件建模语言。那时它只是一种专用语言。由于他们的模拟、仿真器产品的广泛使用，Verilog HDL作为一种便于使用且实用的语言逐渐为众多设计者所接受。在一次努力增加语言普及性的活动中，Verilog HDL 语言于1990 年被推向公众领域。Open Verilog International（O V I ）是促进Verilog 发展的国际性组织。1992 年，OVI 决定致力于推广Verilog OVI 标准成为IEEE 标准。这一努力最后获得成功，Verilog 语言于1995 年成为IEEE 标准，称为IEEE Std1364－1995 。完整的标准在Verilog 硬件描述语言参考手册中有详细描述。 功能Verilog HDL 语言具有下述描述能力：设计的行为特性、设计的数据流特性、设计的结构组成以及包含响应监控和设计验证方面的时延和波形产生机制。所有这些都使用同一种建模语言。此外，Verilog HDL 语言提供了编程语言接口，通过该接口可以在模拟、验证期间从设计外部访问设计，包括模拟的具体控制和运行。需要注意的是Verilog HDL当前主要作为设计使用，大规模的电路设计使用Verilog HDL作为验证语言已经被不太可能，当前的验证语言已经逐渐归一到System Verilog 语言上去。当然，非常小规模的设计可以使用Verilog HDL搭建UT（单元测试）环境进行测试。Verilog HDL 语言不仅定义了语法，而且对每个语法结构都定义了清晰的模拟、仿真语义。因此，用这种语言编写的模型能够使用Verilog 仿真器进行验证。语言从C 编程语言中继承了多种操作符和结构。Verilog HDL 提供了扩展的建模能力，其中许多扩展最初很难理解。但是，Verilog HDL 语言的核心子集非常易于学习和使用，这对大多数建模应用来说已经足够。当然，完整的硬件描述语言足以对从最复杂的芯片到完整的电子系统进行描述。 Verilog建模概述在数字电路设计中，数字电路可简单归纳为两种要素：线和器件。线是器件管脚之间的物理连线；器件也可简单归纳为组合逻辑器件（如与或非门等）和时序逻辑器件（如寄存器、锁存器、RAM等）。一个数字系统（硬件）就是多个器件通过一定的连线关系组合在一块的。因此，Verilog HDL的建模实际上就是如何使用HDL语言对数字电路的两种基本要素的特性及相互之间的关系进行描述的过程。下面通过一些实例，以便对Verilog HDL 的设计建模有个大概的印象。 模块模块（module）是Verilog 的基本描述单位，用于描述某个设计的功能或结构及与其他模块通信的外部端口。模块在概念上可等同一个器件。就如我们调用通用器件（与门、三态门等）或通用宏单元（计数器、ALU、CPU）等，因此，一个模块可在另一个模块中调用。一个电路设计可由多个模块组合而成，因此一个模块的设计只是一个系统设计中的某个层次设计，模块设计可采用多种建模方式。 简单例子 加法器： 123456789module addr (input [2:0] a,input [2:0] b,input cin,output count,output [2:0] sum）；assign &#123;count,sum&#125; = a +b + cin;endmodule 该例描述一个3位加法器，从例子可看出整个模块是以module 开始，endmodule 结束。本例子使用Verilog HDL 2001语法结构，输入输出仿在module声明里面。 比较器 12345678module compare （input [1:0] a, // declare the input signal ;input [1:0] b; // declare the input signal ;output equare // declare the output signal;) ;assign equare = (a == b) ? 1:0 ; // if a = b , output 1, otherwise 0endmodule 模块结构通过上面的实例可看出，一个设计是由一个个模块（module）构成的。一个模块的设计如下： 模块内容是嵌在module 和endmodule两个语句之间。每个模块实现特定的功能，模块可进行层次的嵌套，因此可以将大型的数字电路设计分割成大小不一的小模块来实现特定的功能，最后通过由顶层模块调用子模块来实现整体功能，这就是Top-Down的设计思想。 模块包括接口描述部分和逻辑功能描述部分。这可以把模块与器件相类比。 模块的端口定义部,如上例：123456module addr (input [2:0] a,input [2:0] b,input cin,output count,output [2:0] sum）； 其中module 是模块的保留字，addr 是模块的名字，相当于器件名。（）内是该模块的端口声明、输入和输出声明、位宽声明、wire/reg类型声明。 端口声明定义了该模块的管脚名，是该模块与其他模块通讯的外部接口，相当于器件的pin 。 输入和输出声明定义了该模块的管脚是输入还是输出。 位宽声明定义了该模块的管脚的位宽，从高到低进行定义。 wire/reg类型声明定义了该模块的管脚的属性，一般输入都是wire，建议不显式写出来，直接input [2:0] a这样既可，输出必须显式定义出wire还是reg。 模块的内容，包括内部信号、调用模块等的声明语句和功能定义语句。 内部信号需要定义wire/reg类型、声明信号位宽。 逻辑功能描述部分如： assign d_out = d_en ? din :’bz; 功能描述用来产生各种逻辑（主要是组合逻辑和时序逻辑，可用多种方法进行描述，具体的用法下面章节有介绍），还可用来实例化一个器件，该器件可以是厂家的器件库也可以是我们自己用HDL设计的模块（相当于在原理图输入时调用一个库元件）。在逻辑功能描述中，主要用到assign 和always 两个语句。 对每个模块都要进行端口定义，并说明输入、输出口，然后对模块的功能进行逻辑描述，当然，对测试模块，可以没有输入输出口。 Verilog HDL 的书写格式，一行可以写几个语句，也可以一个语句分几行写。此处建议一行写一个语句，禁止写多个一句，养成良好的代码编写习惯。 除endmodule 语句外，每个语句后面需有分号表示该语句结束。 时延信号在电路中传输会有传播延时等，如线延时、器件延时。时延就是对延时特性的HDL描述。举例如下：assign # 2 B = A；表示 B信号在2个时间单位后得到A信号的值。在Verilog HDL中，所有时延都必须根据时间单位进行定义，定义方式为在文件头添加如下语句：`timescale 1ns/100ps其中’timescale 是Verilog HDL 提供的预编译处理命令， 1ns 表示时间单位是1ns ，100ps表示时间精度是100ps。根据该命令，编译工具才可以认知 #2 为2ns。在Verilog HDL 的IEEE标准中没有规定时间单位的缺省值，由各模拟工具确定。 Tips时延是不可综合的，只在仿真时候使用。 结构化描述方式结构化的建模方式就是通过对电路结构的描述来建模，即通过对器件的调用（HDL概念称为例化），并使用线网来连接各器件的描述方式。这里的器件包括Verilog HDL的内置门如与门and，异或门xor等，也可以是用户的一个设计。结构化的描述方式反映了一个设计的层次结构。 例：一位全加器 123456789101112131415module FA_struct (input A,input B,input Cin,output Sum,output Count);wire S1, T1, T2, T3;xor x1 (S1, A, B);xor x2 (Sum, S1, Cin);and A1 (T3, A, B );and A2 (T2, B, Cin);and A3 (T1, A, Cin);or O1 (Cout, T1, T2, T3 );endmodule 该实例显示了一个全加器由两个异或门、三个与门、一个或门构成。S1、T1、T2、T3则是门与门之间的连线。代码显示了用纯结构的建模方式，其中xor、and、or 是Verilog HDL 内置的门器件和关键字。以 xor x1 (S1,A,B) 该例化语句为例：xor 表明调用一个内置的异或门，器件名称xor ，代码实例化名x1（类似原理图输入方式）。括号内的S1，A，B 表明该器件管脚的实际连接线（信号）的名称 ，其中 A、B是输入，S1是输出。其他同。 数据流描述方式数据流的建模方式就是通过对数据流在设计中的具体行为的描述的来建模。最基本的机制就是用连续赋值语句。在连续赋值语句中，某个值被赋给某个线网变量（信号），语法如下：assign [delay] net_name = expression;如：assign #2 A = B；在数据流描述方式中，还必须借助于HDL提供的一些运算符，如按位逻辑运算符 ：逻辑与（&amp;)，逻辑或（|）等。还是以上面的全加器为例，可用如下的建模方式： 123456789101112131415`timescale 1ns/100psmodule FA_flow(input A,input B,input Cin,output wire Sum,output wire Count);wire S1,T1,T2,T3;assign #2 S1 = A ^ B;assign #2 Sum = S1 ^ Cin;assign #2 T3 = A &amp; B;assign #2 T1 = A &amp; Cin;assign #2 T2 = B &amp; Cin ;endmodule 注意在各assign 语句之间，是并行执行的，即各语句的执行与语句之间的顺序无关。如上，当A有个变化时，S1、T3、T1 将同时变化，S1的变化又会造成Sum的变化。 行为描述方式行为方式的建模是指采用对信号行为级的描述的方法来建模。在表示方面，类似数据流的建模方式，但一般是always 块语句和assign块语句描述的归为行为建模方式。行为建模方式通常需要借助一些行为级的运算符如加法运算符（+），减法运算符（-）等。以下举个例子，对always 语句的具体应用可看相关章节的介绍，这里，先对行为建模方式有个概念。例：一位全加器的行为建模 123456789101112131415161718module FA_BEHAV1(input a,input b,input cin,output sum,output cout);reg sum, cout;reg t1,t2,t3;always@ ( a or b or cin ) begin sum = (a ^ b) ^ cin ; t1 = a &amp; cin; t2 = b &amp; cin ; t3 = a &amp; b; cout = (t1| t2) | t3; endendmodule 需要先建立以下概念： 只有寄存器类型的信号才可以在always语句中进行赋值，类型定义通过reg语句实现，但是寄存器类型的信号不一定是真的寄存器，也可能是线逻辑，只有带有时钟的寄存器类型的信号才是真的寄存器，不带时钟的寄存器类型的信号本质是线逻辑。 always 语句是一直重复执行，由敏感表（always 语句括号内的变量）中的变量触发。 always 语句从0 时刻开始。 阻塞赋值“=”在begin 和end 之间的语句是顺序执行，属于串行语句。 非阻塞赋“&lt;=”值在begin 和end 之间的语句是并行执行，属于并行执语句。 总结当前数字逻辑规模越来越大，使用结构化描述已经越来越不现实，也没有必要，当前行为描述方式已经占据绝对的主导地位，大家学习的时候知道有这两种方式即可，重点学习行为描述。 Verilog基本语法介绍Verilog HDL 语言的一些基本要素，包括标识符、注释、格式、数字值集合、两种数据类型、运算符和表达式和一些基本的语句如IF语句等。 标识符标识符( identifier）用于定义模块名、端口名、信号名等。Verilog HDL 中的标识符( identifier)可以是任意一组字母、数字、$符号和_(下划线)符号的组合，但标识符的第一个字符必须是字母或者下划线。另外，标识符是区分大小写的。以下是标识符的几个例子：CountCOUNT //与Count 不同。R56_68FIVE$虽然标识符写法很多，但是推荐写法如下：countfifo_wr不建议大小写混合使用，普通内部信号建议全部小写，输入输出PAD建议大写，另外信号命名最好体现信号的含义，简洁、清晰、易懂。 关键词Verilog HDL定义了一系列保留字，叫做关键词，附录A 列出了语言中的所有保留字。注意只有小写的关键词才是保留字。例如，标识符always (这是个关键词)与标识符ALWAYS(非关键词)是不同的。 书写规范建议以下是一些书写规范的要求，可参考公司的《Verilog 代码书写规范》。 用有意义的有效的名字如 sum 、cpu_addr等。 用下划线区分词。 采用一些前缀或后缀，如 时钟采用clk前缀：clk_50，clk_cpu； 低电平采用_n 后缀：enable_n； 统一一定的缩写，如全局复位信号rst。 同一信号在不同层次保持一致性，如同一时钟信号必须在各模块保持一致。 自定义的标识符不能与保留字同名。 参数采用大写，如SIZE 。 注释Verilog HDL中有两种注释的方式，一种是以“/*”符号开始，“*/” 结束，在两个符号之间的语句都是注释语句，因此可扩展到多行。如：1234/* statement1 ，statement2，.. ...statementn */ 以上n个语句都是注释语句。另一种是以//开头的语句，它表示以//开始到本行结束都属于注释语句。建议写法：使用//作为注释。 值集合Verilog HDL中规定了四种基本的值类型： 0：逻辑0或“假”； 1：逻辑1或“真”； X：未知值； Z：高阻 注意这四种值的解释都内置于语言中。如一个为z的值总是意味着高阻抗，一个为0 的值通常是指逻辑0 。在门的输入或一个表达式中的为“z”的值通常解释成“x”。此外，x值和z值都是不分大小写的，也就是说，值0x1z与值0X1Z相同。Verilog HDL 中的常量是由以上这四类基本值组成的。]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog HDL</tag>
        <tag>仿真</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初窥Scrapy(Py3.x)]]></title>
    <url>%2F2016%2F02%2F28%2Fscrapy%2F</url>
    <content type="text"><![CDATA[Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。 本文档将通过介绍Scrapy背后的概念使您对其工作原理有所了解， 并确定Scrapy是否是您所需要的。 当您准备好开始您的项目后，您可以参考 入门教程 。 选择一个网站当您需要从某个网站中获取信息，但该网站未提供API或能通过程序获取信息的机制时， Scrapy可以助你一臂之力。 以 Mininova 网站为例，我们想要获取今日添加的所有种子的URL、 名字、描述以及文件大小信息。 今日添加的种子列表可以通过这个页面找到: http://www.mininova.org/today 定义您想抓取的数据第一步是定义我们需要爬取的数据。在Scrapy中， 这是通过Scrapy Items 来完成的。(在本例子中为种子文件) 我们定义的Item: 1234567import scrapyclass TorrentItem(scrapy.Item): url = scrapy.Field() name = scrapy.Field() description = scrapy.Field() size = scrapy.Field() 第二步是编写一个spider。其定义了初始URL(http://www.mininova.org/today)、 针对后续链接的规则以及从页面中提取数据的规则。 通过观察页面的内容可以发现，所有种子的URL都类似 http://www.mininova.org/tor/NUMBER 。 其中， NUMBER 是一个整数。 根据此规律，我们可以定义需要进行跟进的链接的正则表达式: /tor/\d+ 。 我们使用 XPath 来从页面的HTML源码中选择需要提取的数据。 以其中一个种子文件的页面为例: http://www.mininova.org/tor/2676093观察HTML页面源码并创建我们需要的数据(种子名字，描述和大小)的XPath表达式。 通过观察，我们可以发现文件名是包含在 &lt;h1&gt; 标签中的: 1&lt;h1&gt;Darwin - The Evolution Of An Exhibition&lt;/h1&gt; 与此对应的XPath表达式: 1//h1/text() 种子的描述是被包含在 id=&quot;description&quot; 的 &lt;div&gt; 标签中: 123456&lt;h2&gt;Description:&lt;/h2&gt;&lt;div id="description"&gt;Short documentary made for Plymouth City Museum and Art Gallery regarding the setup of an exhibit about Charles Darwin in conjunction with the 200th anniversary of his birth.... 对应获取描述的XPath表达式: 1//div[@id='description'] 文件大小的信息包含在 id=specifications 的 &lt;div&gt; 的第二个 &lt;p&gt; 标签中: 12345678910&lt;div id="specifications"&gt;&lt;p&gt;&lt;strong&gt;Category:&lt;/strong&gt;&lt;a href="/cat/4"&gt;Movies&lt;/a&gt; &amp;gt; &lt;a href="/sub/35"&gt;Documentary&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Total size:&lt;/strong&gt;150.62&amp;nbsp;megabyte&lt;/p&gt; 选择文件大小的XPath表达式: 1//div[@id='specifications']/p[2]/text()[2] 关于XPath的详细内容请参考http://www.w3.org/TR/xpath 最后，结合以上内容给出spider的代码: 1234567891011121314151617from scrapy.contrib.spiders import CrawlSpider, Rulefrom scrapy.contrib.linkextractors import LinkExtractorclass MininovaSpider(CrawlSpider): name = 'mininova' allowed_domains = ['mininova.org'] start_urls = ['http://www.mininova.org/today'] rules = [Rule(LinkExtractor(allow=['/tor/\d+']), 'parse_torrent')] def parse_torrent(self, response): torrent = TorrentItem() torrent['url'] = response.url torrent['name'] = response.xpath("//h1/text()").extract() torrent['description'] = response.xpath("//div[@id='description']").extract() torrent['size'] = response.xpath("//div[@id='info-left']/p[2]/text()[2]").extract() return torrent TorrentItem 的定义在上面 执行spider，获取数据终于，我们可以运行spider来获取网站的数据，并以JSON格式存入到 scraped_data.json 文件中: 1scrapy crawl mininova -o scraped_data.json 命令中使用了 feed导出 来导出JSON文件。您可以修改导出格式(XML或者CSV)或者存储后端(FTP或者 Amazon S3)，这并不困难。 同时，您也可以编写 item管道 将item存储到数据库中。 查看提取到的数据执行结束后，当您查看 scraped_data.json , 您将看到提取到的item: 123[&#123;"url": "http://www.mininova.org/tor/2676093", "name": ["Darwin - The Evolution Of An Exhibition"], "description": ["Short documentary made for Plymouth ..."], "size": ["150.62 megabyte"]&#125;,# ... other items ...] 由于 selectors 返回list, 所以值都是以list存储的(除了 url 是直接赋值之外)。 如果您想要保存单个数据或者对数据执行额外的处理,那将是 Item Loaders 发挥作用的地方。 支持Python3.x的新版本最新的一个好消息是，1.10rc新版本终于可以在Python3.x上使用，下载地址 戳这里. 下载完成之后，在终端使用命令 1python setup.py install 即可使用！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[演员电影评分排序]]></title>
    <url>%2F2016%2F02%2F28%2Factor%2F</url>
    <content type="text"><![CDATA[这几天晕晕乎乎的，什么都不想干，窝在房间里面看电影。可是呢，这些年已经把太多好评如潮的电影塞进脑子里，又不想一个个的翻豆瓣、烂番茄再看每个影人的电影评分，这时候呢，需求是我码代码的推动力:)爬虫试试呗 获取演员ID豆瓣有个电影栏目，通过在里面的编辑框输入想要搜索的演员名，然后搜索就可以找到对应的影人。大多数搜索服务的连接都是通过get，因为搜索功能不牵扯到过多的私密信息，所以可以绕过搜索框直接在url中添加关键字搜索。 返回的网页中，一般如果是正确搜索，没有错误的演员信息，就会在第一条内容中显示演员的基本信息、简介、网页链接。可以直接通过Xpath获取。 豆瓣中不同演员的区分在url中是以actor id作主要评判。在上面中获取的url中就可以直接截取。 123456789101112def getActorID(): url='https://movie.douban.com/celebrities/search?search_text=' global actorname actorname=input('请输入演员名：\n') html=requests.get(url+actorname.strip()).text dom=etree.HTML(html) urls=dom.xpath('//div[@class="content"]/h3/a/@href') if len(urls)&gt;0: item=urls[0] id=re.findall('https://movie.douban.com/celebrity/(\d*)/',item) return id[0] return None 获取电影分页信息每个影人参与的电影数量肯定是不一样的，豆瓣里面以10部电影划分，所以就会有不同的分页信息。豆瓣的分页信息很工整，每个url都可以通过简单的加减乘除算法获得，但是总共的页面数就需要先行获取。 这里有两种方式： 直接通过计算特定的分页url数目 豆瓣中在每个页面下面会标明总共的影片数目 很明显，第二种方法相当简单,例如 1&lt;span class="count"&gt;(共200条)&lt;/span&gt; 直接通过Xpath语句 1234567891011121314151617181920'\\span[@class="conyent"]\text()'``` ```pythondef getCount(ids): if ids: url='https://movie.douban.com/celebrity/'+ids+'/movies?start=0&amp;format=pic&amp;sortby=time&amp;' html=(requests.get(url)).text dom=etree.HTML(html) counts=dom.xpath('//span[@class="count"]/text()') if len(counts)&gt;0: counts=re.findall('共(\d*?)条',counts[0]) if len(counts)&gt;0: count=counts[0] if int(count)/10-int(int(count)/10)&gt;0: return int(int(count)/10+1) else : return int(int(count)/10) else: return None 获取每部影片的有效信息有了影人的actor id，有了分页信息，就可以直接在影片的摘要上面获取我们所需的信息– 电影名称 评分 相应的豆瓣页面URL 这里就相当的简单方便了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112def getContent(ids,count): movieList=list() if ids and count: for id in range(0,count): starturl='https://movie.douban.com/celebrity/'+ids+'/movies?start='+str(id*10)+'&amp;format=pic&amp;sortby=time&amp;' html=(requests.get(starturl)).text dom=etree.HTML(html) url=dom.xpath('//h6/a/@href') content=dom.xpath('//h6/a/text()') soup=BeautifulSoup(html,'lxml') star=soup.findAll(attrs=&#123;'class':'star clearfix'&#125;) for i in range(0,len(star)): items=re.findall('&lt;span&gt;(\d\.\d)&lt;/span&gt;',str(star[i])) if not items: star[i]=0 else: star[i]=float(items[0]) assert(len(url)==len(content)==len(star)) tem=zip(content,star,url) for index in tem: movieList.append(index) movieList=sorted(movieList,key=lambda d:d[1],reverse=True) return movieList``` # 小结 #这里直接贴出来整个的代码，接入了写入磁盘功能:```pythonimport osfrom operator import itemgetterimport requestsimport timeimport reimport sysfrom bs4 import BeautifulSoupfrom lxml import etreeactorname=''def getActorID(): url='https://movie.douban.com/celebrities/search?search_text=' global actorname actorname=input('请输入演员名：\n') html=requests.get(url+actorname.strip()).text dom=etree.HTML(html) urls=dom.xpath('//div[@class="content"]/h3/a/@href') if len(urls)&gt;0: item=urls[0] id=re.findall('https://movie.douban.com/celebrity/(\d*)/',item) return id[0] return Nonedef getCount(ids): if ids: url='https://movie.douban.com/celebrity/'+ids+'/movies?start=0&amp;format=pic&amp;sortby=time&amp;' html=(requests.get(url)).text dom=etree.HTML(html) counts=dom.xpath('//span[@class="count"]/text()') if len(counts)&gt;0: counts=re.findall('共(\d*?)条',counts[0]) if len(counts)&gt;0: count=counts[0] if int(count)/10-int(int(count)/10)&gt;0: return int(int(count)/10+1) else : return int(int(count)/10) else: return Nonedef getContent(ids,count): movieList=list() if ids and count: for id in range(0,count): starturl='https://movie.douban.com/celebrity/'+ids+'/movies?start='+str(id*10)+'&amp;format=pic&amp;sortby=time&amp;' html=(requests.get(starturl)).text dom=etree.HTML(html) url=dom.xpath('//h6/a/@href') content=dom.xpath('//h6/a/text()') soup=BeautifulSoup(html,'lxml') star=soup.findAll(attrs=&#123;'class':'star clearfix'&#125;) for i in range(0,len(star)): items=re.findall('&lt;span&gt;(\d\.\d)&lt;/span&gt;',str(star[i])) if not items: star[i]=0 else: star[i]=float(items[0]) assert(len(url)==len(content)==len(star)) tem=zip(content,star,url) for index in tem: movieList.append(index) movieList=sorted(movieList,key=lambda d:d[1],reverse=True) return movieListdef saveFilebyList(movieList): if movieList: filename=os.path.join(sys.path[0],actorname+'.txt') with open(filename, "w",encoding='utf-8') as fp: for s in movieList: fp.write("%s\t\t%s\t\t%s\n" % (s[0], s[1], s[2]))if __name__ == '__main__': ids=getActorID() count=getCount(ids) movieList=getContent(ids,count) saveFilebyList(movieList) if movieList: for item in movieList: print(item[0],item[1],item[2])]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伯乐对象年龄爬虫]]></title>
    <url>%2F2016%2F02%2F28%2F%E4%BC%AF%E4%B9%90%E7%88%AC%E8%99%AB2%2F</url>
    <content type="text"><![CDATA[接着上一篇相关文章，还是说伯乐在线这个网站上有一个面向对象栏目。这次呢，不看妹子要求男生的身高问题，来瞧一瞧妹子在这个栏目上发帖子寻找soul mate的时间：） 实际上呢，网页信息是跟上次的一模一样，也就是说完全可以将上篇文章的网页代码保存在本地，设置好间隔符，通过不同的过滤规则获取相应的数据。 下面是我的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import requestsimport reimport osimport sysimport timefrom bs4 import BeautifulSoupurlsFile = os.path.join(sys.path[0],'urls.txt')# 保存帖子url的本地路径的字符串,os.path.join()知识提供文件路径拼接功能 如果想要创建文件 则使用os.mkdir(path)infoNum = 0 #有效信息的总条数num = 0 #包含敏感信息的总条数def getUrls(): if os.path.exists(urlsFile) : return getUrlsFromFile() urlList = list() url='http://date.jobbole.com/page/1/?sort=latest' while url: html = requests.get(url) pattern='href=\"(.*?)\"&gt;.*?&lt;/a&gt;&lt;label class=\"hide-on-480 small-domain-url\"&gt;&lt;/label&gt;' urlList += re.findall(pattern,html.text) tem=(re.findall('&lt;li id=\"pagination-next-page\"&gt;&lt;a href=\"(.*?)\"',html.text)) if len(tem)&gt;0:url=tem[0] else:url=None saveUrls(urlList) return urlListdef getUrlsFromFile(): urlList = list() f = open(urlsFile,'r') for line in f.readlines(): #需要注意的是，智力读取的是包括换行符的字符串，因为在写入文件时已经直接写入了换行符，这里将文件按行分开 #想要获取纯正的源数据可以使用str.strip()函数 urlList.append(line) f.close() return urlListdef saveUrls(urlList): with open(urlsFile, "w",encoding='utf-8') as fp: fp.write("%s" % '\n'.join(urlList))#查询该帖子下的内容def viewUrl(url): result = "" html = requests.get(url) info = re.findall('出生年月：(.*?)&lt;br /&gt;',html.text) print(url.strip()) if len(info): if len(info)&gt;1: if len(info[0])&gt;len(info[1]) and info[1]!='':info[0]=info[1] if info[0]!='': result = info[0] isAboutA(result) f.close()#是否有涉及身高的敏感信息def isAboutA(info): global num keys=['(\d&#123;4&#125;)','(\d&#123;4&#125;\.\d&#123;2&#125;)','(\d&#123;2&#125;\.\d*)','(\d&#123;2&#125;)年'] f=open('infoA.txt','a') for p in keys: r = re.findall(p,info) if(len(r)): num = num + 1 f.write(str(r[0])+"\n") print(info) print(r[0]) break f.close()def getAvarge(): numList=list() f = open("infoA.txt","r") for line in f.readlines(): line=line.strip() if line!='': #去除小数点 if line.find('.')!=-1: line=(line.split('.'))[0] if len(line)==2: line='19'+line num = int(line) numList.append(num) result=0.0 for num in numList: result+=num return '%.2f' % (2016-result/len(numList))f=open('infoA.txt','w')f.close()urlList = getUrls()num = 0for i in range(0,len(urlList)): print('第'+str(i+1)+'个begin:') viewUrl(urlList[i]) print('进度 %.2f\n' % ((i+1)/len(urlList))) time.sleep(0.1)print(len(urlList))print(num)print('结果为 %.2f' % getAvarge()) 结果为27.44 通过爬虫信息可以看出，27岁是个中间值，我也没有具体的研究年龄分布问题，后续等我有更科学的方法、数据量之后再来研究~]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Requests</tag>
        <tag>re</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电脑定时睡眠]]></title>
    <url>%2F2016%2F02%2F28%2F%E7%94%B5%E8%84%91%E5%AE%9A%E6%97%B6%E7%9D%A1%E7%9C%A0%2F</url>
    <content type="text"><![CDATA[原理实际上实现的原理相当简单，python可以通过os模块的system函数执行相应平台提供的系统API函数，在win平台下，有很多cmd命令行可供我们调用，有两种方式实现: 通过at指令在指定时间为系统天剑一项作业 计算指定时间与当前时间的差值，然后暂歇等待执行 经过测试，at指令在某些环境下面并不能够正常执行，所以我选择了方法2. 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import osimport timeimport sysrh=int(time.strftime("%H",time.localtime()))rm=int(time.strftime("%M",time.localtime()))print('当前时间:'+str(rh)+':'+str(rm))cmd="cmd.exe /k shutdown -s -t 0"c1=Truewhile c1: try: h=int(input("Please input the hour:")) if h&gt;=0 and h&lt;=23: c1=False else: continue except: continuec2=Truewhile c2: try: m=int(input("Please input the minute:")) if m&gt;=0 and m&lt;=59: c2=False else: continue except: continuec3=Truewhile c3: try: print('Please input the Mode:') print('1: 睡眠 2：注销') print('3: 关机') m=int(input("Please input the Mode:")) c3=False if m==3: cmd="cmd.exe /k shutdown -s -t 0" elif m==1: cmd="cmd.exe /k rundll32.exe powrprof.dll,SetSuspendState" elif m==2: cmd="cmd.exe /k shutdown -l -t 0" else: c3=True continue except: continueif h==rh: if m&lt;=rm: os.system(cmd) else: time.sleep((m-rm)*60) time.sleep(5) os.system(cmd)elif h&gt;rh: tem1=(h-rh-1)*3600+(60-rm+m)*60 time.sleep(tem1) time.sleep(5) os.system(cmd)else: tem2=(23-rh+h)*3600+(60-rm+m)*60 time.sleep(tem2) time.sleep(5) os.system(cmd) 相关程序提供了3种模式，分别是定时关机、定时注销、定时睡眠。指定这三种模式的初衷也是因为防止我晚上在床上通过Ipad使用电脑电影资源时间上的无节制。 Windows下有两种相似的模式，睡眠与休眠，这两种模式的区别大家可以在专业的百科网站上面获取。正常情况下，这两种模式不能在同一时间使用，电脑性能较高的情况下，建议优先使用睡眠功能，恢复的时间更短。 开启关闭休眠模式 on powercfg -h on off powercfg -h off 相关命令 rundll32.exe powrprof.dll,SetSuspendState &lt;睡眠（关闭休眠时）&gt; shutdown -l &lt;注销&gt; shutdown -h &lt;休眠&gt; shutdown -s &lt;关机&gt; shutdown -t &lt;设置倒计时&gt;]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>实用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网易新闻爬取]]></title>
    <url>%2F2016%2F02%2F28%2F163news%2F</url>
    <content type="text"><![CDATA[使用requests包来爬取页面。 使用正则表达式分析一级页面，使用Xpath来分析二级页面。 将得到的标题和链接，保存为本地文件。 只是一个闲来无事的小练手： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# -*- coding: utf-8 -*-import osimport requestsimport reimport timefrom lxml import etreedef StringListSave(save_path, filename, slist): if not os.path.exists(save_path): os.makedirs(save_path) path = save_path+"/"+filename+".txt" with open(path, "w+",encoding='utf-8') as fp: for s in slist: fp.write("%s\t\t%s\n" % (s[0], s[1]))def Page_Info(myPage): #使用re.S进行忽略\r\n换行号匹配 mypage_Info = re.findall(r'&lt;div class="titleBar" id=".*?"&gt;&lt;h2&gt;(.*?)&lt;/h2&gt;&lt;div class="more"&gt;&lt;a href="(.*?)"&gt;.*?&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;', myPage, re.S) return mypage_Infodef New_Page_Info(new_page): dom = etree.HTML(new_page) new_items = dom.xpath('//tr/td/a/text()') new_urls = dom.xpath('//tr/td/a/@href') #添加断言 assert(len(new_items) == len(new_urls)) return zip(new_items, new_urls)def Spider(url): i = 0 print("downloading ", url) myPage = requests.get(url).text myPageResults = Page_Info(myPage) save_path = u"网易新闻抓取" filename = str(i)+"_"+u"新闻排行榜" StringListSave(save_path, filename, myPageResults) i += 1 for item, url in myPageResults: print("downloading ", url) new_page = requests.get(url).text newPageResults = New_Page_Info(new_page) filename = str(i)+"_"+item StringListSave(save_path, filename, newPageResults) i += 1 #放置requests模块过快频率访问 time.sleep(0.2)print("start")start_url = "http://news.163.com/rank/"Spider(start_url)print("end") 这里要注意的是，使用单线程requests模块短时间高频率的访问一个服务器上的内容，可能会导致requests崩溃，报错 1requests.exceptions.ConnectionError: HTTPConnectionPool(host='******', port=80): Max retries exceeded with url 错误信息也已经指的相当清楚，在这里可以通过人工的暂歇处理，降低当前服务器的访问频率： time.sleep(0.x) 先使用lxml模块中的etree对象进行原始网页数据的页读取处理，生成元素树，然后通过强大的Xpath模块解析获取所需的内容。]]></content>
      <categories>
        <category>网页解析</category>
      </categories>
      <tags>
        <tag>lxml</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pyquery小记]]></title>
    <url>%2F2016%2F02%2F28%2Fpyquery%2F</url>
    <content type="text"><![CDATA[pyquery库是jQuery的Python实现，可以用于解析HTML网页内容，使用方法： 1from pyquery import PyQuery as pq 可加载一段HTML字符串，或一个HTML文件，或是一个url地址，例： 123d = pq("&lt;html&gt;&lt;title&gt;hello&lt;/title&gt;&lt;/html&gt;")d = pq(filename=path_to_html_file)d = pq(url='http://www.baidu.com') # 此处url必须写全 html() 和 text() ——获取相应的HTML块或文本块，例： 123p = pq("&lt;head&gt;&lt;title&gt;hello&lt;/title&gt;&lt;/head&gt;")p('head').html() # 返回&lt;title&gt;hello&lt;/title&gt;p('head').text() # 返回hello 根据HTML标签来获取元素，例： 1234d = pq('&lt;div&gt;&lt;p&gt;test 1&lt;/p&gt;&lt;p&gt;test 2&lt;/p&gt;&lt;/div&gt;') d('p') # 返回[&lt;p&gt;,&lt;p&gt;]print d('p') # 返回&lt;p&gt;test 1&lt;/p&gt;&lt;p&gt;test 2&lt;/p&gt;print d('p').html() # 返回test 1 注意：当获取到的元素不只一个时，html()、text()方法只返回首个元素的相应内容块 eq(index) ——根据给定的索引号得到指定元素 接上例，若想得到第二个p标签内的内容，则可以： 1print d('p').eq(1).html() # 返回test 2 filter() ——根据类名、id名得到指定元素，例： 123d = pq("&lt;div&gt;&lt;p id='1'&gt;test 1&lt;/p&gt;&lt;p class='2'&gt;test 2&lt;/p&gt;&lt;/div&gt;")d('p').filter('#1') # 返回[&lt;p#1&gt;]d('p').filter('.2') # 返回[&lt;p.2&gt;] find() ——查找嵌套元素，例： 123d = pq("&lt;div&gt;&lt;p id='1'&gt;test 1&lt;/p&gt;&lt;p class='2'&gt;test 2&lt;/p&gt;&lt;/div&gt;")d('div').find('p') # 返回[&lt;p#1&gt;, &lt;p.2&gt;]d('div').find('p').eq(0) #返回[&lt;p#1&gt;] 直接根据类名、id名获取元素，例： 123d = pq("&lt;div&gt;&lt;p id='1'&gt;test 1&lt;/p&gt;&lt;p class='2'&gt;test 2&lt;/p&gt;&lt;/div&gt;")d('#1').html() # 返回test 1d('.2').html() # 返回test 2 获取属性值，例： 123d = pq("&lt;p id='my_id'&gt;&lt;a href='http://hello.com'&gt;hello&lt;/a&gt;&lt;/p&gt;")d('a').attr('href') # 返回http://hello.comd('p').attr('id') # 返回my_id 修改属性值，例： 1d('a').attr('href', 'http://baidu.com') addClass(value) ——为元素添加类，例： 12d = pq('&lt;div&gt;&lt;/div&gt;')d.addClass('my_class') # 返回[&lt;div.my_class&gt;] hasClass(name) #返回判断元素是否包含给定的类，例： 12d = pq("&lt;div class='my_class'&gt;&lt;/div&gt;")d.hasClass('my_class') # 返回True children(selector=None) ——获取子元素，例： 123d = pq("&lt;span&gt;&lt;p id='1'&gt;hello&lt;/p&gt;&lt;p id='2'&gt;world&lt;/p&gt;&lt;/span&gt;")d.children() # 返回[&lt;p#1&gt;, &lt;p#2&gt;]d.children('#2') # 返回[&lt;p#2&gt;] parents(selector=None)——获取父元素，例： 1234d = pq("&lt;span&gt;&lt;p id='1'&gt;hello&lt;/p&gt;&lt;p id='2'&gt;world&lt;/p&gt;&lt;/span&gt;")d('p').parents() # 返回[&lt;span&gt;]d('#1').parents('span') # 返回[&lt;span&gt;]d('#1').parents('p') # 返回[] clone() ——返回一个节点的拷贝 empty() ——移除节点内容 nextAll(selector=None) ——返回后面全部的元素块，例： 123d = pq("&lt;p id='1'&gt;hello&lt;/p&gt;&lt;p id='2'&gt;world&lt;/p&gt;&lt;img scr='' /&gt;")d('p:first').nextAll() # 返回[&lt;p#2&gt;, &lt;img&gt;]d('p:last').nextAll() # 返回[&lt;img&gt;] not_(selector) ——返回不匹配选择器的元素，例： 12d = pq("&lt;p id='1'&gt;test 1&lt;/p&gt;&lt;p id='2'&gt;test 2&lt;/p&gt;")d('p').not_('#2') # 返回[&lt;p#1&gt;]]]></content>
      <categories>
        <category>网页解析</category>
      </categories>
      <tags>
        <tag>pyquery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xpath笔记]]></title>
    <url>%2F2016%2F02%2F28%2Fxpath%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。XPath基于XML的树状结构，提供在数据结构树中找寻节点的能力。起初 XPath 的提出的初衷是将其作为一个通用的、介于XPointer与XSLT间的语法模型。但是 XPath 很快的被开发者采用来当作小型查询语言。 简单说，xpath就是: 选择XML文件中节点的方法。 所谓节点（node），就是XML文件的最小构成单位，一共分成7种。 element（元素节点） attribute（属性节点） text （文本节点） namespace （名称空间节点） processing-instruction （处理命令节点） comment （注释节点） root （根节点） xpath表达式的基本格式xpath通过”路径表达式”（Path Expression）来选择节点。在形式上，”路径表达式”与传统的文件系统非常类似. 斜杠（/）作为路径内部的分割符。 同一个节点有绝对路径和相对路径两种写法。 绝对路径（absolute path）必须用”/“起首，后面紧跟根节点，比如/step/step/…。 相对路径（relative path）则是除了绝对路径以外的其他写法，比如 step/step，也就是不使用”/“起首。 “.”表示当前节点。 “..”表示当前节点的父节点 选择节点的基本规则 nodename（节点名称）：表示选择该节点的所有子节点 “/“：表示选择根节点 “//“：表示选择任意位置的某个节点 “@”： 表示选择某个属性 选择节点的实例1234567891011&lt;?xml version="1.0" encoding="ISO-8859-1"?&gt;&lt;bookstore&gt; &lt;book&gt; &lt;title lang="eng"&gt;Harry Potter&lt;/title&gt; &lt;price&gt;29.99&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;title lang="eng"&gt;Learning XML&lt;/title&gt; &lt;price&gt;39.95&lt;/price&gt; &lt;/book&gt;&lt;/bookstore&gt; bookstore ：选取 bookstore 元素的所有子节点。 /bookstore ：选取根节点bookstore，这是绝对路径写法。 bookstore/book ：选取所有属于 bookstore 的子元素的 book元素，这是相对路径写法。 //book ：选择所有 book 子元素，而不管它们在文档中的位置。 bookstore//book ：选择所有属于 bookstore 元素的后代的 book 元素，而不管它们位于 bookstore 之下的什么位置。 //@lang ：选取所有名为 lang 的属性。 xpath的谓语条件（Predicate）所谓”谓语条件”，就是对路径表达式的附加条件。 所有的条件，都写在方括号”[]”中，表示对节点进行进一步的筛选。 /bookstore/book[1] ：表示选择bookstore的第一个book子元素。 /bookstore/book[last()] ：表示选择bookstore的最后一个book子元素。 /bookstore/book[last()-1] ：表示选择bookstore的倒数第二个book子元素。 /bookstore/book[position()&lt;3] ：表示选择bookstore的前两个book子元素。 //title[@lang] ：表示选择所有具有lang属性的title节点。 //title[@lang=&#39;eng&#39;] ：表示选择所有lang属性的值等于”eng”的title节点。 /bookstore/book[price] ：表示选择bookstore的book子元素，且被选中的book元素必须带有price子元素。 /bookstore/book[price&gt;35.00] ：表示选择bookstore的book子元素，且被选中的book元素的price子元素值必须大于35。 /bookstore/book[price&gt;35.00]/title ：表示在例14结果集中，选择title子元素。 /bookstore/book/price[.&gt;35.00] ：表示选择值大于35的”/bookstore/book”的price子元素。 通配符 “*”表示匹配任何元素节点。 “@*”表示匹配任何属性值。 node()表示匹配任何类型的节点 //* ：选择文档中的所有元素节点。 /*/* ：表示选择所有第二层的元素节点。 /bookstore/* ：表示选择bookstore的所有元素子节点。 //title[@*] ：表示选择所有带有属性的title元素。 选择多个路径用”|”选择多个并列的路径。 //book/title | //book/price ：表示同时选择book元素的title子元素和price子元素。]]></content>
      <categories>
        <category>网页解析</category>
      </categories>
      <tags>
        <tag>xpath</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selenium模拟测试教务数据]]></title>
    <url>%2F2016%2F02%2F27%2Fselenium%2F</url>
    <content type="text"><![CDATA[前言 Selenium是什么，看看Encyclopedia上的说明： Selenium是一个用于Web应用程序测试的工具。Selenium测试直接运行在浏览器中，就像真正的用户在操作一样。支持的浏览器包括IE(7、8、9)、Mozilla Firefox、Mozilla Suite、Google Chrome等。这个工具的主要功能包括：测试与浏览器的兼容性——测试你的应用程序看是否能够很好得工作在不同浏览器和操作系统之上。测试系统功能——创建回归测试检验软件功能和用户需求。支持自动录制动作和自动生成 .Net、Java、Perl等不同语言的测试脚本。Selenium 是ThoughtWorks专门为Web应用程序编写的一个验收测试工具。 简单地说，Selenium就是一个通过执行预先设置的Browser的指令，解放双手，提高工作效率。 最近在无聊实现爬虫的时候，有些地方害苦了我。我们都知道，很多网页是通过JS行为动态变化了，网页内容并不是一成不变的。当我依然使用传统的爬虫方法直接解析返回的Response，显而易见是失败的，经常提示丢失用户信息等错误。 很明显，可以通过解析JS操作。 通过各大浏览器提供的工具、扩展等虽然都可以从茫茫数据中异步获取所需的json、jsonp数据，但是如果每次爬虫都要如此，对我而言实在是太累了，所以呢，使用Selenium呗。 Selenium安装server的安装Python直接在终端使用pip install -u命令安装，如果想要替换默认的Pyhton安装版本，cd到想要使用的目录Scripts下。比如我通常使用Python版本是py3.x，现在想要暂时换到py2.x下： C:/Python27/Scripts/pip.exe install -u selenium 注意在终端中使用的分隔符，Win平台下的目录系统分隔符&#39;\&#39;在终端中很可能不奏效，建议使用转义字符&#39;\\&#39;或者通用的&#39;/&#39;。 之后就是browser driver的安装; 安装browser driverSelenium在PC平台上提供IE、Chrome、Firefox、Opera等真实浏览器的支持，以及PhantomJS、HtmlUnit等伪浏览器。其中FireFox、Safari、HtmlUnit都已经包含在webdriver包里面（遗憾的是由于HtmlUnit是Pure Java编写，不支持Pyhton平台），而其余的需要选择需要的driver下载。 chromedriver戳这里 Iedriver戳这里 Operadriver戳这里 PhantomJS戳这里 下载完成后，尝试运行，会发现无法正常使用。现在，你就把这个可执行程序移动到Python的环境变量中，使pyhton可以扫描到。 Selenium的简单语法 输入框（text field or textarea） 12345678 #找到输入框元素：element = driver.findElement(By.id("passwd-id")) #将输入框清空：element.clear() #在输入框中输入内容：element.sendKeys(“test”) #获取输入框的文本内容：element.getText() 下拉选择框(Select) 123456789101112131415 #找到下拉选择框的元素：select = driver.findElement(By.id("select")) #选择对应的选择项：select.selectByVisibleText(“mediaAgencyA”) #或select.selectByValue(“MA_ID_001”) #不选择对应的选择项：select.deselectAll()select.deselectByValue(“MA_ID_001”)select.deselectByVisibleText(“mediaAgencyA”) #或者获取选择项的值：select.getAllSelectedOptions()select.getFirstSelectedOption() Tips: 对下拉框进行操作时首先要定位到这个下拉框,然后对它进行操作 单选项(Radio Button) 12345678 #找到单选框元素：bookMode =driver.findElement(By.id("BookMode")) #选择某个单选项：bookMode.click() #清空某个单选项：bookMode.clear() #判断某个单选项是否已经被选择bookMode.isSelected() 多选项(checkbox) 123456 #多选项的操作和单选的差不多：checkbox =driver.findElement(By.id("myCheckbox."))checkbox.click()checkbox.clear()checkbox.isSelected()checkbox.isEnabled() 按钮(button) 123456 #找到按钮元素：saveButton = driver.findElement(By.id("save")) #点击按钮：saveButton.click() #判断按钮是否enable:saveButton.isEnabled () 左右选择框也就是左边是可供选择项，选择后移动到右边的框中，反之亦然。 1lang = new Select(driver.findElement(By.id(&#34;languages&#34;)))&#10;lang.selectByVisibleText(&#8220;English&#8221;)&#10;addLanguage =driver.findElement(By.id(&#34;addButton&#34;))&#10;addLanguage.click() 弹出对话框(Popup dialogs) 1234alert = driver.switchTo().alert()alert.accept()alert.dismiss()alert.getText() 表单(Form)Form中的元素的操作和其它的元素操作一样，对元素操作完成后对表单的提交可以： 1234approve = driver.findElement(By.id("approve"))approve.click() #或者approve.submit();//只适合于表单的提交 上传文件 (Upload File)上传文件的元素操作： 123adFileUpload = driver.findElement(By.id("WAP-upload"))String filePath = "C:\test\\uploadfile\\media_ads\\test.jpg"adFileUpload.sendKeys(filePath) 导航 (Navigationand History) 12345 #打开一个新的页面： driver.navigate().to("http://www.example.com") #通过历史导航返回原页面：driver.navigate().forward()driver.navigate().back() 获取页面CSS属性 1234 #获取文字颜色dr.findElement(By.id("tooltip")).getCssValue("color") #获取文字字号dr.findElement(By.tagName("h3")).getCssValue("font") 爬虫这次要爬虫的页面是一个教务管理系统,有着超级丑的界面，登录页面有三个信息需要我们了解， 用户类型–radio 用户名–input 密码–input 当我们输入正确的信息，选择合适的类型之后提交表格到验证页面，就可以返回用户的个人信息界面。 123456789101112131415161718from selenium import webdriverc = webdriver.Chrome() # Get local session of chromec.get(your_url) # Load page #定位到用户元素 通过Xpath，通过chrome的审查元素可以直接复制ele=c.find_element_by_xpath('//*[@id="__01"]/tbody/tr[2]/td[2]/form/div/table/tbody/tr[2]/td[2]/input') #直接send_key相当于append，容易忽略掉默认的hintele.clear()ele.send_keys('******') #定位到密码元素passwd=c.find_element_by_xpath('//*[@id="__01"]/tbody/tr[2]/td[2]/form/div/table/tbody/tr[3]/td[2]/input')passwd.clear()passwd.send_keys('******') #定位到用户类型单选并选择c.find_element_by_xpath('//*[@id="__01"]/tbody/tr[2]/td[2]/form/div/table/tbody/tr[1]/td[1]/input').click() #定位到表单提交按钮submit=c.find_element_by_class_name('button03')submit.submit()#或者也可以用 submit.click() 如果没有失误，已经到了个人用户界面。最麻烦的就是这里，因为他是框架套框架，我们需要获取的框架的上一层还无法定位。 1234567891011121314&lt;frameset framespacing="0" border="0" rows="100,*" frameborder="0" oncontextmenu="return false" oncopy="document.selection.empty()"&gt; &lt;frame name="banner" scrolling="no" noresize target="contents" src="s_top.htm"&gt; &lt;frameset cols="130,*"&gt; &lt;frame name="contents" target="main" src="../scripts/tree.asp" scrolling="auto" style="background-color: #FFFF66" noresize&gt; &lt;frame name="main" src="../asp/s_welcome.asp"&gt; &lt;/frameset&gt; &lt;noframes&gt; &lt;body topmargin="0" leftmargin="0"&gt; &lt;p&gt;此网页使用了框架，但您的浏览器不支持框架。&lt;/p&gt; &lt;/body&gt; &lt;/noframes&gt;&lt;/frameset&gt; 在Selenium中如果想要定位元素，首要的是你要在当前框架内，Selenium要一步步的切换框架。 c.switch_to.frame(frame.id or frame.name) 不能直接跳步进入最后的框架，这里我们要进入的框架是&#39;contents&#39;，最终，我讨巧使用get方式直接获取这个框架的源文件。因为这里的上下文信息（context）完全一样，我们使用get相当于将这个框架刷新一遍而已。 get这个框架之后，就可以继续进行元素的定位blablabla~~~~ 这是完整的代码: 1234567891011121314151617181920212223from selenium import webdriverc = webdriver.PhantomJS() # Get local session of firefoxc.get("http://222.195.8.201/") # Load pageele=c.find_element_by_xpath('//*[@id="__01"]/tbody/tr[2]/td[2]/form/div/table/tbody/tr[2]/td[2]/input')ele.clear()ele.send_keys('********')passwd=c.find_element_by_xpath('//*[@id="__01"]/tbody/tr[2]/td[2]/form/div/table/tbody/tr[3]/td[2]/input')passwd.clear()passwd.send_keys('********')c.find_element_by_xpath('//*[@id="__01"]/tbody/tr[2]/td[2]/form/div/table/tbody/tr[1]/td[1]/input').click()submit=c.find_element_by_class_name('button03')submit.submit()c.get('http://222.195.8.201/student/scripts/tree.asp')#c.find_element_by_xpath('/html/body/table/tbody/tr[9]/td/input').click()c.get('http://222.195.8.201/student/asp/Select_Success.asp')content=c.find_element_by_xpath('/html/body/table/tbody').textitems=content.split('\n')for i in range(0,len(items)-1): item=items[i].split(' ') print(item[2],item[4],item[5]) 尝试使用了多种的Browser Driver测试，在相同的网络环境下，同样的任务，PhantomJS速度最快、其次是Chrome，而FireFox简直感人.. 就这个例子来讲，PhantomJS因为不需要真实的浏览器在前端加载CSS等信息，只是纯粹的模拟运行，时间上只用了3.7s；Chrome虽然是一个完整的实例运行，速度也是相当不错，7s左右，Firefox要20+…. END]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伯乐对象身高爬虫]]></title>
    <url>%2F2016%2F02%2F27%2F%E4%BC%AF%E4%B9%90%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[最近在朋友的博客里看到了一篇文章，是讲伯乐在线这个网站上有一个面向对象栏目。什么是面向对象呢，面向对象是一个专门为IT单身男女服务的征友传播平台,由伯乐在线专门为程序员爱情创立的一个公益+免费活动。简单来说，网站的女用户在这个栏目组发帖子，包括自己的相关信息，以及理想的男友条件，男生们可以付出一定代价获得女用户保存在网站上的个人联系方式，看对眼的话，就去领证:) 然后呢，我这个朋友关注的点不太主流，他不用爬虫爬妹子照片，或者通过黑客攻击拿到妹子的联系方式，反而用python将所有发表的帖子当中对身高的要求给爬了..&gt; 下面是我将他的代码改进： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import requestsimport reimport osimport sysimport timefrom bs4 import BeautifulSouppageNum = 10 # 所有帖子总共10页urlsFile = os.path.join(sys.path[0],'urls.txt')# 保存帖子url的本地路径的字符串,os.path.join()知识提供文件路径拼接功能 如果想要创建文件夹 则使用os.mkdir(path)infoNum = 0 #有效信息的总条数num = 0 #包含敏感信息的总条数# 获取所有帖子的urldef getUrls(): if(os.path.exists(urlsFile)): return getUrlsFromFile()#如果本地存在数据直接从本地读取 urlList = list() url='http://date.jobbole.com/page/1/?sort=latest' while url: html = requests.get(url) pattern = "href=\"(.*?)\"&gt;.*?&lt;/a&gt;&lt;label class=\"hide-on-480 small-domain-url\"&gt;&lt;/label&gt;" result = re.findall(pattern,html.text) urlList = urlList + result tem=(re.findall('&lt;li id=\"pagination-next-page\"&gt;&lt;a href=\"(.*?)\"',html.text)) if len(tem)&gt;0:url=tem[0] else:url=None saveUrls(urlList) #保存到本地 return urlList#本地读取所有帖子的urldef getUrlsFromFile(): urlList = list() f = open(urlsFile,"r") for line in f.readlines(): #全部读取再按行打乱 则每行是带换行符的数据，使用时 strip过滤 urlList.append(line.strip()) f.close() return urlList#将帖子信息存入本地文件中def saveUrls(urlList): f = open(urlsFile,"w") f.write('%s' % '\n'.join(urlList))#查询该帖子下的内容def viewUrl(url): global infoNum result = "" html = requests.get(url) soup = BeautifulSoup(html.text,"lxml") info = soup.find("div",&#123;"class":"p-entry"&#125;) info = str(info) pattern = "对另一半的最低要求是：(.*?)&lt;br/&gt;" r = re.findall(pattern,info) if len(r)&gt;0:#保证不会抛出异常 if (r[0]!=""): infoNum = infoNum+ 1 result = r[0] isAboutH(result)#是否有涉及身高的敏感信息def isAboutH(info): global num print(info) keys=['(\d&#123;3&#125;)','(\d\.\d\d)','(\d\.\d)'] f = open("infoH.txt","a") for p in keys: r = re.findall(p,info) if(len(r)): num = num + 1 f.write(str(r[0])+"\n") f.close() print(r[0]) break f.close() print("\n")#读取在文件中的身高数据求平均值def getAvarge(): numList=list() f = open("infoH.txt","r") for line in f.readlines(): line=line.strip() if line!='': #去除小数点 if line.find('.')!=-1: line=(float(line))*100 num = float(line) numList.append(num) result=0.0 for num in numList: result+=num return result/len(numList)urlList = getUrls()num = 0#每次爬去时需将上次爬虫信息清空f = open("infoH.txt","w")f.close()for i in range(0,len(urlList)): print('第'+str(i+1)+'个begin:') viewUrl(urlList[i]) print('进度 %.2f\n' % ((i+1)/len(urlList))) time.sleep(0.1)print(infoNum)print(num)print('平均身高 %.2f' % getAvarge()) 这个小玩具呢，实际上很简单，通常我在解析网页信息的时候有两种简单粗暴地选择， BeautifulSoup解析 正则表达式 由于我也没有通过具体的数值计算了解这两种方式的效率，所以我就顺意优先使用BeautifulSoup，如果一个信息通过一次简单的BS解析无法完成时，在这里我就使用Re正则表达式。 通过爬虫信息可以看出，妹子们的要求实际上没有太高，（当然可能是怕吓跑太多人555~），有150+的有效数据，而明确要求最低身高的大概80名左右，经过计算平均值在172左右，嗯，好吧，就这样。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Requests</tag>
        <tag>re</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win建立FTP]]></title>
    <url>%2F2016%2F02%2F27%2Fwin%E5%BB%BA%E7%AB%8BFTP%2F</url>
    <content type="text"><![CDATA[win7系统下利用自带的IIS开启FTP服务，不用关闭防火墙。 步骤 开启FTP服务： 控制面板 -&gt; 程序 -&gt; 打开和关闭Windows功能 -&gt; 在弹出的窗口中选择开启FTP功能和ISS管理控制台。 新建FTP站点 右键“我的电脑” -&gt; 管理，弹出的“计算机管理”窗口 -&gt; 展开服务和应用程序节点，点选Internet信息服务（IIS）管理器 -&gt; 右键“网站”，选择添加FTP站点。按个人需要填写信息即可。 设置防火墙 在开始菜单中输入 window然后找到windows防火墙，点允许程序或功能通过windows防火墙. 在允许程序通过windows防火墙通信中选择FTP服务器，点击下方的“允许运行另一程序”，在弹出窗口里，点“浏览”，找到C:\Windows\System32\inetsrv\inetinfo.exe，点添加，也就是Internet Infomation Services。将后面的两个框也都选中。因为在Win7下，FTP是IIS的一个组件，因此也必须在防火墙中将IIS设置为允许。而IIS又不在默认的列表中，因此得手动添加。 在windows防火墙中点高级设置，在入站规则中点新建规则，选中端口，点下一步 在然后在特定本地端口中输入21，点下一步 登录使用在浏览器中输入建立的FTP服务器地址，比如: ftp://192.168.1.101 会出现登录框,输入你设置的用户名、密码就可以在浏览器中使用FTP功能。]]></content>
      <categories>
        <category>日常</category>
      </categories>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FTP]]></title>
    <url>%2F2016%2F02%2F27%2FFTP%2F</url>
    <content type="text"><![CDATA[FTP小序FTP（File Transfer Protocol），是文件传输协议的简称。用于Internet上的控制文件的双向传输。同时，它也是一个应用程序（Application）。用户可以通过它把自己的PC机与世界各地所有运行FTP协议的服务器相连，访问服务器上的大量程序和信息。 概述 文件传输是Internet提供的一项基本服务，通过Internet，可以把文件从一台计算机传送到另一台计算机，文件传输服务必须遵循文件传输协议（File Transfer Protocol，FTP）。通过FTP从远程计算机上获取文件称为下载（Download）；将本地计算机上的文件复制到远程计算机上称为上传（Upload），文件的“上传”和“下载”功能是用户上网经常要使用到的，许多用户都要从网上“下载”一些文件和资料，那些拥有个人博客（Blog）或者要进行网站管理的用户，经常需要“上传”自己的文件。 正如其名所示FTP的主要作用，就是让用户连接上一个远程计算机（这些计算机上运行着FTP服务器程序）察看远程计算机有哪些文件，然后把文件从远程计算机上拷到本地计算机，或把本地计算机的文件送到远程计算机去。 当启动FTP从远程计算机拷贝文件时，事实上启动了两个程序：一个本地机上的FTP客户程序：它向FTP服务器提出拷贝文件的请求。另一个是启动在远程计算机的上的FTP服务器程序，它响应你的请求把你指定的文件传送到你的计算机中。FTP采用“客户机/服务器”方式，用户端要在自己的本地计算机上安装FTP客户程序。FTP客户程序有字符界面和图形界面两种。字符界面的FTP的命令复杂、繁多。图形界面的FTP客户程序，操作上要简洁方便的多。 支持FTP协议的服务器就是FTP服务器，下面介绍一下什么是FTP协议。用户联网的首要目的就是实现信息共享，文件传输是信息共享非常重要的一个内容之一。Internet上早期实现传输文件，并不是一件容易的事，Internet是一个非常复杂的计算机环境，有PC，有工作站，有MAC，有大型机，据统计连接在Internet上的计算机已有上千万台，而这些计算机可能运行不同的操作系统，有运行Unix的服务器，也有运行Dos、Windows的PC机和运行MacOS的苹果机等等，而各种操作系统之间的文件交流问题，需要建立一个统一的文件传输协议，这就是所谓的FTP。基于不同的操作系统有不同的FTP应用程序，而所有这些应用程序都遵守同一种协议，这样用户就可以把自己的文件传送给别人，或者从其它的用户环境中获得文件。 工作原理 与大多数Internet服务一样，FTP也是一个客户机/服务器系统。用户通过一个支持FTP协议的客户机程序，连接到在远程主机上的FTP服务器程序。用户通过客户机程序向服务器程序发出命令，服务器程序执行用户所发出的命令，并将执行的结果返回到客户机。比如说，用户发出一条命令，要求服务器向用户传送某一个文件的一份拷贝，服务器会响应这条命令，将指定文件送至用户的机器上。客户机程序代表用户接收到这个文件，将其存放在用户目录中。 在FTP的使用当中，用户经常“下载”（Download）和“上载”（Upload）。“下载”文件就是从远程主机拷贝文件至自己的计算机上；“上载”文件就是将文件从自己的计算机中拷贝至远程主机上。用Internet语言来说，用户可通过客户机程序向（从）远程主机上载（下载）文件。 使用FTP时必须首先登录，在远程主机上获得相应的权限以后，方可上载或下载文件。也就是说，要想同哪一台计算机传送文件，就必须具有哪一台计算机的适当授权。换言之，除非有用户ID和口令，否则便无法传送文件。这种情况违背了Internet的开放性，Internet上的FTP主机何止千万，不可能要求每个用户在每一台主机上都拥有帐号。匿名FTP就是为解决这个问题而产生的。 匿名FTP是这样一种机制，用户可通过它连接到远程主机上，并从其下载文件，而无需成为其注册用户。系统管理员建立了一个特殊的用户ID，名为anonymous,Internet上的任何人在任何地方都可使用该用户ID。 通过FTP程序连接匿名FTP主机的方式同连接普通FTP主机的方式差不多，只是在要求提供用户标识ID时必须输入anonymous，该用户ID的口令可以是任意的字符串。习惯上，用自己的E-mail地址作为口令，使系统维护程序能够记录下来谁在存取这些文件。匿名FTP不适用于所有Internet主机，它只适用于那些提供了这项服务的主机。当远程主机提供匿名FTP服务时，会指定某些目录向公众开放，允许匿名存取。系统中的其余目录则处于隐匿状态。作为一种安全措施，大多数匿名FTP主机都允许用户从其下载文件，而不允许用户向其上载文件，也就是说，用户可将匿名FTP主机上的所有文件全部拷贝到自己的机器上，但不能将自己机器上的任何一个文件拷贝至匿名FTP主机上。即使有些匿名FTP主机确实允许用户上载文件，用户也只能将文件上载至某一指定上载目录中。随后，系统管理员会去检查这些文件，他会将这些文件移至另一个公共下载目录中，供其他用户下载，利用这种方式，远程主机的用户得到了保护，避免了有人上载有问题的文件，如带病毒的文件。 作为一个Internet用户，可通过FTP在任何两台Internet主机之间拷贝文件。但是，实际上大多数人只有一个Internet帐户，FTP主要用于下载公共文件，例如共享软件、各公司技术支持文件等。Internet上有成千上万台匿名FTP主机，这些主机上存放着数不清的文件，供用户免费拷贝。实际上，几乎所有类型的信息，所有类型的计算机程序都可以在Internet上找到。这是Internet吸引重要原因之一。 匿名FTP是Internet网上发布软件的常用方法。Internet之所以能延续到今天，是因为人们使用通过标准协议提供标准服务的程序。像这样的程序，有许多就是通过匿名FTP发布的，任何人都可以存取它们。 Internet中的有数目巨大的匿名FTP主机以及更多的文件，那么到底怎样才能知道某一特定文件位于哪个匿名FTP主机上的那个目录中。这正是Archie服务器所要完成的工作。Archie将自动在FTP主机中进行搜索，构造一个包含全部文件目录信息的数据库，使你可以直接找到所需文件的位置信息。 传输步骤要进行远程文件传输的计算机必须安装和运行ftp客户程序。在windows操作系统的安装过程中，通常都安装了tcp/ip协议软件，其中就包含了ftp客户程序。但是该程序是字符界面而不是图形界面，这就必须以命令提示符的方式进行操作，很不方便。 启动ftp客户程序工作的另一途径是使用IE浏览器，用户只需要在ie地址栏中输入如下格式的url地址：ftp：//用户名：口令@ ftp服务器域名端口号(在CMD命令行下也可以用上述方法连接，通过put命令和get命令达到上传和下载的目的，通过ls命令列出目录，除了上述方法外还可以在cmd下输入ftp回车，然后输入openIP来建立一个连接，此方法还适用于linux下连接ftp服务器) 通过IE浏览器启动ftp的方法尽管可以使用，但是速度较慢，还会将密码暴露在IE浏览器中而不安全。因此一般都安装并运行专门的ftp客户程序。 在本地电脑上登陆到国际互联网。 搜索有文件共享主机或者个人电脑(一般有专门的FTP服务器网站上公布的，上面有进入该主机或个人电脑的名称，口令和路径)。 当与远程主机或者对方的个人电脑建立连接后，用对方提供的用户名和口令登陆到该主机或对方的个人电脑、 在远程主机或对方的个人电脑登陆成功后，就可以上传你想跟别人分享的东东或者下载别人授权共享的东东(这里的东东是指能放到电脑里去又能在显示屏上看到的东东)。 完成工作后关闭FTP下载软件，切断连接。 运行模式FTP支持两种模式，一种方式叫做Standard(也就是PORT方式，主动方式)，一种是Passive(也就是PASV，被动方式)。Standard模式FTP的客户端发送PORT命令到FTP服务器。Passive模式FTP的客户端发送PASV命令到FTPServer。下面介绍一个这两种方式的工作原理： Port模式FTP客户端首先和FTP服务器的TCP21端口建立连接，通过这个通道发送命令，客户端需要接收数据的时候在这个通道上发送PORT命令。PORT命令包含了客户端用什么端口接收数据。在传送数据的时候，服务器端通过自己的TCP20端口连接至客户端的指定端口发送数据。FTPserver必须和客户端建立一个新的连接用来传送数据。 Passive模式在建立控制通道的时候和Standard模式类似，但建立连接后发送的不是Port命令，而是Pasv命令。FTP服务器收到Pasv命令后，随机打开一个高端端口（端口号大于1024）并且通知客户端在这个端口上传送数据的请求，客户端连接FTP服务器此端口，然后FTP服务器将通过这个端口进行数据的传送，这个时候FTPserver不再需要建立一个新的和客户端之间的连接。 很多防火墙在设置的时候都是不允许接受外部发起的连接的，所以许多位于防火墙后或内网的FTP服务器不支持PASV模式，因为客户端无法穿过防火墙打开FTP服务器的高端端口；而许多内网的客户端不能用PORT模式登陆FTP服务器，因为从服务器的TCP20无法和内部网络的客户端建立一个新的连接，造成无法工作。]]></content>
      <categories>
        <category>日常</category>
      </categories>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打赏]]></title>
    <url>%2F2016%2F02%2F27%2F%E6%89%93%E8%B5%8F%2F</url>
    <content type="text"><![CDATA[随着支付宝和微信转账支付的日益深入人心，有时候我们甚至可以在很多博客文章后面看到小编和文章作者自己添加的DIY打赏功能，包括微信、支付宝等扫描支付转账，本篇文章就是为hexo优化，在每篇文章后面添加打赏功能。 打赏模块的代码layout\_partial 下新建 donate.ejs 输入如下内容： 123456789101112131415161718192021222324&lt;! -- 添加捐赠图标 --&gt;&lt;div class ="post-donate"&gt; &lt;div id="donate_board" class="donate_bar center"&gt; &lt;a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"&gt;&lt;/a&gt; &lt;span class="donate_txt"&gt; &amp;uarr;&lt;br&gt; &lt;%=theme.donate_message%&gt; &lt;/span&gt; &lt;br&gt; &lt;/div&gt; &lt;div id="donate_guide" class="donate_bar center hidden" &gt; &lt;!-- 支付宝打赏图案 --&gt; &lt;img src="https://raw.githubusercontent.com/chuangwailinjie/chuangwailinjie.github.io/master/img/zhifubao.jpg" alt="支付宝打赏"&gt; &lt;!-- 微信打赏图案 --&gt; &lt;img src="https://raw.githubusercontent.com/chuangwailinjie/chuangwailinjie.github.io/master/img/wx.jpg" alt="微信打赏"&gt; &lt;/div&gt; &lt;script type="text/javascript"&gt; document.getElementById('btn_donate').onclick = function()&#123; $('#donate_board').addClass('hidden'); $('#donate_guide').removeClass('hidden'); &#125; &lt;/script&gt;&lt;/div&gt;&lt;! -- 添加捐赠图标 --&gt; 设置打赏模块的样式source\css\_partial 下新建 donate.styl 输入如下内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546.donate_bar &#123; text-align: center; margin-top: 5%&#125;.donate_bar a.btn_donate &#123; display: inline-block; width: 82px; height: 82px; margin-left: auto; margin-right: auto; background: url(http://img.t.sinajs.cn/t5/style/images/apps_PRF/e_media/btn_reward.gif)no-repeat; -webkit-transition: background 0s; -moz-transition: background 0s; -o-transition: background 0s; -ms-transition: background 0s; transition: background 0s&#125;.donate_bar a.btn_donate:hover &#123; background-position: 0 -82px&#125;.donate_bar .donate_txt &#123; display: block; color: #9d9d9d; font: 14px/2 "Microsoft Yahei"&#125;.donate_bar.hidden&#123; display: none&#125;.post-donate&#123; margin-top: 80px;&#125;#donate_guide&#123; height: 210px; width: 420px; margin: 0 auto;&#125;#donate_guide img&#123; height: 200px; height: 200px;&#125; 最后，记得在 source\css\style.styl 中添加 @import &#39;_partial/donate&#39;第三步： 讲打赏模块整合到文章中在 layout\_partial\article.ejs 中的 &lt;article&gt; &lt;/article&gt; 标签内添加如下内容：123&lt;% if (!index &amp;&amp; theme.donate)&#123; %&gt; &lt;%- partial('donate') %&gt;&lt;% &#125; %&gt; 第四步： 编写配置文件我们可以在主题的 _config.yml 文件中关闭和打开打赏功能，还可以自定义设置打赏文案。例如： #是否开启打赏功能donate: true #打赏文案donate_message: ****]]></content>
      <categories>
        <category>日常</category>
      </categories>
      <tags>
        <tag>hexo优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优化目录]]></title>
    <url>%2F2016%2F02%2F27%2F%E4%BC%98%E5%8C%96%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[这次主要介绍一下如何使用Hexo自带的帮助函数在站点中添加文章目录。功能使用了Hexo提供的帮助函数，创建对应局部模块之前，首先要想想这块内容应该属于哪个布局？要添加到哪个局部模块下？考虑这些是为了整洁性，当你添加的东西越来越多的时候才不至于令自己混乱。 文章目录文章目录肯定是添加到post布局上，这个毋庸置疑，因为只有看文章详情页的时候才需要目录。那么我们在目录layout/_partial/post/下创建toc.ejs文件，代码如下： 1234&lt;div id="toc" class="toc-article"&gt; &lt;div class="toc-title"&gt;目录&lt;/div&gt; &lt;%- toc(item.content, &#123;list_number: false&#125;) %&gt;&lt;/div&gt; 这里使用了Hexo提供的toc()帮助函数，它的使用方法如下： 1&lt;%- toc(str, [options]) %&gt; str就是文章内容，options有两个参数，一个是class，也就是html标签的class值，默认为toc；一个是list_number，是否显示列表编号，默认值是true。 接下考虑把这个局部模块放到哪呢，既然属于post布局，那么就看看layout/post.ejs代码如下: 1&lt;%- partial('_partial/article', &#123;item: page, index: false&#125;) %&gt; 很明显，我们要到_partial/article.ejs文件里添加toc.ejs，添加后article.ejs代码如下： 1234567891011121314&lt;div class="article-entry" itemprop="articleBody"&gt; &lt;% if (post.excerpt &amp;&amp; index)&#123; %&gt; &lt;%- post.excerpt %&gt; &lt;% &#125; else &#123; %&gt; &lt;!-- Table of Contents --&gt; &lt;% if (!index &amp;&amp; post.toc)&#123; %&gt; &lt;div id="toc" class="toc-article"&gt; &lt;strong class="toc-title"&gt;文章目录&lt;/strong&gt; &lt;%- toc(post.content) %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;%- post.content %&gt; &lt;% &#125; %&gt; &lt;/div&gt; 判断是否有摘要以及index值，显然post.ejs传过来的index值为false； 接下来判断page.toc是不是不等于false，这一块的主要作用是可以在文章的前置声明里设置toc: false来关闭目录功能。当没有设置false时，插入上面写的toc.ejs局部模块。 OK！完美嵌入进去，接下来就是设置样式了，进入source/css/_partial/目录下，创建toc.styl.最后别忘了在source/css/style.styl文件里加入这句了@import &#39;_partial/toc&#39;。显示如下图，样式可以自行调整。 toc.styl 123456789101112131415161718192021222324252627282930313233.toc-article &#123; background: #eee; padding: 1em; position: relative; left:2em;&#125; .toc-article .toc-title&#123; padding-bottom: 0.8em; font-weight: bold;&#125; #toc &#123; line-height: 1.1em; font-size: 0.8em; float: right&#125; #toc .toc &#123; padding: 0&#125; #toc li , .toc li &#123; list-style-type: none&#125; #toc ol &#123; margin: 0;&#125; #toc .toc-child &#123; padding-left: 1.5em&#125; 效果如图]]></content>
      <categories>
        <category>日常</category>
      </categories>
      <tags>
        <tag>hexo优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[片上网络]]></title>
    <url>%2F2016%2F02%2F25%2F%E7%89%87%E4%B8%8A%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[引言随着半导体工艺技术步入纳米阶段，在单一芯片中集成上亿晶体管已经成为现实，据itrs（international technology roadmap for semiconductors，国际半导体技术路线图）预测，到2010年，单个芯片上的晶体管数目将达到22亿个。如何有效地利用数目众多的晶体管是芯片体系结构必须回答的新问题。倘若因循单核的发展思路，芯片设计将面临互连延迟、存储带宽、功耗极限等性能提升的瓶颈问题。因此，业内普遍认识到，有必要研究新型的芯片体系架构以适应性能增长和功耗下降同时发生这样看似矛盾的需求。多核技术是一条可行之路。多核能够用多个低频率核单元产生超过高频率单核的处理效能，获得较佳的性价比。围绕着多核的一系列技术问题业已成为近期芯片业研究的重点和未来的主要发展方向。 按照不同的片上互连方式，多核soc可分为两大类：传统的基于总线的互连和基于网络的互连。前者是现有soc的扩展，通过多总线及层次化总线等技术使得片上集成更多的处理器核，从而实现高复杂度和高性能；而后者是近些年提出的崭新的概念，即多处理器核之间采用分组路由的方式进行片内通信，从而克服了由总线互连所带来的各种瓶颈问题，这种片内通信方式称为片上网络（network on a chip，noc）。 noc概述 基本概念noc是指在单芯片上集成大量的计算资源以及连接这些资源的片上通信网络，如图1所示。noc包括计算和通信两个子系统，计算子系统（图中由pe，processing element构成的子系统）完成广义的“计算”任务，pe既可以是现有意义上的cpu、soc，也可以是各种专用功能的ip核或存储器阵列、可重构硬件等；通信子系统（图中由switch组成的子系统）负责连接pe，实现计算资源之间的高速通信。通信节点及其间的互连线所构成的网络被称为片上通信网络（on-chip network, ocn）[1-3]，它借鉴了分布式计算系统的通信方式，用路由和分组交换技术替代传统的片上总线来完成通信任务。 noc技术优势分析基于分组路由方式进行片上通信的noc在片上通信方式、功耗、基于重用的设计方法学、解决单一时钟全局同步等方面都具有优越性。 有利于提高通讯带宽总线结构是现有芯片架构的通信脉络，随着电路规模越来越大，总线结构将成为芯片设计的瓶颈：虽然总线可以有效地连接多个通信方，但总线地址资源并不能随着计算单元的增加而无限扩展；虽然总线可由多用户共享，但一条总线无法支持一对以上的用户同时通信，即串行访问机制导致了通信的瓶颈。此外，片上通信是功耗的主要来源，庞大的时钟网络与总线的功耗将占据芯片总功耗的绝大部分。noc的网络拓扑结构提供了良好的可扩展性；noc连线网络提供了良好的并行通信能力，从而使得通信带宽增加几个数量级；此外，noc将长的互连线变成交换开关之间互相连接的短连线，这对功耗控制变得极为有利；另一方面，noc借鉴了通讯协议中的分层思想，这就为从物理级到应用级的全面功耗控制提供了可能。 有利于提升重用设计总线架构可扩展性和可重用性差，为此在芯片计算能力演变时，必须跟随着处理能力的需求而变更设计（如更高的内存宽度、更高的频率、更灵活的同步或异步设计等等），每一代芯片的推出都伴随着程度不等的设计变更，这对于开发人员而言是相当大的负担。若是将通信架构独立设计，并且运用更具弹性的技术，对于缩短设计周期、减少开发成本都有不小的帮助。由于noc所使用的通信协议层本身属于独立的资源，因此提供了支持高效率可重用设计方法学的体系结构：现有规模的soc可以基于片上通信协议作为计算节点“即插即用”于noc的网络节点；给定的互连拓扑结构使得芯片集成可以采用基于片上通信的设计方法（communication-based design，cbd）来完成。通信和计算完全分离的技术（也就是通信与计算的正交设计）将重用范围从计算单元可重用扩展到计算与通信单元皆可重用的层次，从而大大提升了重用设计的水平。 有利于解决全局同步的难题纳米工艺所带来的各种物理效应使得片上全局同步越来越困难。当采用50nm工艺，时钟频率为10ghz时，全局线延迟将达6～10个时钟周期，时钟偏斜（skew）变得难以控制，而时钟树又是影响芯片功耗和成本的一个主要因素。这些问题，随着集成器件尺寸越来越小，时钟频率越来越高，将变得越来越突出。noc的片内网络通信方式，资源之间的短线互连和天然的全局异步局部同步（gals）时钟策略等特性是解决这些问题有效途径。总而言之，研究noc设计方法和设计技术是满足纳米工艺条件下高集成度芯片发展的必然需求。 noc设计空间完整的noc设计方法学包括很多方面的问题，它们对noc的发展都是至关重要的，且已经引起了学术界的广泛研究。carnegie mellon大学的u.y. ogras等人在文献中提出了noc设计空间的概念并将noc研究归纳为三大类关键问题：基础架构、通讯机制和映射优化 图中，“hard noc”（网格部分）指基本架构确定，各pe节点的内容也固定的一类noc结构，其设计空间只是图中一矩形部分，设计余度最小；“firm noc”（灰色阴影空间）指其基本架构已确定，网络通道宽度与通讯节点缓存大小不确定，其他维度对设计者完全自由的一类noc结构，设计者可以根据确定的应用实现最优的布图规划、通讯调度与任务分配算法、ip映射算法和路由交换解决方案，设计空间比较灵活；“soft noc”（白色立方体部分）指设计者需要根据应用来优化noc设计空间的所有问题，设计灵活性最高，但设计难度和工作量也相应最大。设计者根据给定的具体应用，依据应用特征图（application characterization graph，apcg），在时间、成本、技术储备等约束条件下，首先按应用选择基于哪类noc开展设计；其次在该类noc的设计空间范围内解决相应关键问题，以探索最优的noc实现方案。 noc关键技术难点noc关键技术主要包括系统建模、拓扑结构、路由方法、交换方法、缓存策略、服务质量和映射优化等，近年来都不同程度地取得研究进展，而阻碍noc走向大规模应用的瓶颈在于以下几方面： 存储结构问题memory是noc中十分重要的组件，在现有的片上多处理器系统中，存储器占到70％的芯片面积，并且在不久的将来会上升到90％；而从能耗的角度来看，存储器所引入的功耗也可达系统功耗的90％，这对芯片的散热、封装和可靠性等都带来了严重的问题；noc系统需要大量的存储元件，并被组织成复杂的存储子系统（memory subsystem），这个存储子系统将支持noc的并行数据存储、传输及交换。noc中大量的存储资源必将占用多个路由节点，且由于处理单元与存储资源之间的数据交换非常频繁，若在数据包传输路径上路由节点数目过多，会带来很大的通信延时。如何有效缩短源节点到目的节点间的距离对提高整个noc系统性能十分关键。再者，从通信带宽的角度，随着工艺的进步，计算访存比进一步增大，意味着基于该结构获得接近峰值性能的应用算法越少。这就引入了一系列问题，如何让众多处理器核有足够的数据可算？如何更充分地利用片上有限存储空间实现核间共享，以避免片外访存？如何充分利用有限访存带宽，尽量让访存通道优先满足处于关键路径处理器核的访问请求？最近美国sandia国家实验室提出在多核处理器芯片上堆叠存储芯片，来解决带宽增长不足的问题，这或许是一种可行的方案。总而言之，片上存储结构已经成为影响noc性能的关键因素之一。 软件并行化问题未来的基于多核的高性能处理芯片可能会遇到很多传统的串行程序自动并行化方法较难实施的应用。如果不能有效地利用noc片上并行处理资源，则并行计算的实际性能将会很低，因此如何通过有效的方法和模型，充分地利用noc的众多处理单元，并极大地降低应用的开发难度，便成为迫切需要解决的问题。与并行计算机发展过程中遇到的问题相类似，noc并行处理体系结构所面临的主要问题是如何将应用中蕴含的不同层次、不同粒度的并行性有效地提取出来并映射到多核的并行硬件结构上去。这一问题的解决涉及包括程序设计模型、程序设计语言、编译系统及硬件支撑等在内的多个方面。总体来说，开发并行程序可以有三种途径，一是串行程序自动并行化。这条路目前尚未走通，更为实际的目标应为人机交互的自动并行化；二是设计全新的并行程序设计语言。这种方法的缺点是需要全部改写原有程序，对用户来说成本和风险也很高，且效率不能保证。但是，随着多核的出现，若面向大众推广并行计算环境，就必须有一种新的容易被接受的程序设计语言。目前国际上正在研究的新兴并行程序设计语言如ibm的x10、upc（统一并行 c语言，c语言的扩展）和titanmin（java的扩展）等；第三条途径就是串行语言加并行库或伪注释制导语句的扩展，也即增加一个库或一些新的制导语句来帮助进行消息传递和并行。这正是mpi和openmp所采取的途径，也是目前比较容易被接受且性能较高的途径。但其程序开发效率很低，难度也比较大。 功耗管理问题虽然noc有助于提高芯片的能效（energy-efficiency），但不能忽视，由于多核系统片上集成规模的大幅度增加，功耗问题依然突出。如何在noc设计中提高能效，对众多计算资源进行调度管理以最大限度降低功耗依然是noc设计所面临的重要问题之一。从体系结构角度看，noc主要包括处理器核、核间互连以及片上存储三个主要部分。noc的低功耗研究可以围绕功耗评估，处理器核功耗优化，片上网络功耗优化以及片上存储功耗优化这四个方面对各部分展开，其中功耗评估是noc低功耗设计的基础。功耗是导致包括noc在内的多核技术出现的重要诱因，也是片上多处理器设计的重要制约因素。对于noc的不同设计模块和设计层次，都存在行之有效的降低功耗的方法，而这些方法又可能是互相牵制，互相影响的。因此需要贯穿noc体系结构到电路工艺的各方面的丰富知识，才能在设计早期做出正确的多核架构的选择。一般而言，从越高的设计抽象层次入手考虑低功耗设计问题，则可获得的降低功耗的效率就越大。 noc发展趋势 向层次化众核方向发展微软公司2007年6月在美国西雅图召开了第一个以manycore（众核）为主题的研讨会（workshop），标志着众核设计已经成为技术发展的趋势和学术研究的热点。集成电路设计总是想方设法把现有的各种电子电路乃至计算系统集成到单一芯片上，因此计算机体系结构历来是集成电路片上系统架构的参考体系。超级计算机是最强大的计算机，充分参考超级计算机的体系结构是设计多核处理器的基本思路。超级计算机体系架构的基本特征就是小核大阵列和层次化管理。无论是世界排名第一的roadrunner（122400个核），还是排名第二的bluegene/l（212992个核），如图3所示，都是采用高性能、层次化、可扩展的巨大阵列，连接数目众多的普通微处理器（小核）来保障最优的性能。超级计算机告诉我们，小核大阵列和层次化管理必将成为众核处理器的主流技术发展方向。 向三维noc方向发展itrs 2007年版阐述了more moore（延伸摩尔定律）和more than moore（超越摩尔定律）两个概念，如图4所示，其中延伸摩尔定律是按照等比例缩小继续走微细化的道路，而超越摩尔定律追求的是功能多样化，并指出下一代soc（noc）与sip技术融合的发展趋势。 正如itrs所预测，在工艺技术发展和设计技术需求的双重驱动下，三维集成（又称为系统级封装，sip）技术愈来愈受到学术界和工业界的关注和重视。noc虽然克服了全局延迟过长带来的信号完整性及全局同步等一系列问题，但并没有在根本上解决缩短物理连线，减小信号时延的问题。由于二维 noc布局条件的限制，难以保证关键部件相邻以缩短关键路径长度，而三维集成技术可把不同的器件层堆叠起来，不仅在真正意义上缩短了连线的长度，并克服这种布局的限制。因此把noc和三维集成这两种设计技术融合起来的三维 noc就显得自然且引人。三维noc是在单个芯片上将资源节点（resource）分布在不同的物理层上，并用三维立体架构实现资源间的互连，以构建高带宽、低延时、低功耗的noc系统。典型的三维mesh结构noc如图5所示。三维 noc是一个崭新的研究话题，近两年才在国际上被提出（最早一篇相关研究论文于2005年公开发表）。目前从事该领域研究的学术机构包括美国斯坦福大学、加州理工大学、宾州州立大学、华盛顿州立大学，瑞典皇家工学院、日本的keio university，加拿大的不列颠哥伦比亚大学，以及intel、toshiba等大公司的研究中心。可见，三维noc已经引起了国际上学术界和产业界的注意，很可能在未来几年内发展成为一个重要的研究领域，并得到广泛的关注。 产业发展趋势多核技术在产业界已有广泛应用。从intel、amd、sun、cisco等国际老牌企业，到picochip（2000年成立）、ambric（2003年成立）、tilera（2004年成立）等新兴公司，多核产品层出不穷；从超级计算机到pc机，从路由器等宽带应用到多媒体等嵌入式市场，多核产品逐渐广为人知。 vdc research于2007年发表了《多核计算的嵌入式应用：全球市场机会与需求分析》。报告分析了多核技术从2006年到2011年的市场需求走势，如图6所示。图中的纵轴是以2006年总值为单位1，其他年份与2006年相比多核产品市场总额的倍数关系。研究表明，多核技术到2011年，嵌入式应用领域的市场总额将超过2007年的6倍，超过2006的44倍。如此快速的增长速度决定了我国不应该介入太晚，否则就只能再次走“产品跟踪”的老路。 结语包括noc在内的多核技术是通用处理器技术升级的大方向已成为业内共识。多核技术是当代集成电路设计的战略性技术，它以很低的功率消耗、较强的并行处理以及优异的计算性能，征服了人们对集成电路性能的追求，“成为业界的重要里程碑”（intel总裁语）。先进的noc结构可以通过集成现有的百兆频率核形成高性能多核处理器，大大降低了技术门槛，为中等设计公司带来了机会，目前已有一批中等公司和新兴公司在多核领域崭露头角，“国际寡头”垄断高性能处理器的格局正在发生变化。对我国现有设计能力而言，即使不能“一步登天”，但完全可以做到“所想即所得”，这亦为我国发展自主产权的高性能处理器产业提供了宝贵的契机。]]></content>
      <categories>
        <category>片上网络</category>
      </categories>
      <tags>
        <tag>noc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoC小序]]></title>
    <url>%2F2016%2F02%2F25%2FNoC%2F</url>
    <content type="text"><![CDATA[片上网络（NoC）是基于多处理器技术的一种新型的计算集成形式，涉及硬件通信结构、中间件、操作系统通信服务、设计方法及工具等。基于NoC的系统能很好地适应在现在复杂SoC设计中常使用的多异步时钟。 片上网络的存储结构 物理层（Wiring）:主要解决通信通道的物理实现问题，包括互连结构、电气性能等，这时候的信号由于噪音的存在是不可靠的。 数据链路层（Data Link）:通过数据分包（packetize）技术解决物理层信号不可靠的问题。在数据包中加入标准错误检测码（ECC）或者其他冗余信息来实现数据包的检错纠错功能。 网络层（Network）:主要研究数据包如何在网络中传输，分为开关（Switching）算法或路由（Routing）算法，前者决定建立连接的类型，后者决定数据传输的路径。 传输层（Transport）:主要研究在发送方如何将数据分解并建立数据包以及在接受方如何从数据包中获得数据信息。 系统层（System）:系统软件负责提供一个抽象的物理平台。 应用层（Application）。 片上网络的性能 网络结构：在NOC中，普遍使用也是最适合的网络结构是包交换的直接网络。每个节点通过双向通道连接到相邻的节点。NOC的网络连接是异构的，需连接不同的处理部件和存储部件，通信量的分布也是不均匀的。 协议：在NOC巾，通信协议比总线协议要复杂得多，为了便于扩展，往往采用分层的网络协议。协议的每一层提供特定的功能和接口。 服务质量QOS：在NOC的路由决策时，可以提供服务质量，对关键部件的网络带宽或者延迟进行保证，没有被保证的通信采用尽力而为的路由策略。另外，由于中扰和电压降等问题使得部件之间的连线是不可靠的，为了保证可靠的数据传输，当遇到数据错误时，需要进行重传，NOC通过流控机制来保证服务质量。 片上网络的优缺点优点 通过点对点传输获得低功耗 通过分层协议获得可靠的传输 通过分组交换获得更高的链路利用率 通过并发和非阻塞交换获得更高的带宽 全局异步或准同步的、模块化、可升级的结构 缺点 交换电路和接口增加了电路面积 缓冲和增加的逻辑造成了功耗增加 与原有IP核接口和协议的兼容问题 数据打包、缓冲、同步和接口增加了延迟 片上网络面临的问题 带宽限制：总线是一种共享介质的互连结构，某一时刻只允许一个设备使用总线。仲裁逻辑允许高优先级的设备获得总线的使用权，在总线被占用期间，所有其他的请求被阻塞，直到总线空闲。如果成百上千个组件争用一条总线，很难想象结果会是怎样。这还没考虑由于太多的组件连接到总线上而导致的总线频率降低等因素。 信号集成度：更低的电源电压，更小的线宽，使得整个VLSI系统对电流中的噪声更加敏感。而共享介质上的更多功能部件则进一步加重了噪声。 信号延迟：随着特征尺寸的下降，连线延迟成为影响信号延迟的主要因素。总线结构是全局控制的。在10亿晶体管时代，全局的线延迟会大于时钟周期。总线结构的全局连线使得时钟的偏移很难管理。 全局同步：全局连线上的信号延迟决定了系统的时钟周期，为了保持甚至提高系统时钟频率，只能对全局连线进行分布流水，或者采用区域同步全局异步（GALS）的时钟模式。 片上网络的发展趋势片上网络的研究才刚刚起步，还没有在商业产品中广泛应用。片上网络的标准化可以增加组件的互连性，但会造成性能的损失，而对特定的片上系统，性能是片上系统的一个关键因素。片上网络的标准化与性能的权衡是一个重要的研究方向。另外，片上网络是一个全局异步、局部同步的系统，如何对片上网络系统进行模拟也是值得研究的问题。还有，不同应用领域对片上网络有不同的需求，研究面向特定应用领域（如多媒体、无线通信等）的片上网络，也是一个重要的研究方向。低功耗是片上系统的永恒话题，片上网络的低功耗研究当然也是一个重要的研究方向。由于片上网络涉及了从物理实现到体系结构、到操作系统、到应用的各个层次，这就需要对片上网络的各个层面进行研究。 尽管我们可以看到NOC在片上通信方面相比共享总线技术有着很大的优势，然而可以想象NOC并不会完全取代共享总线技术，事实上为了达到性能与复杂性的平衡，它们会相互结合并存在CMP系统中，比如在局部范围内仍然采用总线方式以达到较高的通信速度和较低的复杂度，而在全局范围内采用NOC以减少全局同步的需求、增加数据带宽并达到较高的信号可靠性。]]></content>
      <categories>
        <category>片上网络</category>
      </categories>
      <tags>
        <tag>noc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[校园网上网认证]]></title>
    <url>%2F2016%2F02%2F24%2FInternet_authentication%2F</url>
    <content type="text"><![CDATA[Python实现上网认证 在学校的同行们应该都知道，目前国内大部分高校的上网采用网络认证系统，这可以简单化不同用户的权限管理，同时对于财务处理方面也有很大的优势。国内类似的系统，例如锐捷，我接触的比较多，通过简单的B/S网页账户登录认证实现上网。这几天，我就尝试使用了抓包工具以及Pyhton的模块做了一个简单的模拟一键登录、一键下线工具。 Pyhton中流行的相关模块urllib urlencode不能直接处理unicode对象，所以如果是unicode，需要先编码，有unicode转到utf8，举例： 1urllib.urlencode (u'bl'.encode('utf-8')) 示例 1234567891011import urllib #sohu 手机主页url = 'http://m.sohu.com/?v=3&amp;_once_=000025_v2tov3&amp;_smuid=\ICvXXapq5EfTpQTVq6Tpz'resp = urllib.urlopen(url)page = resp.read()f = open('./urllib_index.html', 'w')f.write(page)print dir(resp)#结果:['doc', 'init', 'iter', 'module', 'repr', 'close', 'code', 'fileno', 'fp', 'getcode', 'geturl', 'headers', 'info', 'next', 'read', 'readline', 'readlines', 'url']print resp.getcode(), resp.geturl(), resp.info(), resp.headers, resp.url#resp.url和resp.geturl()结果一样 编解码示例 urllib.quote和urllib.urlencode都是编码，但用法不一样 123456789101112131415161718s = urllib.quote('This is python') #编码print 'quote:\t'+s ＃空格用%20替代s_un = urllib.unquote(s) ＃解码print 'unquote:\t'+s_uns_plus = urllib.quote_plus('This is python') ＃编码print 'quote_plus:\t'+s_plus ＃空格用＋替代s_unplus = urllib.unquote_plus(s_plus) ＃解码print 's_unplus:\t'+s_unpluss_dict = &#123;'name': 'dkf', 'pass': '1234'&#125;s_encode = urllib.urlencode(s_dict) ＃编码字典转换成url参数 print 's_encode:\t'+s_encode#结果：quote: This%20is%20pythonunquote: This is pythonquote_plus: This+is+pythons_unplus: This is pythons_encode: name=dkf&amp;pass=1234 urlretrieve() urlretrieve多数适用单纯的只下载的功能或者显示下载的进度等 12345url = 'http://m.sohu.com/?v=3&amp;_once_=000025_v2tov3&amp;_\smuid=ICvXXapq5EfTpQTVq6Tpz'urllib.urlretrieve(url, './retrieve_index.html')#直接把url链接网页内容下载到retrieve_index.html里了，适用于单纯的下载的功能。#urllib.urlretrieve(url, local_name, method) urllib2 urllib2模块定义的函数和类用来获取URL（主要是HTTP的），他提供一些复杂的接口用于处理： 基本认证，重定向，Cookies等。 常用方法和类 urllib2.urlopen(url[, data][, timeout]) #传url时候，用法同urllib里的urlopen,它打开URL网址，url参数可以是一个字符串url或者是一个Request对象。可选的参数timeout，阻塞操作以秒为单位，如尝试连接（如果没有指定，将使用设置的全局默认timeout值）。实际上这仅适用于HTTP，HTTPS和FTP连接。 123url = 'http://m.sohu.com/?v=3&amp;_once_=000025_v2tov3&amp;_\smuid=ICvXXapq5EfTpQTVq6Tpz'resp = urllib2.urlopen(url)page = resp.read() urlopen方法也可通过建立了一个Request对象来明确指明想要获取的url。调用urlopen函数对请求的url返回一个response对象。这个response类似于一个file对象，所以用.read()函数可以操作这个response对象 12345url = 'http://m.sohu.com/?v=3&amp;_once_=000025_v2tov3&amp;_smuid\=ICvXXapq5EfTpQTVq6Tpz'req = urllib2.Request(url)resp = urllib2.urlopen(req)page = resp.read() class urllib2.Request(url[, data][, headers][, originreqhost][, unverifiable]) Request类是一个抽象的URL请求。5个参数的说明如下: URL——是一个字符串，其中包含一个有效的URL。 data——是一个字符串，指定额外的数据发送到服务器，如果没有data需要发送可以为“None”。目前使用data的HTTP请求是唯一的。当请求含有data参数时，HTTP的请求为POST，而不是GET。数据应该是缓存在一个标准的application/x-www-form-urlencoded格式中。urllib.urlencode()函数用映射或2元组，返回一个这种格式的字符串。通俗的说就是如果想向一个URL发送数据（通常这些数据是代表一些CGI脚本或者其他的web应用）。例如在网上填的form（表单）时，浏览器会POST表单的内容，这些数据需要被以标准的格式编码（encode），然后作为一个数据参数传送给Request对象。Encoding是在urlib模块中完成的，而不是在urlib2中完成的。下面是个例子： 12345678910import urllibimport urllib2url = 'http://www.someserver.com/cgi-bin/register.cgi'values = &#123;'name' : 'Michael Foord', 'location' : 'Northampton', 'language' : 'Python' &#125;data = urllib.urlencode(values) req = urllib2.Request(url, data) #send postresponse = urllib2.urlopen(req)page = response.read() headers——是字典类型，头字典可以作为参数在request时直接传入，也可以把每个键和值作为参数调用add_header()方法来添加。作为辨别浏览器身份的User-Agent header是经常被用来恶搞和伪装的，因为一些HTTP服务只允许某些请求来自常见的浏览器而不是脚本，或是针对不同的浏览器返回不同的版本。例如，Mozilla Firefox浏览器被识别为“Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11”。默认情况下，urlib2把自己识别为Python-urllib/x.y（这里的xy是python发行版的主要或次要的版本号，如在Python 2.6中，urllib2的默认用户代理字符串是“Python-urllib/2.6。下面的例子和上面的区别就是在请求时加了一个headers，模仿IE浏览器提交请求。 123456789101112import urllibimport urllib2url = 'http://www.someserver.com/cgi-bin/register.cgi'user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'values = &#123;'name' : 'Michael Foord', 'location' : 'Northampton', 'language' : 'Python' &#125;headers = &#123; 'User-Agent' : user_agent &#125;data = urllib.urlencode(values)req = urllib2.Request(url, data, headers)response = urllib2.urlopen(req)the_page = response.read() 标准的headers组成是(Content-Length, Content-Type and Host)，只有在Request对象调用urlopen()（上面的例子也属于这个情况）或者OpenerDirector.open()时加入。两种情况的例子如下： 使用headers参数构造Request对象，如上例在生成Request对象时已经初始化header，而下例是Request对象调用add_header(key, val)方法附加header（Request对象的方法下面再介绍）： 12345import urllib2req = urllib2.Request('http://www.example.com/')req.add_header('Referer', 'http://www.python.org/') #http是无状态的协议，上一次客户端的请求与下一次客户端到服务器的请求无关系的，多数省略这一步r = urllib2.urlopen(req) OpenerDirector为每一个Request自动加上一个User-Agent header，所以第二种方法如下（urllib2.buildopener会返回一个OpenerDirector对象，关于urllib2.buildopener类下面再说）： 1234import urllib2opener = urllib2.build_opener()opener.addheaders = [('User-agent', 'Mozilla/5.0')]opener.open('http://www.example.com/') urllib2.installopener(opener)和urllib2.buildopener([handler, …]) installopener和buildopener这两个方法通常都是在一起用,也有时候buildopener单独使用来得到OpenerDirector对象。installopener实例化会得到OpenerDirector 对象用来赋予全局变量opener。如果想用这个opener来调用urlopen，那么就必须实例化得到OpenerDirector；这样就可以简单的调用OpenerDirector.open()来代替urlopen()。build_opener实例化也会得到OpenerDirector对象，其中参数handlers可以被BaseHandler或他的子类实例化。子类中可以通过以下实例化：ProxyHandler (如果检测代理设置用)扫描代理会用到，很重要这个, UnknownHandler, HTTPHandler, HTTPDefaultErrorHandler, HTTPRedirectHandler, FTPHandler, FileHandler, HTTPErrorProcessor。 12345import urllib2req = urllib2.Request('http://www.python.org/')opener=urllib2.build_opener()urllib2.install_opener(opener)f = opener.open(req) 如上使用 urllib2.install_opener()设置 urllib2 的全局 opener。这样后面的使用会很方便，但不能做更细粒度的控制，比如想在程序中使用两个不同的 Proxy 设置等。比较好的做法是不使用 install_opener 去更改全局的设置，而只是直接调用 opener的open 方法代替全局的 urlopen 方法。 说到这Opener和Handler之间的操作听起来有点晕。整理下思路就清楚了。 当获取一个URL时，可以使用一 个opener（一个urllib2.OpenerDirector实例对象，可以由build_opener实例化生成）。正常情况下程序一直通过urlopen使用默认的opener（也就是说当你使用urlopen方法时，是在隐式的使用默认的opener 对象），但也可以创建自定义的openers（通过操作 器handlers创建的opener实例）。所有的重活和麻烦都交给这些handlers来做。 每一个handler知道如何以一种特定的协议（http，ftp等等）打开url，或者如何处理打开url发生的HTTP重定向，或者包含的HTTP cookie。创建openers时如果想要安装特别的handlers来实现获取url（如获取一个处理cookie的opener，或者一个不处理重定向的opener）的话，先实例一个OpenerDirector对象，然后多次调用.add_handler(some_handler_instance)来创建一个opener。或者，你可以用build_opener，这是一个很方便的创建opener对象的函数，它只有一个函数调用 。build_opener默认会加入许多handlers，它提供了一个快速的方法添加更多东西和使默认的handler 失效。 install_opener如上所述也能用于创建一个opener对象，但是这个对象是（全局）默认的opener。这意味着调用urlopen将会用到你刚创建的opener。也就是说上面的代码可以等同于下面这段。这段代码最终还是使用的默认opener。一般情况下我们用build_opener为的是生成自定义opener，没有必要调用install_opener，除非是为了方便。 123456import urllib2req = urllib2.Request('http://www.python.org/')opener=urllib2.build_opener() ＃ 创建opener对象urllib2.install_opener(opener) ＃定义全局默认openerf = urllib2.urlopen(req) #urlopen使用默认opener，但是install_opener#已经把opener设为全局默认了，这里便是使用上面的建立的opener 如果只是单纯的下载或者显示下载进度，不对下载后的内容做处理等，比如下载图片，css，js文件等，可以用urlilb.urlretrieve（） 如果是下载的请求需要填写表单，输入账号，密码等，建议用urllib2.urlopen(urllib2.Request()) 在对字典数据编码时候，用到的是urllib.urlencode() urllib and urllib2 区别urllib和urllib2模块都做与请求URL相关的操作，但他们提供不同的功能。 urllib2.urlopen accepts an instance of the Request class or a url, （where as urllib.urlopen only accepts a url 中文意思就是：urllib2.urlopen可以接受一个Request对象或url在接受Request对象时候，并以此可以来设置一个URL的headers urllib.urlopen只接收一个url urllib 有urlencode,urllib2没有，这也是为什么总是urllib，urllib2常会一起使用的原因 requests Requests 使用的是 urllib3，继承了urllib2的所有特性。Requests支持HTTP连接保持和连接池，支持使用cookie保持会话，支持文件上传，支持自动确定响应内容的编码，支持国际化的 URL 和 POST 数据自动编码。 举例： 123456789101112131415import requestsresp = requests.get('http://www.mywebsite.com/user')userdata = &#123;"firstname": "John", "lastname": "Doe", "password": "jdoe123"&#125;resp = requests.post('http://www.mywebsite.com/user', params=userdata)resp = requests.put('http://www.mywebsite.com/user/put')resp = requests.delete('http://www.mywebsite.com/user/delete')resp.json() # 假如返回的是json数据resp.text #返回的不是text数据resp.headers['content-type'] #返回text/html;charset=utf-8f = open('request_index.html', 'w')f.write(page.encode('utf8')) #test 发现requests抓下来的页面必须要编码\#写入,（抓下来的是unicode），urllib和urllib2抓下来可以直接写入，#因为这两者抓下来的page是str 其他功能特性 国际化域名和 URLs Keep-Alive &amp; 连接池 持久的 Cookie 会话 类浏览器式的 SSL 加密认证 基本/摘要式的身份认证 优雅的键/值 Cookies 自动解压 Unicode 编码的响应体 多段文件上传 连接超时 支持 .netrc 适用于 Python 2.6—3.4 线程安全 requests不是python自带的库，需要另外安装 easy_install or pip install requests缺陷:直接使用不能异步调用，速度慢（from others）。官方的urllib可以替代它。 通过Requests模块实现最开始我尝试使用的是urllib模块，通过抓包工具获取上网认证的流程。一般正常的使用情况是，我们通过Browser的Get方式，获取服务器的Response，拿到登录界面，然后通过账户、密码的填写，表格POST传递给相应的action处理，然后在获取Response获取认证成功数据。我在做完了这一个工作之后，简化了第一步，直接构造传递表格信息，简化流程，提高运行速度。 12345678POST http://***.***.***.***/eportal/userV2.do?method=login&amp;param=true&amp;wlanuserip=***&amp;wlanacname=***&amp;nasip=***&amp;mac=***&amp;t=wirelessv2&amp;url=***&amp;username=***&amp;pwd=*** HTTP/1.1Host: 172.18.6.30User-Agent: Content-Length: 67Accept-Encoding: gzip, deflateAccept: */*Content-Type: application/x-www-form-urlencodedConnection: closed 通过urllib模块，我没能够将Connection这一状态保持，正常通过浏览器登录，在传递之后，肯定是保持连接存活的，但是通过Python的urllib模块，由于在模块的函数AbstractHTTPHandler.do_open()中已经固化了Connection为closed，所以很难改变。keep-alive 是http persistent connection，urllib 没有实现这个特性，所以不允许 keep-alive。试验后，上网认证必须保持keep-alive，否则的话就会提示没有这个设备，不能认证成功。 我查阅了相关资料，有几种解决方案： httplib urlgrabber Requests 最后我就尝试使用了Requests模块，相当的简单方便。学校在认证信息传递过程的POST操作过程中，并没有将先关信息加密处理，省去了我的很多工作。 postData = {'username' : '***', 'usernameHidden':'', 'authorMode':'', 'pwd' : '***'}#自己填充 #构造header，一般header至少要包含一下两项。这两项是从抓到的包里分析得出的。 headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 UBrowser/5.5.10106.5 Safari/537.36', 'Referer' : 'http://172.18.6.30/', 'Connection':'keep-alive', 'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', 'Accept-Encoding':'gzip, deflate'} posturl='http://172.18.6.30/eportal/userV2.do?method=login&amp;param=true&amp;wlanuserip=4a74b7a4b9aa0b72c9f20758e1b35282&amp;wlanacname=353477f414861cdd&amp;ssid=15e792de8d103cfd&amp;nasip=704b71fc82aa0c88911e9f71944eba43&amp;mac=aad9ba78888755209ff8e82016aa5765&amp;t=wireless-v2&amp;url=f58cd7a67bbfecbcf3027f3e4bf7b3807231ca007bf7eab9a0a21ad866eb54c0ca6c6fc25773bb30&amp;username=***&amp;pwd=***' #上面的url是通过抓包获得 然后做了一个简单的UI，打包成win平台可执行程序]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Requests</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用PIL模块创建验证码文件]]></title>
    <url>%2F2016%2F02%2F12%2Fpy_PIL%2F</url>
    <content type="text"><![CDATA[图片模糊效果： 12345678from PIL import Image, ImageFilter# 打开一个jpg图像文件，注意是当前路径:im = Image.open('test.jpg')# 应用模糊滤镜:im2 = im.filter(ImageFilter.BLUR)# 覆盖原图im2.save('test.jpg', 'jpeg') PIL的ImageDraw提供了一系列绘图方法，让我们可以直接绘图。下面的例子展示了一种创建随机验证码的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041from PIL import Image,ImageFont,ImageFilter,ImageDrawimport os,random#返回一个数字或者字母def rndChar(): def rndChar(): x=random.random() return chr(random.randint(48,57)) if x&lt;=0.33 else chr(random.randint(65,90)) if 0.33&lt;x&lt;=0.67 else chr(random.randint(97,122))#返回背景颜色的其中一个RGB值def rndColor(): return (random.randint(64, 255), random.randint(64, 255), random.randint(64, 255))#返回前置text颜色的其中一个RGB值def rndColor2(): return (random.randint(32, 127), random.randint(32, 127), random.randint(32, 127))width=100*4height=100image=Image.new('RGB',(width,height),(255,255,255))font=ImageFont.truetype(r'C:\Windows\Fonts\Arial.ttf', 50)draw=ImageDraw.Draw(image)#对每个像素点进行填充for x in range(width): for y in range(height): draw.point((x,y),fill=rndColor())#绘制生成的验证码for t in range(4): draw.text((100*t+25,25),rndChar(),fill=rndColor2(),font=font)#对验证码进行简单的模糊化处理image=image.filter(ImageFilter.BLUR)image.save('code.jpg',format='jpeg')#使用默认的img查看器对保存的文件预览os.system('start code.jpg')]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSDN访问量作弊器]]></title>
    <url>%2F2016%2F02%2F03%2Fcsdn_viewer%2F</url>
    <content type="text"><![CDATA[前言前些天在逛论坛的时候突然发现了一篇文章，标题是通过编程自动化提高自己博客访问量的。我想了下，突然感觉可以用学过的Python的简单知识来实现这一目的。主要原理就是BeautifulSoup+urllib的组合,通过BS解析网页，获取目录，然后深入，获取文章的url，通过urllib.request模块尝试连接CSDN的服务器。说干就干 脚本实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293from bs4 import BeautifulSoupimport urllib.requestimport urllib.parseimport sysimport time#运行过程中的日志函数def LOG(*argv): sys.stderr.write(*argv) sys.stderr.write('\n')class Grab(): url = '' soup = None #读取当前网页的源代码数据返回 def GetPage(self, url): self.url = url LOG('input url is: %s' % self.url) req = urllib.request.Request(url, headers=&#123;'User-Agent' : "Magic Browser"&#125;) try: page = urllib.request.urlopen(req) except: return tem = page.read() if not tem: print('GetPage failed!') sys.exit() return tem #获取目录页面下的文章url集合 def ExtractInfo(self,buf): dom=etree.HTML(buf) links=dom.xpath('//h3[@class="list_c_t"]/a/@href') titles=dom.xpath('//h3[@class="list_c_t"]/a/text()') for i in range(0,len(links)):links[i]='http://blog.csdn.net'+links[i] for i in range(0,len(titles)):titles[i]=titles[i].strip() return links,titles #获取所有文章的目录页面url集合 def GetPageUrl(self,buf): pages = set() self.soup = BeautifulSoup(buf,'html.parser') pageInfo=self.soup.find(attrs=&#123;'id':'papelist'&#125;) #如果当前文章数量只有一页 if not pageInfo: return None pagelinks = pageInfo.findAll('a') for link in pagelinks: pages.add('http://blog.csdn.net/'+link['href']) return pages #获取当前访问文章的访问数、文章标题 def GetCurViewerPoint(self,buf): self.soup = BeautifulSoup(buf,'html.parser') pointobj = (self.soup.find(attrs=&#123;'class':'read_r'&#125;)).label.span.string title = (self.soup.find(attrs=&#123;'class':'list_c_t'&#125;)).get_text() pointobj=pointobj[2:len(pointobj)-1] return title+' 当前阅读数：'+pointobjgrab = Grab()#buf是当前页面经过转换之后的网页源代码buf = grab.GetPage('http://blog.csdn.net/peihaozhu')#pages中存放的是目录页面url集合pages = ['http://blog.csdn.net/peihaozhu',]#先从入口进入，如果文章数量不够，文章的目录页面只有一页tem = grab.GetPageUrl(buf)if not tem: passelse: pages+=tem#articles中存放所有的文章url集合articles=set()for page in pages: buf = grab.GetPage(page) links = grab.ExtractInfo(buf) for url in links: articles.add('http://blog.csdn.net/'+url)#通过url.request访问文章for url in articles: for i in range(1,11): buf=grab.GetPage(url) print('第'+str(i)+'次访问 '+grab.GetCurViewerPoint(buf)) #每次访问之后停歇300ms time.sleep(0.3) UI实现用PyQt5将程序的大致控件摆放完成了：将pyqt生成的ui文件直接通过命令生成.py文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657pyuic5.bat -o layout.py untitled.ui#代码如下# -*- coding: utf-8 -*-# Form implementation generated from reading ui file 'untitled.ui'## Created by: PyQt5 UI code generator 5.5.1## WARNING! All changes made in this file will be lost!from PyQt5 import QtCore, QtGui, QtWidgetsclass Ui_Form(object): def setupUi(self, Form): Form.setObjectName("Form") self.label = QtWidgets.QLabel(Form) self.label.setGeometry(QtCore.QRect(20, 30, 81, 21)) self.label.setObjectName("label") self.username = QtWidgets.QPlainTextEdit(Form) self.username.setGeometry(QtCore.QRect(110, 20, 341, 41)) self.username.setObjectName("username") self.label_2 = QtWidgets.QLabel(Form) self.label_2.setGeometry(QtCore.QRect(30, 80, 61, 31)) self.label_2.setObjectName("label_2") self.times = QtWidgets.QPlainTextEdit(Form) self.times.setGeometry(QtCore.QRect(110, 80, 151, 41)) self.times.setObjectName("times") self.beginBtn = QtWidgets.QPushButton(Form) self.beginBtn.setGeometry(QtCore.QRect(300, 80, 61, 41)) self.beginBtn.setObjectName("beginBtn") self.progressBar = QtWidgets.QProgressBar(Form) self.progressBar.setGeometry(QtCore.QRect(30, 350, 461, 41)) self.progressBar.setProperty("value", 24) self.progressBar.setObjectName("progressBar") self.listView = QtWidgets.QListView(Form) self.listView.setGeometry(QtCore.QRect(30, 180, 431, 151)) self.listView.setObjectName("listView") self.info = QtWidgets.QLabel(Form) self.info.setGeometry(QtCore.QRect(30, 140, 421, 31)) self.info.setText("") self.info.setObjectName("info") self.exitBtn = QtWidgets.QPushButton(Form) self.exitBtn.setGeometry(QtCore.QRect(390, 80, 61, 41)) self.exitBtn.setObjectName("exitBtn") self.retranslateUi(Form) self.exitBtn.clicked.connect(Form.close) QtCore.QMetaObject.connectSlotsByName(Form) def retranslateUi(self, Form): _translate = QtCore.QCoreApplication.translate Form.setWindowTitle(_translate("Form", "Form")) self.label.setText(_translate("Form", " CSDN用户名")) self.label_2.setText(_translate("Form", "设置次数")) self.beginBtn.setText(_translate("Form", "Start")) self.exitBtn.setText(_translate("Form", "Exit")) UI、逻辑处理遇到的一些问题 在这次编写GUI的过程中，我遇到了原来没有的问题。 以往的时候，如上篇文章，通过Python的QR模块生成QR二维码，因为逻辑非常简单，只是单纯的将所需要转换的数据变换成为相应的0、1二进制码，然后放到图片中的相应位置上，所以不会花费太多的时间，逻辑部分与界面部分就直接写在了一起没有问题。 这次刚开始的时候，我也没注意，直接就还是写在一块，由于牵扯到了url网络连接部分，所以不可避免的出现了阻塞现象。几乎在所有的GUI设计中，如果当长时间出现阻塞、无状态回应情况，都会出现界面的未响应状态，所以我想到了在Android开发中相当常规的子线程与UI线程通信，Handler的使用，在PyQt中也有类似的机制，也就是Qt的核心机制，信号槽机制，更多的内容可以看我另外的文章，我会详细的介绍下。 下面是我修改完成后的代码，可以顺利完成我预设的功能： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184import urllib.requestimport urllib.parseimport timefrom PyQt5 import QtCore, QtGui, QtWidgetsfrom PyQt5.QtCore import pyqtSignalfrom bs4 import BeautifulSoup#抓取网页的类class Grab(): url = '' soup = None #读取当前网页的源代码数据返回 def GetPage(self, url): self.url = url LOG('input url is: %s' % self.url) req = urllib.request.Request(url, headers=&#123;'User-Agent' : "Magic Browser"&#125;) try: page = urllib.request.urlopen(req) except: return tem = page.read() if not tem: print('GetPage failed!') sys.exit() return tem #获取目录页面下的文章url集合 def ExtractInfo(self,buf): dom=etree.HTML(buf) links=dom.xpath('//h3[@class="list_c_t"]/a/@href') titles=dom.xpath('//h3[@class="list_c_t"]/a/text()') for i in range(0,len(links)):links[i]='http://blog.csdn.net'+links[i] for i in range(0,len(titles)):titles[i]=titles[i].strip() return links,titles #获取所有文章的目录页面url集合 def GetPageUrl(self,buf): pages = set() self.soup = BeautifulSoup(buf,'html.parser') pageInfo=self.soup.find(attrs=&#123;'id':'papelist'&#125;) #如果当前文章数量只有一页 if not pageInfo: return None pagelinks = pageInfo.findAll('a') for link in pagelinks: pages.add('http://blog.csdn.net/'+link['href']) return pages #获取当前访问文章的访问数、文章标题 def GetCurViewerPoint(self,buf): self.soup = BeautifulSoup(buf,'html.parser') pointobj = (self.soup.find(attrs=&#123;'class':'read_r'&#125;)).label.span.string title = (self.soup.find(attrs=&#123;'class':'list_c_t'&#125;)).get_text() pointobj=pointobj[2:len(pointobj)-1] return title+' 当前阅读数：'+pointobj#界面类class Ui_Form(object): def setupUi(self, Form): Form.setObjectName("Form") self.label = QtWidgets.QLabel(Form) self.label.setGeometry(QtCore.QRect(20, 30, 81, 21)) self.label.setObjectName("label") self.username = QtWidgets.QPlainTextEdit(Form) self.username.setGeometry(QtCore.QRect(110, 20, 341, 41)) self.username.setObjectName("username") self.label_2 = QtWidgets.QLabel(Form) self.label_2.setGeometry(QtCore.QRect(30, 80, 61, 31)) self.label_2.setObjectName("label_2") self.times = QtWidgets.QPlainTextEdit(Form) self.times.setGeometry(QtCore.QRect(110, 80, 151, 41)) self.times.setObjectName("times") self.beginBtn = QtWidgets.QPushButton(Form) self.beginBtn.setGeometry(QtCore.QRect(300, 80, 61, 41)) self.beginBtn.setObjectName("beginBtn") self.progressBar = QtWidgets.QProgressBar(Form) self.progressBar.setGeometry(QtCore.QRect(30, 350, 461, 41)) self.progressBar.setProperty("value", 0) self.progressBar.setObjectName("progressBar") self.listWidget = QtWidgets.QListWidget(Form) self.listWidget.setGeometry(QtCore.QRect(30, 180, 431, 151)) self.listWidget.setObjectName("listWidget") self.info = QtWidgets.QLabel(Form) self.info.setGeometry(QtCore.QRect(30, 140, 421, 31)) self.info.setText("") self.info.setObjectName("info") self.exitBtn = QtWidgets.QPushButton(Form) self.exitBtn.setGeometry(QtCore.QRect(390, 80, 61, 41)) self.exitBtn.setObjectName("exitBtn") self.thread=MyThread() self.thread.sinOut.connect(self.handler) self.retranslateUi(Form) self.exitBtn.clicked.connect(Form.close) self.beginBtn.pressed.connect(self.mainFunc) QtCore.QMetaObject.connectSlotsByName(Form) def handler(self,type,text,content): if type == 1: self.listWidget.addItems(content) elif type == 2: self.progressBar.setProperty("value", float(text)) elif type == 3: self.info.setText(text) def mainFunc(self): username = self.username.toPlainText().strip() times = self.times.toPlainText().strip() if username and times: self.thread.setVal(username,times) self.thread.start() def retranslateUi(self, Form): _translate = QtCore.QCoreApplication.translate Form.setWindowTitle(_translate("Form", "Blog作弊器")) self.label.setText(_translate("Form", " CSDN用户名")) self.label_2.setText(_translate("Form", "设置次数")) self.beginBtn.setText(_translate("Form", "Start")) self.exitBtn.setText(_translate("Form", "Exit"))#子线程class MyThread(QtCore.QThread): sinOut = pyqtSignal(int,str,set) articles = set() def __init__(self): super(MyThread,self).__init__() self.username='' self.times='' def setVal(self,username,times): self.username=username self.times=times def run(self): #发射信号 grab = Grab() buf = grab.GetPage('http://blog.csdn.net/'+self.username) pages = ['http://blog.csdn.net/'+self.username,] tem = grab.GetPageUrl(buf) content = set() links = [] titles = [] if not tem:pass else: pages+=tem for page in pages: buf = grab.GetPage(page) link,title = grab.ExtractInfo(buf) links+=link titles+=title titles=zip(links,titles) for link in links: self.articles.add(link) for title in titles: tem = '' for val in title: tem+=val+' ' content.add(tem) self.sinOut.emit(1,'',content) sumRes = len(self.articles)*int(self.times) cur = 1 for url in self.articles: for i in range(0,int(self.times)): buf=grab.GetPage(url) self.sinOut.emit(2,str(cur/sumRes*100),content) self.sinOut.emit(3,grab.GetCurViewerPoint(buf),content) cur+=1 time.sleep(0.1)if __name__=='__main__': import sys app=QtWidgets.QApplication(sys.argv) widget=QtWidgets.QWidget() ui=Ui_Form() ui.setupUi(widget) widget.show() sys.exit(app.exec_()) 总结由于使用了designer默认的绝对布局方式，代码比较杂乱。总的来说也就分3个模块： 网页获取、解析工作类 Grab 界面布局、实时数据展现类 Ui_Form 逻辑控制、监控与沟通类 MyThread 各个模块相互合作，实现功能. 通过Requests、Xpath改写这是后来补上的. 在我完成这篇文章之前的部分的时候，还是对python刚入门，使用了比较经典的一些网络模块。后来通过一些实例练习，接触到了一些简洁、优雅的模块，通过这些模块继续完善。 Grab类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Grab(): url = '' soup = None #读取当前网页的源代码数据返回 #读取当前网页的源代码数据返回 def GetPage(self, url): self.url = url LOG('input url is: %s' % self.url) req = urllib.request.Request(url, headers=&#123;'User-Agent' : "Magic Browser"&#125;) try: page = urllib.request.urlopen(req) except: return tem = page.read() if not tem: print('GetPage failed!') sys.exit() return tem #获取目录页面下的文章url集合 def ExtractInfo(self,buf): dom=etree.HTML(buf) links=dom.xpath('//h3[@class="list_c_t"]/a/@href') titles=dom.xpath('//h3[@class="list_c_t"]/a/text()') for i in range(0,len(links)):links[i]='http://blog.csdn.net'+links[i] for i in range(0,len(titles)):titles[i]=titles[i].strip() return links,titles #获取所有文章的目录页面url集合 def GetPageUrl(self,buf): pages = set() self.soup = BeautifulSoup(buf,'html.parser') pageInfo=self.soup.find(attrs=&#123;'id':'papelist'&#125;) #如果当前文章数量只有一页 if not pageInfo: return None pagelinks = pageInfo.findAll('a') for link in pagelinks: pages.add('http://blog.csdn.net/'+link['href']) return pages #获取当前访问文章的访问数、文章标题 def GetCurViewerPoint(self,buf): self.soup = BeautifulSoup(buf,'html.parser') pointobj = (self.soup.find(attrs=&#123;'class':'read_r'&#125;)).label.span.string title = (self.soup.find(attrs=&#123;'class':'list_c_t'&#125;)).get_text() pointobj=pointobj[2:len(pointobj)-1] return title+' 当前阅读数：'+pointobj Request模块 在上网认证这篇文章有过大概的介绍。模块通过提供极其简单的方法名称接口，隐藏了复杂的网络工作，大大简化了代码。 Xpath Xpath介绍Xpath不是一个模块，而是活跃在众多平台的一种工具，也可以称她是一种语言。通过对网页源代码解析，内部构建路径，轻松获取想要的内容。在BeautifulSoup太沉重复杂、又不想使用正则的情况下，是一种很棒的解决方案。 MyThread类12345678910111213141516171819202122232425262728293031323334353637383940414243class MyThread(QtCore.QThread): sinOut = pyqtSignal(int,str,set) articles = set() global username def __init__(self): super(MyThread,self).__init__() self.times='' def setVal(self,username,times): self.times=times def run(self): #发射信号 grab = Grab() #获取各个目录页面信息 buf = grab.GetPage('http://blog.csdn.net/'+username) pages = grab.GetPageUrl(buf) content = set() links = [] titles = [] for page in pages: buf = grab.GetPage(page) link,title = grab.ExtractInfo(buf) links+=link titles+=title titles=zip(links,titles) for link in links: self.articles.add(link) for title in titles: tem = title[0]+' '+title[1] content.add(tem) self.sinOut.emit(1,'',content) sumRes = len(self.articles)*int(self.times) cur = 1 for i in range(0,int(self.times)): for url in self.articles: buf=grab.GetPage(url) self.sinOut.emit(2,str(cur/sumRes*100),content) self.sinOut.emit(3,grab.GetCurViewerPoint(buf),content) cur+=1 time.sleep(0.1) 去掉time.sleep(seconds)推迟线程调用之后，会出现网络模块报错，这应该是所有网络模块都会碰到的情况。 软件下载]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>BeautifulSoup</tag>
        <tag>python</tag>
        <tag>urllib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习(三)]]></title>
    <url>%2F2016%2F02%2F01%2Fpython3%2F</url>
    <content type="text"><![CDATA[接着我的上篇文章，Python学习(二). 扩展PythonPython可以实现一切，但是有时候显然会感觉到比较缓慢（相对于C、C++甚至Java等语言），在某些科学模拟程序、图形渲染方面。使用python也许就不是一个好的选择，使用python的目的就是易用、高效的开发速度，但是相应的运行速度会降低。 当我们需要额外的速度的情况时候，最好的解决方案肯定不是整个开发过程都使用C语言或其他相对低级的语言，而是推荐以下的方法，使用这些方法能够满足很多工业强度上的速度要求: 在Python中开发一个原型程序（prototype） 分析程序并且找到平静 用C语言或其他作为扩展重写出现瓶颈的代码 一些简单的途径 如果曾经使用过Jython和IronPython，你就会发现用这两种方式来扩展Pyhton是相当方便的。Jython对应Java，IronPython对应C#和其他.Net语言，可以直接访问对应的底层类和标准库。 目前的主流情况下，除了C语言，扩展比较多的就是Java语言，这里我就简单的尝试一下。 12345public class JythonTest&#123; public void greting()&#123; System.out.println('Hello,Jython'); &#125;&#125; 将文件JythonTest.java编译成.class二进制代码，放置到当前工作目录下或者放到配置的Java CLASSPATH中的某处，启动Jython1$ CLASSPATH=JythonTest.class jython 直接导入类1234&gt;&gt;&gt;import JythonTest&gt;&gt;&gt;test=JythonTest()&gt;&gt;&gt;test.greeting()Hello,Jython 编写C语言扩展扩展Python通常就是指扩展CPython，它使用C语言实现的额标准Python版本.SWIG是简单包装和接口生成器的缩写。它是一个能用几种语言的工具，一方面，可以通过它使用C语言或者C++编写扩展代码，另一方面，他会自动包装那些代码，以便能在一些高级语言中使用（Perl、Ruby、Java、Python）。如果决定将系统的一部分使用C语言扩展编写，而不是直接在Python中实现的话，使用C语言扩展库也能在其他语言中使用。 C语言源文件palindrome.c 1234567891011//palindrome.c#include &lt;string.h&gt;int is_palindrome(char *text)&#123; int i,n=strlen(text); for(i=0;i&lt;=n/2;i++)&#123; if(text[i]!=text[n-i-1]) return 0; &#125; return 1;&#125; 相应的C语言头文件palindrome.h 123/* File: palindrome.h */int is_palindrome(char *text); 使用swig模块写一个描述文件palindrome.i 123456789/* File: palindrome.i */%module palindrome%&#123;#define SWIG_FILE_WITH_INIT#include "palindrome.h"%&#125;int is_palindrome(char *text); 为了建python模块，利用-python参数执行swig 1swig -python palindrome.i 执行完命令后生成两个不同的文件：palindrome_wrap.c和palindrome.py。 自动生成文件名的原则：生成的c文件名与写的c文件名有关（例如写的c文件名为example.c则生成example_wrap.c）；生成的python文件即.i文件中%module后面的名字。 利用distutils生成动态库python自带一个distutils工具，可以用它来创建python的扩展模块。使用它也很简单，只需要先定义一个配置文件，通常是命名为setup.py123456789101112131415161718"""setup.py""" from distutils.core import setup, Extension palindrome_module = Extension('_palindrome', sources=['palindrome_wrap.c', 'palindrome.c'], ) setup (name = 'palindrome', version = '0.1', author = "SWIG Docs", description = """Simple swig example from docs""", ext_modules = [palindrome_module], py_modules = ["palindrome"], ) pic：头文件和源文件都是palindrome.*，那么setup.py脚本中Extension的参数必须为“_palindrome” 编译1python setup.py build 会在本目录下build/lib*/下生成_palindrome.pyd模块，可以直接使用，例如123&gt;&gt;&gt;import palindrome&gt;&gt;&gt;print palindrome.is_palindrome("sssttsss")1 可以把动态模块直接生成当前目录下1python setup.py build_ext --inplace]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二维码与Python]]></title>
    <url>%2F2016%2F01%2F30%2FQR%2F</url>
    <content type="text"><![CDATA[关于二维码二维条码/二维码（2-dimensional bar code）是用某种特定的几何图形按一定规律在平面（二维方向上）分布的黑白相间的图形记录数据符号信息的；在代码编制上巧妙地利用构成计算机内部逻辑基础的“0”、“1”比特流的概念，使用若干个与二进制相对应的几何形体来表示文字数值信息，通过图象输入设备或光电扫描设备自动识读以实现信息自动处理：它具有条码技术的一些共性：每种码制有其特定的字符集；每个字符占有一定的宽度；具有一定的校验功能等。同时还具有对不同行的信息自动识别功能、及处理图形旋转变化点。 QRCodeQR Code码，是由Denso公司于1994年9月研制的一种矩阵二维码符号，它具有一维条码及其它二维条码所具有的信息容量大、可靠性高、可表示汉字及图象多种文字信息、保密防伪性强等优点。 从QR Code码的英文名称Quick Response Code可以看出，超高速识读特点是QR Code码区别于四一七条码、Data Matrix等二维码的主要特性。由于在用CCD识读QR Code码时，整个QR Code码符号中信息的读取是通过QR Code码符号的位置探测图形，用硬件来实现，因此，信息识读过程所需时间很短，它具有超高速识读特点。用CCD二维条码识读设备，每秒可识读30个含有100个字符的QR Code码符号；对于含有相同数据信息的四一七条码符号，每秒仅能识读3个符号；对于Data Martix矩阵码，每秒仅能识读2～3个符号。QR Code码的超高速识读特性使它能够广泛应用于工业自动化生产线管理等领域。 在目前几十种二维条码中，常用的码制有：PDF417二维条码, Datamatrix二维条码, Maxicode二维条码, QR Code, Code 49, Code 16K ,Code one,等，除了这些常见的二维条码之外，还有Vericode条码、CP条码、Codablock F条码、田字码、 Ultracode条码，Aztec条码。 pyqrcodepyqrcode 是 Python 的扩展用来生成二维条形码以及对二维条形码进行解码。利用pyqrcode可以很轻松的将我们需要的信息转换成为二进制编码图片，并通过本地图片浏览方式展示： 1234567891011121314151617181920212223242526272829import qrcodeimport osimport sysimport timeQRImagePath = os.getcwd() + '/qrcode.jpg'qr = qrcode.QRCode( version=1, error_correction=qrcode.constants.ERROR_CORRECT_L, box_size=10, border=2,)data=input()qr.add_data(data)qr.make(fit=True)img = qr.make_image()img.save('qrcode.jpg')#针对不同的系统平台选取相应的系统调用代码if sys.platform.find('darwin') &gt;= 0: os.system('open %s' % QRImagePath)elif sys.platform.find('linux')&gt;=0: os.write('xdg-open %s' % QRImagePath)else: os.system('call %s' % QRImagePath)os.system('call %s' % QRImagePath)time.sleep(5)os.remove(QRImagePath) 扩展使用上面的代码很不美观，所以我尝试使用python支持的GUI重新整理了相关的代码，使用PyQT5模块，所以在尝试使用相关代码的时候，需要已经安装pyqt5： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172from PyQt5 import QtCore, QtGui, QtWidgetsimport qrcodeimport osimport sysimport timefrom PyQt5.QtGui import QPixmapqr = qrcode.QRCode( version=1, error_correction=qrcode.constants.ERROR_CORRECT_L, box_size=10, border=2,)class Ui_Form(object): def setupUi(self, Form): Form.setObjectName("Form") Form.resize(400, 300) self.label = QtWidgets.QLabel(Form) self.label.setGeometry(QtCore.QRect(10, 10, 71, 41)) self.label.setObjectName("label") self.sourceEdit = QtWidgets.QTextEdit(Form) self.sourceEdit.setGeometry(QtCore.QRect(90, 10, 291, 31)) self.sourceEdit.setObjectName("sourceEdit") self.picLab = QtWidgets.QLabel(Form) self.picLab.setGeometry(QtCore.QRect(30, 80, 221, 201)) self.picLab.setObjectName("picLab") self.genButton = QtWidgets.QPushButton(Form) self.genButton.setGeometry(QtCore.QRect(300, 80, 75, 81)) self.genButton.setObjectName("genButton") self.exitButton = QtWidgets.QPushButton(Form) self.exitButton.setGeometry(QtCore.QRect(300, 200, 75, 81)) self.exitButton.setObjectName("exitButton") self.retranslateUi(Form) #退出按钮绑定的槽函数 self.exitButton.clicked.connect(Form.close) #生成图片按钮绑定的自定义槽函数 self.genButton.clicked.connect(self.generateImg) QtCore.QMetaObject.connectSlotsByName(Form) def retranslateUi(self, Form): _translate = QtCore.QCoreApplication.translate Form.setWindowTitle(_translate("Form", "二维码生成")) self.label.setText(_translate("Form", "SourceCode")) self.genButton.setText(_translate("Form", "生成")) self.exitButton.setText(_translate("Form", "退出")) self.OkImage = os.getcwd() + r'\qrcode.png' def generateImg(self): qr.add_data(self.sourceEdit.toPlainText()) qr.make(fit=True) #生成二维码图片 img = qr.make_image() #需要注意的是，有序自身机制，使用png形式图片会相当方便，其他的格式在生成QPixmap形式时候会报null img.save('qrcode.png') #将已经生成的图片加载成为QPixmap格式 qpic=QPixmap(self.OkImage).scaled(self.picLab.width(),self.picLab.height()) self.picLab.setPixmap(qpic) #将已经生成的图片删除，不占用空间 os.remove(self.OkImage)if __name__=='__main__': import sys app=QtWidgets.QApplication(sys.argv) widget=QtWidgets.QWidget() ui=Ui_Form() ui.setupUi(widget) widget.show() sys.exit(app.exec_()) 效果如图 二维码解析Python中关于二维码解析的现成模块有很多，比较著名的就是Zbar以及ZXing.然而很不幸的是，官方的版本都是支持到python2.x，下面是在python2.x的例子: 123456789101112131415from PIL import Imageimport zbarscanner = zbar.ImageScanner()scanner.parse_config("enable")pil = Image.open("char.png").convert('L')width, height = pil.size#经测试，将pil.tostring()替换成了pil.tobytes()raw = pil.tobytes()image = zbar.Image(width, height, 'Y800', raw)scanner.scan(image)data = ''for symbol in image: data+=symbol.datadel(image)print data 其中 data就是我们需要的已经解析得到的内容。 查阅了相关资料，关于Python3.x的zbar适配已经有人放出来了，叫做zbarlight，我尝试按照作者的的步骤执行，却发生了一些麻烦，最终没有完成。作者关于win平台上的支持还没有足够重视。 http://zbar.sourceforge.net/这是zbar的win软件版本，运行之后，我们可以直接使用命令行形式解析二维码图片。 1zbarimg -d http://7xowaa.com1.z0.glb.clouddn.com/qrcode.jpg zbar分为zbarimg和zbarcam分别对应图片格式、摄像头格式，摄像头形式在win平台不太管用，图片格式可以填写本地图片文件名，也可以使用URL.效果图]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>二维码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python查看微信删除好友]]></title>
    <url>%2F2016%2F01%2F26%2Fpython_wx%2F</url>
    <content type="text"><![CDATA[查看被删的微信好友 原理就是新建群组,如果加不进来就是被删好友了(不要在群组里讲话,别人是看不见的) 用的是微信网页版的接口 查询结果可能会引起一些心理上的不适,请小心使用 :) 还有些小问题: 结果好像有疏漏一小部分,原因不明.. 最终会遗留下一个只有自己的群组,需要手工删一下 没试过被拉黑的情况 转自 https://github.com/0x5e/wechat-deleted-friends 用法:启动终端Terminal $ python code.py 原作者是是py2.x平台下编写，所以不能直接在py3.x平台下直接使用，本文的代码是适配py3.4之后，提升了程序稳定性，并增加查看被拉黑名单功能 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561#!/usr/bin/env python# coding=utf-8from __future__ import print_functionimport osimport requestsimport reimport timeimport xml.dom.minidomimport jsonimport sysimport mathimport subprocessimport sslimport threadingDEBUG = FalseMAX_GROUP_NUM = 35 # 每组人数INTERFACE_CALLING_INTERVAL = 20 # 接口调用时间间隔, 间隔太短容易出现"操作太频繁", 会被限制操作半小时左右MAX_PROGRESS_LEN = 50QRImagePath = os.path.join(os.getcwd(), 'qrcode.jpg')tip = 0uuid = ''base_uri = ''redirect_uri = ''push_uri = ''skey = ''wxsid = ''wxuin = ''pass_ticket = ''deviceId = 'e000000000000000'BaseRequest = &#123;&#125;ContactList = []My = []SyncKey = []def responseState(func, BaseResponse): ErrMsg = BaseResponse['ErrMsg'] Ret = BaseResponse['Ret'] if DEBUG or Ret != 0: print('func: %s, Ret: %d, ErrMsg: %s' % (func, Ret, ErrMsg)) if Ret != 0: return False return Truedef getUUID(): global uuid url = 'https://login.weixin.qq.com/jslogin' params = &#123; 'appid': 'wx782c26e4c19acffb', 'fun': 'new', 'lang': 'zh_CN', '_': int(time.time()), &#125; r= myRequests.get(url=url, params=params) r.encoding = 'utf-8' data = r.text # print(data) # window.QRLogin.code = 200; window.QRLogin.uuid = "oZwt_bFfRg=="; regx = r'window.QRLogin.code = (\d+); window.QRLogin.uuid = "(\S+?)"' pm = re.search(regx, data) code = pm.group(1) uuid = pm.group(2) if code == '200': return True return Falsedef showQRImage(): global tip url = 'https://login.weixin.qq.com/qrcode/' + uuid params = &#123; 't': 'webwx', '_': int(time.time()), &#125; r = myRequests.get(url=url, params=params) tip = 1 f = open(QRImagePath, 'wb') f.write(r.content) f.close() time.sleep(1) if sys.platform.find('darwin') &gt;= 0: subprocess.call(['open', QRImagePath]) elif sys.platform.find('linux') &gt;= 0: subprocess.call(['xdg-open', QRImagePath]) else: os.startfile(QRImagePath) print('请使用微信扫描二维码以登录')def waitForLogin(): global tip, base_uri, redirect_uri, push_uri url = 'https://login.weixin.qq.com/cgi-bin/mmwebwx-bin/login?tip=%s&amp;uuid=%s&amp;_=%s' % ( tip, uuid, int(time.time())) r = myRequests.get(url=url) r.encoding = 'utf-8' data = r.text # print(data) # window.code=500; regx = r'window.code=(\d+);' pm = re.search(regx, data) code = pm.group(1) if code == '201': # 已扫描 print('成功扫描,请在手机上点击确认以登录') tip = 0 elif code == '200': # 已登录 print('正在登录...') regx = r'window.redirect_uri="(\S+?)";' pm = re.search(regx, data) redirect_uri = pm.group(1) + '&amp;fun=new' base_uri = redirect_uri[:redirect_uri.rfind('/')] # push_uri与base_uri对应关系(排名分先后)(就是这么奇葩..) services = [ ('wx2.qq.com', 'webpush2.weixin.qq.com'), ('qq.com', 'webpush.weixin.qq.com'), ('web1.wechat.com', 'webpush1.wechat.com'), ('web2.wechat.com', 'webpush2.wechat.com'), ('wechat.com', 'webpush.wechat.com'), ('web1.wechatapp.com', 'webpush1.wechatapp.com'), ] push_uri = base_uri for (searchUrl, pushUrl) in services: if base_uri.find(searchUrl) &gt;= 0: push_uri = 'https://%s/cgi-bin/mmwebwx-bin' % pushUrl break # closeQRImage if sys.platform.find('darwin') &gt;= 0: # for OSX with Preview os.system("osascript -e 'quit app \"Preview\"'") elif code == '408': # 超时 pass # elif code == '400' or code == '500': return codedef login(): global skey, wxsid, wxuin, pass_ticket, BaseRequest r = myRequests.get(url=redirect_uri) r.encoding = 'utf-8' data = r.text # print(data) doc = xml.dom.minidom.parseString(data) root = doc.documentElement for node in root.childNodes: if node.nodeName == 'skey': skey = node.childNodes[0].data elif node.nodeName == 'wxsid': wxsid = node.childNodes[0].data elif node.nodeName == 'wxuin': wxuin = node.childNodes[0].data elif node.nodeName == 'pass_ticket': pass_ticket = node.childNodes[0].data # print('skey: %s, wxsid: %s, wxuin: %s, pass_ticket: %s' % (skey, wxsid, # wxuin, pass_ticket)) if not all((skey, wxsid, wxuin, pass_ticket)): return False BaseRequest = &#123; 'Uin': int(wxuin), 'Sid': wxsid, 'Skey': skey, 'DeviceID': deviceId, &#125; return Truedef webwxinit(): url = (base_uri + '/webwxinit?pass_ticket=%s&amp;skey=%s&amp;r=%s' % ( pass_ticket, skey, int(time.time())) ) params = &#123;'BaseRequest': BaseRequest &#125; headers = &#123;'content-type': 'application/json; charset=UTF-8'&#125; r = myRequests.post(url=url, data=json.dumps(params),headers=headers) r.encoding = 'utf-8' data = r.json() if DEBUG: f = open(os.path.join(os.getcwd(), 'webwxinit.json'), 'wb') f.write(r.content) f.close() # print(data) global ContactList, My, SyncKey dic = data ContactList = dic['ContactList'] My = dic['User'] SyncKey = dic['SyncKey'] state = responseState('webwxinit', dic['BaseResponse']) return statedef webwxgetcontact(): url = (base_uri + '/webwxgetcontact?pass_ticket=%s&amp;skey=%s&amp;r=%s' % ( pass_ticket, skey, int(time.time())) ) headers = &#123;'content-type': 'application/json; charset=UTF-8'&#125; r = myRequests.post(url=url,headers=headers) r.encoding = 'utf-8' data = r.json() if DEBUG: f = open(os.path.join(os.getcwd(), 'webwxgetcontact.json'), 'wb') f.write(r.content) f.close() # print(data) dic = data MemberList = dic['MemberList'] # 倒序遍历,不然删除的时候出问题.. SpecialUsers = ["newsapp", "fmessage", "filehelper", "weibo", "qqmail", "tmessage", "qmessage", "qqsync", "floatbottle", "lbsapp", "shakeapp", "medianote", "qqfriend", "readerapp", "blogapp", "facebookapp", "masssendapp", "meishiapp", "feedsapp", "voip", "blogappweixin", "weixin", "brandsessionholder", "weixinreminder", "wxid_novlwrv3lqwv11", "gh_22b87fa7cb3c", "officialaccounts", "notification_messages", "wxitil", "userexperience_alarm"] for i in range(len(MemberList) - 1, -1, -1): Member = MemberList[i] if Member['VerifyFlag'] &amp; 8 != 0: # 公众号/服务号 MemberList.remove(Member) elif Member['UserName'] in SpecialUsers: # 特殊账号 MemberList.remove(Member) elif Member['UserName'].find('@@') != -1: # 群聊 MemberList.remove(Member) elif Member['UserName'] == My['UserName']: # 自己 MemberList.remove(Member) return MemberListdef createChatroom(UserNames): MemberList = [&#123;'UserName': UserName&#125; for UserName in UserNames] url = (base_uri + '/webwxcreatechatroom?pass_ticket=%s&amp;r=%s' % ( pass_ticket, int(time.time())) ) params = &#123; 'BaseRequest': BaseRequest, 'MemberCount': len(MemberList), 'MemberList': MemberList, 'Topic': '', &#125; headers = &#123;'content-type': 'application/json; charset=UTF-8'&#125; r = myRequests.post(url=url, data=json.dumps(params),headers=headers) r.encoding = 'utf-8' data = r.json() # print(data) dic = data ChatRoomName = dic['ChatRoomName'] MemberList = dic['MemberList'] DeletedList = [] BlockedList = [] for Member in MemberList: if Member['MemberStatus'] == 4: # 被对方删除了 DeletedList.append(Member['UserName']) elif Member['MemberStatus'] == 3: # 被加入黑名单 BlockedList.append(Member['UserName']) state = responseState('createChatroom', dic['BaseResponse']) return ChatRoomName, DeletedList, BlockedListdef deleteMember(ChatRoomName, UserNames): url = (base_uri + '/webwxupdatechatroom?fun=delmember&amp;pass_ticket=%s' % (pass_ticket) ) params = &#123; 'BaseRequest': BaseRequest, 'ChatRoomName': ChatRoomName, 'DelMemberList': ','.join(UserNames), &#125; headers = &#123;'content-type': 'application/json; charset=UTF-8'&#125; r = myRequests.post(url=url, data=json.dumps(params),headers=headers) r.encoding = 'utf-8' data = r.json() # print(data) dic = data state = responseState('deleteMember', dic['BaseResponse']) return statedef addMember(ChatRoomName, UserNames): url = (base_uri + '/webwxupdatechatroom?fun=addmember&amp;pass_ticket=%s' % (pass_ticket) ) params = &#123; 'BaseRequest': BaseRequest, 'ChatRoomName': ChatRoomName, 'AddMemberList': ','.join(UserNames), &#125; headers = &#123;'content-type': 'application/json; charset=UTF-8'&#125; r = myRequests.post(url=url, data=json.dumps(params),headers=headers) r.encoding = 'utf-8' data = r.json() # print(data) dic = data MemberList = dic['MemberList'] DeletedList = [] BlockedList = [] for Member in MemberList: if Member['MemberStatus'] == 4: # 被对方删除了 DeletedList.append(Member['UserName']) elif Member['MemberStatus'] == 3: # 被加入黑名单 BlockedList.append(Member['UserName']) state = responseState('addMember', dic['BaseResponse']) return DeletedList, BlockedListdef syncKey(): SyncKeyItems = ['%s_%s' % (item['Key'], item['Val']) for item in SyncKey['List']] SyncKeyStr = '|'.join(SyncKeyItems) return SyncKeyStrdef syncCheck(): url = push_uri + '/synccheck?' params = &#123; 'skey': BaseRequest['Skey'], 'sid': BaseRequest['Sid'], 'uin': BaseRequest['Uin'], 'deviceId': BaseRequest['DeviceID'], 'synckey': syncKey(), 'r': int(time.time()), &#125; r = myRequests.get(url=url,params=params) r.encoding = 'utf-8' data = r.text # print(data) # window.synccheck=&#123;retcode:"0",selector:"2"&#125; regx = r'window.synccheck=&#123;retcode:"(\d+)",selector:"(\d+)"&#125;' pm = re.search(regx, data) retcode = pm.group(1) selector = pm.group(2) return selectordef webwxsync(): global SyncKey url = base_uri + '/webwxsync?lang=zh_CN&amp;skey=%s&amp;sid=%s&amp;pass_ticket=%s' % ( BaseRequest['Skey'], BaseRequest['Sid'], quote_plus(pass_ticket)) params = &#123; 'BaseRequest': BaseRequest, 'SyncKey': SyncKey, 'rr': ~int(time.time()), &#125; headers = &#123;'content-type': 'application/json; charset=UTF-8'&#125; r = myRequests.post(url=url, data=json.dumps(params)) r.encoding = 'utf-8' data = r.json() # print(data) dic = data SyncKey = dic['SyncKey'] state = responseState('webwxsync', dic['BaseResponse']) return statedef heartBeatLoop(): while True: selector = syncCheck() if selector != '0': webwxsync() time.sleep(1)def main(): global myRequests ssl._create_default_https_context = ssl._create_unverified_context headers = &#123;'User-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.125 Safari/537.36'&#125; myRequests = requests.Session() myRequests.headers.update(headers) if not getUUID(): print('获取uuid失败') return print('正在获取二维码图片...') showQRImage() while waitForLogin() != '200': pass os.remove(QRImagePath) if not login(): print('登录失败') return if not webwxinit(): print('初始化失败') return MemberList = webwxgetcontact() print('开启心跳线程') threading.Thread(target=heartBeatLoop) MemberCount = len(MemberList) print('通讯录共%s位好友' % MemberCount) ChatRoomName = '' result = [] d = &#123;&#125; for Member in MemberList: d[Member['UserName']] = (Member['NickName'], Member['RemarkName']) print('开始查找...') group_num = int(math.ceil(MemberCount / float(MAX_GROUP_NUM))) for i in range(0, group_num): UserNames = [] for j in range(0, MAX_GROUP_NUM): if i * MAX_GROUP_NUM + j &gt;= MemberCount: break Member = MemberList[i * MAX_GROUP_NUM + j] UserNames.append(Member['UserName']) # 新建群组/添加成员 if ChatRoomName == '': (ChatRoomName, DeletedList, BlockedList) = createChatroom( UserNames) else: (DeletedList, BlockedList) = addMember(ChatRoomName, UserNames) # todo BlockedList 被拉黑列表 DeletedCount = len(DeletedList) if DeletedCount &gt; 0: result += DeletedList # 删除成员 deleteMember(ChatRoomName, UserNames) # 进度条 progress = MAX_PROGRESS_LEN * (i + 1) / group_num print('[', '#' * int(progress), '-' * int(MAX_PROGRESS_LEN - progress), ']', end=' ') print('新发现你被%d人删除' % DeletedCount) for i in range(DeletedCount): if d[DeletedList[i]][1] != '': print('%s(%s)' % (d[DeletedList[i]][0],d[DeletedList[i]][1])) else: print(d[DeletedList[i]][0]) if i != group_num - 1: print('正在继续查找,请耐心等待...') # 下一次进行接口调用需要等待的时间 time.sleep(INTERFACE_CALLING_INTERVAL) # todo 删除群组 print('\n结果汇总完毕,20s后可重试...') resultNames = [] for r in result: if d[r][1] != '': resultNames.append('%s(%s)' % (d[r][0],d[r][1])) else: resultNames.append(d[r][0]) print('---------- 被删除的好友列表(共%d人) ----------' % len(result)) # 过滤emoji resultNames = list(map(lambda x: re.sub(r'&lt;span.+/span&gt;', '', x), resultNames)) if len(resultNames): print('\n'.join(resultNames)) else: print("无") print('---------------------------------------------')class UnicodeStreamFilter: def __init__(self, target): self.target = target self.encoding = 'utf-8' self.errors = 'replace' self.encode_to = self.target.encoding def write(self, s): if type(s) == str: try: s = s.decode('utf-8') except: pass s = s.encode(self.encode_to, self.errors).decode(self.encode_to) self.target.write(s)if sys.stdout.encoding == 'cp936': sys.stdout = UnicodeStreamFilter(sys.stdout)if __name__ == '__main__': print('本程序的查询结果可能会引起一些心理上的不适,请小心使用...') print('1小时内只能使用一次，否则会因操作繁忙阻止建群') main() print('回车键退出...') input()]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda]]></title>
    <url>%2F2016%2F01%2F26%2Fpython_lambda%2F</url>
    <content type="text"><![CDATA[Python的Lambda函数lambda函数也叫匿名函数，即函数没有具体的名称，函数冒号之前是函数的参数，没有return语句，参数的结果就是返回值。先来看一个最简单例子： 12345def f(x): return x**3print f(5)#结果是125 Python中使用lambda的话，写成这样 123g = lambda x : x**3print g(5)#同样的结果 125 使用Python写一些执行脚本时，使用lambda可以省去定义函数的过程，让代码更加精简。 对于一些抽象的，不会别的地方再复用的函数，有时候给函数起个名字也是个难题，使用lambda不需要考虑命名的问题。 使用lambda在某些时候让代码更容易理解。 lambda基础lambda语句中，冒号前是参数，可以有多个，用逗号隔开，冒号右边的返回值。lambda语句构建的其实是一个函数对象，见证一下： 1234g = lambda x : x**2print g&lt;function &lt;lambda&gt; at x00AFAAF0&gt; 12345678910&gt;&gt;&gt; foo = [2, 18, 9, 22, 17, 24, 8, 12, 27]&gt;&gt;&gt;&gt;&gt;&gt; print filter(lambda x: x % 3 == 0, foo)[18, 9, 24, 12, 27]&gt;&gt;&gt;&gt;&gt;&gt; print map(lambda x: x * 2 + 10, foo)[14, 46, 28, 54, 44, 58, 26, 34, 64]&gt;&gt;&gt;&gt;&gt;&gt; print reduce(lambda x, y: x + y, foo)139 lambda在很多地方都能使代码更加简洁，例如 12345#sort()s = [('a', 3), ('b', 2), ('c', 1)]#对这个数组用第二个元素排序。可以写成 sorted(s, key=lambda x:x[1]) lambda与序列的结合使用： python中有几个常用的内建高级函数，map、reduce、filter。这几个函数都是处理iteraable的，三个函数都是采用函数处理序列返回新的序列形式，所以这里我们就可以是使用lambda。 map() 返回的是一个序列print(list(map(lambda x:str(x),[1,2,3,4,5,6]))) [‘1’, ‘2’, ‘3’, ‘4’, ‘5’, ‘6’] reduce() 返回的是一个经过运算得到的结果123456789from functools import reduceprint(reduce(lambda x,y:x*y+2,[1,2,3,4,5,6]))#1754from functools import reduceprint(reduce(lambda x,y:(x+y)%2==0,range(1,20)))#False filter() print(list(filter(lambda x:x%2==0,range(1,20)))) [2, 4, 6, 8, 10, 12, 14, 16, 18]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>lambda</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单的拼写检查]]></title>
    <url>%2F2016%2F01%2F25%2Fspell_check%2F</url>
    <content type="text"><![CDATA[大家在使用谷歌或者百度搜索时，输入搜索内容时，谷歌总是能提供非常好的拼写检查，比如你输入 speling，谷歌会马上返回 spelling。下面是用python代码实现的一个简易但是具备完整功能的拼写检查器: 12345678910111213141516171819202122import re, collectionsdef words(text): return re.findall('[a-z]+', text.lower()) def train(features): model = collections.defaultdict(lambda: 1) for f in features: model[f] += 1 return modelNWORDS = train(words(open('big.txt').read()))alphabet = 'abcdefghijklmnopqrstuvwxyz'def edits1(word): splits = [(word[:i], word[i:]) for i in range(len(word) + 1)] deletes = [a + b[1:] for a, b in splits if b] transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)&gt;1] replaces = [a + c + b[1:] for a, b in splits for c in alphabet if b] inserts = [a + c + b for a, b in splits for c in alphabet] return set(deletes + transposes + replaces + inserts)def known_edits2(word): return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS)def known(words): return set(w for w in words if w in NWORDS)def correct(word): candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word] return max(candidates, key=NWORDS.get) 可以看出来，代码量很少，correct函数是程序的入口，传进去错误拼写的单词会返回正确。 12345678&gt;&gt;&gt; correct("cpoy")'copy'&gt;&gt;&gt; correct("engilsh")'english'&gt;&gt;&gt; correct("sruprise")'surprise'&gt;&gt;&gt; correct('thiink')'think' 除了这段代码外，作为机器学习的一部分，肯定还应该有大量的样本数据，准备了样本数据。 big.txt-戳这里 或者戳这里：） 背后原理 上面的代码是基于贝叶斯来实现的，事实上谷歌百度实现的拼写检查也是通过贝叶斯实现，不过肯定比这个复杂多了。首先简单介绍一下背后的原理，如果读者之前了解过了，可以跳过这段。给一个词，我们试图选取一个最可能的正确的的拼写建议（建议也可能就是输入的单词）。有时也不清楚（比如lates应该被更正为late或者latest），我们用概率决定把哪一个作为建议。我们从跟原始词w相关的所有可能的正确拼写中找到可能性最大的那个拼写建议c： 1argmaxc P(c|w) 通过贝叶斯定理，上式可以转化为 1argmaxc P(w|c) P(c) / P(w) 下面介绍一下上式中的含义： P(c|w)代表在输入单词w 的情况下，你本来想输入单词c的概率。P(w|c)代表用户想输入单词c却输入w的概率，这个可以我们认为给定的。P(c)代表在样本数据中单词c出现的概率P(w)代表在样本数字中单词w出现的概率可以确定P(w)对于所有可能的单词c概率都是一样的，所以上式可以转换为argmaxc P(w|c) P(c)我们所有的代码都是基于这个公式来的，下面分析具体代码实现 代码分析 利用words()函数提取big.txt中的单词 1def words(text): return re.findall('[a-z]+', text.lower()) re.findall(‘[a-z]+’是利用python正则表达式模块，提取所有的符合’[a-z]+’条件的，也就是由字母组成的单词。（这里不详细介绍正则表达式了，有兴趣的同学可以看正则表达式简介。text.lower()是将文本转化为小写字母，也就是“the”和“The”一样定义为同一个单词。 利用train()函数计算每个单词出现的次数然后训练出一个合适的模型 1234567def train(features): model = collections.defaultdict(lambda: 1) for f in features: model[f] += 1 return modelNWORDS = train(words(open('big.txt').read())) 这样NWORDS[w]代表了单词w在样本中出现的次数。如果有一个单词并没有出现在我们的样本中该怎么办？处理方法是将他们的次数默认设为1，这里通过collections模块和lambda表达式实现。collections.defaultdict()创建了一个默认的字典，lambda：1将这个字典中的每个值都默认设为1。（lambda表达式可以看lambda简介 现在我们处理完了公式argmaxc P(w|c) P(c)中的P(c)，接下来处理P(w|c)即想输入单词c却错误地输入单词w的概率，通过 “edit distance“－－将一个单词变为另一个单词所需要的编辑次数来衡量，一次edit可能是一次删除，一个交换（两个相邻的字母），一次插入，一次修改。下面的函数返回一个将c进行一次编辑所有可能得到的单词w的集合： 1234567def edits1(word): splits = [(word[:i], word[i:]) for i in range(len(word) + 1)] deletes = [a + b[1:] for a, b in splits if b] transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)&gt;1] replaces = [a + c + b[1:] for a, b in splits for c in alphabet if b] inserts = [a + c + b for a, b in splits for c in alphabet] return set(deletes + transposes + replaces + inserts) 相关论文显示，80-95%的拼写错误跟想要拼写的单词都只有1个编辑距离，如果觉得一次编辑不够，那我们再来一次 12def known_edits2(word): return set(e2 for e1 in edits1(word) for e2 in edits1(e1) if e2 in NWORDS) 同时还可能有编辑距离为0次的即本身就拼写正确的： 12def known(words): return set(w for w in words if w in NWORDS) 我们假设编辑距离1次的概率远大于2次的，0次的远大于1次的。下面通过correct函数先选择编辑距离最小的单词，其对应的P(w|c)就会越大，作为候选单词，再选择P(c)最大的那个单词作为拼写建议 123def correct(word): candidates = known([word]) or known(edits1(word)) or known_edits2(word) or [word] return max(candidates, key=NWORDS.get)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python CGI初体验]]></title>
    <url>%2F2016%2F01%2F25%2Fpython_cgi%2F</url>
    <content type="text"><![CDATA[CGI小述CGI（Common Gateway Interface,通用网页接口）。CGI是网络服务器可以将查询（一般来说是通过Web表单）传递到专门的程序（比如Python等）中并且在网页上显示结果的标准机制。它是创建万维网应用程序而不用编写特殊用途的应用服务器的简单方法。 CGI(Common Gateway Interface) 是WWW技术中最重要的技术之一，有着不可替代的重要地位。CGI是外部应用程序（CGI程序）与Web服务器之间的接口标准，是在CGI程序和Web服务器之间传递信息的规程。CGI规范允许Web服务器执行外部程序，并将它们的输出发送给Web浏览器，CGI将Web的一组简单的静态超媒体文档变成一个完整的新的交互式媒体。Common Gateway Interface，简称CGI。在物理上是一段程序，运行在服务器上，提供同客户端HTML页面的接口。这样说大概还不好理解。那么我们看一个实际例子：现在的个人主页上大部分都有一个留言本。留言本的工作是这样的：先由用户在客户端输入一些信息，如名字之类的东西。接着用户按一下“留言”（到目前为止工作都在客户端），浏览器把这些信息传送到服务器的CGI目录下特定的CGI程序中，于是CGI程序在服务器上按照预定的方法进行处理。在本例中就是把用户提交的信息存入指定的文件中。然后CGI程序给客户端发送一个信息，表示请求的任务已经结束。此时用户在浏览器里将看到“留言结束”的字样。整个过程结束。 绝大多数的CGI程序被用来解释处理来自表单的输入信息，并在服务器产生相应的处理，或将相应的信息反馈给浏览器。CGI程序使网页具有交互功能。 Python CGI程序设计的关键工具是cgi、cgitb模块。 实现 处理步骤 通过Internet把用户请求送到web服务器。 web服务器接收用户请求并交给CGI程序处理。 CGI程序把处理结果传送给web服务器。 web服务器把结果送回到用户。 CGI程序不是放在服务器上就能顺利运行，如果要想使其在服务器上顺利的运行并准确的处理用户的请求，则须对所使用的服务器进行必要的设置。配置：根据所使用的服务器类型以及它的设置把CGI程序放在某一特定的目录中或使其带有特定的扩展名。 工作原理 浏览器通过HTML表单或超链接请求指向一个CGI应用程序的URL。 服务器收发到请求。 服务器执行指定CGI应用程序。 CGI应用程序执行所需要的操作，通常是基于浏览者输入的内容。 CGI应用程序把结果格式化为网络服务器和浏览器能够理解的文档（通常是HTML网页）。 网络服务器把结果返回到浏览器中。 服务器设置CGI是运行在服务器端的，所以与服务器的接触在所难免。 Apache是web服务器，Tomcat是应用（java）服务器，它只是一个servlet容器，是Apache的扩展。 Apache和Tomcat都可以做为独立的web服务器来运行，但是Apache不能解释java程序（jsp,servlet）。两者都是一种容器，只不过发布的东西不同：Apache是html容器，功能像IIS一样；Tomcat是jsp/servlet容器，用于发布jsp及java的，类似的有IBM的websphere、BEA的Weblogic，sun的JRun等等。打个比方：Apache是一辆卡车，上面可以装一些东西如html等。但是不能装水，要装水必须要有容器（桶），Tomcat就是一个桶（装像Java这样的水），而这个桶也可以不放在卡车上。 CGI程序应该放在通过网络可以访问的目录中，并且将他们标识为CGI脚本，这样网络服务器就不会将普通源代码作为网页处理。 将脚本放在叫做cgi-bin的子目录中. 将脚本文件的扩展名改为.cgi. 当把脚本放在正确位置之后，需要在脚本的开始处增加pound bang行。这一步是至关重要的，如果没要这行标识，网络服务器就不知道如何执行脚本。脚本可以用其他语言来写，比如Perl、Ruby。一般来讲，只要加上这句 1#!/usr/bin/env python 这一这行文字是以UNIX风格填写的，前面无空行、结尾以’\n’而非’\r\n’.在Windows中，可以使用Python二进制版本的全路径： 1#!C:\Python34\python.exe 要做的最后一件事情就是这只合适的文件许可。确保每个人都可以读取和执行脚本文件，同时要确保这个文件只能由你写入。（就是在Linux中修改文件的权限）修改文件许可的Linux命令式chmod，只要运行下列命令 1chmod 755 somescript.cgi 即将文件权限设置为只能由本用户全部操作，而用户组以及其他用户只享有r、w权限，无x执行权限。在做好这些准备之后，应该能够将脚本作为网页打开、执行。 1234567891011#!C:\Python34\python.exe print('Content-type: text/html')print()#打印空行以结束首部print("""&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello,Python&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;""") 下面分别来介绍Apache与Tomcat两种服务器上运行CGI。 Apache 打开http.conf，找到 #ScriptInterpreterSource Registry，把前面的#去掉。如果没有找到这句话，则自行添加。 找到AddHandler cgi-script，去掉前面的#，在后面加上.py 找到Options Indexes FollowSymLinks，在其后加上ExecCGI, 去掉 Indexes 保存，重启apache。 之后将我们之前新建的CGI文件python_cgi.py保存在Apache服务器默认的工作目录htdocs下，创建新的项目目录cgitest或者直接在htdocs目录下，保存文件python_cgi.py或者python_cgi.cgi.打开Apache服务器，（apache默认port=80），在浏览器中输入 localhost/python_cgi.py、localhost/python_cgi.cgi或者在htdocs的其他可以访问的cgi路径。此时网页中显示 Hello,World Tomcat 打开web.xml文件（D:\apache-tomcat-6.0.36\conf\web.xml），找到这一段被注释的节点（如下），如果你从没自己修改过，那应该是被注释的，你还需要添加一些参数。 12345678910111213141516171819202122232425&lt;servlet&gt;&lt;servlet-name&gt;cgi&lt;/servlet-name&gt;&lt;servlet-class&gt;org.apache.catalina.servlets.CGIServlet&lt;/servlet-class&gt;&lt;init-param&gt;&lt;param-name&gt;clientinputTimeout&lt;/param-name&gt;&lt;param-value&gt;100&lt;/param-value&gt;&lt;/init-param&gt;&lt;init-param&gt;&lt;param-name&gt;debug&lt;/param-name&gt;&lt;param-value&gt;0&lt;/param-value&gt;&lt;/init-param&gt;&lt;init-param&gt;&lt;param-name&gt;passShellEnvironment&lt;/param-name&gt;&lt;param-value&gt;true&lt;/param-value&gt;&lt;/init-param&gt;&lt;init-param&gt;&lt;param-name&gt;cgiPathPrefix&lt;/param-name&gt;&lt;param-value&gt;WEB-INF/cgi-bin&lt;/param-value&gt;&lt;/init-param&gt;&lt;init-param&gt;&lt;param-name&gt;executable&lt;/param-name&gt;&lt;param-value&gt;C:/Python34/python.exe&lt;/param-value&gt;&lt;/init-param&gt;&lt;load-on-startup&gt;5&lt;/load-on-startup&gt;&lt;/servlet&gt; 解释几个重要的参数： “passShellEnvironment”: 与Python解析器解析CGI脚本有关，但是一定要配置好Python的环境变量； “cgiPathPrefix”: 与Server能够访问的脚本目录有关，与第二步内容相对应; “executable”: （这是我的安装路径）与Python解析器有关，没有解析器，Server怎么解析呢~ 找到第二段被注释的节点： 1234&lt;servlet-mapping&gt;&lt;servlet-name&gt;cgi&lt;/servlet-name&gt;&lt;url-pattern&gt;/cgi-bin/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 这里的/cgi-bin/*指定了浏览器访问的地址，与前面WEB-INF/cgi-bin相对应。 配置权限： 打开context.xml，添加：privileged=”true” 12345678910111213&lt;Context privileged="true"&gt;&lt;!-- Default set of monitored resources --&gt;&lt;WatchedResource&gt;WEB-INF/web.xml&lt;/WatchedResource&gt;&lt;!-- Uncomment this to disable session persistence across Tomcat restarts --&gt;&lt;!--&lt;Manager pathname="" /&gt;--&gt;&lt;!-- Uncomment this to enable Comet connection tacking (provides eventson session expiration as well as webapp lifecycle) --&gt;&lt;!--&lt;Valve className="org.apache.catalina.valves.CometConnectionManagerValve" /&gt;--&gt;&lt;/Context&gt; 此时Tomcat应该就可以正常解析放在正确路径的cgi程序了。还是上面的python cgi文件python_cgi.py： 在Tomcat默认的工作目录下面新建项目cgitest，即cgitest目录。 在新建的项目目录下，新建WEB-INF目录，这个是Web程序的标准安全目录，客户端无法访问，只能在服务器端访问 将原来创建的python_cgi.py存放在WEB-INF目录下的cgi-bin目录下。 现在就可以将Tomcat WEB容器启动，Tomcat自动将cgitest部署，访问 http://localhost:8080/cgitest/cgi-bin/python-cgi.py ，出现了与Apache相同的效果。 当然了，CGI的功能肯定远不止如此，更多的细节我会在其他文章中记录。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>cgi</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[抓取豆瓣电影信息]]></title>
    <url>%2F2016%2F01%2F22%2FBeautifulSooup%2F</url>
    <content type="text"><![CDATA[BeautifulSoup抓取豆瓣电影信息Beautiful Soup 是用Python写的一个HTML/XML的解析器，它可以很好的处理不规范标记并生成剖析树(parse tree)。 它提供简单又常用的导航（navigating），搜索以及修改剖析树的操作。它可以大大节省你的编程时间。 BeautifulSoup4的安装一、使用pip直接安装beautifulsoup4 12345678F:\demo&gt;pip install beautifulsoup4Collecting beautifulsoup4Downloading beautifulsoup4-4.4.0-py3-none-any.whl (80kB)328kB/sInstalling collected packages: beautifulsoup4Successfully installed beautifulsoup4-4.4.0F:\demo&gt; 或者从官网下载Beautifulsoup的软件包，然后解压，cmd命令行进入解压包目录，输入以下命令安装：python setup.py install 实例，新浪双色球开奖数据实现： 12345678910111213141516171819202122232425262728293031323334from bs4 import BeautifulSoupimport reimport urllib.request, urllib.parse, http.cookiejardef getHtml(url): cj = http.cookiejar.CookieJar() opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj)) opener.addheaders = [('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36'),('Cookie', '4564564564564564565646540')] urllib.request.install_opener(opener) html_bytes = urllib.request.urlopen(url).read() html_string = html_bytes.decode('utf-8') return html_stringhtml_doc = getHtml("http://zst.aicai.com/ssq/openInfo/")soup = BeautifulSoup(html_doc, 'html.parser')tr = soup.find('tr',attrs=&#123;"onmouseout": "this.style.background=''"&#125;) #print(tr)tds = tr.find_all('td')opennum = tds[0].get_text() #彩票期号time = tds[1].get_text() #开奖时间reds = [] for i in range(2,8): reds.append(tds[i].get_text()) #print(reds) 前面开出的普通号码blue = tds[8].get_text() #特殊号码print(opennum+'期开奖号码：'+ (',').join(reds)+", 蓝球："+blue+", 开奖时间 ："+time)$ python hello.py2016009期开奖号码：10,14,24,25,27,32, 蓝球：04, 开奖时间 ：2016-01-21 soup = BeautifulSoup(html_doc) soup 就是BeautifulSoup处理格式化后的字符串，soup.title 得到的是title标签，soup.p 得到的是文档中的第一个p标签，要想得到所有标签，得用find_all 函数。find_all 函数返回的是一个序列，可以对它进行循环，依次得到想到的东西. get_text() 是返回文本,这个对每一个BeautifulSoup处理后的对象得到的标签都是生效的。你可以试试 print soup.p.get_text() 其实是可以获得标签的其他属性的，比如我要获得a标签的href属性的值，可以使用 print soup.a[‘href’],类似的其他属性，比如class也是可以这么得到的（soup.a[‘class’]）。 特别的，一些特殊的标签，比如head标签，是可以通过soup.head 得到，其实前面也已经说了。 如何获得标签的内容数组？使用contents 属性就可以 比如使用 print soup.head.contents，就获得了head下的所有子孩子，以列表的形式返回结果 封装下面就开始进行一个小的实战操作,http://movie.douban.com/tag/%E5%96%9C%E5%89%A7 这个是豆瓣电影中的喜剧电影页面，我们就对这个页面操作，获取喜剧电影中评分最高的100个电影。 对这个页面需要提取两个信息：1、翻页链接；2、每部电影的信息（外链，图片，评分、简介、标题等） 当我们提取到所有电影的信息后再按评分进行排序，选出最高的即可，这里贴出翻页提取和电影信息提取的代码 from bs4 import BeautifulSoup import urllib.request import re import urllib.parse, http.cookiejar import sys #定义程序运行过程中的日志函数 def LOG(*argv): sys.stderr.write(*argv) sys.stderr.write('\n') class Grab(): url = '' soup = None #读取当前网页的源代码数据返回 def GetPage(self, url): if url.find('http://',0,7) != 0: url = 'http://' + url self.url = url LOG('input url is: %s' % self.url) req = urllib.request.Request(url, headers={'User-Agent' : "Magic Browser"}) try: page = urllib.request.urlopen(req) except: return return page.read() #解析当前页面数据并将所需要的数据通过列表元祖返回 def ExtractInfo(self,buf): try: #buf是传入的网页源代码，通过BeautifulSoup函数返回修正过的数据 self.soup = BeautifulSoup(buf,'html.parser') except: LOG('soup failed in ExtractInfo :%s' % self.url) return try: #分析豆瓣电影网页中的代码，每个电影信息都被单独的放到一个item类中 items = self.soup.findAll(attrs={'class':'item'}) except: LOG('failed on find items:%s' % self.url) return links = [] #电影的详细页面 objs = [] #电影的图片地址 titles = [] #电影名称 scores = [] #电影当前获取分数 comments = [] #评论 intros = [] #简单介绍 for item in items: try: pic = item.find(attrs={'class':'nbg'}) link = pic['href'] obj = pic.img['src'] info = item.find(attrs={'class':'pl2'}) title = re.sub('[ \t]+',' ',info.a.getText().replace(' ','').replace('\n','')) star = info.find(attrs={'class':'star clearfix'}) score = star.find(attrs={'class':'rating_nums'}).getText().replace(' ','') comment = star.find(attrs={'class':'pl'}).getText().replace(' ','') intro = info.find(attrs={'class':'pl'}).getText().replace(' ','') except Exception as e: LOG('process error in ExtractInfo: %s' % self.url) continue links.append(link) objs.append(obj) titles.append(title) scores.append(score) comments.append(comment) intros.append(intro) return [links, objs, titles, scores, comments, intros] #获取所有相邻页面url def ExtractPageTurning(self,buf): links = set([]) if not self.soup: try: self.soup = BeautifulSoup(buf,'html.parser') except: LOG('soup failed in ExtractPageTurning:%s' % self.url) return try: pageturning = self.soup.find(attrs={'class':'paginator'}) a_nodes = pageturning.findAll('a') for a_node in a_nodes: href = a_node['href'] if href.find('http://',0,7) == -1: href = self.url.split('?')[0] + href links.add(href) except: LOG('get pageturning failed in ExtractPageTurning:%s' % self.url) return set(links) def Destroy(self): del self.soup self.soup = None grab = Grab() #添加网页文件的格式 file_object = open('info.html', 'w+') file_object.write('&lt;html&gt;&lt;body&gt;&lt;center&gt;&lt;table&gt;\r\n') #buf是当前页面经过转换之后的源代码 buf = grab.GetPage('http://movie.douban.com/tag/%E5%96%9C%E5%89%A7') if not buf: print('GetPage failed!') sys.exit() #pageturning是当前页面相关连接的集合 pageturning = grab.ExtractPageTurning(buf) pageturning.add('http://movie.douban.com/tag/%E5%96%9C%E5%89%A7') links=[] objs=[] titles=[] comments=[] intros=[] scores=[] for page in pageturning: buf = grab.GetPage(page) [link, obj, title, score, comment, intro]= grab.ExtractInfo(buf) print() links+=link objs+=obj titles+=title scores+=score comments+=comment intros+=intro #zip函数返回一个可迭代的元组，是一个zip object而非直接的元组 tu=zip(links, objs, titles, scores, comments, intros) tu1=[] #将zip对象中的数据一次添加到序列中 for link, obj, title, score, comment, intro in tu: item=[link, obj, title, score, comment, intro] tu1.append(item) #将列表转换成为元组 tu1=tuple(tu1) #将每个条目按照电影的豆瓣评分重新降序排序 tu1=sorted(tu1,key=lambda t:t[3],reverse = True) index=0 for link, obj, title, score, comment, intro in tu1: if index%3==0 and(index+1)%6!=0: file_object.write('&lt;tr&gt;') file_object.write('&lt;td&gt;') str=title+' '+score+'&lt;br&gt;\r\n &lt;a href='+link+'&gt;&lt;img src='+obj+'&gt; &lt;/img&gt;&lt;/a&gt;\r\n'; file_object.write(str.encode('gbk','ignore').decode('gbk')) file_object.write('&lt;br&gt;&lt;/td&gt;') if (index+1)%6==0 : file_object.write('&lt;/tr&gt;') index+=1 grab.Destroy() file_object.write('&lt;/table&gt;&lt;center&gt;&lt;/body&gt;&lt;html&gt;') file_object.close( ) #运行情况 $ python hello.py input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7 input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=7880&amp;type=T input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7 input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=7860&amp;type=T input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=60&amp;type=T input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=160&amp;type=T input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=120&amp;type=T input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=40&amp;type=T input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=80&amp;type=T input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=20&amp;type=T input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=140&amp;type=T input url is: http://movie.douban.com/tag/%E5%96%9C%E5%89%A7?start=100&amp;type=T 成果展示做出的网页效果比较简陋,如下图所示:]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AC自动机]]></title>
    <url>%2F2016%2F01%2F21%2FAho-Corasick-automation%2F</url>
    <content type="text"><![CDATA[文章大部分内容参考自CSDN–飘过的小牛 AC自动机，全程是Aho-Corasick automaton，该算法在1975年产生于贝尔实验室，是著名的多模匹配算法。 要讲清楚比较吃力，直接上实例边消化边理解会好很多。 示例构造 构造一棵Trie，作为AC自动机的搜索数据结构。 构造fail指针，使当前字符失配时跳转到具有最长公共前后缀的字符继续匹配。如同 KMP算法一样， AC自动机在匹配时如果当前字符匹配失败，那么利用fail指针进行跳转。由此可知如果跳转，跳转后的串的前缀，必为跳转前的模式串的后缀并且跳转的新位置的深度（匹配字符个数）一定小于跳之前的节点。所以我们可以利用 bfs在 Trie上面进行 fail指针的求解。 扫描主串进行匹配。 过程记录给出5个单词，say，she，shr，he，her。给定字符串为yasherhs。问多少个单词在字符串中出现过 首先我们需要建立一棵Trie。但是这棵Trie不是普通的Trie，而是带有一些特殊的性质。 Trie树有3个重要的指针，分别为p, p-&gt;fail, temp。 指针p，指向当前匹配的字符。若p指向root，表示当前匹配的字符序列为空。（root是Trie入口，没有实际含义）。 指针p-&gt;fail，p的失败指针，指向与字符p相同的结点，若没有，则指向root。 指针temp，测试指针（自己命名的，容易理解！~），在建立fail指针时有寻找与p字符匹配的结点的作用，在扫描时作用最大，也最不好理解。 构造fail用BFS来构造失败指针，与KMP算法相似的思想。 首先，root入队，第1次循环时处理与root相连的字符，也就是各个单词的第一个字符h和s，因为第一个字符不匹配需要重新匹配，所以第一个字符都指向root（root是Trie入口，没有实际含义）失败指针的指向对应下图中的(1)，(2)两条虚线； 第2次进入循环后，从队列中先弹出h，接下来p指向h节点的fail指针指向的节点，也就是root；p=p-&gt;fail也就是p=NULL说明匹配序列为空，则把节点e的fail指针指向root表示没有匹配序列，对应图-2中的(3)，然后节点e进入队列； 第3次循环时，弹出的第一个节点a的操作与上一步操作的节点e相同，把a的fail指针指向root，对应图-2中的(4)，并入队； 第4次进入循环时，弹出节点h(图中左边那个)，这时操作略有不同。由于p-&gt;next[i]!=NULL(root有h这个儿子节点，图中右边那个)，这样便把左边那个h节点的失败指针指向右边那个root的儿子节点h，对应图-2中的(5)，然后h入队。 以此类推：在循环结束后，所有的失败指针就是图-2中的这种形式。 扫描遍历 构造好Trie和失败指针后，我们就可以对主串进行扫描了。这个过程和KMP算法很类似，但是也有一定的区别，主要是因为AC自动机处理的是多串模式，需要防止遗漏某个单词，所以引入temp指针。匹配过程分两种情况：(1)当前字符匹配，表示从当前节点沿着树边有一条路径可以到达目标字符，此时只需沿该路径走向下一个节点继续匹配即可，目标字符串指针移向下个字符继续匹配；(2)当前字符不匹配，则去当前节点失败指针所指向的字符继续匹配，匹配过程随着指针指向root结束。重复这2个过程中的任意一个，直到模式串走到结尾为止。 对照上图，看一下模式匹配这个详细的流程，其中模式串为yasherhs。 对于i=0,1。Trie中没有对应的路径，故不做任何操作； i=2,3,4时，指针p走到左下节点e。因为节点e的count信息为1，所以cnt+1，并且讲节点e的count值设置为-1，表示改单词已经出现过了，防止重复计数，最后temp指向e节点的失败指针所指向的节点(即图中右边相同的e节点开始)继续查找，以此类推，最后temp指向root，退出while循环，这个过程中count增加了2。表示找到了2个单词she和he。 当i=5时，程序进入第5行，p指向其失败指针的节点，也就是右边那个e节点，随后在第6行指向r节点，r节点的count值为1，从而count+1，循环直到temp指向root为止。 最后i=6,7时，找不到任何匹配，匹配过程结束。 实现HDU2222 Input First line will contain one integer means how many cases will follow by.Each case will contain two integers N means the number of keywords and N keywords follow. (N &lt;= 10000)Each keyword will only contains characters ‘a’-‘z’, and the length will be not longer than 50.The last line is the description, and the length will be not longer than 1000000. Output Print how many keywords are contained in the description. Sample Input 15shehesayshrheryasherhs Sample Output 3 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;string.h&gt;#include &lt;queue&gt;using namespace std;struct Trie&#123; int next[500010][26],fail[500010],end[500010]; int root,L; int newnode() &#123; for(int i = 0;i &lt; 26;i++) next[L][i] = -1; end[L++] = 0; return L-1; &#125; void init() &#123; L = 0; root = newnode(); &#125; void insert(char buf[]) &#123; int len = strlen(buf); int now = root; for(int i = 0;i &lt; len;i++) &#123; if(next[now][buf[i]-'a'] == -1) next[now][buf[i]-'a'] = newnode(); now = next[now][buf[i]-'a']; &#125; end[now]++; &#125; void build() &#123; queue&lt;int&gt;Q; fail[root] = root; for(int i = 0;i &lt; 26;i++) if(next[root][i] == -1) next[root][i] = root; else &#123; fail[next[root][i]] = root; Q.push(next[root][i]); &#125; while( !Q.empty() ) &#123; int now = Q.front(); Q.pop(); for(int i = 0;i &lt; 26;i++) if(next[now][i] == -1) next[now][i] = next[fail[now]][i]; else &#123; fail[next[now][i]]=next[fail[now]][i]; Q.push(next[now][i]); &#125; &#125; &#125; int query(char buf[]) &#123; int len = strlen(buf); int now = root; int res = 0; for(int i = 0;i &lt; len;i++) &#123; now = next[now][buf[i]-'a']; int temp = now; while( temp != root ) &#123; res += end[temp]; end[temp] = 0; temp = fail[temp]; &#125; &#125; return res; &#125; void debug() &#123; for(int i = 0;i &lt; L;i++) &#123; printf("id = %3d,fail = %3d,end = %3d,chi = [",i,fail[i],end[i]); for(int j = 0;j &lt; 26;j++) printf("%2d",next[i][j]); printf("]\n"); &#125; &#125;&#125;;char buf[1000010];Trie ac;int main()&#123; int T; int n; scanf("%d",&amp;T); while( T-- ) &#123; scanf("%d",&amp;n); ac.init(); for(int i = 0;i &lt; n;i++) &#123; scanf("%s",buf); ac.insert(buf); &#125; ac.build(); scanf("%s",buf); printf("%d\n",ac.query(buf)); &#125; return 0;&#125; 位置记录 模式串集合：{“nihao”,”hao”,”hs”,”hsr”} 待匹配文本：”sdmfhsgnshejfgnihaofhsrnihao” 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204#include&lt;iostream&gt;#include&lt;string.h&gt;#include&lt;malloc.h&gt;#include &lt;queue&gt;using namespace std;typedef struct node&#123; struct node *next[26]; //接收的态 struct node *par; //父亲节点 struct node *fail; //失败节点 char inputchar; int patterTag; //是否为可接收态 int patterNo; //接收态对应的可接受模式&#125;*Tree,TreeNode;char pattern[4][30]=&#123;"nihao","hao","hs","hsr"&#125;;/**申请新的节点，并进行初始化*/TreeNode *getNewNode()&#123; int i; TreeNode* tnode=(TreeNode*)malloc(sizeof(TreeNode)); tnode-&gt;fail=NULL; tnode-&gt;par=NULL; tnode-&gt;patterTag=0; for(i=0;i&lt;26;i++) tnode-&gt;next[i]=NULL; return tnode;&#125;/**将Trie树中，root节点的分支节点，放入队列*/int nodeToQueue(Tree root,queue&lt;Tree&gt; &amp;myqueue)&#123; int i; for (i = 0; i &lt; 26; i++) &#123; if (root-&gt;next[i]!=NULL) myqueue.push(root-&gt;next[i]); &#125; return 0;&#125;/**建立trie树*/Tree buildingTree()&#123; int i,j; Tree root=getNewNode(); Tree tmp1=NULL,tmp2=NULL; for(i=0;i&lt;4;i++) &#123; tmp1=root; for(j=0;j&lt;strlen(pattern[i]);j++) ///对每个模式进行处理 &#123; if(tmp1-&gt;next[pattern[i][j]-'a']==NULL) ///是否已经有分支，Trie共用节点 &#123; tmp2=getNewNode(); tmp2-&gt;inputchar=pattern[i][j]; tmp2-&gt;par=tmp1; tmp1-&gt;next[pattern[i][j]-'a']=tmp2; tmp1=tmp2; &#125; else tmp1=tmp1-&gt;next[pattern[i][j]-'a']; &#125; tmp1-&gt;patterTag=1; tmp1-&gt;patterNo=i; &#125; return root;&#125;/**建立失败指针*/int buildingFailPath(Tree root)&#123; int i; char inputchar; queue&lt;Tree&gt; myqueue; root-&gt;fail=root; for(i=0;i&lt;26;i++) ///对root下面的第二层进行特殊处理 &#123; if (root-&gt;next[i]!=NULL) &#123; nodeToQueue(root-&gt;next[i],myqueue); root-&gt;next[i]-&gt;fail=root; &#125; &#125; Tree tmp=NULL,par=NULL; while(!myqueue.empty()) &#123; tmp=myqueue.front(); myqueue.pop(); nodeToQueue(tmp,myqueue); inputchar=tmp-&gt;inputchar; par=tmp-&gt;par; while(true) &#123; if(par-&gt;fail-&gt;next[inputchar-'a']!=NULL) &#123; tmp-&gt;fail=par-&gt;fail-&gt;next[inputchar-'a']; break; &#125; else &#123; if(par-&gt;fail==root) &#123; tmp-&gt;fail=root; break; &#125; else par=par-&gt;fail-&gt;par; &#125; &#125; &#125; return 0;&#125;/**进行多模式搜索，即搜寻AC自动机*/int searchAC(Tree root,char* str,int len)&#123; TreeNode *tmp=root; int i=0; while(i &lt; len) &#123; int pos=str[i]-'a'; if (tmp-&gt;next[pos]!=NULL) &#123; tmp=tmp-&gt;next[pos]; if(tmp-&gt;patterTag==1) ///如果为接收态 &#123; cout&lt;&lt;i-strlen(pattern[tmp-&gt;patterNo])+1&lt;&lt;'\t'&lt;&lt;tmp-&gt;patterNo&lt;&lt;'\t'&lt;&lt;pattern[tmp-&gt;patterNo]&lt;&lt;endl; &#125; i++; &#125; else &#123; if(tmp==root) i++; else &#123; tmp=tmp-&gt;fail; if(tmp-&gt;patterTag==1) //如果为接收态 cout&lt;&lt;i-strlen(pattern[tmp-&gt;patterNo])+1&lt;&lt;'\t'&lt;&lt;tmp-&gt;patterNo&lt;&lt;'\t'&lt;&lt;pattern[tmp-&gt;patterNo]&lt;&lt;endl; &#125; &#125; &#125; while(tmp!=root) &#123; tmp=tmp-&gt;fail; if(tmp-&gt;patterTag==1) cout&lt;&lt;i-strlen(pattern[tmp-&gt;patterNo])+1&lt;&lt;'\t'&lt;&lt;tmp-&gt;patterNo&lt;&lt;'\t'&lt;&lt;pattern[tmp-&gt;patterNo]&lt;&lt;endl; &#125; return 0;&#125;/**释放内存，DFS*/int destory(Tree tree)&#123; if(tree==NULL) return 0; queue&lt;Tree&gt; myqueue; TreeNode *tmp=NULL; myqueue.push(tree); tree=NULL; while(!myqueue.empty()) &#123; tmp=myqueue.front(); myqueue.pop(); for (int i = 0; i &lt; 26; i++) &#123; if(tmp-&gt;next[i]!=NULL) myqueue.push(tmp-&gt;next[i]); &#125; free(tmp); &#125; return 0;&#125;int main()&#123; char a[]="sdmfhsgnshejfgnihaofhsrnihao"; Tree root=buildingTree(); ///建立Trie树 buildingFailPath(root); ///添加失败转移 cout&lt;&lt;"待匹配字符串："&lt;&lt;a&lt;&lt;endl; cout&lt;&lt;"模式"&lt;&lt;pattern[0]&lt;&lt;" "&lt;&lt;pattern[1]&lt;&lt;" "&lt;&lt;pattern[2]&lt;&lt;" "&lt;&lt;pattern[3]&lt;&lt;" "&lt;&lt;endl&lt;&lt;endl; cout&lt;&lt;"匹配结果如下："&lt;&lt;endl&lt;&lt;"位置\t"&lt;&lt;"编号\t"&lt;&lt;"模式"&lt;&lt;endl; searchAC(root,a,strlen(a)); ///搜索 destory(root); ///释放动态申请内存 return 0;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>模式匹配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[矩阵快速幂]]></title>
    <url>%2F2016%2F01%2F21%2F%E7%9F%A9%E9%98%B5%E5%BF%AB%E9%80%9F%E5%B9%82%2F</url>
    <content type="text"><![CDATA[矩阵的快速幂是用来高效地计算矩阵的高次方的。将朴素的o（n）的时间复杂度，降到log（n）. 最简单的例子来讲，一般我们正常计算实数x的n次幂时，都是从1开始，进行n次的x相乘。 但做下简单的改进就能减少连乘的次数，方法如下： 把n个矩阵进行两两分组，比如：A*A*A*A*A*A =&gt; (A*A)*(A*A)*(A*A) 这样变的好处是，你只需要计算一次AA，然后将结果(AA)连乘自己两次就能得到A^6，即(A*A)^3=A^6.这样就很容易的实现了时间复杂度的优化。 在上面的问题中，最重要的就是如何选择间距值，上面的解答给我们展示了间距为2的示例，但我们还可以有很多其他的选择。那么如何选择出时间复杂度最低的呢，我们应该充分的使用现有的计算结果 回头看看矩阵的快速幂问题，我们是不是也能把它离散化呢？比如A^19 =&gt; （A^16）（A^2）（A^1），显然采取这样的方式计算时因子数将是log(n)级别的(原来的因子数是n)，不仅这样，因子间也是存在某种联系的，比如A^4能通过(A^2)(A^2)得到，A^8又能通过(A^4)(A^4)得到，这点也充分利用了现有的结果作为有利条件。 下面举个例子进行说明： 现在要求A^156,而156(10)=10011100(2) 也就有A^156=&gt;(A^4)(A^8)(A^16)*(A^128) while(N) { if(N&amp;1) res=res*A; N&gt;&gt;=1; A=A*A; }]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Trie树]]></title>
    <url>%2F2016%2F01%2F20%2FTrie%2F</url>
    <content type="text"><![CDATA[文章大部分内容引用自Encyclopedia Trie树，即字典树。是一种树形结构，哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。 Trie树可以用来作为搜索引擎中的分词处理手段。 描述根节点不包含字符，除根节点外每一个节点都只包含一个字符； 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串； 每个节点的所有子节点包含的字符都不相同。 实现 从根结点开始一次搜索； 取得要查找关键词的第一个字母，并根据该字母选择对应的子树并转到该子树继续进行检索； 在相应的子树上，取得要查找关键词的第二个字母,并进一步选择对应的子树进行检索。 迭代过程…… 在某个结点处，关键词的所有字母已被取出，则读取附在该结点上的信息，即完成查找。 示例给出say，she，shr，he，her这5个单词作为构造Trie树的元素，构造的Trie树应该是这样的。 应用 串的快速检索 给出N个单词组成的熟词表，以及一篇全用小写英文书写的文章，请你按最早出现的顺序写出所有不在熟词表中的生词。在这种问题下，我们可以用数组枚举、哈希、用字典树，先把熟词建一棵树，然后读入文章进行比较，这种方法效率是比较高的。 “串”排序 给定N个互不相同的仅由一个单词构成的英文名，让你将他们按字典序从小到大输出用字典树进行排序，采用数组的方式创建字典树，这棵树的每个结点的所有儿子很显然地按照其字母大小排序。对这棵树进行先序遍历即可。 最长公共前缀 对所有串建立字典树，对于两个串的最长公共前缀的长度即他们所在的结点的公共祖先个数，于是，问题就转化为当时公共祖先问题。 C++实现HDU1251 Input 输入数据的第一部分是一张单词表,每行一个单词,单词的长度不超过10,它们代表的是老师交给Ignatius统计的单词,一个空行代表单词表的结束.第二部分是一连串的提问,每行一个提问,每个提问都是一个字符串. 注意:本题只有一组测试数据,处理到文件结束. Output 对于每个提问,给出以该字符串为前缀的单词的数量. Sample Input bananabandbeeabsoluteacm babbandabc Sample Output 2310 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;typedef struct Trie_node&#123; int count; // 统计单词前缀出现的次数 struct Trie_node* next[26]; // 指向各个子树的指针 bool exist; // 标记该结点处是否构成单词 &#125;TrieNode , *Trie;TrieNode* createTrieNode()&#123; TrieNode* node = (TrieNode *)malloc(sizeof(TrieNode)); node-&gt;count = 0; node-&gt;exist = false; memset(node-&gt;next , 0 , sizeof(node-&gt;next)); // 初始化为空指针 return node;&#125;void Trie_insert(Trie root, char* word)&#123; Trie node = root; char *p = word; int id; while( *p ) &#123; id = *p - 'a'; if(node-&gt;next[id] == NULL) &#123; node-&gt;next[id] = createTrieNode(); &#125; node = node-&gt;next[id]; // 每插入一步，相当于有一个新串经过，指针向下移动 ++p; node-&gt;count += 1; // 这行代码用于统计每个单词前缀出现的次数（也包括统计每个单词出现的次数） &#125; node-&gt;exist = true; // 单词结束的地方标记此处可以构成一个单词&#125;int Trie_search(Trie root, char* word)&#123; Trie node = root; char *p = word; int id; while( *p ) &#123; id = *p - 'a'; node = node-&gt;next[id]; ++p; if(node == NULL) return 0; &#125; return node-&gt;count;&#125;int main(void)&#123; Trie root = createTrieNode(); // 初始化字典树的根节点 char str[12] ; bool flag = false; while(gets(str)) &#123; if(flag) printf("%d\n",Trie_search(root , str)); else &#123; if(strlen(str) != 0) &#123; Trie_insert(root , str); &#125; else flag = true; &#125; &#125; return 0;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式进程]]></title>
    <url>%2F2016%2F01%2F12%2Fpy_distribute%2F</url>
    <content type="text"><![CDATA[在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。 Python的multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于managers模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。举个例子：如果我们已经有一个通过Queue通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？ 原有的Queue可以继续使用，但是，通过managers模块把Queue通过网络暴露出去，就可以让其他机器的进程访问Queue了。 我们先看服务进程，服务进程负责启动Queue，把Queue注册到网络上，然后往Queue里面写入任务： 12345678910111213141516171819202122232425262728293031323334353637# task_master.py# encoding: utf-8import random, time, Queuefrom multiprocessing.managers import BaseManager# 发送任务的队列:task_queue = Queue.Queue()# 接收结果的队列:result_queue = Queue.Queue()# 从BaseManager继承的QueueManager:class QueueManager(BaseManager): pass# 把两个Queue都注册到网络上, callable参数关联了Queue对象:QueueManager.register('get_task_queue', callable=lambda: task_queue)QueueManager.register('get_result_queue', callable=lambda: result_queue)# 绑定端口5000, 设置验证码'abc':manager = QueueManager(address=('', 5000), authkey=b'abc')# 启动Queue:manager.start()# 获得通过网络访问的Queue对象:task = manager.get_task_queue()result = manager.get_result_queue()# 放几个任务进去:for i in range(10): n = random.randint(0, 10000) print('Put task %d...' % n) task.put(n)# 从result队列读取结果:print('Try get results...')for i in range(10): r = result.get(timeout=10) print('Result: %s' % r)# 关闭:manager.shutdown()print('master exit.') 当我们在一台机器上写多进程程序时，创建的Queue可以直接拿来用，但是，在分布式多进程环境下，添加任务到Queue不可以直接对原始的task_queue进行操作，那样就绕过了QueueManager的封装，必须通过manager.get_task_queue()获得的Queue接口添加。 然后，在另一台机器上启动任务进程（本机上启动也可以）： 1234567891011121314151617181920212223242526272829303132333435# task_worker.py# encoding: utf-8import time, sys, Queuefrom multiprocessing.managers import BaseManager# 创建类似的QueueManager:class QueueManager(BaseManager): pass# 由于这个QueueManager只从网络上获取Queue，所以注册时只提供名字:QueueManager.register('get_task_queue')QueueManager.register('get_result_queue')# 连接到服务器，也就是运行task_master.py的机器:server_addr = '127.0.0.1'print('Connect to server %s...' % server_addr)# 端口和验证码注意保持与task_master.py设置的完全一致:m = QueueManager(address=(server_addr, 5000), authkey=b'abc')# 从网络连接:m.connect()# 获取Queue的对象:task = m.get_task_queue()result = m.get_result_queue()# 从task队列取任务,并把结果写入result队列:for i in range(10): try: n = task.get(timeout=1) print('run task %d * %d...' % (n, n)) r = '%d * %d = %d' % (n, n, n*n) time.sleep(1) result.put(r) except Queue.Empty: print('task queue is empty.')# 处理结束:print('worker exit.') 任务进程要通过网络连接到服务进程，所以要指定服务进程的IP。 现在，可以试试分布式进程的工作效果了。先启动服务进程： 1234567891011Put task 8529...Put task 1659...Put task 6282...Put task 9171...Put task 2446...Put task 2030...Put task 5593...Put task 2396...Put task 5257...Put task 4728...Try get results... 紧接着执行完服务进程后要尽快执行网络任务进程，因为在分发程序中设置了timeout=10。 123456789101112Connect to server 127.0.0.1...run task 8529 * 8529...run task 1659 * 1659...run task 6282 * 6282...run task 9171 * 9171...run task 2446 * 2446...run task 2030 * 2030...run task 5593 * 5593...run task 2396 * 2396...run task 5257 * 5257...run task 4728 * 4728...worker exit. 同时服务进程打印出： 1234567891011Result: 8529 * 8529 = 72743841Result: 1659 * 1659 = 2752281Result: 6282 * 6282 = 39463524Result: 9171 * 9171 = 84107241Result: 2446 * 2446 = 5982916Result: 2030 * 2030 = 4120900Result: 5593 * 5593 = 31281649Result: 2396 * 2396 = 5740816Result: 5257 * 5257 = 27636049Result: 4728 * 4728 = 22353984master exit. 这个简单的Master/Worker模型有什么用？其实这就是一个简单但真正的分布式计算，把代码稍加改造，启动多个worker，就可以把任务分布到几台甚至几十台机器上，比如把计算n*n的代码换成发送邮件，就实现了邮件队列的异步发送。 Queue对象存储在哪？注意到任务中根本没有创建Queue的代码，所以，Queue对象存储在服务进程中 而Queue之所以能通过网络访问，就是通过QueueManager实现的。由于QueueManager管理的不止一个Queue，所以，要给每个Queue的网络调用接口起个名字，比如get_task_queue 以上代码在linux系统上测试实现，win系统代码需要稍加修改： gylpnj同学的topic]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程线程]]></title>
    <url>%2F2016%2F01%2F11%2Fpy-aboutmulti%2F</url>
    <content type="text"><![CDATA[对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word 就启动了一个 Word 进程。 有些进程还不止同时干一件事，比如 Word，它可以同时进行打字、拼写检查、打印等事情。在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）。 由于每个进程至少要干一件事，所以，一个进程至少有一个线程。当然，像 Word 这种复杂的进程可以有多个线程，多个线程可以同时执行，多线程的执行方式和多进程是一样的，也是由操作系统在多个线程之间快速切换，让每个线程都短暂地交替运行，看起来就像同时执行一样。当然，真正地同时执行多线程需要多核 CPU 才可能实现。 Python 既支持多进程，又支持多线程，我们会讨论如何编写这两种多任务程序 processUnix/Linux 操作系统提供了一个 fork() 系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是 fork() 调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。 调用fork方法之后，子进程永远返回 0 ，而父进程返回子进程的ID。这样做的理由是，一个父进程可以 fork 出很多子进程，所以，父进程要记下每个子进程的 ID，而子进程只需要调用 getppid() 就可以拿到父进程的ID。 1234567import osprint('process (%s) is started...' % os.getpid())pid=os.fork()if pid==0: print('I am child process (%s) and my parent process id (%s)' % (os.getpid(),os.getppid()))else : print('I am the process (%s) and created a child process (%s)' % (os.getpid(),pid)) 上面的代码中，在未创建子进程之前现在主进程中打印输出一段主进程标识。随后通过调用os.fork()方法复制一份完全相同的process，并分别返回在两个进程中，此时两个进程都拿到了返回的pid，不同的是pid根据进程的不同返回的不同，主进程中返回的是子进程的pid，儿子进程获取的pid=0；随后我们就在两个进程中判断输出信息。 子进程中获取本身进程标识符使用os.getpid()，获取父进程pid使用os.getppid() 父进程(相对于子进程而言)获取本身进程标识符调用os.getpid()，而子进程的pid则一定要在fork返回时保存。 multiprocessingmultiprocessing是python提供的跨平台的python进程支持，这使得windows/nt系列系统享受多进程编程。 1234567891011121314151617181920212223import osfrom multiprocessing import Processdef run_proc(name): print('Run child process %s (%s)....' % (name,os.getpid()))if __name__=='__main__': print('Parent process %s is running' % os.getpid()) p=Process(target=run_proc,args=('test',)) print('child process will start') p.start() p.join() print('parent child is running again')#print information in winParent process 2688 is runningchild process will startRun child process test (976)....parent child is running again#print info in linuxMain process (5433) is runningchild process test (5434) is runningMain process is running again 多次实验发现，使用multiprocessing模块之后，win系统下新创建的process标识符与父进程pid相差很多，而linux下两个进程pid相邻。 执行Process(func,args=())之后，此时已经创建了新的子进程，但是依然还没有执行，知道调用start()方法后，开始执行，join方法使暂停主进程任务，子进程执行完成之后，继续执行主进程join()后面代码。用于进程间的同步通信。 如果没有执行join方法，那么两个进程将会分别执行各自任务，此时可能出现混乱的输出 进程池如果要启动大量的子进程，可以用进程池的方式批量创建子进程： 123456789101112131415161718192021222324252627282930313233import osimport time,randomfrom multiprocessing import Pooldef func1(name): print('run (%s) pid ...' % os.getpid()) s=time.time() time.sleep(random.random()*4) e=time.time() print('(%s) pid executed %0.2f' % (os.getpid(),(e-s)))if __name__=='__main__': print('Main process (%s) is running' % os.getpid()) p=Pool() for i in range(1,6): p.apply_async(func1,args=(i,)) print('waitting all child process done') p.close() p.join() print('Done')#输出Main process (8128) is runningwaitting all child process donerun (2412) pid ...run (6756) pid ...run (2560) pid ...run (6948) pid ...(6756) pid executed 0.78run (6756) pid ...(6948) pid executed 2.48(2412) pid executed 3.30(2560) pid executed 3.98(6756) pid executed 3.42Done 上面的代码在测试过程中，刚开始新创建的进程总是无法输出正确的信息，最后发现是打印输出是调用了错误的方法，方法名错误。所以正常情况下，使用进程池执行任务时，如果代码错误，将会跳过此次执行（后来发现似乎是只针对apply_async） 如果此处不使用join方法，而主进程的其他任务已经完全执行结束，将会终止所有进程。调用 join() 之前必须先调用close()，调用close()之后就不能继续添加新的Process了 默认情况下，pool的容积都是有大小的，在Linux下默认的容积是CPU核心的数量，如果创建的进程数量超过了pool容积，则会先执行前面新创建的进程，第一个进程任务结束后创建完成新的进程任务。当然我们可以在创建pool时就修改pool的容积 p=Pool(7) 此时池子的容量就是7 进程间通信Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing 模块包装了底层的机制，提供了 Queue 、 Pipes 等多种方式来交换数据。我们以 Queue 为例，在父进程中创建两个子进程，一个往 Queue 里写数据，一个从 Queue里读数据： 123456789101112131415161718192021222324252627282930313233from multiprocessing import Process, Queueimport os, time, random# 写数据进程执行的代码:def write(q): for value in ['A', 'B', 'C']: print 'Put %s to queue...' % value q.put(value) time.sleep(random.random())# 读数据进程执行的代码:def read(q): while True: value = q.get(True) print 'Get %s from queue.' % valueif __name__=='__main__': # 父进程创建Queue，并传给各个子进程： q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw，写入: pw.start() # 启动子进程pr，读取: pr.start() # 等待pw结束: pw.join() # pr进程里是死循环，无法等待其结束，只能强行终止: pr.terminate()#运行结果如下：Put A to queue...Get A from queue.Put B to queue...Get B from queue.Put C to queue...Get C from queue. multiprocessing模块中的Queue是阻塞式的队列模式，如果无法即时获取到数据，本进程将阻塞 父进程与子进程之间的通信需要用到的multiprocessing模块的Manger类，Queue类无法适用于此处场景 线程Python 的线程是真正的Posix Thread，而不是模拟出来的线程。Python 的标准库提供了两个模块： thread 和threading ， thread 是低级模块， threading是高级模块，对 thread 进行了封装。绝大多数情况下，我们只需要使用 threading 这个高级模块。 启动一个线程就是把一个函数传入并创建 Thread 实例，然后调用 start() 开始执行： 12345678910111213141516171819202122232425262728import time, threading# 新线程执行的代码:def loop(): print 'thread %s is running...' % threading.current_thread().name n = 0 while n &lt; 5: n = n + 1 print 'thread %s &gt;&gt;&gt; %s' %(threading.current_thread().name, n) time.sleep(1) print 'thread %s ended.' % threading.current_thread().nameprint 'thread %s is running...' % threading.current_thread().namet = threading.Thread(target=loop, name='LoopThread')t.start()t.join()print 'thread %s ended.' % threading.current_thread().name#打印thread MainThread is running...thread LoopThread is running...thread LoopThread &gt;&gt;&gt; 1thread LoopThread &gt;&gt;&gt; 2thread LoopThread &gt;&gt;&gt; 3thread LoopThread &gt;&gt;&gt; 4thread LoopThread &gt;&gt;&gt; 5thread LoopThread ended.thread MainThread ended. threadinf.Thread(target,name) 锁多线程和多进程最大的不同在于，多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。 例如两个线程同时修改一个变量var，修改变量var的过程有2步，第一步是把需要修改的内容放到临时变量中，第二步就是赋值。而执行这几条语句时，线程可能中断，从而导致多个线程把同一个对象的内容改乱了。此时就需要把这个过程上锁，拿到锁的线程才能执行。 123456789101112var = 0lock = threading.Lock()def run_thread(n): for i in range(100000): # 先要获取锁: lock.acquire() try: # 放心地改吧: change_it(n) finally: # 改完了一定要释放锁: lock.release() 当多个线程同时执行 lock.acquire() 时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止.获得锁的线程用完后一定要释放锁，否则那些苦苦等待锁的线程将永远等待下去，成为死线程。所以我们用 try…finally 来确保锁一定会被释放. threadlocal各个子线程在使用变量的时候最好使用各自线程的局部变量，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。 但是局部变量也有问题，就是在函数调用的时候，传递起来很麻烦，ThreadLocal 应运而生。 123456789101112131415161718import threading# 创建全局ThreadLocal对象:local_school = threading.local()def process_student(): print 'Hello, %s (in %s)' % (local_school.student,threading.current_thread().name)def process_thread(name): # 绑定ThreadLocal的 student: local_school.student = name process_student()t1 = threading.Thread(target= process_thread, args=('Alice',),name='Thread-A')t2 = threading.Thread(target= process_thread, args=('Bob',),name='Thread-B')t1.start()t2.start()t1.join()t2.join()执行结果：Hello, Alice ( in Thread-A)Hello, Bob ( in Thread-B) 全局变量 local_school 就是一个 ThreadLocal 对象，每个 Thread 对它都可以读写 student属性，但互不影响。你可以把 local_school 看成全局变量，但每个属性如local_school.student 都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题， ThreadLocal 内部会处理。 可以理解为全局变量 local_school 是一个 dict ，不但可以用 local_school.student ，还可以绑定其他变量，如 local_school.teacher 等等。ThreadLocal 最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序列化]]></title>
    <url>%2F2016%2F01%2F10%2Fpickle%2F</url>
    <content type="text"><![CDATA[在程序运行的过程中，所有的变量都是在内存中，比如，定义一个dict： d = dict(name=’Bob’, age=20, score=88)可以随时修改变量，比如把name改成’Bill’，但是一旦程序结束，变量所占用的内存就被操作系统全部回收。如果没有把修改后的’Bill’存储到磁盘上，下次重新运行程序，变量又被初始化为’Bob’。 我们把变量从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling，在其他语言中也被称之为serialization，marshalling，flattening等等，都是一个意思。 序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上。 反过来，把变量内容从序列化的对象重新读到内存里称之为反序列化，即unpickling。 Python提供了pickle模块来实现序列化。 首先，我们尝试把一个对象序列化并写入文件： 123456789&gt;&gt;&gt; import pickle&gt;&gt;&gt; d = dict(name='Bob', age=20, score=88)&gt;&gt;&gt; pickle.dumps(d)b'\x80\x03&#125;q\x00(X\x03\x00\x00\x00ageq\x01K\x14X\x05\x00\x00\x00scoreq\x02KXX\x04\x00\x00\x00nameq\x03X\x03\x00\x00\x00Bobq\x04u.'pickle.dumps()方法把任意对象序列化成一个bytes，然后，就可以把这个bytes写入文件。或者用另一个方法pickle.dump()直接把对象序列化后写入一个file-like Object：&gt;&gt;&gt; f = open('dump.txt', 'wb')&gt;&gt;&gt; pickle.dump(d, f)&gt;&gt;&gt; f.close() 看看写入的dump.txt文件，一堆乱七八糟的内容，这些都是Python保存的对象内部信息。 当我们要把对象从磁盘读到内存时，可以先把内容读到一个bytes，然后用pickle.loads()方法反序列化出对象，也可以直接用pickle.load()方法从一个file-like Object中直接反序列化出对象。我们打开另一个Python命令行来反序列化刚才保存的对象： 12345&gt;&gt;&gt; f = open('dump.txt', 'rb')&gt;&gt;&gt; d = pickle.load(f)&gt;&gt;&gt; f.close()&gt;&gt;&gt; d&#123;'age': 20, 'score': 88, 'name': 'Bob'&#125; Json如果我们要在不同的编程语言之间传递对象，就必须把对象序列化为标准格式，比如XML，但更好的方法是序列化为JSON，因为JSON表示出来就是一个字符串，可以被所有语言读取，也可以方便地存储到磁盘或者通过网络传输。JSON不仅是标准格式，并且比XML更快，而且可以直接在Web页面中读取，非常方便 json的语法规范： 数据在名称/值 &quot;firstName&quot; : &quot;John&quot; 数据由逗号分隔 { &quot;firstName&quot;:&quot;John&quot; , &quot;lastName&quot;:&quot;Doe&quot; } 花括号保存对象 方括号保存数组 12345&#123;"employees": [&#123; "firstName":"John" , "lastName":"Doe" &#125;, &#123; "firstName":"Anna" , "lastName":"Smith" &#125;, &#123; "firstName":"Peter" , "lastName":"Jones" &#125;]&#125; 上面的json语句中，json根结构包含一个数组对象，名为employees，数组包含三个对象，每个对象中有两个数据保存 Python内置的json模块提供了非常完善的Python对象到JSON格式的转换。我们先看看如何把Python对象变成一个JSON： 1234&gt;&gt;&gt; import json&gt;&gt;&gt; d = dict(name='Bob', age=20, score=88)&gt;&gt;&gt; json.dumps(d)'&#123;"age": 20, "score": 88, "name": "Bob"&#125;' dumps()方法返回一个str，内容就是标准的JSON。类似的，dump()方法可以直接把JSON写入一个file-like Object。 要把JSON反序列化为Python对象，用loads()或者对应的load()方法，前者把JSON的字符串反序列化，后者从file-like Object中读取字符串并反序列化： 123&gt;&gt;&gt; json_str = '&#123;"age": 20, "score": 88, "name": "Bob"&#125;'&gt;&gt;&gt; json.loads(json_str)&#123;'age': 20, 'score': 88, 'name': 'Bob'&#125; 实例对象与json的转换常规对象一般都不是可序列化为Json的对象，为了可以让dumps函数知道如何将传入的对象序列化为json，我们需要为对象实例的类专门写一个转换函数，将对象转换成一个dic. 12345678910111213141516import jsonclass Student(object): def __init__(self, name, age, score): self.name = name self.age = age self.score = scoredef obj2dic(self): return &#123; 'name':self.name, 'age':self.age, 'score':self.score &#125;s=Student('James',22,99)print(json.dumps(s,default=obj2dic))#&#123;"age": 22, "name": "James", "score": 100&#125; 当然了，我们的转换函数不是类函数，否则dumps方法就无法访问到了。 实际上我们还有一个更简单的方法，那就是通过类的内置dict方法转换，大多数类都是可以直接使用 print(json.dumps(s,default=lambda obj:obj.__dict__)) 因为我们需要的deafult键值是一个方法，而s.dict实际上就是一个dic对象，所以我们要借助匿名方法lambda 同样的道理，如果我们要把JSON反序列化为一个Student对象实例，loads()方法首先转换出一个dict对象，然后，我们传入的object_hook函数负责把dict转换为Student实例： 12345678def dict2student(d): return Student(d['name'], d['age'], d['score'])#运行结果如下：&gt;&gt;&gt; json_str = '&#123;"age": 20, "score": 88, "name": "Bob"&#125;'&gt;&gt;&gt; print(json.loads(json_str, object_hook=dict2student))&lt;__main__.Student object at 0x10cd3c190&gt; 打印出来的是Student实例]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[error机制]]></title>
    <url>%2F2016%2F01%2F10%2Fpy-raise%2F</url>
    <content type="text"><![CDATA[与许多编程语言相似，python提供了一系列默认的error的机制。我们先看看 try-catch12345678910try: print(10/0) print('shouldn't be called')except ZeroDivisionError as e: print('except at:',e)finally: print('done')except at: division by zerodone 当我们认为某些代码可能会出错时，就可以用try来运行这段代码，如果执行出错，则后续代码不会继续执行，而是直接跳转至错误处理代码，即except语句块，执行完except后，如果有finally语句块，则执行finally语句块。即使没有出现except，依然会执行finally包括的语句 此外，如果没有错误发生，可以在except语句块后面加一个else，当没有错误发生时，会自动执行else语句 使用try…except捕获错误还有一个巨大的好处，就是可以跨越多层调用，比如函数main()调用foo()，foo()调用bar()，结果bar()出错了，这时，只要main()捕获到了，就可以处理 也就是说，不需要在每个可能出错的地方去捕获错误，只要在合适的层次去捕获错误就可以了。这样一来，就大大减少了写try…except…finally的麻烦。 错误记录Python内置的logging模块可以非常容易地记录错误信息，在except调用loggong之后，程序会继续执行下去。 12345678910111213141516import loggingdef foo(s): return 10 / int(s)def bar(s): return foo(s) * 2def main(): try: bar('0') except Exception as e: logging.exception(e)main()print('END') 在这里，虽然在console中记录显示出错误信息，但是依然会继续执行下去，打印输出’END’ raise因为错误是class，捕获一个错误就是捕获到该class的一个实例。因此，错误并不是凭空产生的，而是有意创建并抛出的。Python的内置函数会抛出很多类型的错误，我们自己编写的函数也可以抛出错误。 如果要抛出错误，首先根据需要，可以定义一个错误的class，选择好继承关系，然后，用raise语句抛出一个错误的实例： 12345678910111213141516171819class FooError(ValueError): passdef foo(s): n = int(s) if n==0: raise FooError('invalid value: %s' % s) return 10 / nfoo('0')'''Traceback (most recent call last): File "err_throw.py", line 11, in &lt;module&gt; foo('0') File "err_throw.py", line 8, in foo raise FooError('invalid value: %s' % s)__main__.FooError: invalid value: 0''' 执行，可以最后跟踪到我们自己定义的错误。在程序开发过程中，我们通常还有另外一种处理error的机制，在本层中捕获到error之后向上级抛出 raise语句如果不带参数，就会把当前错误原样抛出。此外，在except中raise一个Error，还可以把一种类型的错误转化成另一种类型： 1234try: 10 / 0except ZeroDivisionError: raise ValueError('input error!') Debugprint直接在需要调试的地方打印输出测试 assert断言代替打印： 1234567def foo(s): n = int(s) assert n != 0, 'n is zero!' return 10 / ndef main(): foo('0') assert的意思是，表达式n != 0应该是True，否则，根据程序运行的逻辑，后面的代码肯定会出错。 如果断言失败，assert语句本身就会抛出AssertionError logging把print()替换为logging是第3种方式，和assert比，logging不会抛出错误，而且可以输出到文件 12345678import logginglogging.basicConfig(level=logging.INFO)s = '0'n = int(s)logging.info('n = %d' % n)print(10 / n) logging.basicConfig(level=logging.INFO)这条语句是设置记录的级别，有debug、info、warn和error四种，根据设置的不同，输出包容的信息级别也就不一样，例如设置level=WARNING后，debug和info就没用了。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-OO]]></title>
    <url>%2F2016%2F01%2F02%2Fpy-class2%2F</url>
    <content type="text"><![CDATA[杂乱的note： 添加函数 1234567891011121314151617181920class Student(object): passdef func(age): # 定义一个函数作为实例方法 print(age)s=Student()s.set_age = func # 给实例绑定一个方法s.set_age(25) # 调用实例方法#25#更进一步，我们可以通过绑定的方法为类添加实例属性def set_age(self, age): # 定义一个函数作为实例方法 self.age = agefrom types import MethodTypes.set_age = MethodType(set_age, s) # 给实例绑定一个方法，方法为本实例对象添加属性。后面的s代表的是set_age(self,age)方法中的第一个参数s.set_age(25) # 调用实例方法s.age # 测试结果#25 为了给所有实例都绑定方法，可以给class绑定方法： 1234567891011def set_scorex(self, score): self.score = scoreStudent.set_score = set_scorex#给class绑定方法后，所有实例均可调用：s.set_score(100)s.score#100s2.set_score(99)s2.score#99 通常情况下，上面的set_score方法可以直接定义在class中，但动态绑定允许我们在程序运行的过程中动态给class加上功能，这在静态语言中很难实现。 如果我们想要限制实例的属性怎么办？比如，只允许对Student实例添加name和age属性 Python允许在定义class的时候，定义一个特殊的slots变量，来限制该class实例能添加的属性： 1234567891011class Student(object): __slots__ = ('name', 'age') # 用tuple定义允许绑定的属性名称s = Student() # 创建新的实例s.name = 'Michael' # 绑定属性'name's.age = 25 # 绑定属性'age's.score = 99 # 绑定属性'score'Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'Student' object has no attribute 'score' 使用slots要注意，slots定义的属性仅对当前类实例起作用，对继承的子类是不起作用的 property装饰器Python内置的@property装饰器就是负责把一个方法变成属性调用。 1234567891011class Student(object): def get_score(self): return self._score def set_score(self, value): if not isinstance(value, int): raise ValueError('score must be an integer!') if value &lt; 0 or value &gt; 100: raise ValueError('score must between 0 ~ 100!') self._score = value 上面的类方法中，在对属性_score进行设置操作时进行了限制检查，规定value必须是数字同时限制范围，否则就抛出Error。 12345678s = Student()s.set_score(60) # ok!s.get_score()#60s.set_score(9999)Traceback (most recent call last): ...ValueError: score must between 0 ~ 100! 上面的调用方法又略显复杂，没有直接用属性这么直接简单，此时就可以祭出@property装饰器 12345678910111213141516171819202122232425class Student(object): #修改原来的getter方法 @property def score(self): return self._score #修改原来的setter方法 @score.setter def score(self, value): if not isinstance(value, int): raise ValueError('score must be an integer!') if value &lt; 0 or value &gt; 100: raise ValueError('score must between 0 ~ 100!') self._score = values = Student()s.score = 60 # OK，实际转化为s.set_score(60)s.score # OK，实际转化为s.get_score()#60s.score = 9999Traceback (most recent call last): ...ValueError: score must between 0 ~ 100! str我们先定义一个Student类，打印一个实例： 12345class Student(object): def __init__(self, name): self.name = nameprint(Student('Michael'))&lt;__main__.Student object at 0x109afb190&gt; 打印出一堆，不好看。 怎么才能打印得好看呢？只需要定义好str()方法，返回一个好看的字符串就可以了： 12345678class Student(object): def __init__(self, name): self.name = name def __str__(self): #注意这里是return而不是print return 'Student object (name: %s)' % self.nameprint(Student('Michael'))Student object (name: Michael) 此时直接敲变量不用print，打印出来的实例还是不好看： 123s = Student('Michael')s&lt;__main__.Student object at 0x109afb310&gt; 这是因为直接显示变量调用的不是str()，而是__repr__()，两者的区别是str()返回用户看到的字符串，而repr()返回程序开发者看到的字符串，也就是说，repr()是为调试服务的。 解决办法是再定义一个repr()。但是通常str()和repr()代码都是一样的，所以，有个偷懒的写法： 123456class Student(object): def __init__(self, name): self.name = name def __str__(self): return 'Student object (name=%s)' % self.name __repr__ = __str__ iter如果一个类想被用于for … in循环，类似list或tuple那样，就必须实现一个iter()方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的next()方法拿到循环的下一个值，直到遇到StopIteration错误时退出循环 12345678910111213141516class Fib(object): def __init__(self): self.a, self.b = 0, 1 # 初始化两个计数器a，b def __iter__(self): return self # 实例本身就是迭代对象，故返回自己 def __next__(self): self.a, self.b = self.b, self.a + self.b # 计算下一个值 if self.a &gt; 100000: # 退出循环的条件 raise StopIteration(); return self.a # 返回下一个值for n in Fib(): print(n) getitem为了实现通过下标访问元素，需要增加getitem（）方法： 1234567def __getitem__(self, item): a,b=1,1 for x in range(item): a,b=b,a+b return aprint(Fib()[3]) 为了为当前类添加切片功能（类似列表序列的list[1,5]），我们需要改写下getitem()方法： 123456789101112131415161718192021def __getitem__(self,n): if isinstance(n,int): a,b=1,1 for x in range(n): a,b=b,a+b return a if isinstance(n,slice): start=n.start end=n.stop if start is None: start=0 a,b=1,1 L=[] for x in range(end): if x&gt;=start: L.append(a) a,b=b,a+b return Lprint(Fib()[3,7])#[3,4,5,6] 通过重写call()方法，通过实例自身的调用，达到()调用的效果 123456789class Student(object): def __init__(self,name): self.name=name def __call__(self): print('My name is %s' % self.name)s=Student('James')s()#My name is James 枚举类Enumpython中的枚举类中，每个我们规定的常量都是唯一实例。 1234567891011121314from enum import EnumWeek=Enum('Week',('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'))#可以直接使用Week.Friday来引用一个常量，或者枚举它的所有成员for name,member in Week.__members__.items(): print(name,'=&gt;',member,'&lt;==&gt;',member.value)Monday =&gt; Week.Monday &lt;==&gt; 1Tuesday =&gt; Week.Tuesday &lt;==&gt; 2Wednesday =&gt; Week.Wednesday &lt;==&gt; 3Thursday =&gt; Week.Thursday &lt;==&gt; 4Friday =&gt; Week.Friday &lt;==&gt; 5Saturday =&gt; Week.Saturday &lt;==&gt; 6Sunday =&gt; Week.Sunday &lt;==&gt; 7 枚举派生类为了更方便的操作枚举类型数据，我们可以定义一个继承自Enum.class的子类 1234567891011from enum import Enum, unique@uniqueclass Weekday(Enum): Sun = 0 # Sun的value被设定为0 Mon = 1 Tue = 2 Wed = 3 Thu = 4 Fri = 5 Sat = 6 上面实例中，导入enmu模块中的Enum和unique后，我们可以使用@unique标记对继承自Enum的子类进行元素唯一性检测，当不同的元素被设置成为相同的value，会报错 可以使用多种访问方法： 123456789101112131415161718192021222324252627282930313233day1 = Weekday.Monprint(day1)Weekday.Monprint(Weekday['Tue'])Weekday.Tueprint(Weekday.Tue.value)2print(day1 == Weekday.Mon)Trueprint(day1 == Weekday.Tue)Falseprint(Weekday(1))Weekday.Monprint(day1 == Weekday(1))TrueWeekday(7)Traceback (most recent call last): ...ValueError: 7 is not a valid Weekday for name, member in Weekday.__members__.items(): print(name, '=&gt;', member) metaclass metaclass 元类：python语言在发展中借鉴了smalltalk的思想，所有东西都是对象，类也是对象。元类就是创建类的模板，也就是说，元类就是创建类的类。正常情况下类都是采用pyhton内建的元类type来创建类这个对象，但是当我们在定义类的过程中，我们可以指定使用的元类创建我们的对象。这个元类继承自type。 123456789#a是一个对象，a.__class__指的是对象所属的类，而这个所属类所属的类呢，就是type&gt;&gt;&gt; a.__class__.__class__&lt;type 'type'&gt;&gt;&gt;&gt; age.__class__.__class__&lt;type 'type'&gt;&gt;&gt;&gt; foo.__class__.__class__&lt;type 'type'&gt;&gt;&gt;&gt; b.__class__.__class__&lt;type 'type'&gt; 通常我们第一一个类，然后实例化类的对象，我们都是希望对象能够按照类模板进行创建，而恰恰元类就是我们在创建类的过程中动态修改类的一个方法。 可以在写一个类的时候为其添加metaclass属性： 12class Foo(object): __metaclass__ = something 如果你这么做了，Python就会用元类来创建类Foo.你首先写下class Foo(object)，但是类对象Foo还没有在内存中创建。Python会在类的定义中寻找metaclass属性，如果找到了，Python就会用它来创建类Foo，如果没有找到，就会用内建的type来创建这个类 12class Foo(Bar): pass Foo中有metaclass这个属性吗？如果是，Python会在内存中通过metaclass创建一个名字为Foo的类对象（我说的是类对象，请紧跟我的思路）。如果Python没有找到metaclass，它会继续在Bar（父类）中寻找metaclass属性，并尝试做和前面同样的操作。如果Python在任何父类中都找不到metaclass，它就会在模块层次中去寻找metaclass，并尝试做同样的操作。如果还是找不到metaclass,Python就会用内置的type来创建这个类对象 我们可以在metaclass中放置些什么代码呢？答案就是：可以创建一个类的东西。那么什么可以用来创建一个类呢？type，或者任何使用到type或者子类化type的东东都可以。 type可以像这样工作 type(类名, 父类的元组（针对继承的情况，可以为空），包含属性的字典（名称和值）) 我们先从一个小例子观测metaclass的功能： 1234567891011121314151617181920def upper_attr(future_class_name,future_parent,future_class_attr): attrs=((name,value) for name,value in future_class_attr.items() if not name.startwith('__')) upperattrs=dict((name.upper(),value)for name,value in attrs) return type(future_class_name,future_parents,upperattrs)__metaclass__ = upper_attr # 这会作用到这个模块中的所有类class Foo(object): # 我们也可以只在这里定义__metaclass__，这样就只会作用于这个类中 bar = 'bip'#测试print hasattr(Foo, 'bar')# 输出: Falseprint hasattr(Foo, 'BAR')# 输出:True f = Foo()print f.BAR# 输出:'bip' 使用一个真正的class当做元类 1class UpperAttrMetaclass(type):&#10; def __new__(cls, name, bases, dct):&#10; attrs = ((name, value) for name, value in dct.items() if not name.startswith(&#39;__&#39;)&#10; uppercase_attr = dict((name.upper(), value) for name, value in attrs)&#10; return type.__new__(cls, name, bases, uppercase_attr)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的str与bytes]]></title>
    <url>%2F2016%2F01%2F02%2Fstr-bytes%2F</url>
    <content type="text"><![CDATA[在Python中，bytes和string是不同的东西。由一系列不可改变的Unicode字符组成的叫string。而一系列不可改变的介于0-255之间的数字被称为bytes对象。 unicode是一种编码标准，具体的实现标准可能是utf-8，utf-16，gbk …… python 在内部使用两个字节来存储一个unicode，使用unicode对象而不是str的好处，就是unicode方便于跨平台。 UnicodeUnicode是计算机可以支持这个星球上的多种语言的秘密武器，在Unicode之前，用的都是ASCII，ASCII吗非常简单，每个英文字符都用7位二进制数的方式存储在计算机内，其范围是32到126.它的实现原理这里也不说了。但是ASCII码只能表示95个可打印的字符，后来把ASCII扩展到了8位，这样就能表示223个字符了，虽然这个来表示欧美字母语言已经足够了，但是对于像中文等语系来说就太少了。于是Unicode码诞生了。 Unicode通过使用一个或者多个字节来表示一个字符，这样就突破了ASCII的限制，这样，Unicode可以表示超过90000个字符了。 Py3python3的str等于python2的unicode，也就是在python3处理时，源码相当于全部都是u’’而且python3的str不提供decode（因为概念上unicode就没有带encoding） Python 3最重要的新特性大概要算是对文本和二进制数据作了更为清晰的区分。文本总是Unicode，由str类型表示，二进制数据则由bytes类型表示。Python 3不会以任意隐式的方式混用str和bytes，正是这使得两者的区分特别清晰。你不能拼接字符串和字节包，也无法在字节包里搜索字符串（反之亦然），也不能将字符串传入参数为字节包的函数（反之亦然）。 常见编码 GB2312编码：适用于汉字处理、汉字通信等系统之间的信息交换 GBK编码：是汉字编码标准之一，是在 GB2312-80 标准基础上的内码扩展规范，使用了双字节编码 ASCII编码：是对英语字符和二进制之间的关系做的统一规定 Unicode编码：这是一种世界上所有字符的编码。当然了它没有规定的存储方式。 UTF-8编码：是 Unicode Transformation Format - 8 bit 的缩写， UTF-8 是 Unicode 的一种实现方式。它是可变长的编码方式，可以使用 1~4 个字节表示一个字符，可根据不同的符号而变化字节长度。 decode与encodePython内部的字符串一般都是 Unicode编码。代码中字符串的默认编码与代码文件本身的编码是一致的。所以要做一些编码转换通常是要以Unicode作为中间编码进行转换的，即先将其他编码的字符串解码（decode）成 Unicode，再从 Unicode编码（encode）成另一种编码。 decode的作用是将其他编码的字符串转换成Unicode编码，name.decode(“GB2312”)，表示将GB2312编码的字符串name转换成Unicode编码`,也就是将将原来name解码成unicode，字面上理解为将其他字符编码成unicode encode的作用是将Unicode编码转换成其他编码的字符串，name.encode(”GB2312“)，表示将GB2312编码的字符串name转换成GB2312编码 所以在进行编码转换的时候必须先知道 name 是那种编码，然后 decode 成 Unicode 编码，最后在 encode 成需要编码的编码。当然了，如果 name 已经就是 Unicode 编码了，那么就不需要进行 decode 进行解码转换了，直接用 encode 就可以编码成你所需要的编码。 Tips：对 Unicode 进行编码和对 str 进行编码都是错误的。 字符串可以编码成字节包，而字节包可以解码成字符串。 1234&gt;&gt;&gt;'€20'.encode('utf-8')b'\xe2\x82\xac20'&gt;&gt;&gt; b'\xe2\x82\xac20'.decode('utf-8')'€20' 简单的win剪切板操作1234567891011def getText(): w.OpenClipboard() d = w.GetClipboardData(win32con.CF_TEXT) w.CloseClipboard() return d.decode('utf-8','ignore')def setText(aString): w.OpenClipboard() w.EmptyClipboard() w.SetClipboardData(win32con.CF_TEXT,aString) w.CloseClipboard() 上面是定义的两个函数，分别是对剪切板进行读、写操作。遗憾的是，由于剪切板中复杂的编码问题，在win平台下很难有效的对非英文字符进行操作。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-OO相关]]></title>
    <url>%2F2016%2F01%2F01%2Fpy-class%2F</url>
    <content type="text"><![CDATA[杂乱的note： 123class Student(object): passbart = Student() class后面紧接着是类名，即Student，类名通常是大写开头的单词，紧接着是(object)，表示该类是从哪个类继承下来的，继承的概念我们后面再讲，通常，如果没有合适的继承类，就使用object类，这是所有类最终都会继承的类。 可以自由地给一个实例变量绑定属性，比如，给实例bart绑定一个name属性： 123bart.name = 'Bart Simpson'bart.name#'Bart Simpson' 由于类可以起到模板的作用，因此，可以在创建实例的时候，把一些我们认为必须绑定的属性强制填写进去。通过定义一个特殊的init方法，在创建实例的时候，就把name，score等属性绑上去： 12345class Student(object): def __init__(self, name, score): self.name = name self.score = score 注意到init方法的第一个参数永远是self，表示创建的实例本身，因此，在init方法内部，就可以把各种属性绑定到self，因为self就指向创建的实例本身。 和静态语言不同，Python允许对实例变量绑定任何数据，也就是说，对于两个实例变量，虽然它们都是同一个类的不同实例，但拥有的变量名称都可能不同： 123456789bart = Student('Bart Simpson', 59)lisa = Student('Lisa Simpson', 87)bart.age = 8bart.age#8lisa.ageTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'Student' object has no attribute 'age' Student类中模板原件是没有age属性的，bar实例动态增加了这个属性，但是lisa实例依然没有age属性，所以获取此属性是报错 类属性，是直接定义在class下面的属性，归类本身管理，类中的所有方法都可以对其进行操作访问 更多关于类属性对象属性关系 在Class内部，可以有属性和方法，而外部代码可以通过直接调用实例变量的方法来操作数据，这样，就隐藏了内部的复杂逻辑。 但是，从前面Student类的定义来看，外部代码还是可以自由地修改一个实例的name、score属性： 123456bart = Student('Bart Simpson', 98)bart.score#98bart.score = 59bart.score#59 如果要让内部属性不被外部访问，可以把属性的名称前加上两个下划线，在Python中，实例的变量名如果以（两个下划线组成）开头，就变成了一个私有变量（private），只有内部可以访问，外部不能访问，所以，我们把Student类改一改： 12345678class Student(object): def __init__(self, name, score): self.__name = name self.__score = score def print_score(self): print('%s: %s' % (self.__name, self.__score)) 改完后，对于外部代码来说，没什么变动，但是已经无法从外部访问实例变量.name和实例变量.score了： 12345bart = Student('Bart Simpson', 98)bart.__nameTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'Student' object has no attribute '__name' 这样就确保了外部代码不能随意修改对象内部的状态，这样通过访问限制的保护，代码更加健壮。 需要注意的是，在Python中，变量名类似xxx的，也就是以双下划线开头，并且以双下划线结尾的，是特殊变量，特殊变量是可以直接访问的，不是private变量，所以，不能用name、score这样的变量名。 有些时候，你会看到以一个下划线开头的实例变量名，比如_name，这样的实例变量外部是可以访问的，但是，按照约定俗成的规定，当你看到这样的变量时，意思就是，“虽然我可以被访问，但是，请把我视为私有变量，不要随意访问”。 双下划线开头的实例变量是不是一定不能从外部访问呢？其实也不是。不能直接访问name是因为Python解释器对外把name变量改成了_Studentname，所以，仍然可以通过_Studentname来访问__name变量： 12bart._Student__name'Bart Simpson' 下面的做法要注意下： 1234567891011bart = Student('Bart Simpson', 98)bart.get_name()'Bart Simpson'bart.__name = 'New Name' # 设置__name变量！bart.__name'New Name''''表面上看，外部代码“成功”地设置了__name变量，但实际上这个__name变量和class内部的__name变量不是一个变量！内部的__name变量已经被Python解释器自动改成了_Student__name，而外部代码给bart新增了一个__name变量'''bart.get_name() # get_name()内部返回self.__name'Bart Simpson' 继承与多态在OOP程序设计中，当我们定义一个class的时候，可以从某个现有的class继承，新的class称为子类（Subclass），而被继承的class称为基类、父类或超类（Base class、Super class）。 比如，我们已经编写了一个名为Animal的class，有一个run()方法可以直接打印： 123class Animal(object): def run(self): print('Animal is running...') 当我们需要编写Dog和Cat类时，就可以直接从Animal类继承： 12345class Dog(Animal): passclass Cat(Animal): pass 对于Dog来说，Animal就是它的父类，对于Animal来说，Dog就是它的子类。Cat和Dog类似。 继承有什么好处？最大的好处是子类获得了父类的全部功能。由于Animial实现了run()方法，因此，Dog和Cat作为它的子类，什么事也没干，就自动拥有了run()方法 判断一个变量是否是某个类型可以用isinstance()判断 123a = list() # a是list类型isinstance(a, list)#True 静态vs动态对于静态语言（例如Java）来说，如果需要传入Animal类型，则传入的对象必须是Animal类型或者它的子类，否则，将无法调用run()方法。 对于Python这样的动态语言来说，则不一定需要传入Animal类型。我们只需要保证传入的对象有一个run()方法就可以了： 123class Timer(object): def run(self): print('Start...') 这就是动态语言的“鸭子类型”，它并不要求严格的继承体系，一个对象只要“看起来像鸭子，走起路来像鸭子”，那它就可以被看做是鸭子。 一些常用的技巧12345#获取对象的所有方法和属性class test: passprint(dir(test()))#['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__'] 配合getattr()、setattr()以及hasattr()，我们可以直接操作一个对象的状态： 1234567891011121314151617181920212223242526272829303132333435363738class MyObject(object): def __init__(self): self.x = 9 def power(self): return self.x * self.xobj = MyObject()hasattr(obj, 'x') # 有属性'x'吗？#Trueobj.x#9hasattr(obj, 'y') # 有属性'y'吗？#Falsesetattr(obj, 'y', 19) # 设置一个属性'y'hasattr(obj, 'y') # 有属性'y'吗？#Truegetattr(obj, 'y') # 获取属性'y'#19obj.y # 获取属性'y'#19#试图获取不存在的属性，会抛出AttributeError的错误#可以传入一个default参数，如果属性不存在，就返回默认值getattr(obj, 'z', 404) # 获取属性'z'，如果不存在，返回默认值404#404#获得对象的方法hasattr(obj, 'power') # 有属性'power'吗？#Truegetattr(obj, 'power') # 获取属性'power'&lt;bound method MyObject.power of &lt;__main__.MyObject object at 0x10077a6a0&gt;&gt;fn = getattr(obj, 'power') # 获取属性'power'并赋值到变量fnfn # fn指向obj.power&lt;bound method MyObject.power of &lt;__main__.MyObject object at 0x10077a6a0&gt;&gt;fn() # 调用fn()与调用obj.power()是一样的#81]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习(二)]]></title>
    <url>%2F2016%2F01%2F01%2Fpython2%2F</url>
    <content type="text"><![CDATA[接着我的上篇文章，Python学习(一)这篇文章，到目前为止，学习到的知识都是和解释器自带的数据结构打交道，程序与外部的交互知识通过input、print函数，这篇文章以及以后的内容会更多在这些方面倾斜。 文件素材open函数用来打开文件，语法如下： 1open(name[,mode[,buffering]]) open函数使用一个文件名作为唯一的强制参数，然后返回一个文件对象。模式mode和缓冲buffering参数都是可选的。下面是open函数中模式参数的常用值: ‘r’—读模式(不提供参数时的默认选择) ‘w’—写模式 ‘w’—写模式 ‘a’—追加模式 ‘b’—二进制模式(可添加到其他模式中使用) ‘+’—读/写模式(可添加到其他模式中使用) ‘+’参数可以应用到其他任何模式中，指明读和写都是允许的，比如’r+’能在打开一个文本文件用来读写时使用 ‘b’模式给变处理文件的方法，普通情况下，Python嘉定处理的是文本文件（包含字符），但是如果处理的是其他类型的文件，比如说是图形、视频文件，就乐意选用此参数 open的第3个参数控制着文件的缓冲。如果参数是0或者是False，IO就是无缓冲的，所有的读写操作都是直接针对硬盘，如果是1或者是True，IO就是有缓冲的。，意味着Python使用暂时使用内存代替硬盘，让程序更快，只有使用flush或者close方法才会将缓冲写入硬盘。如果参数是大于1的数值，代表缓冲区的大小(B)，-1或者任意负数则是使用默认缓冲区大小。 基本文件方法:类文件对象是支持一些文件的方法的对象（有时候也称为流），比如file方法，更重要的是支持read、write方法。 UNIX中的管式输出: 12345678910111213#data.txt内容My name is chuangwailinjie ,and I want to make friends with u.#hello.py内容import systext=sys.stdin.read()words=text.split()wordcount=len(words)print('Wordcount:',wordcount)#在终端中输入$ cat data.txt|python hello.py#运行结果Wordcount:12 cat data.txt ：吧data.txt的内容写到标准输出(sys.stdout) python hello.py ：运行了Python脚本hello.py，脚本从标准输入读，结果写入标准输出 管道符号 ‘|’ :管道符号讲一个命令的标准输出和下一个命令的标准输入连接在一起. 如此，就知道hello.py会从它的sys.stdin中读取数据(从data.txt写入),并把结果写入它的sys.stdout中. 如果想要确保文件对象被关闭，有下面两种方法： 使用try/except/finally块，并且在finally自剧中调用close方法. 使用with语句.with语句可以打开文件并且复制到变量上面，之后就可将数据写入具体中的文件或执行其他操作，文件在语句结束后自动关闭. 1234567891011121314151617181920212223with open('data.txt') as file: file.read()#或者其他文件操作#输出结果#基本的文件使用方法：f=open('data.txt')#这里length是指想要读取的字节数，要注意的是虽然python使用utf-8但是依然无法通过普通的read(n)#正常显示汉字信息f.read(length)#读取整个文件的信息file.read()#readline()函数，逐行获取文件内容#一次性逐行获取内容，并分行将信息储存到序列中file.readlines()file.close()#当文件的打开模式设置为包括写权限(w、+)时，可以进行写操作file=open('data.txt','w')#虽然文件操作没有writeline函数，但是可以通过在字符串中添加换行符达到相同的目的file.write('this is\njust a\ntest')#还有一个常用的写方法file.writelines(#需要写的文本序列)file.close() Python的GUI Python有很多流行的跨平台GUI模块，Tkinter、wxPython、Jython等等。这些模块可以协助我们打造很多精美的用户界面接口。本章主要介绍TKinter的使用，原来比较流行的wxpython最高只支持到python2.x. Tkinter模块(“Tk 接口”)是Python的标准Tk GUI工具包的接口.Python使用Tkinter可以快速的创建GUI应用程序。由于Tkinter是内置到python的安装包中、只要安装好Python之后就能import Tkinter库、而且IDLE也是用Tkinter编写而成、对于简单的图形界面Tkinter还是能应付自如。 创建一个GUI程序1、导入Tkinter模块2、创建控件3、指定这个控件的master， 即这个控件属于哪一个4、告诉GM(geometry manager)有一个控件产生了。 1234import tkintertop = Tk()# 进入消息循环top.mainloop() 两个简单的列表控件 1234567891011121314from tkinter import *list1=['C','C++','Java','Python']list2=['Python','Java','C++','C']root=Tk()listbox=Listbox(root)for item in list1: listbox.insert(0,item)listbox1=Listbox(root)for item in list2: listbox1.insert(0,item)listbox.pack()listbox1.pack()root.mainloop() Tkinter 组件 Tkinter的提供各种控件，如按钮，标签和文本框，一个GUI应用程序中使用。这些控件通常被称为控件或者部件。目前有15种Tkinter的部件。我们提出这些部件以及一个简短的介绍，在下面的表: Python与数据库的支持支持SQL标准的可用数据库有很多，其中多数在Python中都有对应的客户端模块。在提供相同功能的不同模块之间进行切换的问题通常是他们的接口API不同，为了解决Python中各种数据库模块间的兼容问题，现在已经通过了一个标准的DB API。每个数据库模块都支持一下三种全局变量： 123apilevel #所使用的Python DB API版本threadsafety #模块的线程安全等级paramstyle #在SQL查询中使用的参数风格 这里的线程安全性等级是个取值为0~3的整数。0表示线程安全不共享模块，3表示模块是完全线程安全的。1表示线程本身可以共享模块，但不对连接共享。 异常 下面是Python为DB提供的一些标准异常类： 连接 为了使用基础的数九系统，首先必须连接到它。这个时候需要使用具有恰当名称的connect函数，该函数有多个参数，二聚体使用哪个参数取决于数据库。API推荐一下参数作为数据库模块连接函数的参数，并以顺序输入. 12345dsn 数据源名称，给出该参数表示数据库依赖 必选user 用户名 可选password 用户密码 可选host 主机名 可选database 数据库名 可选 当正确连接到数据库之后，在使用connect()函数之后会返回一个句柄，使用此句柄可以进行其他函数操作。其他有关的函数: 1234close() 关闭连接后，连接对象和他的游标均不可用commit() 如果支持的话就提交挂起的事务，否则不做任何事rollback() 回滚挂起的事务cursor() 返回连接的游标对象 SQLite和PySQLite 如果你曾经经历过安卓开发，一定对SQLite这个数据库不陌生。小型的数据库引擎SQlite，不需要作为独立的服务器运行，并且不基于集中式数据库存储机制，而好似直接作用于本地文件，所以上手非常容易。 在Python3.x版本中，SQLite的一个优势在于它的一个包装（PySQLite）已经被包括在标准库内。 SQLite的简单入门12345678910#将SQlite作为名为sqlite3的模块导入import sqlite3#创建一个到数据库文件的连接，如果文件不存在就会被创建conn=sqlite3.connect('firstdb.db')#之后使用conn这个对象可以对数据库进行操作#获取连接的游标，这些游标用来执行SQL查询curs=conn.cursor()#完成查询并且做出某些更改后确保已经进行了提交，这样才能确保修改真正保存在数据库文件conn.commit()conn.close() 数据库应用程序示例建立一个小型营养成分数据库作为示例程序，程序基于USDA的营养数据实验室提供的数据，数据文件点此下载，国外的服务器，所以可能回需要梯子操作。 ABBREV.txt文件中的数据每行都有一个数据记录，字段以脱字符(^)进行分割。数字字段直接包含数字，而文本字段由波浪号（~）括起来的字符串。使用line.split(‘^’)可以很轻松的把这样一行文字解析为多个字段。如果字段以波浪号开始，就是个字符串，使用field.strip(‘~’)获取字段的有效值。 根据ABBREV.txt的数据建表 12345678910111213141516171819202122232425262728293031#通过调用curs.execute执行INSERT语句并将文本字段中的值插入到数据库import sqlite3def convert(value): if value.startswith('~'): return value.strip('~') if not value: value='0' return float(value)conn=sqlite3.connect('food.db')curs=conn.cursor()curs.execute(''' CREATE TABLE food( id TEXT PRIMARY KEY, desc TEXT, water FLOAT, kcal FLOAT, fat FLOAT, ash FLOAT, carbs FLOAT, fiber FLOAT, sugar FLOAT ) ''')query='INSERT INTO food VALUES(?,?,?,?,?,?,?,?,?)'for line in open('ABBREV.txt'): fields=line.split('^') #这里要注意的是，因为提供的数据一行有很多数值，我们需要的只有在表中定义的列数，所以只使用前9列 vals=[convert(f) for f in fields[:9]] curs.execute(query,vals)conn.commit()conn.close() 搜索和展示数据 使用数据库很简单，创建连接并获得该链接的游标，使用execute方法执行SQL查询，用fetchall提取结果。 1234567891011121314151617import sqlite3,sysconn=sqlite3.connect('food.db')curs=conn.cursor()#这里使用sys.argv[1]获取输入的query指令，sys.argv[0]是 #'python hello.py'query='select * from food where %s' % sys.argv[1]curs.execute(query)#curs.description存储的是关于表没列属性的一些信息，序列包裹着元组，子序列的第一个值就是标的属性名称names=[f[0] for f in curs.description]#curs.fetchall()存储的是根据query语句获得的纯数据，形式也是序列包裹着元组，因为属性的数目是确定的，用元组for row in curs.fetchall(): for pair in zip(names,row): print('%s:%s' % pair) print()#在终端中输入如下命令$ python hello.py 'kcal &lt;= 100 AND fiber &gt;=10 order by sugar'#在终端中会有滚屏显示数据 网络编程socket模块在网络编程中的一个基本组件就是套接字，套接字主要是两个程序之间的信息通道。程序通过网络连接分布在不同的计算机上面，通过套接字相互发送信息。在Python中的大多数网络编程都隐藏socket模块的基本细节，套接字包括服务器套接字、客户端套接字： 服务器套接字创建之后，让他等待连接，这样他就在某个网络地址（IP+Port）处监听网络 客户机套接字只是简单的连接，完成事务、断开连接 服务器端套接字使用bind方法后，在调用listen方法去监听这个给定的地址。客户端套接字使用connect方法连接到服 务器坚监听的地址。服务器端可以使用socket.gethostname得到当前主机名 listen方法之后一个参数，即服务器未处理的连接的长度，也就是允许排队等待的连接数目，这些连接在停止接收之前等待接收。 服务器端套接字开始监听后，他就可以接收客户端的连接。这个步骤使用accept方法来完成，方法会阻塞直到客户端的连接，然后该方法返回一个格式为(client,address)的元组，client是客户端的套接字。 套接字有两个方法：send和recv来传输接收数据。 一个简单的客户端、服务器端示例:12345678910111213141516171819#服务器端import sockets=socket.socket()host=socket.gethostname()s.bind((host,1224))s.listen(3)while True: c,addr=s.accept() print('get connect from',addr) #Python3.x以上要求send流为字节化字符串 c.send('Thx your connect'.decode('utf-8')) c.close()#客户端import sockets=socket.socket()host=socket.gethostname()s.connect((host,1224))#加上'.decode('utf-8')是为了将字节字符串正常显示'print(s.recv(1024).decode('utf-8')) urllib模块 这个模块能让通过网络访问文件，通过简单的函数调用，几乎可以吧任何URL所指的东西用作程序的输入。 123456789import urllib.request#获取存储在本机的文本信息localapp=urlopen(r'file:c:\key.txt')data=localapp.read()print(data.decode('utf-8'))#获取网络信息webapp=urlopen('http://www.python.org')data=wepapp.read()print(data.decode('utf-8')) urllib.request模块提供了获取远程文件的方法，我们可以通过调用它实现简单的下载器: 1234567import urllib.request#这里以前面提到的USDA的营养数据实验室提供的数据文件作为示范,由于是国外的数据文件，需要vpn或者能够直连代理&gt;&gt;&gt; urllib.request.urlretrieve('https://www.ars.usda.gov/SP2UserFiles/Place/80400525/Data/SR/SR28/dnload/sr28abbr.zip',r'c:\123.zip')#函数调用之后返回的信息('c:\\123.zip', &lt;http.client.HTTPMessage object at 0x02E0ACD0&gt;)#现在下载的文件就保存在本机电脑的硬盘上 socketserver模块 SocketServer包含了4个基本的类： 针对TCP套接字的TCPServer 针对UDO数据包套接字的UDPServer UnixStreamServer UnixDatagramServer 为了写一个使用SocketServer框架的服务器，大部分代码会在一个请求处理程序中。每当服务器收到一个客户端的连接请求，就会实例化一个请求处理程序，并且处理方法会在处理请求时被调用。具体使用那个方法取决于特定的服务器和使用的处理程序类。 基本的BaseRequestHandler类所有的操作都放在了处理器的一个叫做handle的方法中，当有客户消息进入的时候,方法会被服务器调用。这个方法会访问属性self.request中的客户端套接字，如果使用的是流(例如TCPServer)那么可以使用StreamRequestHandler类，创建两个新属性，self.rfile用于读取，self.wfile用于写入。然会就可以使用这类文件对象和客户机进行通信. socketserver(在Python2.*中的是SocketServer模块)是标准库中一个高级别的模块。用于简化网络客户与服务器的实现（在前面使用socket的过程中，我们先设置了socket的类型，然后依次调用bind(),listen(),accept()，最后使用while循环来让服务器不断的接受请求。而这些步骤可以通过socketserver包来简化。）。模块中，已经实现了一些可供使用的类。 我们将再次实现之前的那个基本TCP的例子。你会注意到新实现与之前有很多相似之处，但你也要注意到，现在很多繁杂的事情已经被封装好了，你不用再去关心那个样板代码了。例子给出的是一个最简单的同步服务器。 为了要隐藏实现的细节。我们现在写程序时会使用类，这是与之前代码的另一个不同。用面向对象的方法可以帮助我们更好的组织数据与逻辑功能。你也会注意到，我们的程序现在是“事件驱动”了。这就意味着，只有在事件出现的时候，程序才有“反应”。 在之前的服务循环中，我们阻塞等待请求，有请求来的时候就处理请求，然后再回去继续等待。现在的服务循环中，就不用在服务器里写代码了，改成定义一个处理器，服务器在收到进来的请求的时候，可以调用你的处理函数。 BaseServer 包含服务器的核心功能与混合(mix-in)类的钩子功能。这个类用于派生，不要直接生成这个类的类对象，可以考虑使用 TCPServer 和UDPServer。 TCPServer/UDPServer 基本的网络同步 TCP/UDP 服务器 UnixStreamServer/UnixDatagramServer 基本的基于文件同步 TCP/UDP 服务器 ForkingMixIn/ThreadingMixIn 实现了核心的进程化或线程化的功能，用于与服务器类进行混合(mix-in)，以提供一些异步特性。不要直接生成这个类的对象 ForkingTCPServer/ForkingUDPServer ForkingMixIn 和 TCPServer/UDPServer 的组合 ThreadingTCPServer/ThreadingUDPServer ThreadingMixIn 和 TCPServer/UDPServer 的组合 BaseRequestHandler 包含处理服务请求的核心功能。只用于派生新的类，不要直接生成这个类的对象，可以考虑使用StreamRequestHandler或DatagramRequestHandler StreamRequestHandler/DatagramRequestHandler TCP/UDP 服务器的请求处理类的一个实现 123456789101112131415161718192021222324252627#使用socketserver重新创建简易服务器from socketserver import TCPServer,StreamRequestHandlerfrom time import ctimeclass Handler(StreamRequestHandler): def handle(self): addr=self.request.getpeername() print('got connect from',self.client_address) self.wfile.write(('[%s] %s' %(ctime(),self.rfile.readline().decode('utf-8'))).encode('utf-8')) server=TCPServer(('',1234),Handler) server.serve_forever()#客户端代码，依然使用socket模块import socketwhile True: client=socket.socket() host=socket.gethostname() client.connect((host,1234)) data=input('--&gt;') if not data: break data=(data+'\r\n').encode('utf-8') client.send(data) data=client.recv(1024).decode('utf-8') if not data: break print(data.strip()) client.close() 多连接 前面提到的服务器解决方案都是同步的：一次只能连接一个客户机并处理它的请求。 有3种方法能够实现多连接模式： 分叉forking 线程thread 异步I/O asynchronous 通过对socketserver服务器使用混入类(mix-in class)，派生进程和线程很容易处理。即使要自己实现它们，这些方法也很容易使用。它们确实有缺点：分叉占据资源，并且如果有太多的客户端时分叉不能很好分叉（尽管如此，对于合理数量的客户端，分叉在现代的UNIX或者Linux系统中是很高效的，如果有一个多CPU系统，那系统效率会更高）；线程处理能导致同步问题。使用socketserver框架创建分叉或者线程服务器非常简单。 分叉是一个UNIX术语，当分叉一个进程(一个运行的程序)时，基本上是复制了它，并且分叉后的两个进程都是从当前的执行点继续运行，并且每 个进程都有自己的内存副本。一个进程成为父进程，另一个进程成为子进程。 当一个使用分叉的服务器中，每一个客户机连接都利用分叉创在一个子进程。父进程继续监听新的连接，同时子进程处理客户端。当客户端的请求结束时，子进程就退出了。分叉的晋城市并行运行的，所以客户端之间不必互相等待。 线程是轻量级的进程或者子进程，所有的线程都存在与相同的进程中，共享内存。资源消耗的下降伴随一个缺陷：因为线程共享内存，所以必须确保他们的变量不会冲突，这些都是同步问题。 Tips:现代操作系统中windows不支持分叉 分叉服务器 12345678910111213141516#windows不支持分叉from socketserver import (TCPServer as TCP, StreamRequestHandler as SRH,ForkingMixIn as FMI) #变动位置 from time import ctime HOST = '' PORT = 1234 ADDR = (HOST, PORT) class Server(FMI, TCP): #变动位置 pass class MyRequestHandler(SRH): def handle(self): print ('已经连接:', self.client_address) self.wfile.write(('[%s] %s' % (ctime(), self.rfile.readline().decode("UTF-8"))).encode("UTF-8")) tcpServ = Server(ADDR, MyRequestHandler) #变动位置 print ('等待新的连接。。。。') tcpServ.serve_forever() 多线程SocketServer服务器 12345678910111213141516171819202122from socketserver import (TCPServer as TCP, StreamRequestHandler as SRH,ThreadingMixIn as TMI) #变动位置 from time import ctime HOST = '' PORT = 1234 ADDR = (HOST, PORT) class Server(TMI, TCP): #变动位置 pass class MyRequestHandler(SRH): def handle(self): print ('已经连接:', self.client_address) data=self.request.recv(1024).strip().decode('utf-8') self.wfile.write(('[%s] %s' % (ctime(), data)).encode("UTF-8")) tcpServ = Server(ADDR, MyRequestHandler) #变动位置 print ('等待新的连接。。。。') tcpServ.serve_forever() #对应的客户端代码import sockets=socket.socket()host=socket.gethostname()s.connect((host,1234))s.send('I am connecting successful!'.encode('utf-8'))print(s.recv(1024).decode('utf-8')) 带有select和poll的异步I/O 当一个服务器与一个客户端通信时，来自客户端的数据可能是不连续的。如果使用分叉或者线程处理，这些没有问题。因为当一个程序在等待数据，另一个并行的程序可以继续处理他们自己的客户端。另外的方法就是只处理在给定时间内真正要进行通信的客户端，不需要一直监听，然后把它方法其他客户端的后面。 这就是asyncore/asynchat框架和Twisted框架采用的方法，这种功能的基础是select/poll函数。（poll函数只能在unix系统中使用，poll函数的伸缩性相对性要好） select函数需要3个序列作为必选参数，此外还有一个以秒为单位的超时时间作为可选。这些参数都是文件描述符整数，或者是带有返回这样整数的fileno方法的对象。这些就是我们等待的连接。3个序列分别用于输入、输出以及异常情况。如果没有给定超时时间，则默认为阻塞方式，如果超时时间为0，就是一个连续的poll，不阻塞。select的返回值是3个序列，每个代表相应参数的活动子集。 下面的示例代码展示了一个使用select的为很多连接服务的服务器。服务器套接字本身被提供给select，这样select就能在准备接受一个新的连接时发出通知。服务器是一个简单的记录器，输出来自客户机的所有数据。 12345678910111213141516171819202122232425262728import socket,selects=socket.socket()host=socket.gethostname()port=1234s.bind((host,port))s.listen(5)inputs=[s]while True: #返回相应参数的活动子集 rs,ws,es=select.select(inputs,[],[]) for r in rs: if r is s: #如果是刚join的客户机，就将创建的socket加入到inputs参数 c,addr=s.accept() print('Got connection from',addr) inputs.append(c) else: try: data=r.recv(1024) disconnected=not data except socket.error: disconnected=True if disconnected: print(r.getpeername(),'disconnected') inputs.remove(r) else: print(data.decode('utf-8'))#客户端的代码参考上面 可以看出来，通过一个While True跟一个for循环，逐次的处理客户机的事件。通过测试代码可以打印出来rs中的信息: 123456[&lt;socket.socket fd=296, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('192.168.252.1', 1234)&gt;]Got connection from ('192.168.252.1', 4451)[&lt;socket.socket fd=364, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('192.168.252.1', 1234), raddr=('192.168.252.1', 4451)&gt;]I am connecting successful! inputs中保存的是服务器的依次socket、以及服务器与客户机连接创建的socket信息。 而通过select函数返回的则是一一对应的关于socket的信息。如果for循环的是服务器socket，则处理它的客户机加入事件，否则则处理客户机的桥梁socket的会话消息 poll方法的使用poll方法使用起来币select方法较简单。在调用poll时候=，会得到一个poll对象，然后可以使用poll对象的register方法注册一个文件描述符（或者带有fileno方法的对象）。注册后可以使用register方法注册一个文件描述符。poll方法有一个可选的超时时间参数，并得到一个（fd，event）格式列表。其中fd是文件描述符，event则告诉你发生了什么，event是一个位掩符码(bitmask),就是一个整数，整数的每一位都会对应不同的事件，可以使用按位与&amp;操作符进行检测某件事件是否发生。 pollin 读取来自文件描述符的数据pollpri 读取来自文件描述符的紧急数据pollout 文件描述符已经准备好数据，写入时候不会发生阻塞pollerr 与文件描述符有关的错误情况pollhup 挂起，链接丢失 pollnyal 无效请求，链接没有打开 123456789101112131415161718192021222324252627282930313233343536#使用poll方法重写select方法实现的serversocket#在Windows系统下面不适用import socket,selects=socket.socket()host=socket.gethostname()port=1234#socket.bind方法的参数是一个元组s.bind((host,port))#fd是一个字典映射，键和值分别是文件描述符(ints)和套接字的映射fdmap=&#123;s.fileno():s&#125;#表示监听数目最多为5个s.listen(5)#poll方法实现的原理还是select模块，不过相比select更加灵活。不需要一直监听，只需要监听一会，然后将此服务器信息放在消息队列的末尾，等待再次处理#p是select模块的poll对象p=select.poll()#通过p.register方法将套接字对象添加到监听的套接字列表p.register(s)while True: #将文件描述符以及事件返回 events=p.poll() for fd,event in events: if fd in fdmap: #如果是服务器套接字的文件描述符，则获取与服务器连接的主机信息 c,addr=s.accept() print("Got connection from",addr) #将新加入的套接字添加到监听列表 p.register(c) elif event &amp; select.POLLIN: #如果是其他主机通过其他套接字发送的数据，信息获取 data=fdmap[fd].recv(1024) if not data: print(fdmap[fd].getpeername(),disconnction) p.unregister(fd) del fdmap[fd] else: print(data) 编写Twisted服务器 前面编写的基本套接字服务器都是显式的，其中有一些很清楚的事件循环，用来查找新的连接和新数据，但是基于socketserver的服务器有一个隐式的循环，在循环中服务器查找连接并为每个连接创建一个处理程序，但处理程序在读取数据时必须是显式的。Twited以及asyncore/asynchat框架使用一个甚至多个基于事件的方法。要编写基本的服务器，就要就要实现处理比如新客户端连接、新数据到达以及一个客户端断开连接等事件的时间处理程序。具体的类能通过基本类简历更精炼的事件，比如包装”数据到达“事件、收集数据直到新的一行，然后触发”一行数据到达“事件。 事件处理程序在一个协议protocol中定义，在一个新的连接到达时，同样需要一个创建这种协议对象的工厂，但如果只是想要创建一个通用的协议类实例，那么可以使用Twited自带的工厂。factory类在twisted.internet.protocol模块中。当编写自己的协议时候，要使用和超类一样的模块中的protocol。得到了一个连接后，事件处理程序connectionMade就会被调用；丢失了一个连接后，connetctionLost会被调用。来自客户端的数据是通过处理程序dataReceived接收的。不能把事件处理策略把数据发回到客户端，如果要实现此功能，可以使用对象self.transport，这个对象有一个write方法，也有一个包含客户机地址（hostname+port）的client属性。 这里只设计一点设置，必须实例化factory，还要设置它的protocol属性，这样它在和客户机通信时就知道是用什么协议（自定义协议）。然后就开始在给定的端口处使用工厂监听，这个工厂要通过实例化协议对象来准备处理连接。程序使用的是reactor中的listenTCP函数来监听，最后通过调用同一个模块中的run函数启动服务器。 1234567891011121314151617#Tips: Twisted并非是python提供的标准模块，所以需要在第三方网站中下载，目前支持的最高版本为python2.7#作为监听实例对象from twisted.internet import reactorfrom twisted.internet.protocol import Protocol，Factoryclass SimpleLogger(Protocol): def connectionMade(self): print('GOt connection from',self.transport.client) def connectionLost(self,reason): print(self.transport.client,'disconnected') def dataReceived(self,data): print(data)factory=Factory()factory.protocol=SimpleLogger#监听函数reactor.listenTCP(1234,factory)#Twisted主服务器循环reaction.run() Python与万维网 屏幕抓取技术 屏幕抓取是程序下载网页并提取信息的过程。如果涉及的网页时动态变化的，那么这项技术将更加有用，正常的情况下，使用urllib和re就可以很方便的测试这项技术。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112from urllib.request import urlopenimport rep=re.compile('&lt;a href="(.*)" title=".*"&gt;(.*)&lt;/a&gt;');text=urlopen('https://www.python.org/community/jobs/').read().decode('utf-8');for url,name in p.findall(text): print('%s (%s)' % (name,url))#输出Skip to content (#content)Sign In (/accounts/login/)About (/about/)Applications (/about/apps/)Quotes (/about/quotes/)Getting Started (/about/gettingstarted/)Help (/about/help/)Downloads (/downloads/)All releases (/downloads/)Source code (/downloads/source/)Windows (/downloads/windows/)Mac OS X (/downloads/mac-osx/)Other Platforms (/download/other/)License (https://docs.python.org/3/license.html)Alternative Implementations (/download/alternatives)Documentation (/doc/)Docs (/doc/)Audio/Visual Talks (/doc/av)Beginner&amp;#39;s Guide (https://wiki.python.org/moin/BeginnersGuide)Developer&amp;#39;s Guide (https://docs.python.org/devguide/)FAQ (https://docs.python.org/faq/)Non-English Docs (http://wiki.python.org/moin/Languages)PEP Index (http://python.org/dev/peps/)Python Books (https://wiki.python.org/moin/PythonBooks)Community (/community/)Diversity (/community/diversity/)IRC (/community/irc/)Mailing Lists (/community/lists/)Python Conferences (/community/workshops/)Special Interest Groups (/community/sigs/)Python Wiki (https://wiki.python.org/moin/)Python Logo (/community/logos/)Merchandise (/community/merchandise/)Community Awards (/community/awards)Success Stories (/about/success/)Arts (/about/success/#arts)Business (/about/success/#business)Education (/about/success/#education)Engineering (/about/success/#engineering)Government (/about/success/#government)Scientific (/about/success/#scientific)Software Development (/about/success/#software-development)News (/blogs/)Python News (/blogs/)Community News (http://planetpython.org/)PSF News (http://pyfound.blogspot.com/)PyCon News (http://pycon.blogspot.com/)Events (/events/)Python Events (/events/python-events/)User Group Events (/events/python-user-group/)Python Events Archive (/events/python-events/past/)User Group Events Archive (/events/python-user-group/past/)Submit an Event (https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event)Applications (/about/apps/)Quotes (/about/quotes/)Getting Started (/about/gettingstarted/)Help (/about/help/)All releases (/downloads/)Source code (/downloads/source/)Windows (/downloads/windows/)Mac OS X (/downloads/mac-osx/)Other Platforms (/download/other/)License (https://docs.python.org/3/license.html)Alternative Implementations (/download/alternatives)Docs (/doc/)Audio/Visual Talks (/doc/av)Beginner&amp;#39;s Guide (https://wiki.python.org/moin/BeginnersGuide)Developer&amp;#39;s Guide (https://docs.python.org/devguide/)FAQ (https://docs.python.org/faq/)Non-English Docs (http://wiki.python.org/moin/Languages)PEP Index (http://python.org/dev/peps/)Python Books (https://wiki.python.org/moin/PythonBooks)Diversity (/community/diversity/)IRC (/community/irc/)Mailing Lists (/community/lists/)Python Conferences (/community/workshops/)Special Interest Groups (/community/sigs/)Python Wiki (https://wiki.python.org/moin/)Python Logo (/community/logos/)Merchandise (/community/merchandise/)Community Awards (/community/awards)Success Stories (/about/success/)Arts (/about/success/#arts)Business (/about/success/#business)Education (/about/success/#education)Engineering (/about/success/#engineering)Government (/about/success/#government)Scientific (/about/success/#scientific)Software Development (/about/success/#software-development)News (/blogs/)Python News (/blogs/)Community News (http://planetpython.org/)PSF News (http://pyfound.blogspot.com/)PyCon News (http://pycon.blogspot.com/)Python Events (/events/python-events/)User Group Events (/events/python-user-group/)Python Events Archive (/events/python-events/past/)User Group Events Archive (/events/python-user-group/past/)Submit an Event (https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event)Developer&amp;#39;s Guide (http://docs.python.org/devguide/)Issue Tracker (http://bugs.python.org/)python-dev list (https://mail.python.org/mailman/listinfo/python-dev)Core Mentorship (http://pythonmentors.com/) 这段代码并不是完全可读的，对于更复杂的HTML代码和查询来说，表达式会变得乱七八糟并且不可维护。 程序对于CDATA部分和字符实体&amp;之类的HTML特性是无法处理的，如果碰到了这类特性，程序很有可能会失败。 正则表达式被HTML源代码约束，而不是取决于更抽象的结构，这就意味着网页结构中很小的改变就会导致程序中断。 Tidy和XHTML解析 Python标准库中有很多支持结构化格式的库，例如HTML和XML。XHTML是HTML最新的方言，是XML的一种形式。对于包含正确而且有效的XHTML的网页方言，解析的工作一定相当加单，问题在于很多人在使用HTML的时候并不标准，而很多浏览器对于这些语法问题都相当的宽容，并且会尽最大努力渲染最混乱且无意义的HTML。 标准库中解析HTML的一般方法是基于事件的，所以需要编写像解析器一样顺序处理数据的时间处理程序。标准库模块sgmllib和htmllib可以用这种方式解析非常混乱的HTML，但是如果希望提取基于文档结构的数据（例如在第二个二级标题下的第一个项目），那么在确实标签的情况下可能会比较复杂。这里介绍另外一种办法：Tidy Tidy是用来修复不规范而且随意的HTML的工具，能够以相当智能的方法修复一般错误。Tidy当然不可能修复HTMl文件中的苏有问题，但是它能够至少保证所有被修复过的HTML文件语法正确，保证正确的嵌套结构。这样修复之后再处理解析，工作量就会大大降低。 最新发布的Tidy版本一般都放在github的repository上面，可以自行搜索获取安装，同时要下载一个Tidy的Python包装，例如uTidyLib、mxTidy。需要注意的是mxTidy也是只支持到python2.x版本。下面通过Tidy的subprocess模块或者其他包含popen函数的模块运行Tidy程序： 1234567from subprocess import Popen. PIPEtext=open('messy.html').read()tidy=Popen('tidy',stdin=PIPE,stdout=PIPE,stderr=PIPE)tidy.stdin.write(text)tidy.stdin.close()#由于只能在python2.x版本中使用Tidy，所以这里是用的python语法也是2.x时代print tidy.stdout.read() 之后我们可以将通过Tidy解析过得html内容或者其他标准XHTML、HTML内容使用HTMLParser模块（需要注意的是，这里并不是htmllib中的HTMLParser类）。使用HTMLParser的意思就是继承他，并且对handle_starttage或handle_data等事件处理方法进行覆盖。 如果只是需要正常的屏幕截取，一般不需要实现所有的解析器（事件处理程序）回调，也可能不用创造整个文档抽象表示法来查找自己需要的内容。 12345678910111213141516171819202122232425262728from urllib import urlopenfrom HTMLParser import HTMLParserclass Scraper(HTMLParser): in_li=False in_link=False def handle_starttag(self,tag,attrs): attrs = dict(attrs) if tag== 'li': self.in_li=True if tag=='a' and 'href' in attrs: self.in_link=True self.chunks=[] self.url=attrs['href'] def handle_data(self,data): if self.in_link: self.chunks.append(data) def handle_endtag(self,tag): if tag=='li': self.in_li=False if tag=='a': if self.in_li and self.in_link: print '%s ,(%s)' % (''.join(self.chunks),self.url) self.in_link=Falsetext=urlopen('https://python.org/community/jobs').read().decode('utf-8')parser=Scraper()parser.feed(text)parser.close() 现在介绍另外一种较轻量级的抓取模块Beautuful Soup Beaytiful Soup是个小模块，用来解析和检查经常在网上看到的那类乱七八糟而且极为不规范的HTML，下载完成后将BeautifulSoup.py文件放置在python安装目录中专门存放第三方模块的site-packages文件夹中。捉着直接使用pip命令安装第三方库，pip等工具的安装可以浏览这里。放置完成后，我们开始进行一个简单的测试： 123456789101112131415161718192021222324from bs4 import BeautifulSoup #process htmlhtml_doc = """&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;&lt;p class="story"&gt;&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Elsie&lt;/a&gt;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class="story"&gt;...&lt;/p&gt;"""soup = BeautifulSoup(html_doc)print(soup.find_all('title'))print(soup.find_all('p','title'))print(soup.find_all('a'))print(soup.find_all(id="link2"))print(soup.find_all(id=True))#输出结果&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class="title"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;&lt;p class="story"&gt;&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class="story"&gt;...&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 如上面的代码，可以看出来，本来的原始信息是不正规的，不符合Html语法，但是经过BeautifulSoup函数处理之后输出返回，是格式化的正确修饰信息。当然，BeautifulSoup的强大之处在于对于网页各部分元素、属性的查找。在我另外一篇文章中这方面设计的比较多。戳这里 使用CGI创建动态网页前面讲的都是客户端技术，现在来开始看服务器端。CGI（Common Gateway Interface,通用网页接口）。CGI是网络服务器可以将查询（一般来说是通过Web表单）传递到专门的程序（比如Python等）中并且在网页上显示结果的标准机制。它是创建万维网应用程序而不用编写特殊用途的应用服务器的简单方法。 Python CGI程序设计的关键工具是cgi、cgitb模块。 CGI程序应该放在通过网络可以访问的目录中，并且将他们标识为CGI脚本，这样网络服务器就不会将普通源代码作为网页处理。 将脚本放在叫做cgi-bin的子目录中. 将脚本文件的扩展名改为.cgi. 当把脚本放在正确位置之后，需要在脚本的开始处增加pound bang行。这一步是至关重要的，如果没要这行标识，网络服务器就不知道如何执行脚本。脚本可以用其他语言来写，比如Perl、Ruby。一般来讲，只要加上这句 1#!/usr/bin/env python 这一这行文字是以UNIX风格填写的，前面无空行、结尾以’\n’而非’\r\n’.在Windows中，可以使用Python二进制版本的全路径： 1#!C:\Python34\python.exe 要做的最后一件事情就是这只合适的文件许可。确保每个人都可以读取和执行脚本文件，同时要确保这个文件只能由你写入。（就是在Linux中修改文件的权限）修改文件许可的Linux命令式chmod，只要运行下列命令 chmod 755 somescript.cgi 即将文件权限设置为只能由本用户全部操作，而用户组以及其他用户只享有r、w权限，无x执行权限。在做好这些准备之后，应该能够将脚本作为网页打开、执行。 下面开始进行一些简单的CGI脚本演示： 123456#!usr/bin/env pythonprint('Content-type: text/plain')print()#打印空行以结束首部print('Hello,world!') 将我们需要放置的服务器配置完成后（/2016/01/25/python_cgi/）,就可以通过正确的URL访问我们的CGI程序。 使用cgitb调试 有时候编程的错误会让程序因为没有捕捉到异常而已堆栈跟踪终止。当通过CGI运行程序时，这种情况很有可能会得到由服务器返回的无帮助错误信息。cgitb，适用于CGI回溯的模块，导入它并且调用enable函数，就能够包含出错信息的有用的网页。 12345678#!C:\Python34\python.exeimport cgitb; cgitb.enable()print('Content-type: text/html')print()#打印空行以结束首部print(1/0)print('Hello Python!') 将源代码文件保存在htdocs根目录或其他可访问目录下，访问执行。生成如下信息： 1234567891011121314ZeroDivisionError Python 3.4.3: C:\Python34\python.exeTue Jan 26 00:38:18 2016A problem occurred in a Python script. Here is the sequence of function calls leading up to the error, in the order they occurred. D:\xampp\htdocs\test.py in () 4 print('Content-type: text/html') 5 print()#打印空行以结束首部 6 =&gt; 7 print(1/0) 8 print('Hello Python!')builtin print = &lt;built-in function print&gt;ZeroDivisionError: division by zero args = ('division by zero',) with_traceback = &lt;built-in method with_traceback of ZeroDivisionError object&gt; 使用CGI模块 到目前为止，程序只能产生输出，而不接受任何形式的输入。输入是通过HTML表单提供给CGI脚本的键值对，可以使用cgi模块的FiledStorage类从CGI脚本中获取这些字段。 当创建FieldStorage实例时，他会从请求中获取输入变量，然后通过字典接口将他们提供给程序。FieldStorage的值可以通过普通的键查找方式访问。例如想要知道名为’name’的值，可以这样 123456form = cgi.FieldStorage()name = form['name'].value#或者如下操作form = cgi.FieldStorage()name = form.getvalue('name','Unkonwn')#这里提供了一个默认值'Unkonwn'，如果不提供的话，就会将None作为默认值提供 下面是一个上面示例的扩展版本，在同一个页面内添加一个form表单，尝试改变属性名’name’的值，然后提交，表单的action是页面文件本身。当没有提交的时候，页面显示程序提供的默认值。 1234567891011121314151617181920212223#!C:\Python34\python.exeimport cgiform = cgi.FieldStorage()name = form.getvalue('name','Python')print('Content-type: text/html')print()#打印空行以结束首部print(''' &lt;html&gt; &lt;head&gt; &lt;title&gt;Greeting Page&lt;/title&gt; &lt;head&gt; &lt;body&gt; &lt;h1&gt;Hello,%s!&lt;/h1&gt; &lt;form action="test.py"&gt; Change name&lt;input type="text" name="name"/&gt; &lt;input type="submit"/&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; ''' %name) Mod_Python mod_python是apache组织的一个项目，通过它，可以开发psp或cgi，mod_python功能强大，速度快，是非常优秀的web开发工具。mod_python的一个最主要优点就是在性能上超越传统CGI。 Apache分阶段的处理请求(比方说：读取请求,解析header, 检查存取路径,等等)。这些阶段能被称为”处理器”(handler)的函数实现。传统上, “处理器”是由C语言编写，并编译成Apache的模块。Mod_python提供了一个通过Python写的Apache处理器的来扩展Apache功能的方法。关于Apache请求处理过程的详尽描述，请参阅 Apache API Notes, 也可以参阅 Mod_python - Integrating Python with Apache。为了轻松地从CGI移植，一个标准的mod_python处理器提供了模拟的CGI环境，允许用户在不对代码做任何修改的情况下，使遗留的脚本运行在mod_python下(大多数情况)。 mod_python可以让Python解释器直接成为Apache的一部分，这样一来就可以在程序中应用很多很酷的东西。它提供了Python中编写Apache处理程序的功能，使用mod_python处理程序框架可以访问丰富的API，深入Apache内核。 CGI处理程序，允许使用mod_python解释器运行CGI脚本，执行速度会有相当大的提高。 PSP处理程序，允许用HTML以及Python代码混合编程创建可执行网页（executable web page）或者Python服务器页面（Python Server Page）。 发布处理程序（Publisher Handler），允许使用URL调用Python函数。 更多的信息，我就不在这里叙述了。想要了解的可以自行在网络上获取。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[致杂乱]]></title>
    <url>%2F2015%2F12%2F25%2F%E8%87%B4%E6%9D%82%E4%B9%B1%2F</url>
    <content type="text"><![CDATA[脑中的丝絮缠绕整个身体，将我包裹，跳出这个怪圈。 晚饭，人来人往。冬夜星空中挂上了微风。有风的时候，适合沉默。 风将城市的声音吹过，烧饼油条、斑马线、铁线、肥皂和公车，促膝凌乱。 经过了漫长的等候，梦想是梦想，我还是一个我。 那时间忘记挽留，最美时候，不经意匆匆的放过。 手笔写写断断，键盘起起落落，时钟停停走走，再吃一颗苹果。 如果说最后：宜静不是嫁给了大雄。一生相信的执着：一秒就崩落 一如再现的仪式感，半梭流水的望君安 虚荣虚伪的灵魂，可笑可叹的面具。 这里是奇妙的五月夏夜，我听到了心跳声。你要去哪里 熙熙攘攘人群偶然偶遇，熙熙攘攘人群错觉错过。 #一又三分之二刻]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式简单应用]]></title>
    <url>%2F2015%2F12%2F24%2Fre%2F</url>
    <content type="text"><![CDATA[re即regular expression，正则表达式，关于正则表达式的通用知识可以浏览我的csdn blog。通过正则表达式，我们可以很轻松的过滤获取到需要的信息，然后对这些信息进行操作。 通过re表达式实现简单的邮件人过滤: 寻找这封信的发件人: 12345678910111213#hello.pyimport re,fileinput#为了直接在结果中显示发件人，所以在模式中将所需信息用圆括号扩住，这样就可以通过组方便的取出pat=re.compile('From: (.*)&lt;.*?&gt;$')for line in fileinput.input(): m=pat.match(line) if m: print(m.group(1))#结果python hello.py data.txtFoo Fie 寻找这封信中所有的邮箱地址，并列出来 123456789101112131415161718192021import re,fileinput#忽略大小写pat=re.compile(r'[a-z\-\.]+@[a-z\-\.]+',re.IGNORECASE)#创建集合addresses=set()for line in fileinput.input(): for address in pat.findall(line): addresses.add(address) for address in sorted(addresses): print(address)#进行测试python hello.py data.txtMr.Gumby@bar.bazfoo@bar.bazfoo.baz.commagnus@bozz.floop 下面是一个简单但是经典模板匹配: 1234567891011121314151617181920212223242526272829303132333435363738394041import fileinput,re#要匹配的是一个方括号括起来的表达式，在模式中用括号圈出来组1field_pat = re.compile(r'\[(.+?)\]')#将变量收集到这里scope=dict()#应用在re.sub替换def replacement(match): #获取表达式 code = match.group(1) try: return str(eval(code,scope)) except SyntaxError: #否则执行相同作用域内的赋值语句 exec(code,scope) return ''#将需要替换的文本以一个字符串的形式获取lines=''for line in fileinput.input(r'.\data.txt'): lines+=line#将序列转换成为字符串#text=''.join(lines)#将field模式的所有匹配项都替换print(field_pat.sub(replacement,lines))如果要替换的文本是如下[x=2][y=3]The sum of [x] and [y] is [x+y].运行的结果是:The sum of 2 and 3 is 5. 这里要注意的是，data.txt文件的格式要为utf-8无BOM格式或者ansi编码，Python默认的编码格式为utf-8，否则会无法解析 在扩展，由于Python中fileinput模块的强大性，我们可以一次性输入多个文件进行解析，而且解析的顺序跟我们输入的文件参数顺序一致。这样我们就可以很轻松的吧文章的模板与我们需要替换的内容分离，分别写入两个文件，让python先解析变量定义文件，这样就可以达到同样的目的，而且更符合我们的使用习惯。 123456789101112131415161718192021222324252627282930313233343536#python源码是没有改变的，只是把for line in fileinput.input(r'.\data.txt'):#这条语句改为 for line in fileinput.input():#改为我们在运行解释的时候手动输入文件名#变量定义文件 define.txt[name='chuangwailinjie'][email='peihaozhu@xyz.com'][language='python']#模板定义文件template.txt[import time]Dear [name]I would like to learn how to program. I hear you use the [language] language a lot--is it sth I should consider?And,by the way, is [email] your correct email address/chuangwailinjie,[time.asctime()]#在终端中输入命令:$ python hello.py define.txt template.txtDear chuangwailinjieI would like to learn how to program. I hear you use the python language a lot--is it sth I should consider?And,by the way, is peihaozhu@xyz.com your correct email address/chuangwailinjie,Thu Dec 24 16:49:26 2015]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科学上网]]></title>
    <url>%2F2015%2F12%2F23%2Fshadowsocks%2F</url>
    <content type="text"><![CDATA[shadowsocks Shadowsocks（中文名称：影梭）是一个安全的socks5代理，用于保护网络流量，是一个开源项目。通过客户端以指定的密码、加密方式和端口连接服务器，成功连接到服务器后，客户端在用户的电脑上构建一个本地socks5代理。使用时将流量分到本地socks5代理，客户端将自动加密并转发流量到服务器，服务器以同样的加密方式将流量回传给客户端，以此实现代理上网。 使用ss可以达到正常的科学上网，但是有些特殊情况下，比如gfw导致的DNS污染（wiki中文），或者是普遍的非浏览器客户端需要使用境外信息，你依然无法正常获取。这里就介绍使用Proxifier设置ss全局代理。 首先是shadowsocks的使用 STEP1下载SHADOWSOCKS软件: 网盘点击此处下载 或者githubss网站浏览下载 STEP2解压到任意目录，运行其中的SHADOWSOCKS.EXE STEP3首次运行，会弹出编辑服务器窗口，按图示填写您的SHADOWSOCKS服务器地址，端口，密码和加密方式，点确定 这里我提供一些免费的ss账号共享 http://yomoe.net/在这里注册账号，即可无流量限制获取ss账号，还能够通过ss提供的扫码功能直接获取服务 http://www.ishadowsocks.com/直接提供服务器账号密码使用，但是会隔6小时更换密码 如果以上的几种获取方式失效，请联系笔者获取。 STEP4按提示右键程序图标，弹出菜单，勾选“启用系统代理” 好了，大功告成，打开任意浏览器上网吧，就是这么简单，就是这么任性 设置好以后，IE/Chrome/Firefox无需设置，直接打开网址即可 Tips:PAC和全局模式是什么意思？PAC模式访问国内网站不通过服务器，全局模式所有网站都通过服务器 使用Proxifier全局代理 shadowsocks代理属于socks5代理，通俗的理解，socks5只是局部代理，不能像vpn那样把整个电脑都代理。因此，一般情况下只有支持socks5的软件才能使用shadowsocks代理。 我们使用的IE浏览器就不支持socks5代理，一般的游戏，也不支持socks5代理，那么这些软件如何使用代理？除了使用vpn，我们还有一种不错的办法，那就是把socks5代理转换成全局代理，效果跟vpn几乎一样。 使用Proxifier把shadowsocks代理转全局代理，不建议小白使用，无基础的话会很纠结。 Proxifier下载地址 软件安装以后，即可运行。 首次使用，需要做一番设置才能用。 首先要设置代理服务器。 菜单栏–&gt;&gt;配置文件–&gt;&gt;代理服务器，服务器地址填127.0.0.1，ss软件的端口填是什么就填什么。 严重强调一下，这里的端口是本地端口，不是远程服务器端口，ss的默认端口是1080，注意别搞错。 下面的“协议”选择socks版本5。 然后会弹出窗口，点“是”，然后狂点确定即可。 代理配置 此时还不能用，两点非常重要的设置！，请睁大眼睛看… ※1.开启远程dns解析菜单栏–&gt;&gt;配置文件–&gt;&gt;名称解析–&gt;&gt;勾选“通过代理解析主机名称” 如果不开启远程dns解析，你将会尽情享受到已被污染的dns解析，导致无法打开Facebook之类的网站。 如果你是游戏玩家，建议不要开启远程dns解析，你可以自己设置适合游戏服务器的dns，比如台服魔兽可以设置台湾dns。 代理配置2 ※2.把ssh或shadowsocks端口添加到直连名单这点最重要，很多人卡在这里。如果不设置这个规则，你必定会陷入死循环。 我们需要把ssh或shadowsocks服务器端口（具体端口号以你的账号为准,也就是远程端口了 这次不是本地端口哦 比如ssh常见的端口是22），添加到直连名单中，不让他们走代理。具体方法： 菜单栏–&gt;&gt;配置文件–&gt;&gt;代理规则–&gt;&gt;点击“添加”–&gt;&gt;在“目标端口”里面添加端口，然后下面的动作选择“direct”，然后点确定。 一定要注意以上两点，否则真心无法正常使用。 Proxifier设置好以后，就可以打开ssh或shadowsocks客户端并登录了。此时，默认所有程序的网络都会走代理，百度里查ip，必定会是代理的ip。 ok如果还上不去youtube，极有可能是因为有dns缓存，清除dns缓存和清空浏览器缓存即可。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习(一)]]></title>
    <url>%2F2015%2F12%2F20%2Fpython%2F</url>
    <content type="text"><![CDATA[python中的变量也是弱类型，无须使用保留字定义。想要使用的时候，可以直接对他赋值 12str='this is a string var example'#在python中使用 ‘#’代替其他编程语言中的 ‘//’ 然后就可以直接对他进行caozu9o，当然如果没有这一步骤，直接使用str会报错。之后可以对str进行类型改变。 123str=11;print(str//2);#对一个数字进行整除操作，可以使用'//'符号进行注释#正常的除法操作就可以直接使用'/' Python中十六进制以 “0x”开头，二八进制以”0”开头 1234&gt;&gt;&gt;0xAF #175&gt;&gt;&gt;010#8 获取用户输入: 12345str=input('please input yput str')#当用户在提示下输入信息时候，自动将信息复制给str，python3以上废除raw_inpit#输入的信息制动保存为string类型,如果输入的信息为 156#str的类型此时就是字符串，如果想要改变成为数字 num=int(str)#此时 num即可使用，或者直接使用int(num),但是要注意的是 str的数据类型依然没有改变 函数定义: 12345def func(str): print(str)#python中的缩进很重要 在if、else、函数定义、类定义中，都会用一个冒号隔离语句#调用如下func('hello,python') 模块的导入： 123import mathmath.floor(32.9)#导入了math模块，同时以正常形式使用math模块下的floor函数，获取参数的四舍五入值 也可以进行但函数导入： 12345678910from math import floor#此处就可以不加模块名的直接使用floor函数floor(445.6)#也可以进行如下使用from math import floor as func1func1(34,7)#此时func1==math.floor==(from math import floor之后的)floor#或者如下func2=math.floor;func2(23.45) 拼接字符串: 123456str1='this is 'str2='an example'print(str1+str2)#输出str1的值拼接str2的值，这里是生成一个新的字符串然后返回，而非在str1的基础之上狂冲"a"*4#输出'aaaa' 转换为string可以使用str()、repr()两个函数达到这个目的。str会把值转换成为合理形式的字符串，以便用户理解；repr()函数会创建一个字符串，以合法的python表达式形式表达值。下面是一些例子: 12345678&gt;&gt;&gt;print(repr('hello'));'hello'&gt;&gt;&gt;print(repr(1000L));#以L结尾的数字，拜师长整形数，可以表达很大的数字1000L&gt;&gt;&gt;print(str('hello'));hello&gt;&gt;&gt;print(str(1000L));1000 长字符串、原始字符串 如果需要一个非常长的字符串，可能会跨越多行，可以使用三个引号代替普通引号（单引号、双引号），在一对三引号之间不需要反斜杠转义，直接在里面使用单引号、双引号。 123&gt;&gt;&gt;print('''this ''is'' a 'simple' example''');#输出如下this ''is'' a 'simple' example 还有另外一种方法，即在当前行最后一个字符之后添加 \ 123456&gt;&gt;&gt;str='this is a \...simple \...example'print(str);this is a simple example#原理就是将每行最后的换行字符再加上一个反斜杠'\',使忽略这个换行符 正常情况下，当你输入 12345678910&gt;&gt;&gt;print("C:\test.txt");#输出如下C:est.txt#需要如此使用&gt;&gt;&gt;peint("C:\\test.txt");C:\test.txt#现在你可以使用原始字符串，以 'r'开头&gt;&gt;&gt;print(r'C:\test.txt');C:\test.txt#需要注意的是，不能在原始字符串结尾使用反斜杠'\' 序列python中一共包括6种内建序列，列表、元组、字符串、Unicode字符串、buffer对象以及xrange对象。列表和元组的主要区别就是：列表可以修改，元组不能。 序列的通用属性: 以索引方式访问 1234tag='hello'print(tag[2]);#输出索引为2的tag元素l 分片 123456print(tag[2,5]);#输出索引2-4的元素 llo#可以反向输出print(tag[::-1]);#最后一个参数是步长 步长是-1 则为反向输出 序列乘法 1234tag=['x','y','z'];print(tag*3);['x','y','z','x','y','z','x','y','z']#对于其他类型的序列也适应 成员资格检查通过运算符in检验 1234567users=['mlh','foo','bar'];#users此时是一个列表'mlh' in users#输出TrueTrue'xyz' in usersFalse 一些内建函数使用常用的一些关于序列的内建函数，包括长度、最小值、最大值 12345678910number=[100,54,47848];len(number);#输出序列的长度3max(number)#输出序列中的最大值47848#同理还有最小值函数min min(number)54 列表:列表在python中以’[]’这样的形式出现list函数，将系列转换成为列表 123llist=list('hello');print(llist);['h','e','l','l','o'] 相反的，可以将序列转换成为字符串 ‘’.join(llist) #此时已经生成一个新的字符串 列表的一些方法:1)append 12341st=[1,2,3]1st.append(4);1st[1,2,3,4] 2)count统计某个元素在列表中出现的次数 12&gt;&gt;&gt;['to','x','y','to'].count('to')2 3)extend扩展原列表，而非连接操作 12345a-[1,2,3]b=[4,5,6]a.extend(b)a[1,2,3,4,5,6] 还有一些其他方法，例如index(某元素)、insert(pos,元素)、pop()、remove()、sort()、reverse()、sorted（）…这些函数都可以根据函数名称知道功能 元组元组跟列表很类似，主要区别就是元素不能改变,以”()”隔离将其他类型的序列转换成为元组:tuple函数: 12345678 tuple([1,2,3]); (1,2,3)``` 字符串===字符串的格式化 str="hello , %s" print(str % "chuangwailinjie"); #输出时 %s与 “chuangwailinjie对应” hello ,chuangwailinjie #另外的形式,以元组形式格式化 str="hello , %s age is %d" tag=('chuangwailinjie',100) print(str % tag); #元组形式分别匹配 hello ,chuangwailinjie age 100 1234567字符串的一些常用方法:(1)find在一个较长的字符串中查找子字符串，返回紫川所在位置的最左端索引 (2)join是split()方法的逆方法，用来在队列中添加元素 seq=['1','2','3','4','5']; sep='+' sep.join(seq) '1+2+3+4+5' '/'.join(['usr','bin','dev']) /usr/bin/dev 12345678 (3)lower 返回字符串的小写字母版 (4)replace 返回某字符串的所有匹配项均被替换之后得到字符串 'this is a test'.replace('is','xyz') thxyz xyz a test 12345(5)splitjoin方法的逆方法，用来将字符串分隔成为序列(列表) '1+2+3+4+5'.split('+') ['1','2','3','4','5'] 123456字典===python中的映射数据结构吗，字典中的值并没有特殊的顺序，但都存储在一个特定的键，键可以使数字、字符串甚至以'&#123;&#125;'隔离 phoneBook={'Alice':'2341','Beth':'9102'} phoneBook['Alice'] 2341 1234dict函数 可以使用dict函数，通过其他映射（比如其他字典）或者（键、值）这样的序列构造字典 items=[('name','Gumby'),('age',42)] d=dict(items) d {'age':42,'name':'Gumby'} 12字典的格式化字符串 template='''&lt;html&gt; &lt;head&gt;&lt;title&gt;%(title)s&lt;/title&gt;&lt;/head&gt; &lt;body&gt;%(text)s&lt;/body&gt; &lt;/html&gt;''' data={'title':"My Home Page","text":"Welcome!"}; print(template % data) 123456789101112131415**python中的判等**Python中的对象包含三要素：id、type、value。其中id用来唯一标识一个对象，type标识对象的类型，value是对象的值。 - 'is'判断的是a对象是否就是b对象，是通过id来判断的- '=='判断的是a对象的值是否和b对象的值相等，是通过value来判断的一些迭代工具===pass语句 在python中，如果想要什么都不做（类似其他高级语言中的';'）可以使用pass语句 if（1==1）： print("success") else : pass 12345----------## 元组推导式 ##列表推导式是利用其他列表创建新列表的一种方法。 [x*x for x in range(10)] [0,1,4,9,16,25,36,49,64,81] 12更有趣的使用方法 [x*x for x in range(10) if x 3 ==0] [0,9,36,81] #可以添加更多for语句的成分 [(x,y) for x in range(3) for y in range(3)] [(0,0),(0,1),(0,2),(1,0),(1,1),(1,2),(2,0),(2,,),(2,2)] 12可以与 if语句联用 girls=['alice','bernice','clarice'] boys=['chris','arnold','bob'] [b+'+'g for b in boys for g in girls if b[0]==g[0]] #这样就会得到首字母相同的男孩和女孩 123456del语句 删除不想要使用的变量 x=1 dex x x #之后就会报错 1234exec函数 如果字符串是一个python语句，当我们想要执行它时，可以调用exec(statement)函数 exec('print("hello")') hello 123456789101112由于不一定知道字符串中的具体语句会对当前程序造成什么影像，所以exec()函数要慎用eval函数 eval()函数可以对想要求值的python表达式求值 eval('3423+345534*234') 80858379方法定义=== def func(prompts): statement return 1234关键字和默认值: python中可以在定义函数的时候进行参数的默认值设置 def func(greeting='hello',name='world'): print('%s , %s!' % (greeting,name)); #此时就可以不加参数的调用 func() hello , world! func(greeting='hello',name='www') hello , www! func('www','hello') www , hello! 12收集参数: def func(*params) print(params) #当定义时候，在参数前面加上 * 代表此参数以元组形式存在，并默认手机其他位置的元组参数 func('1','2','3') ('1','2','3') func() #当不提供任何参数时，就是一个空的元组 () 123处理默认值参数: def func(x,y,z=3,*pospar,**keypar): print(x,y,z) print(pospar) print(keypar) #两个 '*'在一个参数前面，代表此参数为字典形式，默认收集 func(1,2,3,5,6,7,foo=1,bar=2) #第一行输出x,y,z 1 2 3 #第二行输出元组形式 (5,6,7) #第三行输出字典形式 {'foo':1,'bar':2} 123456python中的作用域----------变量在编程语言中，我们可以把他们当做是值的名字。在执行x=1赋值语句之后，名称x引用到值1.像dict一样，键引用值，当然变量所对应的值的引用是个不可见的字典。Python中的内建vars函数可以返回这个字典： x=1scope=vars()scope[‘x’]1scope[‘x’]+=1x2 123456但是，很明显呢，一般情况下这类由vars返回的字典是不能修改的，这里的不可修改即不能在字典中增添、删除变量。 这类不可见字典就叫做命名空间(namespace)或者作用域(scope),除了整个程序有一个全局的命名空间，每个函数调用都会创建一个新的作用域。类的使用:=== #创建一个最简单的类 class Person: def func(self): #定义的时候一定要有一个参数 self，类似其他语言的 this print('Hello Python!') instance=Person(); instance.func() #调用了instance实例的方法 Hello Python！ #如果知道instance是Person的一个实例，那么instance.func()==Person.func(instance) #因为在原本的定义中就是参数为self，即一个实例，方法与函数的区别就是参数有没有self 1234Python的类中，不支持直接的方法、属性私有化，但是可以在方法、属性的名称前面加上双下划线,使从外部无法直接访问 class Service: def __inaccessable(self): print("just a test") def accessable(self): print('this method can use') selt.__inaccessable() s=Service() s.__inaccessable() #此时程序会报错 s.accessable() #正常输出 this mathod can use just a test 1234指定超类:子类可以扩展超类的定义，将其他类名卸载class语句后的圆括号内就可以指定超类： class Filter: def init(self): self.blocked=[] def filter(self,sequence): return [x for x in sequence if not in self.blocked] class SPAMFilter(Filter): def init(self): self.blocked=['SPAM'] 1234SPAMFilter类是Filter类的子类，子类继承父类，并且不用重写不想要overwrite的方法。 如果想要知道一个类是否是另外一个类的子类，可以使用内建的issubclass函数 issubclass(SPAMFIlter,Filter) True issubclass(Filter,SPAMFilter) False 12如果想要知道已知类的基类，可以直接使用它的特殊特性 __base__: SPAMFIlter.__base__ &lt;class__main__.Filter&gt; Filter.__base__ &lt;class 'object'&gt; 1234567python支持多重继承，如下：``` class xyz(filter1,filter): def func1(self): print("nothing"); 在这里，类xyz就继承另外两个基类，这里要注意的就是，基类的继承顺序很重要，在括号前面的类与后面的类中如果 有相同的方法，则前面的类会覆盖后面类的方法. 关于类的一些总结:类：类代表对象的集合（或一类对象），每个对象（实例）都有一个类。类的主要任务是定义它的实例会用到的方法。 对象：对象包括特性和方法。特性只是作为对象的一部分的变量，方法则是存储在对象内的函数。（绑定）方法和 其他函数的区别在于方法 总是将对象作为自己的第一个参数，一般称为self. 多态：多态是实现将不同类型和类的对象进行同样对待的特性—不需要知道对象属于哪个类就能调用的方法。 封装:对象可以讲他们内部状态隐藏（或者封装）起来。在一些语言中，这意味着对象的状态（特性）只对自己的 方法可用。 继承：一个类可以是一个或多个类的子类。子类从超类继承所有方法，普通的实现方式是使用核心的超类的一个或者多个混合超类。 Python异常处理python用异常对象来表示异常情况，遇到错误后，会引发异常，如果异常对象并未被处理或者捕捉，成语就会用回溯(Traceback,一种错误信息)终止执行。 与java等其他高级语言类似的是，每个异常都是一些类的实例，这些实例可以被引发，并且可以用很多种方法进行捕捉，使得程序可以捕捉错误并进行处理，而不是让整个程序失败. (1)raise语句为了引发异常，可以使用一个类(应该是Exception的子类)或者实例参数调用raise语句。使用类是，程序会自动创建实例。 123456789101112raise ExceptionTraceback (most recent call last): File "&lt;pyshell#4&gt;", line 1, in &lt;module&gt; raise Exception Exceptionraise Exception('带参数的实例') Traceback (most recent call last): File "&lt;pyshell#5&gt;", line 1, in &lt;module&gt; raise Exception('带参数的实例')Exception: 带参数的实例#与上一个例子不同的就是，此处的Exception带参数，raise语句执行时，自动为期创建一个带参数的Exception实例对象 (2)自定义异常类 class someCustomeException(Exception):pass (3)捕捉异常 在python中可以使用try/except来实现异常捕捉 1234567891011try: x=input('enter the first number: ') y=input('enter the second number: ') print(int(x)/int(y));except ZeroDivisionError: print("the second number can't be 0")enter the first number: 10enter the second number: 0the second number can't be 0 在python中如果没有捕捉异常，他就会将异常反馈至上一层调用他的语句位置，如果在哪里依然没有被捕获，…最终会被反馈到程序的顶层。使用了try/except块之后，即处理了异常，就不会将异常反馈。同样跟java类似的是，python中也有finally语句。 Python魔法方法、特性、迭代器(1)构造方法当一个对象被创建之后，会立即调用构造方法。python中创建一个类的构造方法很简单，只需要将init方法的名字修改为魔法方法版本init即可: 1234class FooBar: def __init(self): self.somevar=42#与前面提到过的魔法方法相同，以一对儿双下划线包裹函数名即可 (2)使用super函数 当前类和对象可以作为super函数的参数使用，调用函数返回的对象的任何方法都是调用超类的方法，而不是当前类的方法12345678910111213141516171819202122232425262728&gt;&gt;&gt; class Bird: def __init__(self): self.hungry=True; def eat(self): if self.hungry: print("Aaaah....") self.hungry=False else : print('No,thx'); &gt;&gt;&gt; class SongBird(Bird): def __init__(self): super().__init__() self.sound='Squawk' def sing(self): print(self.sound) &gt;&gt;&gt; sb=SongBird()&gt;&gt;&gt; sb.sing()Squawk&gt;&gt;&gt; sb.eat()Aaaah....&gt;&gt;&gt; sb.eat()No,thx (3)静态方法和类方法 静态方法和类成员方法分别在创建时被装入Staticmethod类型和Classmethod类型的对象中。静态方法中的定义没有self参数，且能够被类本身直接调用。类方法在定义时需要名为cls的类似self的参数，类成员方法可以直接用类的具体对象调用。 123456789101112131415class MyClass: def smeth(): print('this is a static method') #手动包装 smeth=staticmethod(smeth) def cmeth(cls): print('this is a class method',cls) cmeth=classmethod(cmeth) &gt;&gt;&gt; MyClass.smeth()this is a static method&gt;&gt;&gt; MyClass.cmeth()this is a class method &lt;class '__main__.MyClass'&gt; 或者使用自动包装: 12345678class MyClass: @staticmethod def smeth(): print('this is a static method') @classmethod def cmeth(cls): print('this is a class method',cls) (4)迭代器在python中可以对除了序列、字典外的其他对象迭代：实现iter方法。iter方法返回一个迭代器，所谓的迭代器就是具有next方法的对象。在调用next方法是，迭代器会返回它的下一个值。如果next方法被调用，但迭代器没有值可以返回，会引发异常。迭代器基于下面两个个方法：（1）next 返回容器的下一个项目(下一个值)（2）iter 返回迭代器本身 123456789101112131415161718192021222324class MyIterator: def __init__(self,step): self.step=step def __next__(self): if self.step==0: raise StopIteration self.step-=1 return self.step def __iter__(self): return self for i in MyIterator(6): print(i) #输出结果543210 12345678910111213141516171819#斐波那契数列class Fibs: def __init__(self,count): self.a=0 self.b=1 self.count=count def __next__(self): self.a=self.b self.b=self.a+self.b if self.count==0 :raise StopIteration self.count-=1 return self.a def __iter__(self): return selffibs=Fibs(10)list(fibs)[1, 2, 4, 8, 16, 32, 64, 128, 256, 512] (5)生成器 生成器是一种用普通的函数语法定义的迭代器，任何包含yield语句的函数称为生成器。除了名字不太一样之外，行为业余普通函数有很大差别。它不是向return语句一样返回一个值，而是每次产生多个值。每次产生一个值（使用yield语句），函数就会被冻结：函数停在那点等待激活，函数被激活之后就从停止的那点开始执行。可以通过在生成器上迭代来使用所有的值 12345678&gt;&gt;&gt; def flatten(nested): for sublist in nested: for ele in sublist: yield elenested=[[1,2,3],[4,6,9,43],[25,456,4234],[12,456,'afsdf','sdfsf']]&gt;&gt;&gt; list(flatten(nested))[1, 2, 3, 4, 6, 9, 43, 25, 456, 4234, 12, 456, 'afsdf', 'sdfsf'] 下面一个例子是使用递归的生成器: 12345678910111213&gt;&gt;&gt; def flatten(nested): try: for sublist in nested: for ele in flatten(sublist): yield ele except TypeError: #此时的nested就是一个单元素 yield nested#函数可以处理任意层次的序列list(flatten([[[1,2,3,4],[345,6,7],[23,45,36],[234,2,35]],[[234,645,6],[234,5,3,65],[23,5,534,6,7]],[234,5,6,6],[[234,5,6,7],[423,5],[23,55,6]]]))[1, 2, 3, 4, 345, 6, 7, 23, 45, 36, 234, 2, 35, 234, 645, 6, 234, 5, 3, 65, 23, 5, 534, 6, 7, 234, 5, 6, 6, 234, 5, 6, 7, 423, 5, 23, 55, 6] 当flatten被调用时候，有两种情况，基本元素和需要递归情况。基本情况时，函数被告知展开一个元素，for循环会引发一个TyprError异常（因为试图对一个单元素展开），生成器会产生一个元素（从except那里产生一个元素后，直接返回到上一层） 通用生成器生成器是一个包含yield关键字的函数，当他被调用的时候，函数中的代码不会执行，而是返回一个迭代器。每次请求一个值，就会执行生成器的代码，直到遇到yield语句或者return语句。yield语句即生成一个值，而return意味着停止执行（return语句只有在一个生成器中使用时才能进行无参调用） 所以可以看出来，生成器是由两部分组成的，生成器的函数和生成器的迭代器。生成器的函数是用def语句定义，包含yeld的部分，生成器的迭代器是这个函数的返回部分。 生成器的方法:(1)next外部作用域访问生成器的初设值(2)send使用send方法，就像访问next方法一样，只不过前者使用一个参数，参数是要发送的消息,当想要使用send方法时，必须是生成器已经被挂起，即yield表达式被执行之后（可以使用next()函数之后调用）.(3)throw方法使用异常类型调用，用于在生成器（yield表达式）引发一个异常(4)close方法停止生成器 123456789101112def repeater(value): while True: new = (yield value) if new is not None: value=newr=repeter(42)r.next()#输出42r.send('value')#输出value 模块任何一个Python成语都可以作为模块导入,加入你写了一个如下的代码，并且命名为hello.py 12#hello.pyprint('Hello ,Python') 程序保存在磁盘的摸个位置上，如C:\python_module,那么可以执行下列代码，将这个路径追加到python的搜索目录中，这样python在导入module的时候会自动搜索用户目录下的文件民 1234import syssys.path.append('C:/python_module')import helloHello ,Python 第一次导入时，他会执行导入的module，当再次重复导入时，默认是不再执行。当然可以使用reload函数达到在此执行的效果。导入多次可能会造成一些问题，module一般是用作定义使用，所以一次导入就能达到此目的 12345678#hello.pydef hello(): print('Hello,Python!')import hellohello.hello()Hello,Python! 每个python文件都可以当做一个module，可能会出现两种身份，当你正在使用时，他们的身份是 ‘main‘，而当做module导入到其他程序时候，查看发现是 文件名 12345678910__name__'__main__'import math#math.pymath.__name__'math'import hello#hello.pyhello.__name__'hello' 当我们知道了这个特性之后，就可以通过简单的判断在module中添加测试片段，当正常使用时执行，而当做导入module时就跳过 12345678910#hello.pydef hello(): print('Hello,Python!')def test(): hele();#当正常使用时，就测试方法是否可用，否则只是当做函数定义if __name__=='__main__': test() Package包wie为了组织好模块，可以将他们分组为包package。包也是另外一种模块，但是可以包含另外的模块。当模块存储在文件中的时候，（扩展名 .py）包就是模块所在的目录，为了让Python将其作为包对待，必须包含一个命名为init.py的文件（模块）.如果将它作为普通模块导入的时候，文件的内容就是包得内容。假设有一个名为 constants的包，文件constant/init.py包括语句 PI=3.14,可以如下使用 1234import contantprint(constant.PI)#当你的constant包下面有colors.py这个文件import constant.color fileinput 模块fileinput模块可以能够轻松的遍历文本文件的所有行。 fileinput.input是上面最重要的函数，会返回能够用于for循环遍历的对象。如果不想使用默认行为(fileinput查找需要循环遍历的文件)，可以给函数提供（序列形式的）一个或多个文件名。可以将inplace参数设为真值(inplace=True)以进行原地处理。对于要访问的每一行，需要打印出替代的内容，以返回到当前的输入文件中。 fileinput.lineno返回当前行的行数，数值是累计的，所以在完成一个文件的处理并且开始处理下一个文件时，行数并不会重置。 下面是一个简单的案例:12345678#hello.pyimport fileinputfor line in fileinput.input(inplace=True): line=line.rstrip() no=fileinput.lineno() print('%-60s # %2i' % (line,no)) 当我们在终端测试时，结果如下: 1234567891011#第一个是要解释的源文件，第二个参数是fileinput.input的文件参数python hello.py hello.py#hello.py的文件变成如下，因为使用了inplace=True参数，所以直接改变了文件import fileinput # 1 # 2for line in fileinput.input(inplace=True): # 3 line=line.rstrip() # 4 no=fileinput.lineno() # 5 print('%-60s # %2i' % (line,no)) # 6 一些常用的数据结构集合Set集合位于sets模块中，与数学对应的是数值的唯一性，所以插入多个相同的值时过滤的. 12set(range(10))&#123;0,1,2,3,4,5,6,7,8,9&#125; 集合是由序列构建的，主要用于检查成员的资格，因此副本是被忽略的，同时根据数学中集合的特性无序性，集合中元素的顺序是随意的。 12set(['hell','hiil','hiahia'])&#123;'hiil','hell','hiahia'&#125; 集合的一些常用方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344a=set([1,2,3])b=set([2,3,4])c=a&amp;b#集合之间的并集a.union(b)#输出&#123;1,2,3,4&#125;a|b#输出&#123;1,2,3,4&#125;#集合之间的交集a.intersection(b)#输出&#123;2,3&#125;a&amp;b#输出&#123;2,3&#125;#判断集合是否是子集c.issubset(a)Truea.issubset(c)Falsec &lt;= aTrue#判断是否是超集a.issuperset(c)Truea &gt;= cTrue#获取两集合差集a.difference(b)&#123;1&#125;b.difference(a)&#123;4&#125;a-b&#123;1&#125;b-a&#123;4&#125;#获取两集合非交集的并集a.symmetric_difference(b)&#123;1,4&#125;b^a&#123;1,4&#125; 堆heap对是优先队列的一种，使用优先队列能够以任一顺序增加对象，并能在任何时候找到最小的元素，对比来讲，比列表的min函数效率要高一些。 heap在Python的heapq模块中，包括6个函数： 上图中的前4个方法都比较简单易懂，后两个方法:nlargest(n,iter)和nsmallest(n,iter)分别用来寻找任何可以迭代对象iter中第n大或第n小的元素. 双端队列双端队列(deque)在需要按照元素增加的顺序来移除元素时非常有用，deque在模块collections中。 12345678910111213141516171819from collections import dequeq=deque(range(5))print(q)#输出[0,1,2,3,4]q.append(5)print(q)[0,1,2,3,4,5]q.appendleft(6)[6,0,1,2,3,4,5]#同理还有q.pop()、q.popleftq.rotate(2)#rotate相当于右移功能print(q)[4,5,6,0,1,2,3]q.rotate(-1)print(q)[5,6,0,1,2,3,4] time模块time模块包含的函数包含以下功能: 获取当前时间 操作时间和日期 从字符串读取时间 格式化时间为字符串 比如元组: (2016,1,21,12,2,56,0,21,0)表示2016年1月21日12时2分56秒，星期一，并且是当年的第21天 可以看出来，asctime()函数与strptime(string[,format])函数时相反的功能而localtime([secs])（或者获取全球统一时间的gtime([secs])）与mktime(tuple)功能相反 random模块这里先说一下伪随机与真随机的区别: 真正意义上的随机数（或者随机事件）在某次产生过程中是按照实验过程中表现的分布概率随机产生的，其结果是不可预测的，是不可见的。而计算机中的随机函数是按照一定算法模拟产生的，其结果是确定的，是可见的。我们可以这样认为这个可预见的结果其出现的概率是100%。所以用计算机随机函数所产生的“随机数”并不随机，是伪随机数。 当然了，在python中使用random模块的普通功能生成的数字都是伪随机数，这在一般情况下是够用了，如果想要体验真的随机性，应该使用os模块的urandom函数或者random模块的SystemRandom类，让数据接近真的随机性. getrandbits(n)以长整形形式返回给定的位数，输出时转换成为10进制数 uniform提供来年各个数值参数a、b，他会返回在a~b随机实数n randrange能够产生该范围内的随机数。randrange(1,20,2)会产生小于20的随机正奇数 shelve模块如果只需要一个简单的存储方案，shelve模块可以满足大部分的需要，所需要的只是为他提供文件名。通过open函数，获取Shelf对象，将它当做字典的handle适应，而且键值必须为字符串。使用之后用close()关闭 123456import shelves=shelve.open('test')s[x]=['a','b','c']s.close()#这样，test.dat文件就自动保存在当前的工作目录下 当再次想要获取数据时: 12345file=shelve.open('test')print(file['x'])#输出['a','b','c'] re模块（regular expression）re即regular expression，正则表达式，关于正则表达式的通用知识可以浏览我的csdn blog。 因为在正则表达式中会使用大量的转义字符，所以在python中使用原始字符串显然是一个不错的解决方案,在想要使用的字符串之前加上’r’即可. 正常情况下，要匹配python.org这个字符串可以使用如下: 12345#字符串中，一个反斜杠代表转义字符，而在正则表达式中，'.'是特殊字符，需要转义，所以要实现一个反斜杠，在字符串中就是两个反斜杠'pyhton\\.org'#使用原始字符串之后就很清晰了r'python\.org' 下面是python中re模块为我们提供的一些常用函数： 函数re.compile将正则表达式(以字符串书写的)转换成模式对象，可以实现更有效率的匹配。如果在调用search或者match函数的时候使用字符串表示的正则表达式时，他们也会在内部将字符串转换成为正则表达式对象。使用compile一次转换后就不用多次在内部转换。模式对象本身也有方法. 12345pattern=re.compile(str_expr)#pattern是正则表达式对象re.search(pattern,string)pattern.search(string)#以上两个语句是等价的 函数re.search会在给定字符串中寻找第一个匹配给定正则表达式的子字符串。一旦找到子字符串，函数就会返回MatchObject,根据Python的规则，if语句当做True，否则返回None（当做False） 函数re.match会在给定字符串的开头匹配正则表达式，因此看如下两个语句: 1234re.match('p','python')#匹配成功re.match('p','www.python.org')#匹配失败 如果要使用match匹配整个字符串，可以再模式的结尾加上美元符号（即末尾匹配标志），美元符号会对字符串的末尾进行匹配，从而顺延了整个字符串的匹配。 函数re.split会根据模式的匹配项来分割字符串，它类似与字符串方法split，不过是用完整的正则表达式代替固定的分割字符串。 12345678some_text='alpha, beta,,,,gamma delta're.split('[, ]+',some_text)['alpha','beta','gamma','delta']#maxsplit参数表示字符串最多可以分割的部分re.split('[, ]+',some_text,maxsplit=2)['alpha','beta','gamma delta']re.split('[, ]+',some_text,maxsplit=1)['alpha','beta,,,,gamma delta'] 函数re.findall以列表形式返回给定模式的所有匹配项 123456pat='[a-zA-a]'#匹配所有英文字母text='abcd456efg67hijk4579lmn're.findall(pat,text)['abcd','efg','hijk','lmn'] re.escape是一个很实用的函数，它可以对字符串中所有可能被解释为正则运算符的字符进行转义的应用函数。如果字符串很长而且包含很多特殊字符，而又不想输入一大堆反斜杠，切这部分要用作正则表达式的一部分，可以使用这个函数。 12345re.escape('www.python.org')'www\\.python\\.org're,escape('But where is the ambiguity')'But\\ where\\ is\\ the\\ ambiguity\\' 匹配对象和组 对于re模块中那些能够对字符串模式匹配的函数而言，当能够找到匹配项的时候，他们都会返回MatchObject对象。这些对象包括匹配模式的子字符串的信息，以及哪个模式匹配了子字符串哪部分的信息，，这些称为组（group） 简而言之，组就是防止在圆括号内的子模式。组的序号取决于它左侧的括号数目。组0就是整个模式。如下: 12'There (was a (wee)(cooper) who (lived in Fyfe)) ' 包含以下这些组 There was a wee cooper who lived Fyfe was a wee cooper wee cooper lived in Fyfe 再比如下面的模式: 1234567891011121314151617r'www\.(.+)\.com$'``` 组0包含整个字符串，而组1包含位于'www.'和'com'之间的所有内容。这样创建的话，就能取出字符串中感兴趣的部分了。re匹配对象(MatchObject)的一些重要方法：![](http://7xowaa.com1.z0.glb.clouddn.com/reobject.jpg)group方法返回模式中与给定组匹配的子字符串，默认组为0。如果给定一个组号会返回单个字符串，否则会将对应给定组数的字符串作为元组返回。start方法返回给定组匹配项的开始索引(默认为0，即整个模式)方法end类似于start，但是返回结果是结束索引加1方法span以元组(start,end)的形式返回给定组的开始和结束位置的索引 import rem=re.match(r’www.(.*)..{3}’,’www.python.org’)m.group(1)‘python’m.start(1)4m.end(1)10m.span(1)(4, 10) 12345什么是正则表达式的贪婪与非贪婪匹配 如： String str=”abcaxc”; Patter p=”ab*c”; 123456789101112 - 贪婪匹配:正则表达式一般趋向于最大长度匹配，也就是所谓的贪婪匹配。如上面使用模式p匹配字符串str，结果就是匹配到：abcaxc(ab*c)。 - 非贪婪匹配：就是匹配到结果就好，就少的匹配字符。如上面使用模式p匹配字符串str，结果就是匹配到：abc(ab*c)。通过re表达式实现简单的邮件人过滤:![](http://7xowaa.com1.z0.glb.clouddn.com/chatu_email.jpg)寻找这封信的发件人: #hello.pyimport re,fileinput #为了直接在结果中显示发件人，所以在模式中将所需信息用圆括号扩住，这样就可以通过组方便的取出pat=re.compile(‘From: (.)&lt;.?&gt;$’)for line in fileinput.input(): m=pat.match(line) if m: print(m.group(1)) #结果python hello.py data.txtFoo Fie 12寻找这封信中所有的邮箱地址，并列出来 import re,fileinput #忽略大小写pat=re.compile(r’[a-z-.]+@[a-z-.]+’,re.IGNORECASE) #创建集合addresses=set()for line in fileinput.input(): for address in pat.findall(line): addresses.add(address) for address in sorted(addresses): print(address) #进行测试 python hello.py data.txt Mr.Gumby@bar.bazfoo@bar.bazfoo.baz.commagnus@bozz.floop 123下面是一个简单但是经典模板匹配: import fileinput,re #要匹配的是一个方括号括起来的表达式，在模式中用括号圈出来组1field_pat = re.compile(r’[(.+?)]‘) #将变量收集到这里scope=dict() #应用在re.sub替换def replacement(match): #获取表达式 code = match.group(1) try: return str(eval(code,scope)) except SyntaxError: #否则执行相同作用域内的赋值语句 exec(code,scope) return '' #将需要替换的文本以一个字符串的形式获取lines=’’ for line in fileinput.input(r’.\data.txt’): lines+=line #将序列转换成为字符串 #text=’’.join(lines) #将field模式的所有匹配项都替换print(field_pat.sub(replacement,lines)) 如果要替换的文本是如下[x=2][y=3] The sum of [x] and [y] is [x+y]. 运行的结果是: The sum of 2 and 3 is 5. ``` 这里要注意的是，data.txt文件的格式要为utf-8无BOM格式或者ansi编码，Python默认的编码格式为utf-8，否则会无法解析 更多的例子解析，可以查看我的另一篇杂文，正则表达式简单应用.]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PL中的伪随机]]></title>
    <url>%2F2015%2F12%2F20%2Fpython_rand%2F</url>
    <content type="text"><![CDATA[这里先说一下伪随机与真随机的区别: 真正意义上的随机数（或者随机事件）在某次产生过程中是按照实验过程中表现的分布概率随机产生的，其结果是不可预测的，是不可见的。而计算机中的随机函数是按照一定算法模拟产生的，其结果是确定的，是可见的。我们可以这样认为这个可预见的结果其出现的概率是100%。所以用计算机随机函数所产生的“随机数”并不随机，是伪随机数。 当然了，在python中使用random模块的普通功能生成的数字都是伪随机数，这在一般情况下是够用了，如果想要体验真的随机性，应该使用os模块的urandom函数或者random模块的SystemRandom类，让数据接近真的随机性. getrandbits(n)以长整形形式返回给定的位数，输出时转换成为10进制数 uniform提供来年各个数值参数a、b，他会返回在a~b随机实数n randrange能够产生该范围内的随机数。randrange(1,20,2)会产生小于20的随机正奇数]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[书单]]></title>
    <url>%2F2015%2F12%2F14%2F%E4%B9%A6%E5%8D%95%2F</url>
    <content type="text"><![CDATA[网络小说已读 《亵渎》 《搜神记》 《蛮荒记》 《庆余年》 《陈二狗的妖孽人生》 《橙红年代》 《狩魔笔记》 《紫川》 《朱雀记》 《诛仙》 《网游之盗版神话》 《回到明朝当王爷》 《步步生莲》 《极品家丁》 《神墓》 《悟空传》 《三体》-已读 《鬼吹灯》 《盗墓笔记》 《卡徒》 《巫颂》 《阿里布达年代祭》（禁） 《兽血沸腾》 《人道至尊》 未读 《英雄志》 专业相关已读 《算法导论》 《数学之美》 《编译原理》 《Java编程思想》 《java核心技术》 《鸟哥的Linux私房菜》 《机器学习》 未读 《编程之美》 《编程珠玑》 《剑指offer》 《浪潮之巅》 《C primer plus》 《统计学习方法》 《集体编程智慧》 经济已读 《动物精神》 《货币战争》 《穷爸爸富爸爸》 未读 《公司理财》 生活已读 《失乐园》 《人性的弱点》 《番茄工作法》 《飞鸟集》 《吉檀迦利》 《人类简史》 《未来简史》 《全球通史》 未读 《WORD排版艺术》 《优雅的力量》 《社会心理学》]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>随感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js]]></title>
    <url>%2F2015%2F12%2F13%2Fjs%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[使用对象的属性 通过 对象名[属性名]，这里的属性可以类比为Java中的对象的成员变量 通过 对象名.属性名使用 通过 for(var varble in object)循环获取 object[varble] 通过 with(对象名){直接调用属性} 12345678910111213141516171819202122232425&lt;script type="text/javascript"&gt; //定义一个对象 有两个属性'url' 和 'URL' var objj=&#123;'url':'chuangwailinjie.github.io','URL':'CHUANGWAILINJIE.GITHUB.IO'&#125;; //&lt;1&gt; str=objj['url'] alert(str); //&lt;2&gt; alert(objj.url); //&lt;3&gt; var str=''; for(var em in objj)&#123; str+=objj[em]; &#125; alert(str); //&lt;4&gt; with(objj)&#123; alert(url); &#125;&lt;/script&gt; 使用对象的方法通过 对象名.方法 通过 with(对象名){直接调用对象方法} js中事件处理函数绑定12345678910&lt;input type="button" id="bclick" value="点击"&gt;&lt;script type="text/javascript"&gt; function func()&#123; var res=prompt('请输入红色',''); if(res=="红色") alert("perfect");&#125;bclick.onclick=func;&lt;/script&gt; 这里要注意的是 如果是无参的方法 一定不能写为bclick.onclick=func() 这样写就是直接调用 而非是将事件处理函数绑定. 内置对象添加属性或者方法在Array、String、Date、Boolean、Number这些内置对象中可以通过prototype属性为这些内置对象添加属性或者方法.格式为 object.prototype.属性名=… object.prototype.方法=… 1234567function onclickkk()&#123; alert('just test');&#125;var ob=new model(objj);model.prototype.onclickk=onclickkk; 如上，modle为类模板名称，为model添加了一个onclickk方法，以后就可以直接使用。1&gt;实例化一个对象ob2&gt;直接使用 ob.onclickk 同样要注意的是，如果绑定的function为无参的话，一定不能这样写 model.prototype.onclickk=onclickkk();这样写的后果就是直接执行，不同调用就会执行. 自定义对象-属性或者方法当然这里只是一个简单的示例，如果不是使用内置对象，可以直接这样声明方法: 12345678910111213141516function onclickkk(ar)&#123; alert('just test');&#125;//定义一个对象模板function model(data)&#123; this.url=data.url; this.URL=data.URL; this.onclickk=onclickkk;&#125;var ob=new model(objj);ob.onclickk(''); 一些事件处理文本方面的：oncopy()、onbeforecopy()当指定的文本被复制时触发 onbeforecopy()是在讲文本内容放到剪切板是触发，oncopy()是在复制时触发，所以onbeforecopy()先触发.当想要进制某些文本被复制，可以这样做 function onccopy(){ alert("can't copy"); return false; } function onbbeforecopy(){ alert("can't beforecopy"); return false; } &lt;p oncopy="onccopy()" onbeforecopy="onbbeforecopy()"&gt;...&lt;/p&gt; //当然也可以直接在元素p中 &lt;p onbeforecopy="return false"&gt;&lt;/p&gt; 如果绑定的函数不是内置函数，就必须在最后return，true表示可以复制，false表示禁止复制. 类似的还有onpaste(),onbeforepaste().onbeforepaste()是从系统剪切板复制到文本框识别执行的方法，可以在此设置方法，禁止粘贴 onbeforepaste="return cleanup()" 将使用者的剪切板直接清空，使无法粘贴。可以应用到passwd域，或者重复验证密码时使用。需要注意的是，与onbeforecopy不同，在onbeforepaste()中return true or false没有用。onpaste()是在粘贴时触发，可以直接设置return false禁止粘贴. 在代码片段中，当绑定函数时，不管指定的函数是否无参数，都不能指定函数的语句中加’()’,比如这样 document.forms[0].onsubmit=func1();不管是function funci()这样的无参函数，还是function func1(ar.br)这样的有参函数，上面的代码在script片段中出现函数就会执行。绑定函数时，只能在等号右边加上需要=指定的函数名，而非完整的带括号形式. 与之对应的是在html元素中，指定相应的script句子，需要完整的形式，比如 onclick="alert('hahha')"//可以在alert后面加上冒号 oncopy、onbeforecopy、onsubmit、onreset这样的事件需要有返回boolean值，则可以指定为 oncopy="return false" oncopy="return func1()" 上面的代码中，第一个直接禁止复制，第二个在func1()中加入了逻辑判断，但func1()也是有返回值的，返回值为boolean 同样的可以看出，return func1()这里是需要的添加’()’的，因为这里不是被script包裹，只是指定了处理代码。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Front End</tag>
        <tag>JQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pycharm模板]]></title>
    <url>%2F2015%2F12%2F13%2FTemplate%2F</url>
    <content type="text"><![CDATA[Step1 进入File-&gt;settings-&gt;Editor-&gt;File and Code Templates-&gt;Python Script Step2 添加以下内容： # encoding: utf-8 Step3 额外的板信息 1234567891011121314151617181920212223242526# encoding: utf-8#set( $SITE = "http://peihao.space" )"""@version: ??@author: chuangwailinjie@license: Apache Licence @contact: chuangwailinjie@gmail.com@site: $&#123;SITE&#125;@software: $&#123;PRODUCT_NAME&#125;@file: $&#123;NAME&#125;.py@time: $&#123;DATE&#125; $&#123;TIME&#125;"""def func(): passclass Main(): def __init__(self): passif __name__ == '__main__': pass]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>随感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tarjan强连通分量]]></title>
    <url>%2F2015%2F12%2F02%2Ftarjan%2F</url>
    <content type="text"><![CDATA[引入在有向图G中，如果两个顶点间至少存在一条路径，称两个顶点强连通(strongly connected)。如果有向图G的每两个顶点都强连通，称G是一个强连通图。非强连通图有向图的极大强连通子图，称为强连通分量(strongly connected components)。 下图中，子图{1,2,3,4}为一个强连通分量，因为顶点1,2,3,4两两可达。{5},{6}也分别是两个强连通分量。 tarjan是一种由Robert Tarjan提出的求解有向图强连通分量的线性时间的算法。 Tip DFN(n)为节点n搜索的次序编号(时间戳)，Low(n)为n或n的子树能够追溯到的最早的栈中节点的次序号。 Low数组是一个标记数组，记录该点所在的强连通子图所在搜索子树的根节点的DFN值 当DFN(n)=Low(n)时，栈里n以及n以上的顶点全部出栈，且刚刚出栈的就是一个极大强连通分量。 算法演示 从节点1开始DFS，把遍历到的节点加入栈中。搜索到节点u=6时，DFN[6]=LOW[6]，找到了一个强连通分量。退栈到u=v为止，{6}为一个强连通分量。 返回节点5，发现DFN[5]=LOW[5]，退栈后{5}为一个强连通分量。 返回节点3，继续搜索到节点4，把4加入堆栈。发现节点4向节点1有后向边，节点1还在栈中，所以LOW[4]=1。节点6已经出栈，(4,6)是横叉边，返回3，(3,4)为树枝边，所以LOW[3]=LOW[4]=1。 继续回到节点1，最后访问节点2。访问边(2,4)，4还在栈中，所以LOW[2]=DFN[4]=5。返回1后，发现DFN[1]=LOW[1]，把栈中节点全部取出，组成一个连通分量{1,3,4,2}。 以上，求出了图中全部的三个强连通分量{1,3,4,2},{5},{6}。 运行Tarjan算法的过程中，每个顶点都被访问了一次，且只进出了一次堆栈，每条边也只被访问了一次，所以该算法的时间复杂度为O(N+M)。 Low[i]表示i所能直接或间接达到时间最小的顶点。(实际操作中Low[i]不一定最小，但不会影响程序的最终结果) 详解 数组的初始化：当首次搜索到点p时，DFN与Low数组的值都为到该点的时间。 堆栈：每搜索到一个点，将它压入栈顶。 当点p有与点p’相连时，如果此时（时间为dnf[p]时）p’还未访问过，p的low值为两点的low值中较小的一个。 当点p有与点p’相连时，如果此时（时间为dfn[p]时）p’在栈中，p的low值为p的low值和p’的dfn值中较小的一个。 每当搜索到一个点经过以上操作后（也就是子树已经全部遍历）的low值等于dfn值，则将它以及在它之上的元素弹出栈。这些出栈的元素组成一个强连通分量。 继续搜索（或许会更换搜索的起点，因为整个有向图可能分为两个不连通的部分），直到所有点被遍历。 支撑 Tarjan算法基于定理：在任何深度优先搜索中，同一强连通分量内的所有顶点均在同一棵深度优先搜索树中。也就是说，强连通分量一定是有向图的某个深搜树子树。 可以证明，当一个点既是强连通子图Ⅰ中的点，又是强连通子图Ⅱ中的点，则它是强连通子图Ⅰ∪Ⅱ中的点。 low值记录该点所在强连通子图对应的搜索子树的根节点的Dfn值。该子树中的元素在栈中一定是相邻的，且根节点在栈中一定位于所有子树元素的最下方。 强连通分量由若干个环组成的。所以，当有环形成时（也就是搜索的下一个点已在栈中），我们将这一条路径的low值统一，即这条路径上的点属于同一个强连通分量。 如果遍历完整个搜索树后某个点的dfn值等于low值，则它是该搜索子树的根。这时，它以上（包括它自己）一直到栈顶的所有元素组成一个强连通分量。 实现伪代码12345678910111213141516tarjan(u)&#123; DFN[u]=Low[u]=++Index//为节点u设定次序编号和Low初值 Stack.push(u)//将节点u压入栈中 for each(u,v) in E//枚举每一条边 if (v is not visted)//如果节点v未被访问过 tarjan(v)//继续向下找 Low[u]=min(Low[u],Low[v]) else if (v in S)//如果节点v还在栈内 Low[u]=min(Low[u],DFN[v]) if (DFN[u]==Low[u])//如果节点u是强连通分量的根 repeat&#123; v=S.pop//将v退栈，为该强连通分量中一个顶点 print v until(u==v) &#125; C++实现123456789101112131415161718192021222324252627282930313233343536373839404142#define M 9999//题目中可能的最大点数int STACK[M],top=0;//Tarjan算法中的栈bool InStack[M];//检查是否在栈中int DFN[M];//深度优先搜索访问次序 int Low[M];//能追溯到的最早的次序int ComponentNumber=0;//有向图强连通分量个数int Index=0;//索引号vector&lt;int&gt; Edge[M];//邻接表表示int InComponent[M];//记录每个点在第几号强连通分量里int ComponentDegree[M];//记录每个强连通分量的度 void Tarjan(int i)&#123; int j; DFN[i]=Low[i]=Index++; isvisted[i]=1; InStack[i]=true; STACK[++top]=i; for (int e=0;e&lt;Edge[i].size();e++) &#123; j=Edge[i][e]; if (DFN[j]==-1)//（i，e）中e还未被访问过 &#123; Tarjan(j); Low[i]=min(Low[i],Low[j]); &#125; else if (InStack[j]) Low[i]=min(Low[i],Low[j]); &#125; if (DFN[i]==Low[i]) &#123; ComponentNumber++; do&#123; j=STACK[top--]; InStack[j]=false; push_back(j); InComponent[j]=ComponentNumber; &#125; while (j!=i); &#125;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2015.9CCF认证试题（3）]]></title>
    <url>%2F2015%2F11%2F30%2Fccf3%2F</url>
    <content type="text"><![CDATA[代码来源逍遥丶綦-最佳文章》 最佳文章问题描述 小明最近在研究一门新的语言，叫做Q语言。Q语言单词和文章都可以用且仅用只含有小写英文字母的字符串表示，任何由这些字母组成的字符串也都是一篇合法的Q语言文章。 在Q语言的所有单词中，小明选出了他认为最重要的n个。使用这些单词，小明可以评价一篇Q语言文章的“重要度”。 文章“重要度”的定义为：在该文章中，所有重要的Q语言单词出现次数的总和。其中多次出现的单词，不论是否发生包含、重叠等情况，每次出现均计算在内。 例如，假设n = 2，小明选出的单词是gvagv和agva。在文章gvagvagvagv中，gvagv出现了3次，agva出现了2次，因此这篇文章的重要度为3+2=5。 现在，小明想知道，一篇由m个字母组成的Q语言文章，重要度最高能达到多少。 输入格式 输入的第一行包含两个整数n, m，表示小明选出的单词个数和最终文章包含的字母个数。 接下来n行，每行包含一个仅由英文小写字母构成的字符串，表示小明选出的这n个单词。 输出格式 输出一行一个整数，表示由m个字母组成的Q语言文章中，重要度最高的文章的重要度。 样例 输入 3 15 agva agvagva gvagva 输出 11 说明 15个字母组成的重要度最高的文章为gvagvagvagvagva。 在这篇文章中，agva出现4次，agvagva出现3次，gvagva出现4次，共计4+3+4=11次。 测评在评测时将使用10个评测用例对你的程序进行评测。 设s为构成n个重要单词字母的总个数，例如在样例中，s=4+7+6=17；a为构成n个重要单词字母的种类数，例如在样例中，共有3中字母’a’,’g’,’v’，因此a=3。 评测用例1和2满足2 ≤ n ≤ 3，1500 ≤ m ≤ 2000，s = 40； 评测用例3和4满足m = 20，2 ≤ a ≤ 3； 评测用例5、6和7满足2000 ≤ m ≤ 100000； 评测用例8满足n = 2； 所有的评测用例满足1 ≤ s ≤ 100，1 ≤ m ≤ 1015，每个单词至少包含1个字母，保证 单词中仅出现英文小写字母，输入中不含多余字符，不会出现重复的单词。 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164#include &lt;map&gt;#include &lt;set&gt;#include &lt;cmath&gt;#include &lt;ctime&gt;#include &lt;Stack&gt;#include &lt;queue&gt;#include &lt;cstdio&gt;#include &lt;cctype&gt;#include &lt;bitset&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstring&gt;#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;functional&gt;#define fuck(x) cout &lt;&lt; "[" &lt;&lt; x &lt;&lt; "]"using namespace std;typedef long long LL;typedef pair&lt;int, int&gt; PII;typedef vector&lt;LL&gt; vec;typedef vector&lt;vec&gt; mat;//二维数组const int MX = 1e4 + 5;const LL INF = 0x3f3f3f3f3f3f3f3f;int rear, root;//Next二维数组中26个空间分别对26个小写英文字母进行试探//Fail数组保存Trie树元素的Fail指针//End数组进行词标记int Next[MX][26], Fail[MX], End[MX];//申请Trie元素节点并初始化int New() &#123; rear++; End[rear] = 0; for(int i = 0; i &lt; 26; i++) &#123; Next[rear][i] = -1; &#125; return rear;&#125;//初始化Trie树void Init() &#123; rear = 0; root = New();&#125;//Trie树增加元素节点void Add(char *A) &#123; int n = strlen(A), now = root; for(int i = 0; i &lt; n; i++) &#123; int id = A[i] - 'a'; if(Next[now][id] == -1) &#123; Next[now][id] = New(); &#125; now = Next[now][id]; &#125; End[now]++;&#125;//二维矩阵填充值valvoid mat_fill(mat &amp;A, LL val) &#123; for(int i = 0; i &lt; A.size(); i++) &#123; for(int j = 0; j &lt; A[0].size(); j++) &#123; A[i][j] = val; &#125; &#125;&#125;mat Build() &#123; queue&lt;int&gt;Q; Fail[root] = root; for(int i = 0; i &lt; 26; i++) &#123; if(Next[root][i] == -1) &#123; Next[root][i] = root; &#125; else &#123; Fail[Next[root][i]] = root; Q.push(Next[root][i]); &#125; &#125; while(!Q.empty()) &#123; int u = Q.front(); Q.pop(); End[u] += End[Fail[u]]; for(int i = 0; i &lt; 26; i++) &#123; if(Next[u][i] == -1) &#123; Next[u][i] = Next[Fail[u]][i]; &#125; else &#123; Fail[Next[u][i]] = Next[Fail[u]][i]; Q.push(Next[u][i]); &#125; &#125; &#125; mat A(rear, vec(rear)); mat_fill(A, -INF); for(int i = 1; i &lt;= rear; i++) &#123; for(int j = 0; j &lt; 26; j++) &#123; int chd = Next[i][j]; A[chd - 1][i - 1] = End[chd]; &#125; &#125; return A;&#125;//矩阵乘法mat mat_mul(mat &amp;A, mat &amp;B) &#123; mat C(A.size(), vec(B[0].size())); mat_fill(C, -INF); for(int i = 0; i &lt; A.size(); i++) &#123; for(int j = 0; j &lt; B[0].size(); j++) &#123; for(int k = 0; k &lt; B.size(); k++) &#123; if(A[i][k] + B[k][j] &gt;= 0) &#123; C[i][j] = max(C[i][j], A[i][k] + B[k][j]); &#125; &#125; &#125; &#125; return C;&#125;//矩阵快速幂优化mat mat_pow(mat A, LL n) &#123; mat B = A; n--; while(n) &#123; if(n &amp; 1) B = mat_mul(B, A); A = mat_mul(A, A); n &gt;&gt;= 1; &#125; return B;&#125;void print(mat &amp;A) &#123; for(int i = 0; i &lt; A.size(); i++) &#123; for(int j = 0; j &lt; A[0].size(); j++) &#123; fuck(A[i][j]); &#125; printf("\n"); &#125;&#125;char S[MX];int main() &#123; int n; LL m; scanf("%d%lld", &amp;n, &amp;m); Init(); for(int i = 1; i &lt;= n; i++) &#123; scanf("%s", S); Add(S); &#125; mat A = Build(); A = mat_pow(A, m); LL ans = 0; for(int i = 0; i &lt; rear; i++) &#123; ans = max(ans, A[i][0]); &#125; printf("%lld\n", ans); return 0;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2015.9CCF认证试题（2）]]></title>
    <url>%2F2015%2F11%2F28%2Fccf2%2F</url>
    <content type="text"><![CDATA[模板生成问题描述成成最近在搭建一个网站，其中一些页面的部分内容来自数据库中不同的数据记录，但是页面的基本结构是相同的。例如，对于展示用户信息的页面，当用户为 Tom 时，网页的源代码是 而当用户为 Jerry 时，网页的源代码是 这样的例子在包含动态内容的网站中还有很多。为了简化生成网页的工作，成成觉得他需要引入一套模板生成系统. 模板是包含特殊标记的文本。成成用到的模板只包含一种特殊标记，格式为，其中VAR是一个变量。该标记在模板生成时会被变量VAR的值所替代。 例如，如果变量name = &quot;Tom&quot;，则会生成Tom。具体的规则如下： 变量名由大小写字母、数字和下划线(_)构成，且第一个字符不是数字，长度不超过 16个字符。 变量名是大小写敏感的，Name和name是两个不同的变量。 变量的值是字符串。 如果标记中的变量没有定义，则生成空串，相当于把标记从模板中删除。 模板不递归生成。也就是说，如果变量的值中包含形如的内容，不再做进一步的替换。 输入格式 输入的第一行包含两个整数 m, n，分别表示模板的行数和模板生成时给出的变量个数。接下来 m 行，每行是一个字符串，表示模板。 接下来 n 行，每行表示一个变量和它的值，中间用一个空格分隔。值是字符串，用双引号 (“) 括起来，内容可包含除双引号以外的任意可打印 ASCII 字符（ASCII 码范围 32, 33, 35~126）。 输出格式 输出包含若干行，表示模板生成的结果。 样例输入 123456789101112131411 2&lt; !DOCTYPE html&gt;&lt; html&gt;&lt; head&gt;&lt; title&gt;User &#123;&#123; name &#125;&#125;&lt;/title&gt;&lt; /head&gt;&lt; body&gt;&lt; h1&gt;&#123;&#123; name &#125;&#125;&lt;/h1&gt;&lt; p&gt;Email: &lt;a href="mailto:&#123;&#123; email &#125;&#125;"&gt;&#123;&#123; email &#125;&#125;&lt;/a&gt;&lt;/p&gt;&lt; p&gt;Address: &#123;&#123; address &#125;&#125;&lt;/p&gt;&lt; /body&gt;&lt; /html&gt;name "David Beckham"email "david@beckham.com" 样例输出 1234567891011&lt;!DOCTYPE html&gt;&lt; html&gt;&lt; head&gt;&lt; title&gt;User David Beckham&lt;/title&gt;&lt; /head&gt;&lt; body&gt;&lt; h1&gt;David Beckham&lt;/h1&gt;&lt; p&gt;Email: &lt;a href="mailto:david@beckham.com"&gt;david@beckham.com&lt;/a&gt;&lt;/p&gt;&lt; p&gt;Address: &lt;/p&gt;&lt; /body&gt;&lt; /html&gt; 评测用例规模与约定 0 ≤ m ≤ 100 0 ≤ n ≤ 100 输入的模板每行长度不超过80个字符（不包含换行符）。 输入保证模板中所有以。 输入中所有变量的值字符串长度不超过100个字符（不包括双引号）。 保证输入的所有变量的名字各不相同。 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;string.h&gt;#include &lt;cstdio&gt;using namespace std;int main()&#123; int m,n; bool flag; cin&gt;&gt;m&gt;&gt;n; getchar(); string src[m],des[m]; string varstr[n][2]; for(int i=0;i&lt;m;i++) getline(cin,src[i]); for(int i=0;i&lt;n;i++) &#123; cin&gt;&gt;varstr[i][0]; getline(cin,varstr[i][1]); int start=varstr[i][1].find("\""); int end=varstr[i][1].rfind("\""); varstr[i][1]=varstr[i][1].substr(start+1,end-start-1); &#125; for(int i=0;i&lt;m;i++)&#123; while(true)&#123; flag=false; int startx=src[i].find("&#123;&#123;"); int endx=src[i].find("&#125;&#125;"); if(startx&lt;0||endx&lt;0)break; string var=src[i].substr(startx+3,endx-startx-4); for(int i=0;i&lt;n;i++)&#123; if(var==varstr[i][0])&#123; flag=true; var=varstr[i][1]; break; &#125; &#125; if(!flag)var=""; des[i]=des[i]+src[i].substr(0,startx)+var; src[i]=src[i].substr(endx+2,src[i].length()-endx-2); &#125; des[i]=des[i]+src[i]; cout&lt;&lt;des[i]&lt;&lt;endl; &#125; return 0;&#125; 高速公路问题描述 某国有n个城市，为了使得城市间的交通更便利，该国国王打算在城市之间修一些高速公路，由于经费限制，国王打算第一阶段先在部分城市之间修一些单向的高速公路。 现在，大臣们帮国王拟了一个修高速公路的计划。看了计划后，国王发现，有些城市之间可以通过高速公路直接（不经过其他城市）或间接（经过一个或多个其他城市）到达，而有的却不能。如果城市A可以通过高速公路到达城市B，而且城市B也可以通过高速公路到达城市A，则这两个城市被称为便利城市对。 国王想知道，在大臣们给他的计划中，有多少个便利城市对。 输入格式 输入的第一行包含两个整数n, m，分别表示城市和单向高速公路的数量。接下来m行，每行两个整数a, b，表示城市a有一条单向的高速公路连向城市b。 输出格式 输出一行，包含一个整数，表示便利城市对的数量。 样例输入 5 5 1 2 2 3 3 4 4 2 3 5 样例输出 3 样例说明 有3个便利城市对，它们分别是(2, 3), (2, 4), (3, 4)，请注意(2, 3)和(3, 2)看成同一个便利城市对。 评测用例规模与约定 前30%的评测用例满足1 ≤ n ≤ 100, 1 ≤ m ≤ 1000； 前60%的评测用例满足1 ≤ n ≤ 1000, 1 ≤ m ≤ 10000； 所有评测用例满足1 ≤ n ≤ 10000, 1 ≤ m ≤ 100000 实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;iostream&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;vector&gt;#include &lt;stack&gt;using namespace std;#define maxn 10005vector&lt;int&gt; G[maxn];stack&lt;int&gt; s;int dfn[maxn];int low[maxn];int in_stack[maxn];int col_num[maxn];int vis[maxn];int cur_time, color;void tarjan(int u)&#123; dfn[u]=low[u]=cur_time++; s.push(u); in_stack[u]=1; vis[u]=1; int d=G[u].size(); for(int i=0;i&lt;d;i++)&#123; int v=G[u][i]; if(!vis[v])&#123; //防止v是之前已被访问过、但已出栈，所以不使用in_stack，因为不可能跟 //上述情况的v节点构成强连通分量 tarjan(v); low[u]=min(low[u],low[v]); &#125; else if(in_stack[v])&#123; //强连通分量必定是相邻的，一起在栈中 low[u]=min(low[u],dfn[v]); &#125; &#125; if(dfn[u]==low[u])&#123; color++; int v; do&#123; v=s.top(); s.pop(); in_stack[v]=0; col_num[color]++; &#125;while(u!=v); &#125;&#125;int main()&#123; int n,m; while(scanf("%d %d",&amp;n,&amp;m)!=EOF)&#123; for(int i=0;i&lt;m;i++)&#123; int u,v; scanf("%d %d",&amp;u,&amp;v); G[u].push_back(v); &#125; while(!s.empty())s.pop(); cur_time=0; color=0; memset(col_num, 0, sizeof(col_num)); memset(in_stack, 0, sizeof(in_stack)); memset(vis, 0, sizeof(vis)); for(int i=1;i&lt;=n;i++)&#123; if(!vis[i])tarjan(i); &#125; int res=0; for(int i=1;i&lt;=color;i++)&#123; if(col_num[i]&gt;1)&#123; res+=(col_num[i]*(col_num[i]-1))/2; &#125; &#125; cout&lt;&lt;res&lt;&lt;endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2015/9CCF认证试题（1）]]></title>
    <url>%2F2015%2F11%2F28%2Fccf1%2F</url>
    <content type="text"><![CDATA[水题1描述 给定一个整数数列，数列中连续相同的最长整数序列算成一段，问数列中共有多少段？输入格式输入的第一行包含一个整数n，表示数列中整数的个数。第二行包含n个整数a1, a2, …, an，表示给定的数列，相邻的整数之间用一个空格分隔。 输出格式 输出一个整数，表示给定的数列有多个段。 样例输入 8 8 8 8 0 12 12 8 0 样例输出 5 样例说明 8 8 8是第一段，0是第二段，12 12是第三段，倒数第二个整数8是第四段，最后一个0是第五段。 实现12345678910111213141516171819#include &lt;iostream&gt;using namespace std;int main()&#123; int length; cin&gt;&gt;length; int code[length]; cin&gt;&gt;code[0]; int ans=0; if(length!=0)ans=1; for(int i=1;i&lt;length;i++)&#123; cin&gt;&gt;code[i]; if(code[i]!=code[i-1]) ans++; &#125; cout&lt;&lt;ans&lt;&lt;endl; return 0;&#125; 水题问题描述给定一个年份y和一个整数d，问这一年的第d天是几月几日？注意闰年的2月有29天。满足下面条件之一的是闰年：1） 年份是4的整数倍，而且不是100的整数倍；2） 年份是400的整数倍。 输入格式 输入的第一行包含一个整数y，表示年份，年份在1900到2015之间（包含1900和2015）。输入的第二行包含一个整数d，d在1至365之间。 输出格式 输出两行，每行一个整数，分别表示答案的月份和日期。 样例输入 201580 样例输出 321 样例输入 2000 40 样例输出 29 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;bool isRun(int year)&#123; if(year%4==0&amp;&amp;year%100!=0) return true; if(year%400==0) return true; return false;&#125;int main()&#123; int days[12]=&#123;31,28,31,30,31,30,31,31,30,31,30,31&#125;; int year,index; cin&gt;&gt;year&gt;&gt;index; bool isR=isRun(year); if(isR)&#123; //闰年操作 days[1]=29; for(int i=1;i&lt;12;i++) days[i]=days[i]+days[i-1]; int month; for(int i=0;i&lt;12;i++) if(index&lt;days[i])&#123; month=i+1; break; &#125; cout&lt;&lt;month&lt;&lt;endl&lt;&lt;index-days[month-2]&lt;&lt;endl; &#125; else&#123; //普通年操作 for(int i=1;i&lt;12;i++) days[i]=days[i]+days[i-1]; int month; for(int i=0;i&lt;12;i++) if(index&lt;days[i])&#123; month=i+1; break; &#125; cout&lt;&lt;month&lt;&lt;endl&lt;&lt;index-days[month-2]&lt;&lt;endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令]]></title>
    <url>%2F2015%2F11%2F22%2Flinux-shell%2F</url>
    <content type="text"><![CDATA[ubuntu 使用超级管理员 su 程序管理 apt 程序安装apt-get install xxx centos 使用超级管理员 su 程序管理 yum 程序安装yum install xxx 程序更新 yum update xxx 通用lnln创建链接，分为soft链接和hard链接，两种链接生成的链接文件都与其余文件保证统一性，任何的文件改变都会在链接中体现。 ln -s srcfile destfile软链接，相当于win平台下的快捷方式，不占用内存，文件内容其实就是源文件的路径，可以对目录链接 ln srcfile destfile硬链接，作为副本存在，类似于win平台下的xxx(1).xx，但是不同的是，在这里虽然是副本，实际上并不占空间，不能对目录进行链接 创建文件/目录 vi filename touch filename mkdir 删除文件 rm 删除目录 rm -R（递归方式） 源码安装linux源码的安装一般有配置（configuration）、编译（make）、安装（make install）三个步骤组成 配置有很多，一般发布者会在index上写上usage 设置安装位置： ./configure –prefix=/usr/local –enable-shared 设置安装位置/usr/local 同时编译后会链接成共享对象（.so文件，类似win平台的.dll） 编译 直接就male命令 安装 make install]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7.x shadowsocks多用户问题解决]]></title>
    <url>%2F2015%2F11%2F21%2Fcentos-firewalld%2F</url>
    <content type="text"><![CDATA[firewalld在centos7.x版本中，firewalld 取代 iptables成为了系统默认的防火墙，相比传统的iptables，firewalld有以下特点： 动态更新 修改配置文件后，不需要重启服务，可以动态支持 加入zone概念 /etc/firewalld/zones目录下有多个配置文件： trusted允许所有进来的流量 home拒绝所有进来的流量，除非是与出去的流量相关或者匹配ssh,mdsn,ipp-client,samba-client,dhcpv6-client internal 和home是一样的 word 和home基本一样，但默认允许的程序只有：ssh,ipp-client,dhcpv6-client public和home基本一样，但默认允许的程序只有：ssh,dhcpv6-client 是新加的网络接口的默认zone external 和home类似，但默认允许的程序只有ssh.还可以作为masqueraded(SNAT) dmz 和home类似，但默认允许的程序只有ssh block和home类似,但没有默认允许的程序 drop和home类似，但不用ICMP errors包响应 分别创建或者修改 *.xml文件，添加进指定的xml文件代表端口使用规则，不同zone的优先级还没有研究 usgae ##：一般我们也用不到下面的几条命令，因为firewalld是动态更新的 systemctl start firewalld 启动 systemctl stop firewalld 关闭 systemctl restart firewalld 重启 shadowsocks多用户配置修改配置文件vi /etc/shadowsocks.json 123456789101112&#123; "server":"::", "local_address":"127.0.0.1", "local_port":1080, "port_password":&#123; "8989:"12345678", "8999":"12345678" &#125;, "timeout":300, "method":"aes-256-cfb", "fast_open": false&#125; 如果上面的配置完成后无法使用，centos7.x或者其他使用firewalld的用户继续往下看，多用户正常使用就不用看了 ss的默认中，端口号是8989（应该是吧…），可以在/etc/firewalld/zones/public.xml文件中查看 此时虽然我们配置了多个端口，但是由于另外的端口没有加入到防火墙中，是无法使用的，在文件中添加以下规则： 12&lt;port protocol="udp" port="8999"/&gt;&lt;port protocol="tcp" port="8999"/&gt; 将另外的端口加入tcp、udp白名单，firewalld即可动态更新配置]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[v6]]></title>
    <url>%2F2015%2F11%2F21%2Fv6%2F</url>
    <content type="text"><![CDATA[前几天学校每个月送的20g流量又没了，然后想到了一直有人提到过的，校园网IPv6可以使用双栈协议的服务器做跳板实现免流。经过前人 的无私奉献，很快就搭了一个三藩市的vps，这里记录一下。 VPS的选择说是VPS，实际上就是服务器，VPS也叫虚拟专用服务器，每个提供商都有自己的叫法，类似亚马逊的aws ec，linode 的node，以及digitalocean的droplet，每个提供商都有自己的特点，有的一稳定著称，有的因为高性价比文明，还有的因为网络、性能、计算方面的优势受到欢迎，因为这里主要是使用vps作为我的v6免流服务器中转，所以一下几个方面一定要考虑到： IPv6 enable 低延迟 高流量 稳定 小服务提供商不用选择，容易跑路还不稳定，没有完善的文档，关键是大多数不支持IPv6，下面是一些大的提供商： 亚马逊aws linode digitalocean Vultr Bandwagon aws绑定信用卡提供最低配置的一年免费使用权，过期之后换张信用卡可以接着用，但是最低配置的不支持IPv6，还有就是aws 的扣费规则太多，容易进坑，每个月只提供20G左右的流量，泡个简单的Django可以，做ss还是算了吧 搬瓦工一直以超低价格出名，有过一段之间的不到$10，一年vps使用，不支持IPv6，被国内涌进的站长挤爆了。最近开始支持v6，不过价格也提高了，OpenVZ架构，超售严重 linode跟搬瓦工是经常拿来对比的服务商，linode是高富帅选择，每月$10起步，能提供的一般都提供了，稳定著称，不过性能与剩下的几个没有很大的优势 Vultr与Do定位类似，相同的价格下都有类似的配置，Vultr原来有日本的主机，延迟超低，实际使用体验棒，目前也售完了。这两者最低$5每月，按小时收费，DO支持v6，不限流量，Vultr不太清楚，进过慎重抉择，最终选择使用DO的旧金山主机 DO VPS创建在DigitalOcean主页注册用户，这是我的推广链接，推广链接注册后你会得到$10的初始credit。首次使用需要绑定信用卡/借贷卡或者paypal，使用palpay时需要最低充值$5，信用卡不需要。 注册成功后创建页面选择创建VPS，我的选择是centos7.2,$5/month套餐，sanfrancisco区域vps。 注意下面要在IPv6选项框上打对勾，同时注意建议不要使用Provate Networking，这是在同时部署多台服务器时选择，方便之间使用网络，我第一次创建选择这个选项之后，可以正常访问国外IPv6，国内的大多数无法使用，BackUp选项会增加20%费用。 Add your SSH keys选项是为了方便我们使用安全的连接方式控制主机，可以直接使github上绑定的public key，还没有使用的网友，这里有一篇简单的介绍百度经验，保存好ppk文件和生成的ssh代码内容，复制生成的ssh内容粘贴到网页的ssh key content中，以后就可以直接使用ssh控制主机。 最后确定好实例的名字后点击create就可以了，不到1分钟属于你的vps就创建好了 ss设置使用Xshell ssh方式登录控制主机，vps用户名默认为root，登陆之后： 安装ss wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh chmod +x shadowsocks.sh 一键安装 ss日志 ./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 修改配置 vi /etc/shadowsocks.json 进入之后键盘点击i进入insert模式，清除原来的文本，粘贴下面： 12345678910&#123; "server":"::", "server_port":8989, "local_address":"127.0.0.1", "local_port":1080, "password":"yourpassword", "timeout":300, "method":"aes-256-cfb", "fast_open":false&#125; &quot;server&quot;:&quot;::&quot;代表监听v6请求注意，如果你使用的是centos7.x版本，server_port使用默认的端口号，不要乱改，否则服务器防火墙不通过也没用，多用户配置在另一片文章中有说明修改完后esc退出修改模式，输入:x或者:wq退出vi 启动ss /etc/init.d/shadowsocks restart pc端设置启动 首先安装shadowsocks-windows，最新版的客户端ss要求较高的.net服务，连接给出的是较老版本，最新版本 打开后-&gt;服务器-&gt;编辑服务器-&gt;添加-&gt;服务器地址填入DO的IPv6地址-&gt;服务器端口、密码、加密方式都可以在上面配置的服务器端ss文件中找到 端口号选择本地闲置端口，默认1080 系统代理模式选择全局代理，开启之后就可以畅享免流网络 vps网络优化 内核修改优化 其中centos7.2在vi /etc/sysctl.conf这一步时要注意，去提示的文件中修改 破解版锐速 wget -N --no-check-certificate https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh &amp;&amp; bash serverspeeder-all.sh 百度云与迅雷代理下载 在两种下载工具中设置高级下载代理，选择socket5协议，端口为本地ss端口，默认1080]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小记(2)]]></title>
    <url>%2F2015%2F11%2F17%2F%E5%B0%8F%E8%AE%B0-2%2F</url>
    <content type="text"><![CDATA[去年的今天下着雨，和现在一样的小雨。 身体会很诚实，每年这个时段都是同样的状态，习惯性将自己隐藏在纸盒中，营造一种沉闷的氛围。唱着听着快10年的《拥抱》，放任自己迷醉在修罗场边的荷花池。 晚上借了同学的车子，去了第一次来这个城市​进的理发店，很小，当初去是因为他在放着我正哼唱的小调，今天来是想要再回味我在这个城市的几年痕迹。似乎没有什么不同，同学的车子很棒，让我感觉比去年的现在好一些。 快一年没来了，老板还认得我，问我最近怎样、今后的打算。老板变化不大，和原来一样的健谈，与顾客熟稔，看起来非常安逸。这让我想起了初中，想过做网吧老板，想过当乡村杂货铺掌柜，然而当我真正可以决定去做些什么的时候，这一步比设想的要沉重太多。时间推着我们前行，容不得半分迟疑。我们永远不能再走一次时间左侧，有太多的过客经过我们的原点。 有些人经过我身旁，住在我脑中，在我心里钻洞。有些人变成相片，堆在角落，灰尘像雪一般冰冻。去年的躁动是嫉妒，今年的嫉妒叫压抑。我零零碎碎的尝试用自己半分理智遮掩怪人的负心态，却经常会轻易地让自己压抑的情绪伤害别人。半面是懒惰，半面是高傲，在心底为你们加上莫须有的瑕疵，在纸上划上不能揩平的褶皱，然后心安理得的进入圣人模式。 今天见了想要见的人，可能没有说话，好的。我骑上车子，在雨中前行代替足球场上的奔跑，雨不大，风也不疾，刚好剪一个清爽的头发，电影片段像头发一样来来回回，最终落在地上，头发还好，所以这个决定应该是对的。每当我逃避显而易见的答案时，总会想方设法寻找一些毫无关联的对象，实现一些其轻而易举可以做到的事情，证明我是对的，现在我希望别人是对的。 所以我把最善良的我留给今天，​留给2x​，明年来看是经过我身边，还是变成相片。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++虚函数]]></title>
    <url>%2F2015%2F08%2F05%2FC%2B%2B%E8%99%9A%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[C++的精髓——虚函数=== 简单地说，那些被virtual关键字修饰的成员函数，就是虚函数。虚函数的作用，用专业术语来解释就是实现多态性（Polymorphism），多态性是将接口与实现进行分离；用形象的语言来解释就是实现以共同的方法，但因个体差异，而采用不同的策略.多态有个关键之处就是一切用指向基类的指针或引用来操作对象,指向基类的指针在操作它的多态类对象时，会根据不同的类对象，调用其相应的函数，这个函数就是虚函数。 定义虚函数的限制：（1）非类的成员函数不能定义为虚函数，类的成员函数中静态成员函数和构造函数也不能定义为虚函数，但可以将析构函数定义为虚函数。实际上，优秀的程序员常常把基类的析构函数定义为虚函数。因为，将基类的析构函数定义为虚函数后，当利用delete删除一个指向派生类定义的对象指针时，系统会调用相应的类的析构函数。而不将析构函数定义为虚函数时，只调用基类的析构函数。 （2）只需要在声明函数的类体中使用关键字“virtual”将函数声明为虚函数，而定义函数时不需要使用关键字“virtual”。 （3）当将基类中的某一成员函数声明为虚函数后，派生类中的同名函数（函数名相同、参数列表完全一致、返回值类型相关）自动成为虚函数。 （4）如果声明了某个成员函数为虚函数，则在该类中不能出现和这个成员函数同名并且返回值、参数个数、类型都相同的非虚函数。在以该类为基类的派生类中，也不能出现这种同名函数。 纯虚函数在基类中是没有定义的，必须在子类中加以实现，很像java中的接口函数！ define : virtual &lt;类型&gt;&lt;函数名&gt;(&lt;参数表&gt;)=0; 在许多情况下，在基类中不能对虚函数给出有意义的实现，而把它声明为纯虚函数，它的实现留给该基类的派生类去做。这就是纯虚函数的作用。纯虚函数可以让类先具有一个操作名称，而没有操作内容，让派生类在继承时再去具体地给出定义。凡是含有纯虚函数的类叫做抽象类。这种类不能声明对象，只是作为基类为派生类服务。除非在派生类中完全实现基类中所有的的纯虚函数，否则，派生类也变成了抽象类，不能实例化对象。一般而言纯虚函数的函数体是缺省的，但是也可以给出纯虚函数的函数体（此时纯虚函数变为虚函数），这一点经常被人们忽视，调用纯虚函数的方法为baseclass::virtual function. 虚函数 引入原因：为了方便使用多态特性，我们常常需要在基类中定义虚函数。1234567891011121314151617181920212223242526272829303132333435363738394041class Cman&#123; public: virtual void Eat()&#123;……&#125;; void Move(); private:&#125;;class CChild : public CMan&#123; public: virtual void Eat()&#123;……&#125;; private:&#125;;CMan m_man;CChild m_child;//这才是使用的精髓，如果不定义基类的指针去使用，没有太大的意义CMan *p ;p = &amp;m_man ;p-&gt;Eat(); //始终调用CMan的Eat成员函数，不会调用 CChild 的p = &amp;m_child;p-&gt;Eat(); //如果子类实现(覆盖)了该方法，则始终调用CChild的Eat函数//不会调用CMan 的 Eat 方法；如果子类没有实现该函数，则调用CMan的Eat函数p-&gt;Move(); //子类中没有该成员函数，所以调用的是基类中的 纯虚函数 引入原因： 1、同“虚函数”； 2、在很多情况下，基类本身生成对象是不合情理的。例如，动物作为一个基类可以派生出老虎、孔雀等子类，但动物本身生成对象明显不合常理。 纯虚函数就是基类只定义了函数体，没有实现过程定义方法如下 virtual void Eat() = 0; //直接=0 不要 在cpp中定义就可以了 纯虚函数相当于接口，不能直接实例话，需要派生类来实现函数定义。有的人可能在想，定义这些有什么用啊 ，我觉得很有用。 比如你想描述一些事物的属性给别人，而自己不想去实现，就可以定义为纯虚函数。说的再透彻一些。比如盖楼房，你是老板，你给建筑公司描述清楚你的楼房的特性，多少层，楼顶要有个花园什么的建筑公司就可以按照你的方法去实现了，如果你不说清楚这些，可能建筑公司不太了解你需要楼房的特性。用纯需函数就可以很好的分工合作了。 虚函数和纯虚函数区别 观点一： 类里声明为虚函数的话,这个函数是实现的，哪怕是空实现，它的作用就是为了能让这个函数在它的子类里面可以被重载，这样的话，这样编译器就可以使用后期绑定来达到多态了 纯虚函数只是一个接口，是个函数的声明而已，它要留到子类里去实现。 12345678910class A&#123; protected: void foo();//普通类函数 virtual void foo1();//虚函数 virtual void foo2() = 0;//纯虚函数 &#125; 观点二： 虚函数在子类里面也可以不重载的；但纯虚必须在子类去实现，这就像Java的接口一样。通常我们把很多函数加上virtual，是一个好的习惯，虽然牺牲了一些性能，但是增加了面向对象的多态性，因为你很难预料到父类里面的这个函数不在子类里面不去修改它的实现 观点三： 虚函数的类用于“实作继承”，继承接口的同时也继承了父类的实现。当然我们也可以完成自己的实现。纯虚函数的类用于“介面继承”，主要用于通信协议方面。关注的是接口的统一性，实现由子类完成。一般来说，介面类中只有纯虚函数的。 观点四： 错误：带纯虚函数的类叫虚基类，这种基类不能直接生成对象，而只有被继承，并重写其虚函数后，才能使用。这样的类也叫抽象类。 虚函数是为了继承接口和默认行为 纯虚函数只是继承接口，行为必须重新定义 虚基类的初始化— 虚基类的初始化与一般多继承的初始化在语法上是一样的,但构造函数的调用次序不同.派生类构造函数的调用次序有三个原则: (1)虚基类的构造函数在非虚基类之前调用; (2)若同一层次中包含多个虚基类,这些虚基类的构造函 虚基类和非虚基类的区别虚基类和非虚基类的区别数按它们说明的次序调用; (3)若虚基类由非虚基类派生而来,则仍先调用基类构造函数,再调用派生类的构造函数. C++的虚基类 在派生类继承基类时，加上一个virtual关键词则为虚拟基类继承，如： class derive:virtual public base{}; 虚基类主要解决在多重继承时，基类可能被多次继承，虚基类主要提供一个基类给派生类，如：1234class B&#123;&#125;;class D1:public B&#123;&#125;;class D2:public B&#123;&#125;;class C:public D1,public D2&#123;&#125;; 这里C在D1,D2上继承，但有两个基类，造成混乱。因而使用虚基类，即： 1234class B&#123;&#125;;class D1:virtual public B&#123;&#125;;class D2:virtual publicB&#123;&#125;;class C:public D1,public D2 在使用虚基类时要注意： (1) 一个类可以在一个类族中既被用作虚基类，也被用作非虚基类。 (2) 在派生类的对象中，同名的虚基类只产生一个虚基类子对象，而某个非虚基类产生各自的子对象。 (3) 虚基类子对象是由最远派生类的构造函数通过调用虚基类的构造函数进行初始化的。 (4) 最远派生类是指在继承结构中建立对象时所指定的类。 (5) 派生类的构造函数的成员初始化列表中必须列出对虚基类构造函数的调用；如果未列出，则表示使用该虚基类的缺省构造函数。 (6) 从虚基类直接或间接派生的派生类中的构造函数的成员初始化列表中都要列出对虚基类构造函数的调用。但仅仅用建立对象的最远派生类的构造函数调用虚基类的构造函数，而该派生类的所有基类中列出的对虚基类的构造函数的调用在执行中被忽略，从而保证对虚基类子对象只初始化一次。 (7) 在一个成员初始化列表中同时出现对虚基类和非虚基类构造函数的调用时，虚基类的构造函数先于非虚基类的构造函数执行。 静态联编：在程序链接阶段就可以确定的调用。 动态联编：在程序执行时才能确定的调用。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>基础知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JQuery选择器、过滤器介绍]]></title>
    <url>%2F2015%2F07%2F05%2FJQuery%E9%80%89%E6%8B%A9%E5%99%A8%E3%80%81%E8%BF%87%E6%BB%A4%E5%99%A8%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[一、JQuery对象与DOM对象1.JQuery对象JQuery对象就是使用 $(domobj)，将dom对象包装起来. 一般在jqury前面加上$与dom对象区分，它已经是一种公认的命名约定. JQuery对象不能调用dom对象的属性和方法，同样DOM对象也不能调用JQuery对象的属性和方法。 2.JQuery对象转成DOM对象如果想使用JQuery对象调用DOM对象的方法，怎么办？应该将JQuery对象转换成DOM对象，JQuery对象是一个数组对象，这个很特别。所以只需调用JQueryObj[x]或JQueryObj.get(X);即可转换为DOM对象。 3.DOM对象转换成JQuery对象使用“$(“DOMObj”)”将DOM对象包装起来就可以了。 二、JQuery选择器 选择器是JQuery的根基，在JQuery 中，对事件处理，遍历DOM和Ajax操作都依赖于选择器。这也是今天我们学习的重点内容。 1.基本选择器基本选择器是JQuery中最常用的选择器，也是最简单的选择器，它通过元素id、class 和标签名来查找DOM元素。这个非常重要，下面的内容都是以此为基础，逐级提高的。 123451).“$(“#id”)”，//获取id指定的元素，id是全局唯一的，所以它只有一个成员。 2).“$(“.class”)”，//获取class指定的元素，不同的元素可以具有相同的class属性，所以它可能具有多个成员。 3).“$(“element”)”，//获取element（元素名，比如div、table等）指定的元素，它可能具有多个成员。 4).“$(“*”)”，//获取所有元素，相当于document。 5).“$(“selector1,selector2,…,selectorN”)”，//将每个选择器匹配到的元素合并后一起返回。返回selector1匹配的集合+selector2匹配的集合+…+selectorN匹配的集合。 2.层次选择器什么是层次？层次就是父子关系、兄弟关系的节点。所以，层次选择器就是用来获取指定元素的父子节点、兄弟节点。 12341).“$(“ancestor descendant”)”，获取ancestor元素下边的所有元素。 2).“$(“parent &gt; child”)”，获取parent元素下边的所有子元素（只包含第一层子元素）。 3).“$(“pre + next”)”，获取紧随pre元素的后一个兄弟元素。 4).“$(“pre ~ siblings”)”，获取pre元素后边的所有兄弟元素。 3.过滤选择器过滤？肯定是要添加过滤条件的。通过“:”添加过滤条件，比如“$(“div:first”)”返回div元素集合的第一个div元素，first是过滤条件。按照不同的过滤规则，过滤选择器可以分为基本过滤，内容过滤，可见性过滤，属性过滤，子元素过滤和表单对象属性过滤选择器。 1). 基本过滤选择器 12345678910a) “:first”，选取第一个元素，别忘记它也是被放在一个集合里哦！因为JQuery它是DOM对象的一个集合。如，“$("tr:first")”返回所有tr元素的第一个tr元素，它仍然被保存在集合中。 b) “:last”，选取最后一个元素。如，“$("tr:last")”返回所有tr元素的最后一个tr元素，它仍然被保存在集合中。 c) “:not(selector)”，去除所有与给定选择器匹配的元素。如，“$("input:not(:checked)")”返回所有input元素，但去除被选中的元素（单选框、多选框）。 d) “:even”，选取所有元素中偶数的元素。因为JQuery对象是一个集合，这里的偶数指的就是集合的索引，索引从0开始。 e) “:odd”，选取所有元素中奇数的元素，索引从0开始。 f) “:eq(index)”，选取指定索引的元素，索引从0开始。 g) “:gt(index)”，选取索引大于指定index的元素，索引从0开始。 h) “:lt(index)”，选取索引小于指定index的元素，索引从0开始。 i) “:header”，选取所有的标题元素，如hq、h2等。 j) “:animated”，选取当前正在执行的所有动画元素。 2). 内容过滤选择器它是对元素和文本内容的操作。 1234a) “:contains(text)”，选取包含text文本内容的元素。 b) “:empty”，选取不包含子元素或者文本节点的空元素。 c) “:has(selector)”，选取含有选择器所匹配的元素的元素。 d) “:parent”，选取含有子元素或文本节点的元素。（它是一个父节点） 3). 可见性过滤选择器根据元素的可见与不可见状态来选取元素。 12345“:hidden”，选取所有不可见元素。 “:visible”，选择所有可见元素。 可见选择器：hidden 不仅包含样式属性 display 为 none 的元素，也包含文本隐藏域 (&lt;input type=“hidden”&gt;)和 visible:hidden 之类的元素。 4).属性过滤选择器通过元素的属性来选取相应的元素。 1234567a) “[attribute]”，选取拥有此属性的元素。 b) “[attribute=value]”，选取指定属性值为value的所有元素。 c) “[attribute !=value]”，选取属性值不为value的所有元素。 d) “[attribute ^= value]”，选取属性值以value开始的所有元素。 e) “[attribute $= value]”，选取属性值以value结束的所有元素。 f) “[attribute *= value]”，选取属性值包含value的所有元素。 g) “[selector1] [selector2]…[selectorN]”，复合性选择器，首先经[selector1]选择返回集合A，集合A再经过[selector2]选择返回集合B，集合B再经过[selectorN]选择返回结果集合。 5). 子元素过滤选择器一看名字便是，它是对某一元素的子元素进行选取的。 12345678a) “:nth-child(index/even/odd)”，选取索引为index的元素、索引为偶数的元素、索引为奇数的元素。 l nth-child(even/odd)：能选取每个父元素下的索引值为偶(奇)数的元素。 l nth-child(2)：能选取每个父元素下的索引值为 2 的元素。 l nth-child(3n)：能选取每个父元素下的索引值是 3 的倍数的元素。 l nth-child(3n + 1)：能选取每个父元素下的索引值是 3n + 1的元素。 b) “:first-child”，选取第一个子元素。 c) “:last-child”，选取最后一个子元素。 d) “:only-child”，选取唯一子元素，它的父元素只有它这一个子元素。 6). 表单过滤选择器选取表单元素的过滤选择器。 1234567891011a) “:input”，选取所有&lt;input&gt;、&lt;textarea&gt;、&lt;select &gt;和&lt;button&gt;元素。 b) “:text”，选取所有的文本框元素。 c) “:password”，选取所有的密码框元素。 d) “:radio”，选取所有的单选框元素。 e) “:checkbox”，选取所有的多选框元素。 f) “:submit”，选取所有的提交按钮元素。 g) “:image”，选取所有的图像按钮元素。 h) “:reset”，选取所有重置按钮元素。 i) “:button”，选取所有按钮元素。 j) “:file”，选取所有文件上传域元素。 k) “:hidden”，选取所有不可见元素。 7).表单对象属性过滤选择器选取表单元素属性的过滤选择器。 1234“:enabled”，选取所有可用元素。 “:disabled”，选取所有不可用元素。 “:checked”，选取所有被选中的元素，如单选框、复选框。 “:selected”，选取所有被选中项元素，如下拉列表框、列表框。 四、JQuery中的DOM操作一种与浏览器，平台，语言无关的接口。使用该接口可以轻松地访问页面中所有的标准组件。DOM Core：DOM Core 并不专属于 JavaScript，任何一种支持 DOM 的程序设计语言都可以使用它。它的用途并非仅限于处理网页，也可以用来处理任何一种是用标记语言编写出来的文档，例如：XML。HTML DOM：使用 JavaScript 和 DOM 为 HTML 文件编写脚本时，有许多专属于HTML-DOM的属性。CSS-DOM：针对于CSS操作，在JavaScript中，CSS-DOM 主要用于获取和设置 style 对象的各种属性。 1.查找节点请见上面的“基本选择器”。 2.创建节点使用JQuery的工厂函数，创建一个新节点：1var $newNode = $(“&lt;p&gt;你好&lt;/p&gt;”); 然后将新节点插入到指定元素节点处。 3.插入节点将新创建的节点，或获取的节点插入指定的位置。 12345678“$node.append($newNode)”，向每个匹配的元素内部的结尾处追加结尾处。如，“$("p").append("&lt;b&gt;Hello&lt;/b&gt;");”将"&lt;b&gt;Hello&lt;/b&gt;"添加到"p"内部的结尾处。 “$newNode.appendTo($node)”，将新元素追加到每个匹配元素内部的结尾处。 “$node.prepend($newNode)”，向每个匹配的元素内部的结尾处追加开始处。如，“$("p").prepend("&lt;b&gt;Hello&lt;/b&gt;");”将"&lt;b&gt;Hello&lt;/b&gt;"添加到"p"内部的起始处。 “$newNode.prependTo($node)”， 将新元素追加到每个匹配元素内部的开始处。 “$node.after($newNode)”，向每个匹配的元素的之后插入内容，是并列兄弟。如，“$("p").after("&lt;b&gt;Hello&lt;/b&gt;");”将"&lt;b&gt;Hello&lt;/b&gt;"插入到"p"的后边。它们是兄弟关系。 “$newNode.insertAfter($node)”，将新元素插入到每个匹配元素之后。 “$newNode.before($node)”，向每个匹配的元素的之前插入内容。如，“$("p").before("&lt;b&gt;Hello&lt;/b&gt;");”将"&lt;b&gt;Hello&lt;/b&gt;"插入到"p"的前面，它们是兄弟关系。 “$node.insertBefore($newNode)”，将新元素插入到每个匹配元素之前。 注意：如果插入的节点是不是新创建的，插入将变成移动操作。所以，在插入这样的节点之前应该使用clone的节点。 4.删除节点从DOM中删除所有匹配的元素。如，1$("p").remove(".hello"); 删除所为class属性值为hello的p元素，还有它下面的所有元素。 从DOM中清除所有匹配的元素。如，1$("p").empty(); 清除所有p元素，还有它下面的所有元素。 5.复制节点克隆匹配的DOM元素。如，1$("p").clone(); 返回克隆后的副本，但不具有任何行为。如果要将DOM的事件一起克隆，应该使用1$("p").clone(true); 6.替换节点将所有匹配的元素都替换为指定的 HTML 或 DOM 元素。如，1$("p").replaceWith("&lt;b&gt;Paragraph. &lt;/b&gt;"); 将所有p元素，替换为1"&lt;b&gt;Paragraph. &lt;/b&gt;" 与replaceWith相返：1$("&lt;b&gt;Paragraph. &lt;/b&gt;").replaceAll("p"); 7.包裹节点wrap()：将指定节点用其他标记包裹起来。该方法对于需要在文档中插入额外的结构化标记非常有用， 而且不会破坏原始文档的语义。如，1$("p").wrap("&lt;div class='wrap'&gt;&lt;/div&gt;"); 每个p元素被包裹到中。wrapAll()：将所有匹配的元素用一个元素来包裹。而wrap()方法是将所有的元素进行单独包裹。如，1$("p").wrapAll("&lt;div&gt;&lt;/div&gt;"); 将所有p元素包裹到中。wrapInner()：将每一个匹配的元素的子内容(包括文本节点)用其他结构化标记包裹起来。如，12$("p").wrapInner("&lt;b&gt;&lt;/b&gt;"); &lt;b&gt;被每一个p元素包裹。 8.属性设置attr()：获取属性和设置属性。当为该方法传递一个参数时，即为某元素的获取指定属性。如，1$("img").attr("src"); 获取img元素的src属性值。当为该方法传递两个参数时，即为某元素设置指定属性的值。如，1$("img").attr("src","test.jpg"); 设置img元素的src属性值为test.jsp。jQuery 中有很多方法都是一个函数实现获取和设置。如：attr()，html()，text()，val()，height()，width()，css()等。removeAttr()：删除指定元素的指定属性。 9.样式操作可以通过“attr()”设置或获取css样式。追加样式：addClass() 。如，1$("p").addClass("selected"); 向所有P元素中追加“selected”样式。移除样式：removeClass() — 从匹配的元素中删除全部或指定的class。如，1$("p").removeClass("selected"); 删除所有P元素中的“selected”。切换样式：toggleClass() — 控制样式上的重复切换。如果类名存在则删除它，如果类名不存在则添加它。如，1$("p").toggleClass("selected") 所有的P元素中，如果存在“selected”样式就删除“selected”样式，否则就添加“selected”样式。判断是否含有某个样式：hasClass() — 判断元素中是否含有某个 class，有返回 true； 否则返回 false。如，1$(this).hasClass("protected") 判断当前节点是否有“protected”样式。 10.设置或获取HTML、文本和值读取和设置某个元素中的 HTML 内容： html()，该方法可以用于 XHTML，但不能用于 XML 文档。读取和设置某个元素中的文本内容：text()，该方法既可以用于 XHTML 也可以用于 XML 文档。读取和设置某个元素中的值：val()，该方法类似 JavaScript 中的 value 属性。对于文本框，下拉列表框，单选框该方法可返回元素的值(多选框只能返回第一个值)。如果为多选下拉列表框，则返回一个包含所有选择值的数组。 11.常用遍历节点的方法取得匹配元素的所有子元素组成的集合：children()。该方法只考虑第一层子元素而不考虑任何后代元素。取得匹配元素后面紧邻的兄弟元素的集合(但集合中只有一个元素)：next()。取得匹配元素前面紧邻的兄弟元素的集合(但集合中只有一个元素)：prev()。取得匹配元素前后所有的兄弟元素: siblings()。 12.CSS-DOM操作获取和设置元素的样式属性：css()。获取和设置元素透明度：opacity()属性。获取和设置元素高度，宽度：height()，width()。在设置值时，若只传递数字，则默认单位是px。如需要使用其他单位则需传递一个字符串，例如 “$(“p:first”).height(“2em”)”；获取元素在当前视窗中的相对位移：offset()。它返回的对象包含了两个属性：top，left。该方法只对可见元素有效。 五、JQuery中的事件 1.加载DOM在页面加载完毕后，浏览器会通过 JavaScript 为 DOM 元素添加事件。在常规的 JavaScript 代码中，通常使用 window.onload 方法，在JQuery 中使用$(document).ready() 方法。JQuery中的简化写法“$()”。在window.onload中注册事件时，只能在一个window.onload体中注册。但使用JQuery，可以在多个$(document).ready()或$()中注册。 2.事件绑定对匹配的元素对指定的事件绑定。如，昨天我们在window.onload中绑定事件的方法：1$("p").onclick(function()&#123; alert( $(this).text() ); &#125;); 在JQuery的$(document).ready()中可以这样绑定：1$("p").click(function()&#123; alert( $(this).text() ); &#125;); 使用bind()，可以这样绑定：1$("p").bind("click", function()&#123; alert( $(this).text() ); &#125;); 3.合成事件hover()：模拟光标悬停时间。当光标移动到元素上时，会触发指定的第一个函数，当光标移出这个元素时，会触发指定的第二个函数。如，悬停效果：12$("td").hover( function () &#123;$(this).addClass("hover");&#125;, function () &#123;$(this).removeClass("hover");&#125;); toggle()：用于模拟鼠标连续单击事件。第一次单击元素，触发指定的第一个函数，当再一次单击同一个元素时，则触发指定的第二个函数，如果有更多个函数，则依次触发，直到最后一个。如，设置元素的选择与非选中效果：12("td").toggle( function () &#123;$(this).addClass("selected");&#125;, function () &#123;$(this).removeClass("selected");&#125;); 使用toggle()而不传递参数，效果为切换元素的可见状态。 4.事件的冒泡事件会按照 DOM 层次结构像水泡一样不断向上只止顶端。解决：在事件处理函数中返回 false，会对事件停止冒泡。还可以停止元素的默认行为。目前的所有UI交互或其事件，都支持这个特性。在自己的事件处理函数返回false将中止事件的继续向下传递。返回true事件继续向下传递。 5.事件对象的属性事件对象：当触发事件时，事件对象就被创建了。在程序中使用事件只需要为处理函数添加一个参数。在事件处理函数中使用些参数。如，获取事件发生时，相对于页面的位置：event.pageX, event.pageY，event是事件处理函数的参数。 6.移除事件移除某按钮上的所有click 事件：$(“btn”).unbind(“click”)移除某按钮上的所有事件：$(“btn”).unbind();one()：该方法可以为元素绑定处理函数。当处理函数触发一次后，事件立即被删除。即在每个对象上，事件处理函数只会被执行一次。 六、JQuery中的DOM动画通过设置DOM对象的显示与隐藏方式，可以产生动画效果。 1.无动画效果的隐藏与显示hide()：在HTML文档中，为一个元素调用hide()方法会将该元素的display样式改为none。代码功能同css(“display”, “none”);相同。show()：将元素的display样式改为先前的显示状态。toggle()：切换元素的可见状态：如果元素时可见的，则切换为隐藏；如果元素时隐藏的，则切换为可见的。 2.通过设置透明度效果的隐藏与显示，达到淡入淡出的动画效果fadeIn()，fadeOut()：只改变元素的透明度。fadeOut() 会在指定的一段时间内降低元素的不透明度，直到元素完全消失。fadeIn() 则相反。如，用600毫秒缓慢的将段落淡入：$(“p”).fadeIn(“slow”);。fadeTo()：把不透明度以渐近的方式调整到指定的值(0 – 1 之间)。并在动画完成后可选地触发一个回调函数。如，用200毫秒快速将段落的透明度调整到0.25，动画结束后，显示一个“Animation Done”信息框：1$("p").fadeTo("fast", 0.25, function()&#123; alert("Animation Done."); &#125;); 3.通过设置高度效果的隐藏与显示，达到滑下与收起的动画效果slideDown()，slideUp()：只会改变元素的高度。如果一个元素的display属性为none，当调用slideDown() 方法时，这个元素将由上至下延伸显示。slideUp() 方法正好相反，元素由下至上缩短隐藏。如，用600毫秒缓慢的将段落滑下：1$("p").slideDown("slow");。 slideToggle()：通过高度变化来切换匹配元素的可见性。如，200毫秒快速将段落滑上或滑下，动画结束后，会显示一个“Animation Done”信息框：1$("p").slideToggle("fast",function()&#123; alert("Animation Done."); &#125;); 使用JavaScript、JQuery可以处理当前页面的动态更新，再结合CSS样式可以做出十分漂亮的UI，甚至比桌面软件UI漂亮的多。JavaScript的编写与调试非常麻烦，所以也有一些公司出品了专门针对JavaScript应用的简化开发，比如Google出品的GWT，可以像使用Java编写swing那样编写JavaScript。它为用户提供像swing那样的UI接口与事件等操作并且支持JAVA的核心库。使用GWT自己的编译器，可以将JAVA代码编译为JavaScript代码、CSS样式文件和HTML。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Front End</tag>
        <tag>JQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些CSS选择器]]></title>
    <url>%2F2015%2F06%2F05%2Fsome-css-selector%2F</url>
    <content type="text"><![CDATA[一些CSS选择器1.*1234* &#123;margin: 0;padding: 0;&#125; 在我们看比较高级的选择器之前，应该认识下这个众所周知的清空选择器。星号呢会将页面上所有每一个元素都选到。许多开发者都用它来清空margin和padding。当然你在练习的时候使用这个没问题，但是我不建议在生产环境中使用它。它会给浏览器凭添许多不必要的东西。 *也可以用来选择某元素的所有子元素。 #id #container * { border: 1px solid black; } 它会选中#container下的所有元素。当然，我还是不建议你去使用它，如果可能的话。 DEMO 2. #X#container { width: 960px; margin: auto; } 在选择器中使用#可以用id来定位某个元素。大家通常都会这么使用，然后使用的时候大家还是得相当小心的。需要问自己一下：我是不是必须要给这个元素来赋值个id来定位它呢？ id选择器是很严格的并且你没办法去复用它。如果可能的话，首先试试用标签名字，HTML5中的新元素，或者是伪类。 DEMO 3. .X.error { color: red; } 这是个class选择器。它跟id选择器不同的是，它可以定位多个元素。当你想对多个元素进行样式修饰的时候就可以使用class。当你要对某个特定的元素进行修饰那就是用id来定位它。 DEMO 4. X Yli a { text-decoration: none; } 下一个常用的就是descendant选择器。如果你想更加具体的去定位元素，你可以使用它。例如，假如，你不需要定位所有的a元素，而只需要定位li标签下的a标签？这时候你就需要使用descendant选择器了。 专家提示：如果你的选择器像X Y Z A B.error这样，那你就错了。时刻都提醒自己，是否真的需要对那么多元素修饰。 DEMO 5. Xa { color: red; } ul { margin-left: 0; } 如果你想定位页面上所有的某标签，不是通过id或者是’class’，这简单，直接使用类型选择器。 DEMO 6. X:visited and X:linka:link {color:red;} a:visited {color: purple;} 我们使用:link这个伪类来定位所有还没有被访问过的链接。 另外，我们也使用:visited来定位所有已经被访问过的链接。 DEMO 7. X+Yul + p { color: red; } 这个叫相邻选择器。它指挥选中指定元素的直接后继元素。上面那个例子就是选中了所有ul标签后面的第一段，并将它们的颜色都设置为红色。 DEMO 8. X&gt;Ydiv#container &gt; ul { border: 1px solid black; } X Y和X &gt; Y的差别就是后面这个指挥选择它的直接子元素。看下面的例子： 123456789101112&lt;div id="container"&gt; &lt;ul&gt; &lt;li&gt; List Item &lt;ul&gt; &lt;li&gt; Child &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt; List Item &lt;/li&gt; &lt;li&gt; List Item &lt;/li&gt; &lt;li&gt; List Item &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt; #container &gt; ul只会选中id为’container’的div下的所有直接ul元素。它不会定位到如第一个li下的ul元素。 由于某些原因，使用子节点组合选择器会在性能上有许多的优势。事实上，当在javascript中使用css选择器时候是强烈建议这么做的。 DEMO 9. X ~ Yul ~ p { color: red; } 兄弟节点组合选择器跟X+Y很相似，然后它又不是那么的严格。ul + p选择器只会选择紧挨跟着指定元素的那些元素。而这个选择器，会选择跟在目标元素后面的所有匹配的元素。 DEMO 10. X[title]a[title] { color: green; } 这个叫属性选择器，上面的这个例子中，只会选择有title属性的元素。那些没有此属性的锚点标签将不会被这个代码修饰。那再想想如果你想更加具体的去筛选？那… DEMO 11. X[href=”foo”]a[href="http://strongme.cn"] { color: #1f6053; /* nettuts green */ } 上面这片代码将会把href属性值为http://strongme.cn的锚点标签设置为绿色，而其他标签则不受影响。 注意我们将值用双引号括起来了。那么在使用Javascript的时候也要使用双引号括起来。可以的话，尽量使用标准的CSS3选择器。 这样可以用了，但是还是有点死，如果不是这个链接，而是类似的链接，那么这时就得用正则表达式了。 DEMO 12. X[href*=”strongme”]a[href*="strongme"] { color: #1f6053; } Tada,正是我们需要的，这样，就指定了strongme这个值必须出现在锚点标签的href属性中，不管是strongme.cn还是strongme.com还是www.strongme.cn都可以被选中。但是记得这是个很宽泛的表达方式。如果锚点标签指向的不是strongme相关的站点，如果要更加具体的限制的话，那就使用^和$，分别表示字符串的开始和结束。 DEMO 13. X[href^=”href”]a[href^="http"] { background: url(path/to/external/icon.png) no-repeat; padding-left: 10px; } 大家肯定好奇过，有些站点的锚点标签旁边会有一个外链图标，我也相信大家肯定见过这种情况。这样的设计会很明确的告诉你会跳转到别的网站。用克拉符号就可以轻易做到。它通常使用在正则表达式中标识开头。如果我们想定位锚点属性href中以http开头的标签，那我们就可以用与上面相似的代码。 注意我们没有搜索http://，那是没必要的，因为它都不包含https://。 那如果我们想找到所有指向一张图片的锚点标签呢？那我们来使用下&amp;字符。 DEMO 14. X[href$=”.jpg”]a[href$=".jpg"] { color: red; } 这次我们又使用了正则表达式$，表示字符串的结尾处。这段代码的意思就是去搜索所有的图片链接，或者其它链接是以.jpg结尾的。但是记住这种写法是不会对gifs和pngs起作用的。 DEMO 15. X[data-*=”foo”]a[data-filetype="image"] { color: red; } 在回到第8条，我们如何把所有的图片类型都选中呢png,jpeg,’jpg’,’gif’？我们可以使用多选择器。看下面： a[href$=".jpg"], a[href$=".jpeg"], a[href$=".png"], a[href$=".gif"] { color: red; } 但是这样写着很蛋疼啊，而且效率会很低。另外一个办法就是使用自定义属性。我们可以给每个锚点加个属性data-filetype指定这个链接指向的图片类型。 &lt;a href="path/to/image.jpg" data-filetype="image"&gt; Image Link &lt;/a&gt; 那有了这个钩子，我们就可以去用标准的办法只去选定文件类型为image的锚点了。 a[data-filetype="image"] { color: red; } DEMO 16. X[foo~=”bar”]a[data-info~="external"] { color: red; } a[data-info~="image"] { border: 1px solid black; } 这个我想会让你的小伙伴惊呼妙极了。很少有人知道这个技巧。这个~符号可以定位那些某属性值是空格分隔多值的标签。继续使用第15条那个例子，我们可以设置一个data-info属性，它可以用来设置任何我们需要的空格分隔的值。这个例子我们将指示它们为外部连接和图片链接。 &lt;a href="path/to/image.jpg" data-info="external image"&gt; Click Me, Fool &lt;/a&gt; 给这些元素设置了这个标志之后，我们就可以使用~来定位这些标签了。 123456789/* Target data-info attr that contains the value "external" */a[data-info~="external"] &#123; color: red;&#125; /* And which contain the value "image" */a[data-info~="image"] &#123; border: 1px solid black;&#125; 17. X:checkedinput[type=radio]:checked { border: 1px solid black; } 上面这个伪类写法可以定位那些被选中的单选框和多选框，就是这么简单。 DEMO 18. X:after before和after这俩伪类。好像每天大家都能找到使用它们的创造性方法。它们会在被选中的标签周围生成一些内容。当使用.clear-fix技巧时许多属性都是第一次被使用到里面的。 12345678910111213.clearfix:after &#123; content: ""; display: block; clear: both; visibility: hidden; font-size: 0; height: 0; &#125;.clearfix &#123; *display: inline-block; _height: 1%;&#125; 上面这段代码会在目标标签后面补上一段空白，然后将它清除。这个方法你一定得放你的聚宝盆里面。特别是当overflow:hidden方法不顶用的时候，这招就特别管用了。还想看其他创造性的使用这个伪类，看这里。 根据CSS3标准规定，可以使用两个冒号::。然后为了兼容性，浏览器也会接受一个双引号的写法。其实在这个情况下，用一个冒号还是比较明智的。 19. X::hoverdiv:hover { background: #e3e3e3; } 不用说，大家肯定知道它。官方的说法是user action pseudo class.听起来有点儿迷糊，其实还好。如果想在用户鼠标飘过的地方涂点儿彩，那这个伪类写法可以办到。 注意旧版本的IE只会对加在锚点a标签上的:hover伪类起作用。 通常大家在鼠标飘过锚点链接时候加下边框的时候用到它。 12345a:hover &#123; border-bottom: 1px solid black;&#125;//专家提示：border-bottom:1px solid black;比text-decoration:underline; //要好看很多。 20. X:not(selector)div:not(#container) { color: blue; } 取反伪类是相当有用的，假设我们要把除id为container之外的所有div标签都选中。那上面那么代码就可以做到。 或者说我想选中所有出段落标签之外的所有标签。 *:not(p) { color: green; } DEMO 21. X::pseudoElementp::first-line { font-weight: bold; font-size:1.2em; } 我们可以使用::来选中某标签的部分内容，如地一段，或者是第一个字没有。但是记得必须使用在块式标签上才起作用。 伪标签是由两个冒号::组成的。 定位第一个字 p::first-letter { float: left; font-size: 2em; font-weight: bold; font-family: cursive; padding-right: 2px; } 上面这段代码会找到页面上所有段落，并且指定为每一段的第一个字。 它通常在一些新闻报刊内容的重点突出会使用到。 定位某段的第一行 p::first-line { font-weight: bold; font-size: 1.2em; } 跟::first-line相似，会选中段落的第一行 。 为了兼容性，之前旧版浏览器也会兼容单冒号的写法，例如:first-line,:first-letter,:before,:after.但是这个兼容对新介绍的特性不起作用。 DEMO 22. X:nth-child(n)li:nth-child(3) { color: red; } 还记得我们面对如何取到推跌式标签的第几个元素是无处下手的时光么，有了nth-child那日子就一去不复返了。 请注意nth-child接受一个整形参数，然后它不是从0开始的。如果你想获取第二个元素那么你传的值就是li:nth-child(2). 我们甚至可以获取到由变量名定义的个数个子标签。例如我们可以用li:nth-child(4n)去每隔3个元素获取一次标签。 DEMO 23. X:nth-last-child(n)li:nth-last-child(2) { color: red; } 假设你在一个ul标签中有N多的元素，而你只想获取最后三个元素，甚至是这样li:nth-child(397)，你可以用nth-last-child伪类去代替它。 这个技巧可以很正确的代替第16个TIP，不同的就是它是从结尾处开始的，倒回去的。 DEMO 24. X:nth-of-type(n)ul:nth-of-type(3) { border: 1px solid black; } 曾几何时，我们不想去选择子节点，而是想根据元素的类型来进行选择。 想象一下有5个ul标签。如果你只想对其中的第三个进行修饰，而且你也不想使用id属性，那你就可以使用nth-of-type(n)伪类来实现了，上面的那个代码，只有第三个ul标签会被设置边框。 DEMO 25. X:nth-last-of-type(n)ul:nth-last-of-type(3) { border: 1px solid black; } 同样，也可以类似的使用nth-last-of-type来倒序的获取标签。 26. X:first-childul li:first-child { border-top: none; } 这个结构性的伪类可以选择到第一个子标签，你会经常使用它来取出第一个和最后一个的边框。 假设有个列表，没个标签都有上下边框，那么效果就是第一个和最后一个就会看起来有点奇怪。这时候就可以使用这个伪类来处理这种情况了。 DEMO 27. X:last-childul &gt; li:last-child { color: green; } 跟first-child相反，last-child取的是父标签的最后一个标签。 例如标签 12345678910111213141516171819&lt;ul&gt; &lt;li&gt; List Item &lt;/li&gt; &lt;li&gt; List Item &lt;/li&gt; &lt;li&gt; List Item &lt;/li&gt;&lt;/ul&gt;ul &#123; width: 200px; background: #292929; color: white; list-style: none; padding-left: 0;&#125;li &#123; padding: 10px; border-bottom: 1px solid black; border-top: 1px solid #3c3c3c;&#125; 上面的代码将设置背景色，移除浏览器默认的内边距，为每个li设置边框以凸显一定的深度。 DEMO 28. X:only-childdiv p:only-child { color: red; } 说实话，你会发现你几乎都不会用到这个伪类。然而，它是可用的，有会需要它的。 它允许你获取到那些只有一个子标签的父标签。就像上面那段代码，只有一个段落标签的div才被着色。 &lt;div&gt;&lt;p&gt; My paragraph here. &lt;/p&gt;&lt;/div&gt; &lt;div&gt; &lt;p&gt; Two paragraphs total. &lt;/p&gt; &lt;p&gt; Two paragraphs total. &lt;/p&gt; &lt;/div&gt; 上面例子中，第二个div不会被选中。一旦第一个div有了多个子段落，那这个就不再起作用了。 DEMO 29. X:only-of-typeli:only-of-type { font-weight: bold; } 结构性伪类可以用的很聪明。它会定位某标签只有一个子标签的目标。设想你想获取到只有一个子标签的ul标签？ 使用ul li会选中所有li标签。这时候就要使用only-of-type了。 ul &gt; li:only-of-type { font-weight: bold; } DEMO 30. X:first-of-type first-of-type伪类可以选择指定标签的第一个兄弟标签。 测试 123456789101112&lt;div&gt; &lt;p&gt; My paragraph here. &lt;/p&gt; &lt;ul&gt; &lt;li&gt; List Item 1 &lt;/li&gt; &lt;li&gt; List Item 2 &lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li&gt; List Item 3 &lt;/li&gt; &lt;li&gt; List Item 4 &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; 来你把List Item 2取出来，如果你已经取出来或者是放弃了，来继续。 解决办法1 办法很多，我们看一些比较方便的。首先是first-of-type。 ul:first-of-type &gt; li:nth-child(2) { font-weight: bold; } DEMO 找到第一个ul标签，然后找到直接子标签li，然后找到第二个子节点。 解决办法2 另一个解决办法就是邻近选择器。 p + ul li:last-child { font-weight: bold; } 这种情况下，找到p下的直接ul标签，然后找到它的最后一个直接子标签。 解决办法3 我们可以随便玩耍这些选择器。来看看： ul:first-of-type li:nth-last-child(1) { font-weight: bold; } 先获取到页面上第一个ul标签，然后找到最后一个子标签。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>Front End</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[router-testbench注解]]></title>
    <url>%2F2015%2F04%2F15%2Frouter-testbench-note%2F</url>
    <content type="text"><![CDATA[&lt;– 纯源码注解，于他人无意义 –&gt; 基础知识： credit流控机制相关 wormhole router相关 flit-buffer&amp;routing algorithm 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595`timescale 1ns / 1psmodule top (clk, reset, count_en,router_address, run,error,clk_en,count_in_flits, count_out_flits,in_flits,out_flits,in_creds); `include "c_functions.v"`include "c_constants.v"`include "rtr_constants.v"`include "vcr_constants.v"`include "parameters.v" /*时钟与初始值设置*/ parameter Tclk = 2; parameter initial_seed = 0; // maximum number of packets to generate (-1 = no limit) //生成的最大数据包数目 ，值为-1时为无限制 parameter max_packet_count = -1; //数据包注入速率（周期百分比） parameter packet_rate = 25; // 微片消耗速率（周期百分比） parameter consume_rate = 50; // 记录包数目寄存器的宽度 parameter packet_count_reg_width = 32; // 周期间的信道延迟 parameter channel_latency = 1; //是否只在在节点端口注入 parameter inject_node_ports_only = 1; //周期间的预热时间 parameter warmup_time = 100; //周期间的测量间隔 parameter measure_time = 10000; //选择包长度模式 0：均匀随机 1： 双峰 parameter packet_length_mode = 0; //选择一个资源种类需要的寄存器宽度 localparam resource_class_idx_width = clogb(num_resource_classes); //包的种类数目 localparam num_packet_classes = num_message_classes * num_resource_classes; //虚拟信道数目 localparam num_vcs = num_packet_classes * num_vcs_per_class; //选择一个虚拟信道需要的寄存器宽度 localparam vc_idx_width = clogb(num_vcs); //总的路由器数目 localparam num_routers = (num_nodes + num_nodes_per_router - 1) / num_nodes_per_router; //单位纬度路由器的数目 localparam num_routers_per_dim = croot(num_routers, num_dimensions); //在单位面积选择一个路由器需要的寄存器宽度 localparam dim_addr_width = clogb(num_routers_per_dim); // width required to select individual router in entire network localparam router_addr_width = num_dimensions * dim_addr_width; //在整个网络中选择一个路由器需要的寄存器宽度 // connectivity within each dimension localparam connectivity //单位面积上互联的类别 根据拓扑结构分为线性、环形、全互联 = (topology == `TOPOLOGY_MESH) ? `CONNECTIVITY_LINE : (topology == `TOPOLOGY_TORUS) ? `CONNECTIVITY_RING : (topology == `TOPOLOGY_FBFLY) ? `CONNECTIVITY_FULL : -1; // number of adjacent routers in each dimension localparam num_neighbors_per_dim //单位面积上路由器相邻的路由器节点 根据互联类别分为2和total_num-1 = ((connectivity == `CONNECTIVITY_LINE) || (connectivity == `CONNECTIVITY_RING)) ? 2 : (connectivity == `CONNECTIVITY_FULL) ? (num_routers_per_dim - 1) : -1; // number of input and output ports on router //路由器的输入输出端口数目 num_port=input+output+locals localparam num_ports = num_dimensions * num_neighbors_per_dim + num_nodes_per_router; // width required to select individual port //选择一个单独的端口需要的寄存器宽度 localparam port_idx_width = clogb(num_ports); // width required to select individual node at current router //当前的路由器上选择一个节点需要的寄存器宽度.每个路由器对应着多个node节点 localparam node_addr_width = clogb(num_nodes_per_router); // width required for lookahead routing information localparam lar_info_width = port_idx_width + resource_class_idx_width; //预测的先行路由信息的寄存器宽度 // total number of bits required for storing routing information localparam dest_info_width //存储路由信息所需的总共的比特数 目的节点 = (routing_type == `ROUTING_TYPE_PHASED_DOR) ? (num_resource_classes * router_addr_width + node_addr_width) : -1; // total number of bits required for routing-related information localparam route_info_width = lar_info_width + dest_info_width; //存储相关的路由信息所需的比特数 预测先行的+目的节点的 // width of flow control signals localparam flow_ctrl_width //流量控制信号宽度 = (flow_ctrl_type == `FLOW_CTRL_TYPE_CREDIT) ? (1 + vc_idx_width) : -1; // width of link management signals //链路管理信号宽度 localparam link_ctrl_width = enable_link_pm ? 1 : 0; // width of flit control signals //微片控制信号宽度 localparam flit_ctrl_width = (packet_format == `PACKET_FORMAT_HEAD_TAIL) ? (1 + vc_idx_width + 1 + 1) : (packet_format == `PACKET_FORMAT_TAIL_ONLY) ? (1 + vc_idx_width + 1) : (packet_format == `PACKET_FORMAT_EXPLICIT_LENGTH) ? (1 + vc_idx_width + 1) : -1; // channel width //信道宽度=链路控制宽度+微片控制宽度+微片数据宽度 localparam channel_width = link_ctrl_width + flit_ctrl_width + flit_data_width; // use atomic VC allocation //是否使用原子虚拟信道分配 localparam atomic_vc_allocation = (elig_mask == `ELIG_MASK_USED); // number of pipeline stages in the channels //信道的流水线级数 localparam num_channel_stages = channel_latency - 1; /*Module parameters setting*/ /*input*/ input clk;//时钟信号 input reset;//重置信号 input count_en;//是否进行计数 input [0:router_addr_width-1] router_address; //路由器地址 input run;//是否开始进行路由 input clk_en;//时钟准许信号 //input [0:num_ports*flow_ctrl_width-1] flow_ctrl_in_op; //input [0:num_ports*flow_ctrl_width-1] flow_ctrl_out_ip; /*input*/ /*output*/ output error; wire error; //packet_source 错误 //记录的接收微片数目，发送的微片数目 output [0:31] count_in_flits, count_out_flits; wire [0:31] count_in_flits_s, count_in_flits_q; //基于信用的流控变量 output [0:31] in_creds; wire [0:31] in_creds; //总共生成的 接收微片、发送微片 in_flits&gt;=count_in_flits out_flits&gt;=count_out_flits output [0:31] in_flits,out_flits; wire [0:31] in_flits,out_flits; /*output*/ wire [0:num_ports*channel_width-1] channel_in_ip; //接收端的接受信道 wire [0:num_ports*flow_ctrl_width-1] flow_ctrl_out_ip; //接收端的输出流量控制 wire [0:num_ports-1] flit_valid_in_ip; //接收端接受微片验证 wire [0:num_ports-1] cred_valid_out_ip; //接收端发送信用验证 wire [0:num_ports*channel_width-1] channel_out_op; //发送端信道 wire [0:num_ports*flow_ctrl_width-1] flow_ctrl_in_op; //发送端接受的流量控制 wire [0:num_ports-1] flit_valid_out_op; //发送端发送的微片验证 wire [0:num_ports-1] cred_valid_in_op; //发送端接受信用验证 wire [0:num_ports-1] ps_error_ip; //packet_source 错误 //--------------------------------------------------------------------------- // input ports //--------------------------------------------------------------------------- //模拟输入端的一些行为 由于本程序是对单个router实例操作，这里就是模拟其他通信节点转发的微片以及本子生成微片 generate genvar ip; for(ip = 0; ip &lt; num_ports; ip = ip + 1) //接收端端口从0开始 begin:ips //------------------------------------------------------------------- // input controller //------------------------------------------------------------------- wire [0:flow_ctrl_width-1] flow_ctrl_out; //当前接收端口的输出流量控制 assign flow_ctrl_out = flow_ctrl_out_ip[ip*flow_ctrl_width: (ip+1)*flow_ctrl_width-1]; //flow_ctrl_out_ip里面存放的是所有端口的输出流量控制 //flow_ctrl_out_ip 输入端的输出流控信息（向上游路由器发送的流控信息） assign cred_valid_out_ip[ip] = flow_ctrl_out[0]; //当前接受端口的输出流量控制第一位存放的就是信用验证 if(inject_node_ports_only &amp;&amp; (ip &lt; (num_ports-num_nodes_per_router)))//当前接收端口号&lt;（总端口数-每个路由器管理的节点数，即除了本地节点外的总的端口数目）剩余可分配给其他的数目 begin//除了本地节点外的所有端口都按照此进行，其他节点转发到本router的处理 assign channel_in_ip[ip*channel_width:(ip+1)*channel_width-1] //接收端输入信道值=000000 = &#123;channel_width&#123;1'b0&#125;&#125;; assign flit_valid_in_ip[ip] = 1'b0; // 接收端接收微片验证值=0 assign ps_error_ip[ip] = 1'b0; //接收端包报错=0 end else //本地资源处理 在本地节点随机产生分组数据 begin wire [0:flow_ctrl_width-1] flow_ctrl_dly; //如果当前接收端口号码&gt;每个路由器管理的节点数目 也就是前面接收端口占完了 c_shift_reg //延迟-流量控制 dly-delay #(.width(flow_ctrl_width), .depth(num_channel_stages), .reset_type(reset_type)) flow_ctrl_dly_sr (.clk(clk), .reset(reset), .active(1'b1), .data_in(flow_ctrl_out), .data_out(flow_ctrl_dly)); wire [0:channel_width-1] channel; wire flit_valid; wire ps_error; //伪随机在本地节点生成指定数量的数据分组 packet_source #(.initial_seed(initial_seed+ip), //初始种子 .max_packet_count(max_packet_count), //生成的最大的包数目，-1为无限制 .packet_rate(packet_rate), //每周期 包的注入速率 .packet_count_reg_width(packet_count_reg_width), //记录包数目的寄存器宽度 .packet_length_mode(packet_length_mode), //选择包长度的模式 均匀随机还是双峰分布 .topology(topology), //片上网络拓扑结构 .buffer_size(buffer_size), //缓存容量 .num_message_classes(num_message_classes), //消息种类的类别 比如 请求、回复 .num_resource_classes(num_resource_classes), //选择资源的种类 比如 最小的、自适应的 .num_vcs_per_class(num_vcs_per_class), //每一类的虚拟信道数目 .num_nodes(num_nodes), //节点数目 .num_dimensions(num_dimensions), //维序数目 .num_nodes_per_router(num_nodes_per_router), //每个路由器分管的节点数 .packet_format(packet_format), //数据包编码格式 .flow_ctrl_type(flow_ctrl_type), //流量控制类别 实际上只有基于credit的流控是支持的 .flow_ctrl_bypass(flow_ctrl_bypass), //credit是在credit到达的时候立即更新还是在下一个时钟周期更新，直接影响关键路径的延迟 .max_payload_length(max_payload_length), //数据包分组最大的微片负载数目 .min_payload_length(min_payload_length), //数据包分组最小的微片负载数目 .enable_link_pm(enable_link_pm), //是否启用链路功率管理 .flit_data_width(flit_data_width), .routing_type(routing_type),//选择路由逻辑 只支持一维或多维的维序路由 .dim_order(dim_order), .fb_mgmt_type(fb_mgmt_type), //微片缓存管理模式 .disable_static_reservations(disable_static_reservations), //动态缓存管理相关 .elig_mask(elig_mask), //选择是否从虚拟信道分配中排除满或非空虚拟信道 .port_id(ip), //which router port is this packet source attached to 哪个路由器端口数这个数据包连接 .reset_type(reset_type)) ps (.clk(clk), .reset(reset), .router_address(router_address), //目前路由器的地址 .channel(channel), //输出 .flit_valid(flit_valid), //输出 .flow_ctrl(flow_ctrl_dly), .run(run), //伪随机数据包 .error(ps_error)); //输出 assign ps_error_ip[ip] = ps_error; wire [0:channel_width-1] channel_dly; //延迟信道 c_shift_reg #(.width(channel_width), .depth(num_channel_stages), .reset_type(reset_type)) channel_dly_sr (.clk(clk), .reset(reset), .active(1'b1), .data_in(channel), .data_out(channel_dly)); assign channel_in_ip[ip*channel_width:(ip+1)*channel_width-1] = channel_dly; wire flit_valid_dly; //延迟微片验证 c_shift_reg #(.width(1), .depth(num_channel_stages), .reset_type(reset_type)) flit_valid_dly_sr (.clk(clk), .reset(reset), .active(1'b1), .data_in(flit_valid), .data_out(flit_valid_dly)); assign flit_valid_in_ip[ip] = flit_valid_dly; end end endgenerate wire rtr_error;//根据拓扑结构、路由器结构、数据包源目的地址完成分组的routing logic、virtual channel allocate、switch allocate、switch crossbar//一个完整的路由实例 router_wrap #(.topology(topology), //拓扑结构 .buffer_size(buffer_size), //缓存数量 .num_message_classes(num_message_classes), //消息种类数目 .num_resource_classes(num_resource_classes), //资源种类数目 .num_vcs_per_class(num_vcs_per_class), //每类的虚拟信道 .num_nodes(num_nodes), //总的节点数目 .num_dimensions(num_dimensions), //维序数目 .num_nodes_per_router(num_nodes_per_router), //每个路由器分管的节点数目 .packet_format(packet_format), //包的编码格式 .flow_ctrl_type(flow_ctrl_type), //流量控制类别 这里只支持基于credit的 .flow_ctrl_bypass(flow_ctrl_bypass), //credit是在credit到达的时候立即更新还是在下一个时钟周期更新，直接影响关键路径的延迟 .max_payload_length(max_payload_length), //最大负载的微片数目 .min_payload_length(min_payload_length), //最低负载的微片数目 .router_type(router_type), //路由器类别 是将VC与开关分配分开还是结合虚信道与开关分配的类型 .enable_link_pm(enable_link_pm), //是否启用链路功率管理 如果启用，可以使下游的router的接收逻辑能够clock_gated .flit_data_width(flit_data_width), //微片数据宽度 .error_capture_mode(error_capture_mode), //开启、配置路由器中的错误检测逻辑 .restrict_turns(restrict_turns), //基于路由转向限制的综合优化 .predecode_lar_info(predecode_lar_info), //前缀解析信息 .routing_type(routing_type), //路由算法种类 只支持一维多维的维序路由 .dim_order(dim_order), //选择维序的遍历顺序 .input_stage_can_hold(input_stage_can_hold), //将输入寄存器作为部分的微片缓存use input register as part of the flit buffer .fb_regfile_type(fb_regfile_type), //选择微片缓存寄存器文件类别的实现变种 .fb_mgmt_type(fb_mgmt_type), //微片缓存管理模式 .explicit_pipeline_register(explicit_pipeline_register), //是否使用明确的管道寄存器在缓存和交叉开关 .dual_path_alloc(dual_path_alloc), //是否双重路径分配 .dual_path_allow_conflicts(dual_path_allow_conflicts), //解决因为双重路径分配后的输出冲突 .dual_path_mask_on_ready(dual_path_mask_on_ready), //如果有任何的slow路径请求已就绪就遮盖fast路径请求 .precomp_ivc_sel(precomp_ivc_sel), //预先一个时钟周期计算输入端仲裁结果 .precomp_ip_sel(precomp_ip_sel), //预先一个时钟周期计算输出端仲裁结果 .elig_mask(elig_mask), //选择是否从虚拟信道分配中排除满或非空虚拟信道 .vc_alloc_type(vc_alloc_type), //虚拟信道分配类型 .vc_alloc_arbiter_type(vc_alloc_arbiter_type), //虚拟信道分配仲裁类型 .vc_alloc_prefer_empty(vc_alloc_prefer_empty), //在虚拟信道分配中是否更偏向于空的虚拟信道相比非空虚拟信道 .sw_alloc_type(sw_alloc_type), //开关分配类型 .sw_alloc_arbiter_type(sw_alloc_arbiter_type), //开关分配仲裁类别 .sw_alloc_spec_type(sw_alloc_spec_type), //选择开关分配的预测类型 .crossbar_type(crossbar_type), //交叉开关分配 .reset_type(reset_type)) //重置类型 同步：异步 rtr (.clk(clk), .reset(reset), .router_address(router_address), .channel_in_ip(channel_in_ip), .flow_ctrl_out_ip(flow_ctrl_out_ip), //输出 路由器逻辑完成后更新的返回到接收端的流控信息 .channel_out_op(channel_out_op), //输出 输出时的信道 channel_out_op=link_ctrl+flow_ctrl+flit_data .flow_ctrl_in_op(flow_ctrl_in_op), //输入参数 输出端接收到的下游路由器发送的流控信息 .error(rtr_error)); //输出 /*单路由器内部工作完成*/ wire rchk_error; //模块可以注释掉 router_checker #(.buffer_size(buffer_size), //缓冲大小 .num_message_classes(num_message_classes), //消息类别数目 request、reply .num_resource_classes(num_resource_classes), //资源类别数目 简单的、自适应的 .num_vcs_per_class(num_vcs_per_class), //每个类别虚拟信道数量 .num_routers_per_dim(num_routers_per_dim), //单位面积路由器数目 .num_dimensions(num_dimensions), //面积 .num_nodes_per_router(num_nodes_per_router), //路由器分管节点 .connectivity(connectivity), //互联种类 .packet_format(packet_format), //数据包格式 均匀随机、双峰随机 .max_payload_length(max_payload_length), //最大负载长度 .min_payload_length(min_payload_length),//最小负载长度 .enable_link_pm(enable_link_pm), //是否启用链路功率管理 .flit_data_width(flit_data_width), //微片数据宽度 .error_capture_mode(error_capture_mode), //error检测的逻辑配置 .routing_type(routing_type), //路由算法类型 .dim_order(dim_order), //维序遍历顺序 .reset_type(reset_type)) //reset类别 rchk (.clk(clk), //input .reset(reset), //input .router_address(router_address), //input 当前路由器地址 .channel_in_ip(channel_in_ip), //input 输入信道 .channel_out_op(channel_out_op), //input 输出信道 .error(rchk_error)); //output 错误 wire [0:num_ports-1] fs_error_op; genvar op; //模拟输出端口作用 由于本程序是对单个router实例操作，这里模拟发送到其余通信节点路由器以及本子资源节点 generate for(op = 0; op &lt; num_ports; op = op + 1) begin:ops wire [0:channel_width-1] channel_out; assign channel_out = channel_out_op[op*channel_width: (op+1)*channel_width-1]; wire [0:flit_ctrl_width-1] flit_ctrl_out; assign flit_ctrl_out = channel_out[link_ctrl_width:link_ctrl_width+flit_ctrl_width-1]; assign flit_valid_out_op[op] = flit_ctrl_out[0]; wire [0:channel_width-1] channel_dly; c_shift_reg #(.width(channel_width), .depth(num_channel_stages), .reset_type(reset_type)) channel_dly_sr (.clk(clk), .reset(reset), .active(1'b1), .data_in(channel_out), .data_out(channel_dly)); wire [0:flow_ctrl_width-1] flow_ctrl; wire fs_error; flit_sink //汇聚节点微片控制 #(.initial_seed(initial_seed + num_ports + op), .consume_rate(consume_rate), //微片消耗速率 .buffer_size(buffer_size), .num_vcs(num_vcs), .packet_format(packet_format), .flow_ctrl_type(flow_ctrl_type), .max_payload_length(max_payload_length), .min_payload_length(min_payload_length), .route_info_width(route_info_width), //存储相关的路由信息所需的比特数 .enable_link_pm(enable_link_pm), //是否启用链路功率管理 .flit_data_width(flit_data_width), .fb_regfile_type(fb_regfile_type), //选择微片缓存寄存器文件类别的实现变种 .fb_mgmt_type(fb_mgmt_type), //微片缓存管理模式 .atomic_vc_allocation(atomic_vc_allocation), //是否使用原子虚拟信道分配 .reset_type(reset_type)) fs (.clk(clk), .reset(reset), .channel(channel_dly), .flow_ctrl(flow_ctrl), //output .error(fs_error)); //output assign fs_error_op[op] = fs_error; wire [0:flow_ctrl_width-1] flow_ctrl_dly; //延迟流量控制 c_shift_reg #(.width(flow_ctrl_width), .depth(num_channel_stages), .reset_type(reset_type)) flow_ctrl_in_sr (.clk(clk), .reset(reset), .active(1'b1), .data_in(flow_ctrl), .data_out(flow_ctrl_dly)); assign flow_ctrl_in_op[op*flow_ctrl_width:(op+1)*flow_ctrl_width-1] = flow_ctrl_dly; assign cred_valid_in_op[op] = flow_ctrl_dly[0]; end endgenerate wire [0:2] tb_errors; //3bit 分别是 数据包error、微片汇聚error、路由错误 assign tb_errors = &#123;|ps_error_ip, |fs_error_op, rchk_error&#125;; wire tb_error; assign tb_error = |tb_errors; wire [0:31] in_flits_s, in_flits_q; assign in_flits_s = in_flits_q + pop_count(flit_valid_in_ip); c_dff #(.width(32), .reset_type(reset_type)) in_flitsq (.clk(clk), .reset(reset), .active(1'b1), .d(in_flits_s), .q(in_flits_q)); assign in_flits = in_flits_s; wire [0:31] in_creds_s, in_creds_q; assign in_creds_s = in_creds_q + pop_count(cred_valid_out_ip); c_dff #(.width(32), .reset_type(reset_type)) in_credsq (.clk(clk), .reset(reset), .active(1'b1), .d(in_creds_s), .q(in_creds_q)); assign in_creds = in_creds_q; wire [0:31] out_flits_s, out_flits_q; assign out_flits_s = out_flits_q + pop_count(flit_valid_out_op); c_dff #(.width(32), .reset_type(reset_type)) out_flitsq (.clk(clk), .reset(reset), .active(1'b1), .d(out_flits_s), .q(out_flits_q)); assign out_flits = out_flits_s; wire [0:31] out_creds_s, out_creds_q; assign out_creds_s = out_creds_q + pop_count(cred_valid_in_op); c_dff #(.width(32), .reset_type(reset_type)) out_credsq (.clk(clk), .reset(reset), .active(1'b1), .d(out_creds_s), .q(out_creds_q)); wire [0:31] out_creds; assign out_creds = out_creds_q; assign count_in_flits_s = count_en ? count_in_flits_q + pop_count(flit_valid_in_ip) : count_in_flits_q; c_dff #(.width(32), .reset_type(reset_type)) count_in_flitsq (.clk(clk), .reset(reset), .active(1'b1), .d(count_in_flits_s), .q(count_in_flits_q)); wire [0:31] count_in_flits; assign count_in_flits = count_in_flits_s; wire [0:31] count_out_flits_s, count_out_flits_q; assign count_out_flits_s = count_en ? count_out_flits_q + pop_count(flit_valid_out_op) : count_out_flits_q; c_dff #(.width(32), .reset_type(reset_type)) count_out_flitsq (.clk(clk), .reset(reset), .active(1'b1), .d(count_out_flits_s), .q(count_out_flits_q)); wire [0:31] count_out_flits; assign count_out_flits = count_out_flits_s; assign error=rtr_error|tb_error; always @(posedge clk) begin if(rtr_error) begin $display("internal error detected, cyc=%d", $time); $stop; end if(tb_error) begin $display("external error detected, cyc=%d", $time); $stop; end end endmodule]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于ISE的实现]]></title>
    <url>%2F2015%2F04%2F12%2Fise-implements%2F</url>
    <content type="text"><![CDATA[所谓实现（Implement）是将综合输出的逻辑网表翻译成所选器件的底层模块与硬件原语，将设计映射到器件结构上，进行布局布线，达到在选定器件上实现设计的目的。实现主要分为3个步骤：翻译（Translate）逻辑网表，映射（Map）到器件单元与布局布线（Place &amp; Route）。翻译的主要作用是将综合输出的逻辑网表翻译为Xilinx特定器件的底层结构和硬件原语（具体的原语详见第3章中的原语介绍）。映射的主要作用是将设计映射到具体型号的器件上（LUT、FF、Carry等）。布局布线步骤调用Xilinx布局布线器，根据用户约束和物理约束，对设计模块进行实际的布局，并根据设计连接，对布局后的模块进行布线，产生FPGA/CPLD配置文件。 翻译过程在翻译过程中，设计文件和约束文件将被合并生成NGD（原始类型数据库）输出文件和BLD文件，其中NGD文件包含了当前设计的全部逻辑描述，BLD文件是转换的运行和结果报告。实现工具可以导入EDN、EDF、EDIF、SEDIF格式的设计文件，以及UCF（用户约束文件）、NCF（网表约束文件）、NMC（物理宏库文件）、NGC（含有约束信息的网表）格式的约束文件。翻译项目包括3个命令： [Translation Report]用以显示翻译步骤的报告； [Floorplan Design]用以启动Xilinx布局规划器（Floorplanner）进行手动布局，提高布局器效率； [Generate Post-Translate Simulation Model]用以产生翻译步骤后仿真模型，由于该仿真模型不包含实际布线时延，所以有时省略此仿真步骤。 映射过程在映射过程中，由转换流程生成的NGD文件将被映射为目标器件的特定物理逻辑单元，并保存在NCD（展开的物理设计数据库）文件中。映射的输入文件包括NGD、NMC、NCD和MFP（映射布局规划器）文件，输出文件包括NCD、PCF（物理约束文件）、NGM和MRP（映射报告）文件。其中MRP文件是通过Floorplanner生成的布局约束文件，NCD文件包含当前设计的物理映射信息，PCF文件包含当前设计的物理约束信息，NGM文件与当前设计的静态时序分析有关，MRP文件是映射的运行报告，主要包括映射的命令行参数、目标设计占用的逻辑资源、映射过程中出现的错误和告警、优化过程中删除的逻辑等内容。映射项目包括如下命令： [Map Report]用以显示映射步骤的报告； [Generate Post-Map Static Timing]产生映射静态时序分析报告，启动时序分析器（Timing Analyzer）分析映射后静态时序； [Manually Place &amp; Route （FPGA Editor）]用以启动FPGA底层编辑器进行手动布局布线，指导Xilinx自动布局布线器，解决布局布线异常，提高布局布线效率； [Generate Post-Map Simulation Model]用以产生映射步 骤后仿真模型，由于该仿真模型不包含实际布线时延，所以有时也省略此仿真步骤。 布局和布线过程布局和布线（Place &amp; Route）：通过读取当前设计的NCD文件，布局布线将映射后生成的物理逻辑单元在目标系统中放置和连线，并提取相应的时间参数。布局布线的输入文件包括NCD和PCF模板文件，输出文件包括NCD、DLY（延时文件）、PAD和PAR文件。在布局布线的输出文件中，NCD包含当前设计的全部物理实现信息，DLY文件包含当前设计的网络延时信息，PAD文件包含当前设计的输入输出（I/O）管脚配置信息，PAR文件主要包括布局布线的命令行参数、布局布线中出现的错误和告警、目标占用的资源、未布线网络、网络时序信息等内容。布局布线步骤的命令与工具非常多： [Place &amp; Route Report]用以显示布局布线报告； [Asynchronous Delay Report]用以显示异步实现报告； [Pad Report]用以显示管脚锁定报告； [Guide Results Report]用以显示布局布线指导报告，该报告仅在使用布局布线指导文件NCD文件后才产生； [Generate Post-Place &amp; Route Static Timing]包含了进行布局布线后静态时序分析的一系列命令，可以启动Timing Analyzer分析布局布线后的静态时序； [View/Edit Place Design（Floorplanner）]和[View/Edit Place Design（FPGA Editor）]用以启动Floorplanner和FPGA Editor完成FPGA布局布线的结果分析、编辑，手动更改布局布线结果，产生布局布线指导与约束文件，辅助Xilinx自动布局布线器，提高布局布线效率并解决布局布线中的问题； [Analyze Power（XPower）]用以启动功耗仿真器分析设计功耗； [Generate Post-Place &amp; Route Simulation Model]用以产生布局布线后仿真模型，该仿真模型包含的时延信息最全，不仅包含门延时，还包含了实际布线延时。该仿真步骤必须进行，以确保设计功能与FPGA实际运行结果一致； [Generate IBIS Model]用以产生IBIS仿真模型，辅助PCB布板的仿真与设计； [Multi Pass Place &amp; Route]用以进行多周期反复布线； [Back-annotate Pin Locations]用以反标管脚锁定信息 经过综合后，在过程管理区双击“Implement Design”选项，就可以完成实现.经过实现后能够得到精确的资源占用情况。]]></content>
      <categories>
        <category>Verilog</category>
      </categories>
      <tags>
        <tag>Verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小记(1)]]></title>
    <url>%2F2014%2F11%2F27%2F%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[每当闹事街头，纷纷扰扰的声音聚拢之前，总是习惯性地拿出耳机。我想我非常的习惯音符带给我的安全感。安静，黑暗，每当自己一个人在房间，在椅子上，总会留下最少的光亮，试着用简简单单的本能去聆听世界。 但是又不知不觉，在已经过去的1x时代，毫无意义的在其他的小站里，隐藏在华丽的字符间，堆积在藏书纸片中盖起了一座座城堡。每年的这些天，习惯性将自己隐藏在盒子里，营造一种沉闷的氛围。在无人的半夜里哼着歌，在12点钟寂寞的赛道上欢快的奔跑，故意的跌倒，然后下意识的感觉自己心情很好，昨天的昨天，以及那些永远数不完的昨天里，有着数不完的伤心、烦闷，都在站起来的一瞬间遗失在跑道中央。 还是说人都会有两面性，就像奴良陆生，像Tamama。在最欢快的时刻总有一瞬间会很平静，你所讨厌的人和事，其实都是你很久的曾经。讨厌浮夸却又害怕自己在这个孤寂星球像蛇一样生存。 很喜欢ashin的一句话&lt;衣服晒干，风在穿，心情变的很蔚蓝。 我一个人，很简单，自己放纵自己管。&gt; 也会想要被人理解，却从未想要被人完全了解。应该说都是相对的吧，这世界本来就没有什么是绝对，即使你赤裸裸的站在某个世界中央。楚门的生活充满镜头，而这样的生活，不需要监控，因为它时时刻刻在你的身体里，血液中。世界的乐趣就在于你永远不知道除了你之外的事物，因为我们不可能认清这一切。 这将会是怎样的开始呢，在凌晨的寒风中感受世界，试图从风中触碰到这方天地给我的反馈。奔跑、喊着，会怎样怎样，才发现人生真的不都像是剧本，小时候，you are the king of the world，整个世界都是为你存在，而现在，应该清楚，世界给了我们十多年的假象，感谢这个世界让我们都天真过。 在这个大地上生活的20000多天里，每一天都有你不知道事情发生。未来会怎样？会在你手表秒针一次次的走动间清晰。而我们要做的，就是让这只表一步步，一分分，走下去。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
